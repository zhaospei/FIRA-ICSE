["mmm include / linux / kernel . h \nppp include / linux / kernel . h \nstatic inline char * pack_hex_byte ( char * buf , u8 byte ) \n/* \n* swap - swap value of @ a and @ b \n*/ \n-# define swap ( a , b ) ({ typeof ( a ) __tmp = ( a ); ( a ) = ( b ); ( b ) = __tmp ; }) \n+# define swap ( a , b ) \\ \n+ do { typeof ( a ) __tmp = ( a ); ( a ) = ( b ); ( b ) = __tmp ; } while ( 0 ) \n \n/** \n* container_of - cast a member of a structure out to the containing structure", "mmm arch / arm / mach - berlin / platsmp . c \nppp arch / arm / mach - berlin / platsmp . c \n# include < asm / smp_plat . h > \n# include < asm / smp_scu . h > \n \n-# define CPU_RESET 0x00 \n+/* \n+ * There are two reset registers , one with self - clearing ( SC ) \n+ * reset and one with non - self - clearing reset ( NON_SC ). \n+ */ \n+# define CPU_RESET_SC 0x00 \n+# define CPU_RESET_NON_SC 0x20 \n \n# define RESET_VECT 0x00 \n# define SW_RESET_ADDR 0x94 \nstatic inline void berlin_perform_reset_cpu ( unsigned int cpu ) \n{ \nu32 val ; \n \n- val = readl ( cpu_ctrl + CPU_RESET ); \n+ val = readl ( cpu_ctrl + CPU_RESET_NON_SC ); \n+ val &= ~ BIT ( cpu_logical_map ( cpu )); \n+ writel ( val , cpu_ctrl + CPU_RESET_NON_SC ); \nval |= BIT ( cpu_logical_map ( cpu )); \n- writel ( val , cpu_ctrl + CPU_RESET ); \n+ writel ( val , cpu_ctrl + CPU_RESET_NON_SC ); \n} \n \nstatic int berlin_boot_secondary ( unsigned int cpu , struct task_struct * idle )", "mmm sound / core / control . c \nppp sound / core / control . c \nstatic bool snd_ctl_remove_numid_conflict ( struct snd_card * card , \n{ \nstruct snd_kcontrol * kctl ; \n \n+ /* Make sure that the ids assigned to the control do not wrap around */ \n+ if ( card -> last_numid >= UINT_MAX - count ) \n+ card -> last_numid = 0 ; \n+ \nlist_for_each_entry ( kctl , & card -> controls , list ) { \nif ( kctl -> id . numid < card -> last_numid + 1 + count && \nkctl -> id . numid + kctl -> count > card -> last_numid + 1 ) {", "mmm drivers / net / tulip / uli526x . c \nppp drivers / net / tulip / uli526x . c \nstatic void uli526x_rx_packet ( struct net_device * dev , struct uli526x_board_info \n \nif ( !( rdes0 & 0x8000 ) || \n(( db -> cr6_data & CR6_PM ) && ( rxlen > 6 )) ) { \n+ struct sk_buff * new_skb = NULL ; \n+ \nskb = rxptr -> rx_skb_ptr ; \n \n/* Good packet , send to upper layer */ \n/* Shorst packet used new SKB */ \n- if ( ( rxlen < RX_COPY_SIZE ) && \n- ( ( skb = dev_alloc_skb ( rxlen + 2 ) ) \n- != NULL ) ) { \n+ if (( rxlen < RX_COPY_SIZE ) && \n+ (( new_skb = dev_alloc_skb ( rxlen + 2 ) != NULL ))) { \n+ skb = new_skb ; \n/* size less than COPY_SIZE , allocate a rxlen SKB */ \nskb_reserve ( skb , 2 ); /* 16byte align */ \nmemcpy ( skb_put ( skb , rxlen ),", "mmm net / ipv4 / tcp . c \nppp net / ipv4 / tcp . c \nint tcp_sendmsg ( struct sock * sk , struct msghdr * msg , size_t size ) \n \nif (! skb_can_coalesce ( skb , i , pfrag -> page , \npfrag -> offset )) { \n- if ( i == sysctl_max_skb_frags || ! sg ) { \n+ if ( i >= sysctl_max_skb_frags || ! sg ) { \ntcp_mark_push ( tp , skb ); \ngoto new_segment ; \n}", "mmm arch / mips / include / asm / pgtable . h \nppp arch / mips / include / asm / pgtable . h \nstatic inline struct page * pmd_page ( pmd_t pmd ) \n \nstatic inline pmd_t pmd_modify ( pmd_t pmd , pgprot_t newprot ) \n{ \n- pmd_val ( pmd ) = ( pmd_val ( pmd ) & _PAGE_CHG_MASK ) | \n+ pmd_val ( pmd ) = ( pmd_val ( pmd ) & ( _PAGE_CHG_MASK | _PAGE_HUGE )) | \n( pgprot_val ( newprot ) & ~ _PAGE_CHG_MASK ); \nreturn pmd ; \n}", "mmm net / sctp / socket . c \nppp net / sctp / socket . c \nstatic int sctp_getsockopt_disable_fragments ( struct sock * sk , int len , \nstatic int sctp_getsockopt_events ( struct sock * sk , int len , char __user * optval , \nint __user * optlen ) \n{ \n- if ( len < sizeof ( struct sctp_event_subscribe )) \n+ if ( len <= 0 ) \nreturn - EINVAL ; \n- len = sizeof ( struct sctp_event_subscribe ); \n+ if ( len > sizeof ( struct sctp_event_subscribe )) \n+ len = sizeof ( struct sctp_event_subscribe ); \nif ( put_user ( len , optlen )) \nreturn - EFAULT ; \nif ( copy_to_user ( optval , & sctp_sk ( sk )-> subscribe , len ))", "mmm drivers / misc / eeprom / idt_89hpesx . c \nppp drivers / misc / eeprom / idt_89hpesx . c \nstatic ssize_t idt_dbgfs_csr_write ( struct file * filep , const char __user * ubuf , \ncsraddr_len = colon_ch - buf ; \ncsraddr_str = \nkmalloc ( sizeof ( char )*( csraddr_len + 1 ), GFP_KERNEL ); \n- if ( csraddr_str == NULL ) \n- return - ENOMEM ; \n+ if ( csraddr_str == NULL ) { \n+ ret = - ENOMEM ; \n+ goto free_buf ; \n+ } \n/* Copy the register address to the substring buffer */ \nstrncpy ( csraddr_str , buf , csraddr_len ); \ncsraddr_str [ csraddr_len ] = '\\ 0 ';", "mmm drivers / staging / dgap / dgap . c \nppp drivers / staging / dgap / dgap . c \nstatic int dgap_init_one ( struct pci_dev * pdev , const struct pci_device_id * ent ) \n{ \nint rc ; \n \n+ if ( dgap_NumBoards >= MAXBOARDS ) \n+ return - EPERM ; \n+ \n/* wake up and enable device */ \nrc = pci_enable_device ( pdev ); \n", "mmm fs / overlayfs / inode . c \nppp fs / overlayfs / inode . c \nint ovl_setattr ( struct dentry * dentry , struct iattr * attr ) \nif ( err ) \ngoto out ; \n \n- upperdentry = ovl_dentry_upper ( dentry ); \n- if ( upperdentry ) { \n+ err = ovl_copy_up ( dentry ); \n+ if (! err ) { \n+ upperdentry = ovl_dentry_upper ( dentry ); \n+ \nmutex_lock (& upperdentry -> d_inode -> i_mutex ); \nerr = notify_change ( upperdentry , attr , NULL ); \nmutex_unlock (& upperdentry -> d_inode -> i_mutex ); \n- } else { \n- err = ovl_copy_up_last ( dentry , attr , false ); \n} \novl_drop_write ( dentry ); \nout :", "mmm drivers / block / drbd / drbd_receiver . c \nppp drivers / block / drbd / drbd_receiver . c \nstatic int drbd_asb_recover_0p ( struct drbd_conf * mdev ) __must_hold ( local ) \nbreak ; \n} \n/* Else fall through to one of the other strategies ... */ \n- dev_warn ( DEV , \" Discard younger / older primary did not found a decision \\ n \" \n+ dev_warn ( DEV , \" Discard younger / older primary did not find a decision \\ n \" \n\" Using discard - least - changes instead \\ n \"); \ncase ASB_DISCARD_ZERO_CHG : \nif ( ch_peer == 0 && ch_self == 0 ) {", "mmm drivers / tty / hvc / hvcs . c \nppp drivers / tty / hvc / hvcs . c \nstatic int __devinit hvcs_initialize ( void ) \nnum_ttys_to_alloc = hvcs_parm_num_devs ; \n \nhvcs_tty_driver = alloc_tty_driver ( num_ttys_to_alloc ); \n- if (! hvcs_tty_driver ) \n+ if (! hvcs_tty_driver ) { \n+ mutex_unlock (& hvcs_init_mutex ); \nreturn - ENOMEM ; \n+ } \n \nif ( hvcs_alloc_index_list ( num_ttys_to_alloc )) { \nrc = - ENOMEM ;", "mmm sound / pci / hda / patch_realtek . c \nppp sound / pci / hda / patch_realtek . c \nstatic const struct snd_pci_quirk alc662_fixup_tbl [] = { \nSND_PCI_QUIRK ( 0x1025 , 0x038b , \" Acer Aspire 8943G \", ALC662_FIXUP_ASPIRE ), \nSND_PCI_QUIRK ( 0x1028 , 0x05d8 , \" Dell \", ALC668_FIXUP_DELL_MIC_NO_PRESENCE ), \nSND_PCI_QUIRK ( 0x1028 , 0x05db , \" Dell \", ALC668_FIXUP_DELL_MIC_NO_PRESENCE ), \n+ SND_PCI_QUIRK ( 0x1028 , 0x0626 , \" Dell \", ALC668_FIXUP_DELL_MIC_NO_PRESENCE ), \nSND_PCI_QUIRK ( 0x103c , 0x1632 , \" HP RP5800 \", ALC662_FIXUP_HP_RP5800 ), \nSND_PCI_QUIRK ( 0x1043 , 0x1477 , \" ASUS N56VZ \", ALC662_FIXUP_BASS_CHMAP ), \nSND_PCI_QUIRK ( 0x1043 , 0x1bf3 , \" ASUS N76VZ \", ALC662_FIXUP_BASS_CHMAP ),", "mmm net / ipv4 / netfilter / ipt_MASQUERADE . c \nppp net / ipv4 / netfilter / ipt_MASQUERADE . c \nmasquerade_target ( struct sk_buff ** pskb , \nIP_NF_ASSERT ( ct && ( ctinfo == IP_CT_NEW || ctinfo == IP_CT_RELATED \n|| ctinfo == IP_CT_RELATED + IP_CT_IS_REPLY )); \n \n+ /* Source address is 0 . 0 . 0 . 0 - locally generated packet that is \n+ * probably not supposed to be masqueraded . \n+ */ \n+ if ( ct -> tuplehash [ IP_CT_DIR_ORIGINAL ]. tuple . src . ip == 0 ) \n+ return NF_ACCEPT ; \n+ \nmr = targinfo ; \nrt = ( struct rtable *)(* pskb )-> dst ; \nnewsrc = inet_select_addr ( out , rt -> rt_gateway , RT_SCOPE_UNIVERSE );", "mmm drivers / net / ethernet / intel / igb / igb_main . c \nppp drivers / net / ethernet / intel / igb / igb_main . c \nvoid igb_update_stats ( struct igb_adapter * adapter , \nbytes = 0 ; \npackets = 0 ; \nfor ( i = 0 ; i < adapter -> num_rx_queues ; i ++) { \n- u32 rqdpc_tmp = rd32 ( E1000_RQDPC ( i )) & 0x0FFF ; \n+ u32 rqdpc = rd32 ( E1000_RQDPC ( i )); \nstruct igb_ring * ring = adapter -> rx_ring [ i ]; \n \n- ring -> rx_stats . drops += rqdpc_tmp ; \n- net_stats -> rx_fifo_errors += rqdpc_tmp ; \n+ if ( rqdpc ) { \n+ ring -> rx_stats . drops += rqdpc ; \n+ net_stats -> rx_fifo_errors += rqdpc ; \n+ } \n \ndo { \nstart = u64_stats_fetch_begin_bh (& ring -> rx_syncp );", "mmm sound / soc / fsl / imx - ssi . c \nppp sound / soc / fsl / imx - ssi . c \nstatic int imx_ssi_probe ( struct platform_device * pdev ) \n} \n \nssi -> irq = platform_get_irq ( pdev , 0 ); \n+ if ( ssi -> irq < 0 ) { \n+ dev_err (& pdev -> dev , \" Failed to get IRQ : % d \\ n \", ssi -> irq ); \n+ return ssi -> irq ; \n+ } \n \nssi -> clk = devm_clk_get (& pdev -> dev , NULL ); \nif ( IS_ERR ( ssi -> clk )) {", "mmm mm / vmscan . c \nppp mm / vmscan . c \nvoid unregister_shrinker ( struct shrinker * shrinker ) \ndown_write (& shrinker_rwsem ); \nlist_del (& shrinker -> list ); \nup_write (& shrinker_rwsem ); \n+ kfree ( shrinker -> nr_deferred ); \n} \nEXPORT_SYMBOL ( unregister_shrinker ); \n", "mmm drivers / iommu / dmar . c \nppp drivers / iommu / dmar . c \nint __init dmar_parse_dev_scope ( void * start , void * end , int * cnt , \nif ( scope -> entry_type == ACPI_DMAR_SCOPE_TYPE_ENDPOINT || \nscope -> entry_type == ACPI_DMAR_SCOPE_TYPE_BRIDGE ) \n(* cnt )++; \n- else if ( scope -> entry_type != ACPI_DMAR_SCOPE_TYPE_IOAPIC ) { \n+ else if ( scope -> entry_type != ACPI_DMAR_SCOPE_TYPE_IOAPIC && \n+ scope -> entry_type != ACPI_DMAR_SCOPE_TYPE_HPET ) { \npr_warn (\" Unsupported device scope \\ n \"); \n} \nstart += scope -> length ;", "mmm net / sctp / input . c \nppp net / sctp / input . c \nint sctp_rcv ( struct sk_buff * skb ) \n*/ \nsctp_bh_lock_sock ( sk ); \n \n+ if ( sk != rcvr -> sk ) { \n+ /* Our cached sk is different from the rcvr -> sk . This is \n+ * because migrate ()/ accept () may have moved the association \n+ * to a new socket and released all the sockets . So now we \n+ * are holding a lock on the old socket while the user may \n+ * be doing something with the new socket . Switch our veiw \n+ * of the current sk . \n+ */ \n+ sctp_bh_unlock_sock ( sk ); \n+ sk = rcvr -> sk ; \n+ sctp_bh_lock_sock ( sk ); \n+ } \n+ \nif ( sock_owned_by_user ( sk )) { \nSCTP_INC_STATS_BH ( SCTP_MIB_IN_PKT_BACKLOG ); \nsctp_add_backlog ( sk , skb );", "mmm drivers / block / loop . c \nppp drivers / block / loop . c \nstatic int lo_open ( struct block_device * bdev , fmode_t mode ) \nreturn err ; \n} \n \n- static void lo_release ( struct gendisk * disk , fmode_t mode ) \n+ static void __lo_release ( struct loop_device * lo ) \n{ \n- struct loop_device * lo = disk -> private_data ; \nint err ; \n \nif ( atomic_dec_return (& lo -> lo_refcnt )) \nstatic void lo_release ( struct gendisk * disk , fmode_t mode ) \nmutex_unlock (& lo -> lo_ctl_mutex ); \n} \n \n+ static void lo_release ( struct gendisk * disk , fmode_t mode ) \n+{ \n+ mutex_lock (& loop_index_mutex ); \n+ __lo_release ( disk -> private_data ); \n+ mutex_unlock (& loop_index_mutex ); \n+} \n+ \nstatic const struct block_device_operations lo_fops = { \n. owner = THIS_MODULE , \n. open = lo_open ,", "mmm net / ipv6 / ip6_fib . c \nppp net / ipv6 / ip6_fib . c \nint fib6_add ( struct fib6_node * root , struct rt6_info * rt , struct nl_info * info ) \nfn = fib6_add_1 ( root , & rt -> rt6i_dst . addr , rt -> rt6i_dst . plen , \noffsetof ( struct rt6_info , rt6i_dst ), allow_create , \nreplace_required ); \n- \nif ( IS_ERR ( fn )) { \nerr = PTR_ERR ( fn ); \n+ fn = NULL ; \ngoto out ; \n} \n", "mmm drivers / scsi / ufs / ufs - qcom . c \nppp drivers / scsi / ufs / ufs - qcom . c \nstatic int ufs_qcom_pwr_change_notify ( struct ufs_hba * hba , \nreturn ret ; \n} \n \n+ static u32 ufs_qcom_get_ufs_hci_version ( struct ufs_hba * hba ) \n+{ \n+ struct ufs_qcom_host * host = hba -> priv ; \n+ \n+ if ( host -> hw_ver . major == 0x1 ) \n+ return UFSHCI_VERSION_11 ; \n+ else \n+ return UFSHCI_VERSION_20 ; \n+} \n+ \n/** \n* ufs_qcom_advertise_quirks - advertise the known QCOM UFS controller quirks \n* @ hba : host controller instance \nstatic void ufs_qcom_advertise_quirks ( struct ufs_hba * hba ) \n \nif ( host -> hw_ver . major >= 0x2 ) { \nhba -> quirks |= UFSHCD_QUIRK_BROKEN_LCC ; \n+ hba -> quirks |= UFSHCD_QUIRK_BROKEN_UFS_HCI_VERSION ; \n \nif (! ufs_qcom_cap_qunipro ( host )) \n/* Legacy UniPro mode still need following quirks */ \nstatic const struct ufs_hba_variant_ops ufs_hba_qcom_vops = { \n. name = \" qcom \", \n. init = ufs_qcom_init , \n. exit = ufs_qcom_exit , \n+ . get_ufs_hci_version = ufs_qcom_get_ufs_hci_version , \n. clk_scale_notify = ufs_qcom_clk_scale_notify , \n. setup_clocks = ufs_qcom_setup_clocks , \n. hce_enable_notify = ufs_qcom_hce_enable_notify ,", "mmm drivers / gpu / drm / mediatek / mtk_drm_drv . c \nppp drivers / gpu / drm / mediatek / mtk_drm_drv . c \nstatic void mtk_drm_unbind ( struct device * dev ) \n{ \nstruct mtk_drm_private * private = dev_get_drvdata ( dev ); \n \n- drm_put_dev ( private -> drm ); \n+ drm_dev_unregister ( private -> drm ); \n+ drm_dev_unref ( private -> drm ); \nprivate -> drm = NULL ; \n} \n", "mmm drivers / scsi / libata - eh . c \nppp drivers / scsi / libata - eh . c \nstatic int ata_eh_recover ( struct ata_port * ap , ata_prereset_fn_t prereset , \ndown_xfermask = 0 ; \nrc = 0 ; \n \n+ /* if UNLOADING , finish immediately */ \n+ if ( ap -> flags & ATA_FLAG_UNLOADING ) \n+ goto out ; \n+ \n/* skip EH if possible . */ \nif ( ata_eh_skip_recovery ( ap )) \nehc -> i . action = 0 ;", "mmm drivers / cdrom / cdrom . c \nppp drivers / cdrom / cdrom . c \nstatic int dvd_read_manufact ( struct cdrom_device_info * cdi , dvd_struct * s , \ngoto out ; \n \ns -> manufact . len = buf [ 0 ] << 8 | buf [ 1 ]; \n- if ( s -> manufact . len < 0 || s -> manufact . len > 2048 ) { \n+ if ( s -> manufact . len < 0 ) { \ncdinfo ( CD_WARNING , \" Received invalid manufacture info length \" \n\" (% d )\\ n \", s -> manufact . len ); \nret = - EIO ; \n} else { \n+ if ( s -> manufact . len > 2048 ) { \n+ cdinfo ( CD_WARNING , \" Received invalid manufacture info \" \n+ \" length (% d ): truncating to 2048 \\ n \", \n+ s -> manufact . len ); \n+ s -> manufact . len = 2048 ; \n+ } \nmemcpy ( s -> manufact . value , & buf [ 4 ], s -> manufact . len ); \n} \n", "mmm fs / inode . c \nppp fs / inode . c \nint inode_init_always ( struct super_block * sb , struct inode * inode ) \nmapping -> a_ops = & empty_aops ; \nmapping -> host = inode ; \nmapping -> flags = 0 ; \n+ mapping -> wb_err = 0 ; \natomic_set (& mapping -> i_mmap_writable , 0 ); \nmapping_set_gfp_mask ( mapping , GFP_HIGHUSER_MOVABLE ); \nmapping -> private_data = NULL ;", "mmm drivers / scsi / cxlflash / main . c \nppp drivers / scsi / cxlflash / main . c \nstatic int start_afu ( struct cxlflash_cfg * cfg ) \n \ninit_pcr ( cfg ); \n \n+ /* After an AFU reset , RRQ entries are stale , clear them */ \n+ memset (& afu -> rrq_entry , 0 , sizeof ( afu -> rrq_entry )); \n+ \n/* Initialize RRQ pointers */ \nafu -> hrrq_start = & afu -> rrq_entry [ 0 ]; \nafu -> hrrq_end = & afu -> rrq_entry [ NUM_RRQ_ENTRY - 1 ];", "mmm net / nfc / digital_core . c \nppp net / nfc / digital_core . c \nstatic void digital_wq_cmd ( struct work_struct * work ) \nreturn ; \n} \n \n+ cmd -> pending = 1 ; \n+ \nmutex_unlock (& ddev -> cmd_lock ); \n \nif ( cmd -> req )", "mmm net / core / dev . c \nppp net / core / dev . c \nstatic struct sk_buff * validate_xmit_skb ( struct sk_buff * skb , struct net_device \n \nsegs = skb_gso_segment ( skb , features ); \nif ( IS_ERR ( segs )) { \n- segs = NULL ; \n+ goto out_kfree_skb ; \n} else if ( segs ) { \nconsume_skb ( skb ); \nskb = segs ;", "mmm drivers / net / ethernet / broadcom / bnx2x / bnx2x_sriov . c \nppp drivers / net / ethernet / broadcom / bnx2x / bnx2x_sriov . c \nvoid bnx2x_disable_sriov ( struct bnx2x * bp ) \nstatic int bnx2x_vf_ndo_sanity ( struct bnx2x * bp , int vfidx , \nstruct bnx2x_virtf * vf ) \n{ \n+ if ( bp -> state != BNX2X_STATE_OPEN ) { \n+ BNX2X_ERR (\" vf ndo called though PF is down \\ n \"); \n+ return - EINVAL ; \n+ } \n+ \nif (! IS_SRIOV ( bp )) { \nBNX2X_ERR (\" vf ndo called though sriov is disabled \\ n \"); \nreturn - EINVAL ;", "mmm kernel / time / timekeeping . c \nppp kernel / time / timekeeping . c \nstruct timekeeper { \nu32 mult ; \n}; \n \n- struct timekeeper timekeeper ; \n+ static struct timekeeper timekeeper ; \n \n/** \n* timekeeper_setup_internals - Set up internals to use clocksource clock . \nstatic struct timespec total_sleep_time ; \n/* \n* The raw monotonic time for the CLOCK_MONOTONIC_RAW posix clock . \n*/ \n- struct timespec raw_time ; \n+ static struct timespec raw_time ; \n \n/* flag for if timekeeping is suspended */ \nint __read_mostly timekeeping_suspended ;", "mmm sound / soc / blackfin / bf5xx - i2s . c \nppp sound / soc / blackfin / bf5xx - i2s . c \nstatic int bf5xx_i2s_hw_params ( struct snd_pcm_substream * substream , \nbf5xx_i2s -> tcr2 |= 7 ; \nbf5xx_i2s -> rcr2 |= 7 ; \nsport_handle -> wdsize = 1 ; \n+ break ; \ncase SNDRV_PCM_FORMAT_S16_LE : \nbf5xx_i2s -> tcr2 |= 15 ; \nbf5xx_i2s -> rcr2 |= 15 ;", "mmm drivers / iio / industrialio - buffer . c \nppp drivers / iio / industrialio - buffer . c \nint iio_sw_buffer_preenable ( struct iio_dev * indio_dev ) \nbuffer -> scan_mask ); \nelse \nindio_dev -> active_scan_mask = buffer -> scan_mask ; \n+ \n+ if ( indio_dev -> active_scan_mask == NULL ) \n+ return - EINVAL ; \n+ \niio_update_demux ( indio_dev ); \n \nif ( indio_dev -> info -> update_scan_mode )", "mmm drivers / memory / omap - gpmc . c \nppp drivers / memory / omap - gpmc . c \nstatic void gpmc_cs_show_timings ( int cs , const char * desc ) \npr_info (\" gpmc cs % i access configuration :\\ n \", cs ); \nGPMC_GET_RAW_BOOL ( GPMC_CS_CONFIG1 , 4 , 4 , \" time - para - granularity \"); \nGPMC_GET_RAW ( GPMC_CS_CONFIG1 , 8 , 9 , \" mux - add - data \"); \n- GPMC_GET_RAW_MAX ( GPMC_CS_CONFIG1 , 12 , 13 , \n+ GPMC_GET_RAW_SHIFT_MAX ( GPMC_CS_CONFIG1 , 12 , 13 , 1 , \nGPMC_CONFIG1_DEVICESIZE_MAX , \" device - width \"); \nGPMC_GET_RAW ( GPMC_CS_CONFIG1 , 16 , 17 , \" wait - pin \"); \nGPMC_GET_RAW_BOOL ( GPMC_CS_CONFIG1 , 21 , 21 , \" wait - on - write \");", "mmm sound / pci / hda / hda_codec . c \nppp sound / pci / hda / hda_codec . c \nvoid snd_hda_codec_setup_stream ( struct hda_codec * codec , hda_nid_t nid , \n\" NID = 0x % x , stream = 0x % x , channel =% d , format = 0x % x \\ n \", \nnid , stream_tag , channel_id , format ); \np = get_hda_cvt_setup ( codec , nid ); \n- if (! p ) \n+ if (! p || p -> active ) \nreturn ; \n \nif ( codec -> pcm_format_first ) \nvoid __snd_hda_codec_cleanup_stream ( struct hda_codec * codec , hda_nid_t nid , \n \nsnd_printdd (\" hda_codec_cleanup_stream : NID = 0x % x \\ n \", nid ); \np = get_hda_cvt_setup ( codec , nid ); \n- if ( p ) { \n+ if ( p && p -> active ) { \n/* here we just clear the active flag when do_now isn ' t set ; \n* actual clean - ups will be done later in \n* purify_inactive_streams () called from snd_hda_codec_prpapre ()", "mmm sound / drivers / pcsp / pcsp_input . c \nppp sound / drivers / pcsp / pcsp_input . c \nstatic void pcspkr_do_sound ( unsigned int count ) \nspin_lock_irqsave (& i8253_lock , flags ); \n \nif ( count ) { \n- /* enable counter 2 */ \n- outb_p ( inb_p ( 0x61 ) | 3 , 0x61 ); \n/* set command for counter 2 , 2 byte write */ \noutb_p ( 0xB6 , 0x43 ); \n/* select desired HZ */ \noutb_p ( count & 0xff , 0x42 ); \noutb (( count >> 8 ) & 0xff , 0x42 ); \n+ /* enable counter 2 */ \n+ outb_p ( inb_p ( 0x61 ) | 3 , 0x61 ); \n} else { \n/* disable counter 2 */ \noutb ( inb_p ( 0x61 ) & 0xFC , 0x61 );", "mmm drivers / staging / greybus / audio_codec . c \nppp drivers / staging / greybus / audio_codec . c \nstatic int gbcodec_trigger ( struct snd_pcm_substream * substream , int cmd , \ndev_err ( dai -> dev , \"% d : Error during % s stream \\ n \", ret , \nstart ? \" Start \" : \" Stop \"); \n \n+ /* in case device removed , return 0 for stop trigger */ \n+ if ( stop && ( ret == - ENODEV )) \n+ ret = 0 ; \n+ \nfunc_exit : \nmutex_unlock (& gb -> lock ); \nreturn ret ;", "mmm drivers / gpu / drm / amd / amdgpu / amdgpu_device . c \nppp drivers / gpu / drm / amd / amdgpu / amdgpu_device . c \nint amdgpu_device_ip_suspend ( struct amdgpu_device * adev ) \nif ( amdgpu_sriov_vf ( adev )) \namdgpu_virt_request_full_gpu ( adev , false ); \n \n+ /* ungate SMC block powergating */ \n+ if ( adev -> powerplay . pp_feature & PP_GFXOFF_MASK ) \n+ amdgpu_device_ip_set_powergating_state ( adev , \n+ AMD_IP_BLOCK_TYPE_SMC , \n+ AMD_CG_STATE_UNGATE ); \n+ \n/* ungate SMC block first */ \nr = amdgpu_device_ip_set_clockgating_state ( adev , AMD_IP_BLOCK_TYPE_SMC , \nAMD_CG_STATE_UNGATE );", "mmm kernel / sched_fair . c \nppp kernel / sched_fair . c \nstatic void task_fork_fair ( struct task_struct * p ) \n \nupdate_rq_clock ( rq ); \n \n- if ( unlikely ( task_cpu ( p ) != this_cpu )) \n+ if ( unlikely ( task_cpu ( p ) != this_cpu )) { \n+ rcu_read_lock (); \n__set_task_cpu ( p , this_cpu ); \n+ rcu_read_unlock (); \n+ } \n \nupdate_curr ( cfs_rq ); \n", "mmm kernel / auditsc . c \nppp kernel / auditsc . c \nstatic int audit_log_single_execve_arg ( struct audit_context * context , \n* for strings that are too long , we should not have created \n* any . \n*/ \n- if ( unlikely (( len = - 1 ) || len > MAX_ARG_STRLEN - 1 )) { \n+ if ( unlikely (( len == - 1 ) || len > MAX_ARG_STRLEN - 1 )) { \nWARN_ON ( 1 ); \nsend_sig ( SIGKILL , current , 0 ); \n+ return - 1 ; \n} \n \n/* walk the whole argument looking for non - ascii chars */ \nstatic int audit_log_single_execve_arg ( struct audit_context * context , \nif ( ret ) { \nWARN_ON ( 1 ); \nsend_sig ( SIGKILL , current , 0 ); \n+ return - 1 ; \n} \nbuf [ to_send ] = '\\ 0 '; \nhas_cntl = audit_string_contains_control ( buf , to_send ); \nstatic int audit_log_single_execve_arg ( struct audit_context * context , \nif ( ret ) { \nWARN_ON ( 1 ); \nsend_sig ( SIGKILL , current , 0 ); \n+ return - 1 ; \n} \nbuf [ to_send ] = '\\ 0 '; \n", "mmm drivers / acpi / acpica / exstorob . c \nppp drivers / acpi / acpica / exstorob . c \nacpi_ex_store_buffer_to_buffer ( union acpi_operand_object * source_desc , \n \nACPI_FUNCTION_TRACE_PTR ( ex_store_buffer_to_buffer , source_desc ); \n \n+ /* If Source and Target are the same , just return */ \n+ \n+ if ( source_desc == target_desc ) { \n+ return_ACPI_STATUS ( AE_OK ); \n+ } \n+ \n/* We know that source_desc is a buffer by now */ \n \nbuffer = ACPI_CAST_PTR ( u8 , source_desc -> buffer . pointer ); \nacpi_ex_store_string_to_string ( union acpi_operand_object * source_desc , \n \nACPI_FUNCTION_TRACE_PTR ( ex_store_string_to_string , source_desc ); \n \n+ /* If Source and Target are the same , just return */ \n+ \n+ if ( source_desc == target_desc ) { \n+ return_ACPI_STATUS ( AE_OK ); \n+ } \n+ \n/* We know that source_desc is a string by now */ \n \nbuffer = ACPI_CAST_PTR ( u8 , source_desc -> string . pointer );", "mmm tools / perf / util / callchain . c \nppp tools / perf / util / callchain . c \n__append_chain ( struct callchain_node * root , struct ip_callchain * chain , \nvoid append_chain ( struct callchain_node * root , struct ip_callchain * chain , \nstruct symbol ** syms ) \n{ \n+ if (! chain -> nr ) \n+ return ; \n__append_chain_children ( root , chain , syms , 0 ); \n}", "mmm tools / perf / util / event . c \nppp tools / perf / util / event . c \nint perf_event__synthesize_thread_map ( struct perf_tool * tool , \nif ( comm_event == NULL ) \ngoto out ; \n \n- mmap_event = malloc ( sizeof ( mmap_event -> mmap ) + machine -> id_hdr_size ); \n+ mmap_event = malloc ( sizeof ( mmap_event -> mmap2 ) + machine -> id_hdr_size ); \nif ( mmap_event == NULL ) \ngoto out_free_comm ; \n \nint perf_event__synthesize_threads ( struct perf_tool * tool , \nif ( comm_event == NULL ) \ngoto out ; \n \n- mmap_event = malloc ( sizeof ( mmap_event -> mmap ) + machine -> id_hdr_size ); \n+ mmap_event = malloc ( sizeof ( mmap_event -> mmap2 ) + machine -> id_hdr_size ); \nif ( mmap_event == NULL ) \ngoto out_free_comm ; \n", "mmm arch / sparc / kernel / devices . c \nppp arch / sparc / kernel / devices . c \nstatic int __cpu_find_by ( int (* compare )( int , int , void *), void * compare_arg , \nint err = check_cpu_node ( dp -> node , & cur_inst , \ncompare , compare_arg , \nprom_node , mid ); \n- if (! err ) \n+ if (! err ) { \n+ of_node_put ( dp ); \nreturn 0 ; \n+ } \n} \n \nreturn - ENODEV ;", "mmm fs / btrfs / ctree . c \nppp fs / btrfs / ctree . c \n__tree_mod_log_free_eb ( struct btrfs_fs_info * fs_info , struct extent_buffer * eb ) \nu32 nritems ; \nint ret ; \n \n+ if ( btrfs_header_level ( eb ) == 0 ) \n+ return ; \n+ \nnritems = btrfs_header_nritems ( eb ); \nfor ( i = nritems - 1 ; i >= 0 ; i --) { \nret = tree_mod_log_insert_key_locked ( fs_info , eb , i ,", "mmm fs / btrfs / xattr . c \nppp fs / btrfs / xattr . c \nssize_t btrfs_listxattr ( struct dentry * dentry , char * buffer , size_t size ) \n \nif (! buffer || ( name_len + 1 ) > size_left ) { \nret = - ERANGE ; \n- break ; \n+ goto err ; \n} \n \nname_ptr = ( unsigned long )( di + 1 );", "mmm drivers / mmc / host / atmel - mci . c \nppp drivers / mmc / host / atmel - mci . c \nstatic int atmci_regs_show ( struct seq_file * s , void * v ) \natmci_show_status_reg ( s , \" SR \", buf [ MCI_SR / 4 ]); \natmci_show_status_reg ( s , \" IMR \", buf [ MCI_IMR / 4 ]); \n \n+ kfree ( buf ); \n+ \nreturn 0 ; \n} \n", "mmm net / batman - adv / soft - interface . c \nppp net / batman - adv / soft - interface . c \nstatic int interface_tx ( struct sk_buff * skb , struct net_device * soft_iface ) \nstruct hard_iface * primary_if = NULL ; \nstruct bcast_packet * bcast_packet ; \nstruct vlan_ethhdr * vhdr ; \n+ static const uint8_t stp_addr [ ETH_ALEN ] = { 0x01 , 0x80 , 0xC2 , 0x00 , 0x00 , \n+ 0x00 }; \nunsigned int header_len = 0 ; \nint data_len = skb -> len , ret ; \nshort vid = - 1 ; \nstatic int interface_tx ( struct sk_buff * skb , struct net_device * soft_iface ) \n/* Register the client MAC in the transtable */ \ntt_local_add ( soft_iface , ethhdr -> h_source , skb -> skb_iif ); \n \n+ /* don ' t accept stp packets . STP does not help in meshes . \n+ * better use the bridge loop avoidance ... \n+ */ \n+ if ( compare_eth ( ethhdr -> h_dest , stp_addr )) \n+ goto dropped ; \n+ \nif ( is_multicast_ether_addr ( ethhdr -> h_dest )) { \ndo_bcast = true ; \n", "mmm drivers / tty / pty . c \nppp drivers / tty / pty . c \nstatic void pty_close ( struct tty_struct * tty , struct file * filp ) \nmutex_unlock (& devpts_mutex ); \n} \n# endif \n+ tty_unlock ( tty ); \ntty_vhangup ( tty -> link ); \n+ tty_lock ( tty ); \n} \n} \n", "mmm drivers / bluetooth / btbcm . c \nppp drivers / bluetooth / btbcm . c \nEXPORT_SYMBOL_GPL ( btbcm_setup_patchram ); \nint btbcm_setup_apple ( struct hci_dev * hdev ) \n{ \nstruct sk_buff * skb ; \n+ int err ; \n+ \n+ /* Reset */ \n+ err = btbcm_reset ( hdev ); \n+ if ( err ) \n+ return err ; \n \n/* Read Verbose Config Version Info */ \nskb = btbcm_read_verbose_config ( hdev ); \nif (! IS_ERR ( skb )) { \n- BT_INFO (\"% s : BCM : chip id % u build % 4 . 4u \", hdev -> name , skb -> data [ 1 ], \n- get_unaligned_le16 ( skb -> data + 5 )); \n+ BT_INFO (\"% s : BCM : chip id % u build % 4 . 4u \", hdev -> name , \n+ skb -> data [ 1 ], get_unaligned_le16 ( skb -> data + 5 )); \nkfree_skb ( skb ); \n} \n", "mmm net / batman - adv / bat_iv_ogm . c \nppp net / batman - adv / bat_iv_ogm . c \nbatadv_iv_ogm_orig_get ( struct batadv_priv * bat_priv , const uint8_t * addr ) \nfree_bcast_own : \nkfree ( orig_node -> bat_iv . bcast_own ); \nfree_orig_node : \n+ /* free twice , as batadv_orig_node_new sets refcount to 2 */ \n+ batadv_orig_node_free_ref ( orig_node ); \nbatadv_orig_node_free_ref ( orig_node ); \n \nreturn NULL ;", "mmm kernel / trace / trace_events_hist . c \nppp kernel / trace / trace_events_hist . c \nstatic int create_tracing_map_fields ( struct hist_trigger_data * hist_data ) \nstruct tracing_map * map = hist_data -> map ; \nstruct ftrace_event_field * field ; \nstruct hist_field * hist_field ; \n- int i , idx ; \n+ int i , idx = 0 ; \n \nfor_each_hist_field ( i , hist_data ) { \nhist_field = hist_data -> fields [ i ];", "mmm arch / x86 / kvm / lapic . c \nppp arch / x86 / kvm / lapic . c \nstatic void start_apic_timer ( struct kvm_lapic * apic ) \n{ \nktime_t now = apic -> lapic_timer . timer . base -> get_time (); \n \n- apic -> lapic_timer . period = apic_get_reg ( apic , APIC_TMICT ) * \n+ apic -> lapic_timer . period = ( u64 ) apic_get_reg ( apic , APIC_TMICT ) * \nAPIC_BUS_CYCLE_NS * apic -> divide_count ; \natomic_set (& apic -> lapic_timer . pending , 0 ); \n", "mmm tools / perf / util / symbol . c \nppp tools / perf / util / symbol . c \nstatic int dso__load_sym ( struct dso * self , struct map * map , const char * name , \n \nsection_name = elf_sec__name (& shdr , secstrs ); \n \n+ /* On ARM , symbols for thumb functions have 1 added to \n+ * the symbol address as a flag - remove it */ \n+ if (( ehdr . e_machine == EM_ARM ) && \n+ ( map -> type == MAP__FUNCTION ) && \n+ ( sym . st_value & 1 )) \n+ -- sym . st_value ; \n+ \nif ( self -> kernel != DSO_TYPE_USER || kmodule ) { \nchar dso_name [ PATH_MAX ]; \n", "mmm drivers / usb / phy / phy - msm - usb . c \nppp drivers / usb / phy / phy - msm - usb . c \nstatic int msm_otg_read_dt ( struct platform_device * pdev , struct msm_otg * motg ) \nmotg -> pdata = pdata ; \n \nid = of_match_device ( msm_otg_dt_match , & pdev -> dev ); \n- pdata -> phy_type = ( int ) id -> data ; \n+ pdata -> phy_type = ( enum msm_usb_phy_type ) id -> data ; \n \nmotg -> link_rst = devm_reset_control_get (& pdev -> dev , \" link \"); \nif ( IS_ERR ( motg -> link_rst ))", "mmm arch / powerpc / platforms / powernv / pci - ioda . c \nppp arch / powerpc / platforms / powernv / pci - ioda . c \nstatic void pnv_ioda_release_pe ( struct pnv_ioda_pe * pe ) \nstruct pnv_phb * phb = pe -> phb ; \nstruct pnv_ioda_pe * slave , * tmp ; \n \n- /* Release slave PEs in compound PE */ \n- if ( pe -> flags & PNV_IODA_PE_MASTER ) { \n- list_for_each_entry_safe ( slave , tmp , & pe -> slaves , list ) \n- pnv_ioda_release_pe ( slave ); \n- } \n- \nlist_del (& pe -> list ); \nswitch ( phb -> type ) { \ncase PNV_PHB_IODA1 : \nstatic void pnv_ioda_release_pe ( struct pnv_ioda_pe * pe ) \n \npnv_ioda_release_pe_seg ( pe ); \npnv_ioda_deconfigure_pe ( pe -> phb , pe ); \n+ \n+ /* Release slave PEs in the compound PE */ \n+ if ( pe -> flags & PNV_IODA_PE_MASTER ) { \n+ list_for_each_entry_safe ( slave , tmp , & pe -> slaves , list ) { \n+ list_del (& slave -> list ); \n+ pnv_ioda_free_pe ( slave ); \n+ } \n+ } \n+ \npnv_ioda_free_pe ( pe ); \n} \n", "mmm drivers / nfc / pn533 / pn533 . c \nppp drivers / nfc / pn533 / pn533 . c \nstatic int pn533_data_exchange_complete ( struct pn533 * dev , void * _arg , \n*/ \nvoid pn533_recv_frame ( struct pn533 * dev , struct sk_buff * skb , int status ) \n{ \n+ if (! dev -> cmd ) \n+ goto sched_wq ; \n+ \ndev -> cmd -> status = status ; \n \n+ if ( status != 0 ) { \n+ dev_dbg ( dev -> dev , \"% s : Error received : % d \\ n \", __func__ , status ); \n+ goto sched_wq ; \n+ } \n+ \nif ( skb == NULL ) { \npr_err (\" NULL Frame -> link is dead \\ n \"); \ngoto sched_wq ;", "mmm drivers / pci / host / pcie - xilinx . c \nppp drivers / pci / host / pcie - xilinx . c \nstatic void xilinx_msi_teardown_irq ( struct msi_controller * chip , \nunsigned int irq ) \n{ \nxilinx_pcie_destroy_msi ( irq ); \n+ irq_dispose_mapping ( irq ); \n} \n \n/**", "mmm arch / mips / kernel / process . c \nppp arch / mips / kernel / process . c \nstatic inline int is_sp_move_ins ( union mips_instruction * ip ) \n*/ \nif ( mm_insn_16bit ( ip -> halfword [ 1 ])) { \nreturn ( ip -> mm16_r3_format . opcode == mm_pool16d_op && \n- ip -> mm16_r3_format . simmediate && mm_addiusp_func ) || \n+ ip -> mm16_r3_format . simmediate & mm_addiusp_func ) || \n( ip -> mm16_r5_format . opcode == mm_pool16d_op && \nip -> mm16_r5_format . rt == 29 ); \n}", "mmm drivers / usb / usbip / usbip_common . c \nppp drivers / usb / usbip / usbip_common . c \nint usbip_recv_xbuff ( struct usbip_device * ud , struct urb * urb ) \nif (!( size > 0 )) \nreturn 0 ; \n \n+ if ( size > urb -> transfer_buffer_length ) { \n+ /* should not happen , probably malicious packet */ \n+ if ( ud -> side == USBIP_STUB ) { \n+ usbip_event_add ( ud , SDEV_EVENT_ERROR_TCP ); \n+ return 0 ; \n+ } else { \n+ usbip_event_add ( ud , VDEV_EVENT_ERROR_TCP ); \n+ return - EPIPE ; \n+ } \n+ } \n+ \nret = usbip_recv ( ud -> tcp_socket , urb -> transfer_buffer , size ); \nif ( ret != size ) { \ndev_err (& urb -> dev -> dev , \" recv xbuf , % d \\ n \", ret );", "mmm drivers / regulator / core . c \nppp drivers / regulator / core . c \nstatic ssize_t regulator_name_show ( struct device * dev , \nstruct regulator_dev * rdev = dev_get_drvdata ( dev ); \nconst char * name ; \n \n- if ( rdev -> constraints -> name ) \n+ if ( rdev -> constraints && rdev -> constraints -> name ) \nname = rdev -> constraints -> name ; \nelse if ( rdev -> desc -> name ) \nname = rdev -> desc -> name ;", "mmm fs / fuse / dev . c \nppp fs / fuse / dev . c \nstatic void process_init_reply ( struct fuse_conn * fc , struct fuse_req * req ) \nint i ; \nstruct fuse_init_out * arg = & req -> misc . init_out ; \n \n- if ( arg -> major != FUSE_KERNEL_VERSION ) \n+ if ( req -> out . h . error || arg -> major != FUSE_KERNEL_VERSION ) \nfc -> conn_error = 1 ; \nelse { \nfc -> minor = arg -> minor ;", "mmm net / ipv4 / tcp_input . c \nppp net / ipv4 / tcp_input . c \nstatic void tcp_mark_head_lost ( struct sock * sk , int packets ) \ncnt += tcp_skb_pcount ( skb ); \n \nif ( cnt > packets ) { \n- if ( tcp_is_sack ( tp ) || ( oldcnt >= packets )) \n+ if (( tcp_is_sack ( tp ) && ! tcp_is_fack ( tp )) || \n+ ( oldcnt >= packets )) \nbreak ; \n \nmss = skb_shinfo ( skb )-> gso_size ;", "mmm drivers / pci / quirks . c \nppp drivers / pci / quirks . c \nstatic int pci_quirk_amd_sb_acs ( struct pci_dev * dev , u16 acs_flags ) \n# endif \n} \n \n+ static int pci_quirk_cavium_acs ( struct pci_dev * dev , u16 acs_flags ) \n+{ \n+ /* \n+ * Cavium devices matching this quirk do not perform peer - to - peer \n+ * with other functions , allowing masking out these bits as if they \n+ * were unimplemented in the ACS capability . \n+ */ \n+ acs_flags &= ~( PCI_ACS_SV | PCI_ACS_TB | PCI_ACS_RR | \n+ PCI_ACS_CR | PCI_ACS_UF | PCI_ACS_DT ); \n+ \n+ return acs_flags ? 0 : 1 ; \n+} \n+ \n/* \n* Many Intel PCH root ports do provide ACS - like features to disable peer \n* transactions and validate bus numbers in requests , but do not provide an \nstatic const struct pci_dev_acs_enabled { \n{ PCI_VENDOR_ID_INTEL , PCI_ANY_ID , pci_quirk_intel_pch_acs }, \n{ 0x19a2 , 0x710 , pci_quirk_mf_endpoint_acs }, /* Emulex BE3 - R */ \n{ 0x10df , 0x720 , pci_quirk_mf_endpoint_acs }, /* Emulex Skyhawk - R */ \n+ /* Cavium ThunderX */ \n+ { PCI_VENDOR_ID_CAVIUM , PCI_ANY_ID , pci_quirk_cavium_acs }, \n{ 0 } \n}; \n", "mmm include / linux / lockdep . h \nppp include / linux / lockdep . h \nstruct lock_chain { \n}; \n \n# define MAX_LOCKDEP_KEYS_BITS 11 \n-# define MAX_LOCKDEP_KEYS ( 1UL << MAX_LOCKDEP_KEYS_BITS ) \n+/* \n+ * Subtract one because we offset hlock -> class_idx by 1 in order \n+ * to make 0 mean no class . This avoids overflowing the class_idx \n+ * bitfield and hitting the BUG in hlock_class (). \n+ */ \n+# define MAX_LOCKDEP_KEYS (( 1UL << MAX_LOCKDEP_KEYS_BITS ) - 1 ) \n \nstruct held_lock { \n/*", "mmm security / smack / smack_lsm . c \nppp security / smack / smack_lsm . c \nstatic int smack_cred_prepare ( struct cred * new , const struct cred * old , \nif ( new_tsp == NULL ) \nreturn - ENOMEM ; \n \n+ new -> security = new_tsp ; \n+ \nrc = smk_copy_rules (& new_tsp -> smk_rules , & old_tsp -> smk_rules , gfp ); \nif ( rc != 0 ) \nreturn rc ; \nstatic int smack_cred_prepare ( struct cred * new , const struct cred * old , \nif ( rc != 0 ) \nreturn rc ; \n \n- new -> security = new_tsp ; \nreturn 0 ; \n} \n", "mmm drivers / ide / ide - io . c \nppp drivers / ide / ide - io . c \nvoid ide_do_drive_cmd ( ide_drive_t * drive , struct request * rq ) \n \nspin_lock_irqsave ( q -> queue_lock , flags ); \n__elv_add_request ( q , rq , ELEVATOR_INSERT_FRONT , 0 ); \n- blk_start_queueing ( q ); \nspin_unlock_irqrestore ( q -> queue_lock , flags ); \n} \nEXPORT_SYMBOL ( ide_do_drive_cmd );", "mmm drivers / scsi / aacraid / commctrl . c \nppp drivers / scsi / aacraid / commctrl . c \nstatic int aac_send_raw_srb ( struct aac_dev * dev , void __user * arg ) \ngoto cleanup ; \n} \n \n- if ( fibsize > ( dev -> max_fib_size - sizeof ( struct aac_fibhdr ))) { \n+ if (( fibsize < ( sizeof ( struct user_aac_srb ) - sizeof ( struct user_sgentry ))) || \n+ ( fibsize > ( dev -> max_fib_size - sizeof ( struct aac_fibhdr )))) { \nrcode = - EINVAL ; \ngoto cleanup ; \n}", "mmm drivers / pinctrl / freescale / pinctrl - imx . c \nppp drivers / pinctrl / freescale / pinctrl - imx . c \nstatic void imx_pinconf_group_dbg_show ( struct pinctrl_dev * pctldev , \nconst char * name ; \nint i , ret ; \n \n- if ( group > pctldev -> num_groups ) \n+ if ( group >= pctldev -> num_groups ) \nreturn ; \n \nseq_puts ( s , \"\\ n \");", "mmm drivers / net / wireless / iwlwifi / iwl - trans . h \nppp drivers / net / wireless / iwlwifi / iwl - trans . h \nstruct iwl_trans { \nstatic inline void iwl_trans_configure ( struct iwl_trans * trans , \nconst struct iwl_trans_config * trans_cfg ) \n{ \n- /* \n- * only set the op_mode for the moment . Later on , this function will do \n- * more \n- */ \ntrans -> op_mode = trans_cfg -> op_mode ; \n \ntrans -> ops -> configure ( trans , trans_cfg ); \nstatic inline void iwl_trans_stop_hw ( struct iwl_trans * trans , \n \ntrans -> ops -> stop_hw ( trans , op_mode_leaving ); \n \n+ if ( op_mode_leaving ) \n+ trans -> op_mode = NULL ; \n+ \ntrans -> state = IWL_TRANS_NO_FW ; \n} \n", "mmm fs / btrfs / volumes . c \nppp fs / btrfs / volumes . c \nint btrfs_rm_device ( struct btrfs_fs_info * fs_info , const char * device_path , \n \ncur_devices -> num_devices --; \ncur_devices -> total_devices --; \n+ /* Update total_devices of the parent fs_devices if it ' s seed */ \n+ if ( cur_devices != fs_devices ) \n+ fs_devices -> total_devices --; \n \nif ( test_bit ( BTRFS_DEV_STATE_MISSING , & device -> dev_state )) \ncur_devices -> missing_devices --;", "mmm net / unix / af_unix . c \nppp net / unix / af_unix . c \nstatic struct pernet_operations unix_net_ops = { \nstatic int __init af_unix_init ( void ) \n{ \nint rc = - 1 ; \n- struct sk_buff * dummy_skb ; \n \n- BUILD_BUG_ON ( sizeof ( struct unix_skb_parms ) > sizeof ( dummy_skb -> cb )); \n+ BUILD_BUG_ON ( sizeof ( struct unix_skb_parms ) > FIELD_SIZEOF ( struct sk_buff , cb )); \n \nrc = proto_register (& unix_proto , 1 ); \nif ( rc != 0 ) {", "mmm drivers / staging / ozwpan / ozproto . c \nppp drivers / staging / ozwpan / ozproto . c \nstatic void oz_add_farewell ( struct oz_pd * pd , u8 ep_num , u8 index , \nreturn ; \nf -> ep_num = ep_num ; \nf -> index = index ; \n+ f -> len = len ; \nmemcpy ( f -> report , report , len ); \noz_dbg ( ON , \" RX : Adding farewell report \\ n \"); \nspin_lock (& g_polling_lock );", "mmm fs / nfsd / nfs4proc . c \nppp fs / nfsd / nfs4proc . c \nnfsd4_layout_verify ( struct svc_export * exp , unsigned int layout_type ) \nreturn NULL ; \n} \n \n- if (!( exp -> ex_layout_types & ( 1 << layout_type ))) { \n+ if ( layout_type >= LAYOUT_TYPE_MAX || \n+ !( exp -> ex_layout_types & ( 1 << layout_type ))) { \ndprintk (\"% s : layout type % d not supported \\ n \", \n__func__ , layout_type ); \nreturn NULL ;", "mmm net / mctp / device . c \nppp net / mctp / device . c \nvoid mctp_dev_hold ( struct mctp_dev * mdev ) \nvoid mctp_dev_put ( struct mctp_dev * mdev ) \n{ \nif ( mdev && refcount_dec_and_test (& mdev -> refs )) { \n+ kfree ( mdev -> addrs ); \ndev_put ( mdev -> dev ); \nkfree_rcu ( mdev , rcu ); \n} \nstatic void mctp_unregister ( struct net_device * dev ) \n \nmctp_route_remove_dev ( mdev ); \nmctp_neigh_remove_dev ( mdev ); \n- kfree ( mdev -> addrs ); \n \nmctp_dev_put ( mdev ); \n}", "mmm drivers / pci / pci - sysfs . c \nppp drivers / pci / pci - sysfs . c \nstatic int pci_create_attr ( struct pci_dev * pdev , int num , int write_combine ) \nres_attr -> size = pci_resource_len ( pdev , num ); \nres_attr -> private = & pdev -> resource [ num ]; \nretval = sysfs_create_bin_file (& pdev -> dev . kobj , res_attr ); \n+ if ( retval ) \n+ kfree ( res_attr ); \n} else \nretval = - ENOMEM ; \n", "mmm net / dccp / proto . c \nppp net / dccp / proto . c \nint dccp_disconnect ( struct sock * sk , int flags ) \nsk -> sk_err = ECONNRESET ; \n \ndccp_clear_xmit_timers ( sk ); \n+ \n__skb_queue_purge (& sk -> sk_receive_queue ); \n+ __skb_queue_purge (& sk -> sk_write_queue ); \nif ( sk -> sk_send_head != NULL ) { \n__kfree_skb ( sk -> sk_send_head ); \nsk -> sk_send_head = NULL ;", "mmm fs / cifs / smb2pdu . c \nppp fs / cifs / smb2pdu . c \nSMB2_negotiate ( const unsigned int xid , struct cifs_ses * ses ) \n} else if ( rsp -> DialectRevision == cpu_to_le16 ( SMB21_PROT_ID )) { \n/* ops set to 3 . 0 by default for default so update */ \nses -> server -> ops = & smb21_operations ; \n- } else if ( rsp -> DialectRevision == cpu_to_le16 ( SMB311_PROT_ID )) \n+ ses -> server -> vals = & smb21_values ; \n+ } else if ( rsp -> DialectRevision == cpu_to_le16 ( SMB311_PROT_ID )) { \nses -> server -> ops = & smb311_operations ; \n+ ses -> server -> vals = & smb311_values ; \n+ } \n} else if ( le16_to_cpu ( rsp -> DialectRevision ) != \nses -> server -> vals -> protocol_id ) { \n/* if requested single dialect ensure returned dialect matched */", "mmm net / batman - adv / icmp_socket . c \nppp net / batman - adv / icmp_socket . c \nstatic ssize_t bat_socket_read ( struct file * file , char __user * buf , \n \nspin_unlock_bh (& socket_client -> lock ); \n \n- error = copy_to_user ( buf , & socket_packet -> icmp_packet , \n- socket_packet -> icmp_len ); \n+ packet_len = min ( count , socket_packet -> icmp_len ); \n+ error = copy_to_user ( buf , & socket_packet -> icmp_packet , packet_len ); \n \n- packet_len = socket_packet -> icmp_len ; \nkfree ( socket_packet ); \n \nif ( error )", "mmm drivers / usb / core / devio . c \nppp drivers / usb / core / devio . c \nstatic int usbdev_open ( struct inode * inode , struct file * file ) \nstruct dev_state * ps ; \nint ret ; \n \n+ lock_kernel (); \n/* Protect against simultaneous removal or release */ \nmutex_lock (& usbfs_mutex ); \n \nstatic int usbdev_open ( struct inode * inode , struct file * file ) \nif ( ret ) \nkfree ( ps ); \nmutex_unlock (& usbfs_mutex ); \n+ unlock_kernel (); \nreturn ret ; \n} \n", "mmm drivers / scsi / pmcraid . c \nppp drivers / scsi / pmcraid . c \nstatic long pmcraid_ioctl_passthrough ( \npmcraid_err (\" couldn ' t build passthrough ioadls \\ n \"); \ngoto out_free_buffer ; \n} \n+ } else if ( request_size < 0 ) { \n+ rc = - EINVAL ; \n+ goto out_free_buffer ; \n} \n \n/* If data is being written into the device , copy the data from user", "mmm drivers / net / wireless / mwifiex / ie . c \nppp drivers / net / wireless / mwifiex / ie . c \nint mwifiex_del_mgmt_ies ( struct mwifiex_private * priv ) \nar_ie , & priv -> assocresp_idx ); \n \ndone : \n+ kfree ( gen_ie ); \nkfree ( beacon_ie ); \nkfree ( pr_ie ); \nkfree ( ar_ie );", "mmm include / net / inet_connection_sock . h \nppp include / net / inet_connection_sock . h \nstruct inet_connection_sock { \n \nu32 probe_timestamp ; \n} icsk_mtup ; \n- u32 icsk_ca_priv [ 16 ]; \nu32 icsk_user_timeout ; \n-# define ICSK_CA_PRIV_SIZE ( 16 * sizeof ( u32 )) \n+ \n+ u64 icsk_ca_priv [ 64 / sizeof ( u64 )]; \n+# define ICSK_CA_PRIV_SIZE ( 8 * sizeof ( u64 )) \n}; \n \n# define ICSK_TIME_RETRANS 1 /* Retransmit timer */", "mmm kernel / time / tick - sched . c \nppp kernel / time / tick - sched . c \nstatic void tick_nohz_handler ( struct clock_event_device * dev ) \ntick_sched_do_timer ( now ); \ntick_sched_handle ( ts , regs ); \n \n+ /* No need to reprogram if we are running tickless */ \n+ if ( unlikely ( ts -> tick_stopped )) \n+ return ; \n+ \nwhile ( tick_nohz_reprogram ( ts , now )) { \nnow = ktime_get (); \ntick_do_update_jiffies64 ( now );", "mmm net / sched / sch_api . c \nppp net / sched / sch_api . c \nint tc_classify ( struct sk_buff * skb , struct tcf_proto * tp , \ntp = otp ; \n \nif ( verd ++ >= MAX_REC_LOOP ) { \n- printk (\" rule prio % u protocol % 02x reclassify loop , \" \n- \" packet dropped \\ n \", \n- tp -> prio & 0xffff , ntohs ( tp -> protocol )); \n+ if ( net_ratelimit ()) \n+ printk ( KERN_NOTICE \n+ \"% s : packet reclassify loop \" \n+ \" rule prio % u protocol % 02x \\ n \", \n+ tp -> q -> ops -> id , \n+ tp -> prio & 0xffff , ntohs ( tp -> protocol )); \nreturn TC_ACT_SHOT ; \n} \nskb -> tc_verd = SET_TC_VERD ( skb -> tc_verd , verd );", "mmm include / linux / mmzone . h \nppp include / linux / mmzone . h \ntypedef struct pglist_data { \n# include < linux / memory_hotplug . h > \n \nextern struct mutex zonelists_mutex ; \n- void get_zone_counts ( unsigned long * active , unsigned long * inactive , \n- unsigned long * free ); \nvoid build_all_zonelists ( void * data ); \nvoid wakeup_kswapd ( struct zone * zone , int order ); \nint zone_watermark_ok ( struct zone * z , int order , unsigned long mark ,", "mmm drivers / mfd / tc6393xb . c \nppp drivers / mfd / tc6393xb . c \nstatic int tc6393xb_resume ( struct platform_device * dev ) \nint ret ; \nint i ; \n \n- clk_prepare_enable ( tc6393xb -> clk ); \n+ ret = clk_prepare_enable ( tc6393xb -> clk ); \n+ if ( ret ) \n+ return ret ; \n \nret = tcpd -> resume ( dev ); \nif ( ret )", "mmm drivers / gpu / drm / bridge / synopsys / dw - hdmi . c \nppp drivers / gpu / drm / bridge / synopsys / dw - hdmi . c \nint dw_hdmi_probe ( struct platform_device * pdev , \nconst struct dw_hdmi_plat_data * plat_data ) \n{ \nstruct dw_hdmi * hdmi ; \n- int ret ; \n \nhdmi = __dw_hdmi_probe ( pdev , plat_data ); \nif ( IS_ERR ( hdmi )) \nreturn PTR_ERR ( hdmi ); \n \n- ret = drm_bridge_add (& hdmi -> bridge ); \n- if ( ret < 0 ) { \n- __dw_hdmi_remove ( hdmi ); \n- return ret ; \n- } \n+ drm_bridge_add (& hdmi -> bridge ); \n \nreturn 0 ; \n}", "mmm drivers / md / md . c \nppp drivers / md / md . c \nstatic int get_bitmap_file ( struct mddev * mddev , void __user * arg ) \nchar * ptr ; \nint err ; \n \n- file = kmalloc ( sizeof (* file ), GFP_NOIO ); \n+ file = kzalloc ( sizeof (* file ), GFP_NOIO ); \nif (! file ) \nreturn - ENOMEM ; \n", "mmm arch / parisc / kernel / perf . c \nppp arch / parisc / kernel / perf . c \n# include < linux / init . h > \n# include < linux / proc_fs . h > \n# include < linux / miscdevice . h > \n+# include < linux / smp_lock . h > \n# include < linux / spinlock . h > \n \n# include < asm / uaccess . h > \nprintk (\" Preparing to start counters \\ n \"); \n*/ \nstatic int perf_open ( struct inode * inode , struct file * file ) \n{ \n+ lock_kernel (); \nspin_lock (& perf_lock ); \nif ( perf_enabled ) { \nspin_unlock (& perf_lock ); \n+ unlock_kernel (); \nreturn - EBUSY ; \n} \nperf_enabled = 1 ; \nspin_unlock (& perf_lock ); \n+ unlock_kernel (); \n \nreturn 0 ; \n}", "mmm kernel / cgroup . c \nppp kernel / cgroup . c \nstatic long cgroup_create ( struct cgroup * parent , struct dentry * dentry , \n \nmutex_lock (& cgroup_mutex ); \n \n- cgrp -> flags = 0 ; \nINIT_LIST_HEAD (& cgrp -> sibling ); \nINIT_LIST_HEAD (& cgrp -> children ); \nINIT_LIST_HEAD (& cgrp -> css_sets ); \nstatic long cgroup_create ( struct cgroup * parent , struct dentry * dentry , \ncgrp -> root = parent -> root ; \ncgrp -> top_cgroup = parent -> top_cgroup ; \n \n+ if ( notify_on_release ( parent )) \n+ set_bit ( CGRP_NOTIFY_ON_RELEASE , & cgrp -> flags ); \n+ \nfor_each_subsys ( root , ss ) { \nstruct cgroup_subsys_state * css = ss -> create ( ss , cgrp ); \nif ( IS_ERR ( css )) {", "mmm kernel / audit . c \nppp kernel / audit . c \nstatic void audit_log_feature_change ( int which , u32 old_feature , u32 new_feature \n{ \nstruct audit_buffer * ab ; \n \n+ if ( audit_enabled == AUDIT_OFF ) \n+ return ; \n+ \nab = audit_log_start ( NULL , GFP_KERNEL , AUDIT_FEATURE_CHANGE ); \naudit_log_format ( ab , \" feature =% s old =% d new =% d old_lock =% d new_lock =% d res =% d \", \naudit_feature_names [ which ], !! old_feature , !! new_feature ,", "mmm kernel / irq / irqdomain . c \nppp kernel / irq / irqdomain . c \nstatic inline void debugfs_remove_domain_dir ( struct irq_domain * d ) { } \n# endif \n \nconst struct fwnode_operations irqchip_fwnode_ops ; \n+ EXPORT_SYMBOL_GPL ( irqchip_fwnode_ops ); \n \n/** \n* irq_domain_alloc_fwnode - Allocate a fwnode_handle suitable for", "mmm net / bluetooth / hci_event . c \nppp net / bluetooth / hci_event . c \nstatic inline void hci_pin_code_request_evt ( struct hci_dev * hdev , struct sk_buff \nhci_dev_lock ( hdev ); \n \nconn = hci_conn_hash_lookup_ba ( hdev , ACL_LINK , & ev -> bdaddr ); \n- if ( conn && conn -> state == BT_CONNECTED ) { \n+ if (! conn ) \n+ goto unlock ; \n+ \n+ if ( conn -> state == BT_CONNECTED ) { \nhci_conn_hold ( conn ); \nconn -> disc_timeout = HCI_PAIRING_TIMEOUT ; \nhci_conn_put ( conn ); \nstatic inline void hci_pin_code_request_evt ( struct hci_dev * hdev , struct sk_buff \nmgmt_pin_code_request ( hdev -> id , & ev -> bdaddr , secure ); \n} \n \n+ unlock : \nhci_dev_unlock ( hdev ); \n} \n", "mmm drivers / net / wireless / marvell / mwifiex / scan . c \nppp drivers / net / wireless / marvell / mwifiex / scan . c \nmwifiex_cmd_append_vsie_tlv ( struct mwifiex_private * priv , \nvs_param_set -> header . len = \ncpu_to_le16 (((( u16 ) priv -> vs_ie [ id ]. ie [ 1 ]) \n& 0x00FF ) + 2 ); \n+ if ( le16_to_cpu ( vs_param_set -> header . len ) > \n+ MWIFIEX_MAX_VSIE_LEN ) { \n+ mwifiex_dbg ( priv -> adapter , ERROR , \n+ \" Invalid param length !\\ n \"); \n+ break ; \n+ } \n+ \nmemcpy ( vs_param_set -> ie , priv -> vs_ie [ id ]. ie , \nle16_to_cpu ( vs_param_set -> header . len )); \n* buffer += le16_to_cpu ( vs_param_set -> header . len ) +", "mmm arch / x86 / kvm / vmx . c \nppp arch / x86 / kvm / vmx . c \nstatic inline void nested_release_vmcs12 ( struct vcpu_vmx * vmx ) \n*/ \nstatic void free_nested ( struct vcpu_vmx * vmx ) \n{ \n- if (! vmx -> nested . vmxon ) \n+ if (! vmx -> nested . vmxon && ! vmx -> nested . smm . vmxon ) \nreturn ; \n \nvmx -> nested . vmxon = false ; \n+ vmx -> nested . smm . vmxon = false ; \nfree_vpid ( vmx -> nested . vpid02 ); \nvmx -> nested . posted_intr_nv = - 1 ; \nvmx -> nested . current_vmptr = - 1ull ;", "mmm drivers / phy / phy - core . c \nppp drivers / phy / phy - core . c \nstatic struct phy * _of_phy_get ( struct device_node * np , int index ) \nif ( ret ) \nreturn ERR_PTR (- ENODEV ); \n \n+ /* This phy type handled by the usb - phy subsystem for now */ \n+ if ( of_device_is_compatible ( args . np , \" usb - nop - xceiv \")) \n+ return ERR_PTR (- ENODEV ); \n+ \nmutex_lock (& phy_provider_mutex ); \nphy_provider = of_phy_provider_lookup ( args . np ); \nif ( IS_ERR ( phy_provider ) || ! try_module_get ( phy_provider -> owner )) {", "mmm drivers / bus / arm - ccn . c \nppp drivers / bus / arm - ccn . c \nstatic void arm_ccn_pmu_xp_dt_config ( struct perf_event * event , int enable ) \nstruct arm_ccn_component * xp ; \nu32 val , dt_cfg ; \n \n+ /* Nothing to do for cycle counter */ \n+ if ( hw -> idx == CCN_IDX_PMU_CYCLE_COUNTER ) \n+ return ; \n+ \nif ( CCN_CONFIG_TYPE ( event -> attr . config ) == CCN_TYPE_XP ) \nxp = & ccn -> xp [ CCN_CONFIG_XP ( event -> attr . config )]; \nelse", "mmm drivers / firewire / core - cdev . c \nppp drivers / firewire / core - cdev . c \nstatic void outbound_phy_packet_callback ( struct fw_packet * packet , \n{ \nstruct outbound_phy_packet_event * e = \ncontainer_of ( packet , struct outbound_phy_packet_event , p ); \n+ struct client * e_client ; \n \nswitch ( status ) { \n/* expected : */ \nstatic void outbound_phy_packet_callback ( struct fw_packet * packet , \n} \ne -> phy_packet . data [ 0 ] = packet -> timestamp ; \n \n+ e_client = e -> client ; \nqueue_event ( e -> client , & e -> event , & e -> phy_packet , \nsizeof ( e -> phy_packet ) + e -> phy_packet . length , NULL , 0 ); \n- client_put ( e -> client ); \n+ client_put ( e_client ); \n} \n \nstatic int ioctl_send_phy_packet ( struct client * client , union ioctl_arg * arg )", "mmm drivers / crypto / inside - secure / safexcel . c \nppp drivers / crypto / inside - secure / safexcel . c \nstatic int safexcel_probe ( struct platform_device * pdev ) \nsnprintf ( irq_name , 6 , \" ring % d \", i ); \nirq = safexcel_request_ring_irq ( pdev , irq_name , safexcel_irq_ring , \nring_irq ); \n- \n- if ( irq < 0 ) \n+ if ( irq < 0 ) { \n+ ret = irq ; \ngoto err_clk ; \n+ } \n \npriv -> ring [ i ]. work_data . priv = priv ; \npriv -> ring [ i ]. work_data . ring = i ;", "mmm drivers / platform / mellanox / mlxreg - hotplug . c \nppp drivers / platform / mellanox / mlxreg - hotplug . c \nmlxreg_hotplug_health_work_helper ( struct mlxreg_hotplug_priv_data * priv , \n{ \nstruct mlxreg_core_data * data = item -> data ; \nu32 regval ; \n- int i , ret ; \n+ int i , ret = 0 ; \n \nfor ( i = 0 ; i < item -> count ; i ++, data ++) { \n/* Mask event . */", "mmm drivers / staging / android / ion / ion_system_heap . c \nppp drivers / staging / android / ion / ion_system_heap . c \nint ion_system_heap_map_user ( struct ion_heap * heap , struct ion_buffer * buffer , \nremap_pfn_range ( vma , addr , page_to_pfn ( sg_page ( sg )), \nsg_dma_len ( sg ), vma -> vm_page_prot ); \naddr += sg_dma_len ( sg ); \n+ if ( addr >= vma -> vm_end ) \n+ return 0 ; \n} \nreturn 0 ; \n}", "mmm drivers / thermal / thermal_hwmon . c \nppp drivers / thermal / thermal_hwmon . c \nint thermal_add_hwmon_sysfs ( struct thermal_zone_device * tz ) \n \nINIT_LIST_HEAD (& hwmon -> tz_list ); \nstrlcpy ( hwmon -> type , tz -> type , THERMAL_NAME_LENGTH ); \n- hwmon -> device = hwmon_device_register ( NULL ); \n+ hwmon -> device = hwmon_device_register (& tz -> device ); \nif ( IS_ERR ( hwmon -> device )) { \nresult = PTR_ERR ( hwmon -> device ); \ngoto free_mem ;", "mmm net / llc / af_llc . c \nppp net / llc / af_llc . c \nstatic void llc_cmsg_rcv ( struct msghdr * msg , struct sk_buff * skb ) \nif ( llc -> cmsg_flags & LLC_CMSG_PKTINFO ) { \nstruct llc_pktinfo info ; \n \n+ memset (& info , 0 , sizeof ( info )); \ninfo . lpi_ifindex = llc_sk ( skb -> sk )-> dev -> ifindex ; \nllc_pdu_decode_dsap ( skb , & info . lpi_sap ); \nllc_pdu_decode_da ( skb , info . lpi_mac );", "mmm drivers / mmc / host / mxcmmc . c \nppp drivers / mmc / host / mxcmmc . c \nstatic int mxcmci_probe ( struct platform_device * pdev ) \ngoto out_release_mem ; \n} \n \n- mmc_of_parse ( mmc ); \n+ ret = mmc_of_parse ( mmc ); \n+ if ( ret ) \n+ goto out_free ; \nmmc -> ops = & mxcmci_ops ; \n \n/* For devicetree parsing , the bus width is read from devicetree */", "mmm sound / soc / intel / sst - haswell - ipc . c \nppp sound / soc / intel / sst - haswell - ipc . c \nint sst_hsw_dsp_runtime_resume ( struct sst_hsw * hsw ) \nret = wait_event_timeout ( hsw -> boot_wait , hsw -> boot_complete , \nmsecs_to_jiffies ( IPC_BOOT_MSECS )); \nif ( ret == 0 ) { \n- dev_err ( hsw -> dev , \" error : audio DSP boot timeout \\ n \"); \n+ dev_err ( hsw -> dev , \" error : audio DSP boot timeout IPCD 0x % x IPCX 0x % x \\ n \", \n+ sst_dsp_shim_read_unlocked ( hsw -> dsp , SST_IPCD ), \n+ sst_dsp_shim_read_unlocked ( hsw -> dsp , SST_IPCX )); \nreturn - EIO ; \n} \n \nint sst_hsw_dsp_init ( struct device * dev , struct sst_pdata * pdata ) \nmsecs_to_jiffies ( IPC_BOOT_MSECS )); \nif ( ret == 0 ) { \nret = - EIO ; \n- dev_err ( hsw -> dev , \" error : ADSP boot timeout \\ n \"); \n+ dev_err ( hsw -> dev , \" error : audio DSP boot timeout IPCD 0x % x IPCX 0x % x \\ n \", \n+ sst_dsp_shim_read_unlocked ( hsw -> dsp , SST_IPCD ), \n+ sst_dsp_shim_read_unlocked ( hsw -> dsp , SST_IPCX )); \ngoto boot_err ; \n} \n", "mmm drivers / net / wireless / ath / ath10k / usb . c \nppp drivers / net / wireless / ath / ath10k / usb . c \nstatic int ath10k_usb_hif_tx_sg ( struct ath10k * ar , u8 pipe_id , \nath10k_dbg ( ar , ATH10K_DBG_USB_BULK , \n\" usb bulk transmit failed : % d \\ n \", ret ); \nusb_unanchor_urb ( urb ); \n+ usb_free_urb ( urb ); \nret = - EINVAL ; \ngoto err_free_urb_to_pipe ; \n}", "mmm kernel / audit . c \nppp kernel / audit . c \nvoid audit_log_n_hex ( struct audit_buffer * ab , const unsigned char * buf , \nint i , avail , new_len ; \nunsigned char * ptr ; \nstruct sk_buff * skb ; \n- static const unsigned char * hex = \" 0123456789ABCDEF \"; \n \nif (! ab ) \nreturn ; \nvoid audit_log_n_hex ( struct audit_buffer * ab , const unsigned char * buf , \n} \n \nptr = skb_tail_pointer ( skb ); \n- for ( i = 0 ; i < len ; i ++) { \n- * ptr ++ = hex [( buf [ i ] & 0xF0 )>> 4 ]; /* Upper nibble */ \n- * ptr ++ = hex [ buf [ i ] & 0x0F ]; /* Lower nibble */ \n- } \n+ for ( i = 0 ; i < len ; i ++) \n+ ptr = hex_byte_pack_upper ( ptr , buf [ i ]); \n* ptr = 0 ; \nskb_put ( skb , len << 1 ); /* new string is twice the old string */ \n}", "mmm drivers / mmc / host / omap . c \nppp drivers / mmc / host / omap . c \nstatic inline void set_cmd_timeout ( struct mmc_omap_host * host , struct mmc_reques \n \nstatic inline void set_data_timeout ( struct mmc_omap_host * host , struct mmc_request * req ) \n{ \n- int timeout ; \n+ unsigned int timeout , cycle_ns ; \nu16 reg ; \n \n- /* Convert ns to clock cycles by assuming 20MHz frequency \n- * 1 cycle at 20MHz = 500 ns \n- */ \n- timeout = req -> data -> timeout_clks + req -> data -> timeout_ns / 500 ; \n+ cycle_ns = 1000000000 / host -> current_slot -> fclk_freq ; \n+ timeout = req -> data -> timeout_ns / cycle_ns ; \n+ timeout += req -> data -> timeout_clks ; \n \n/* Check if we need to use timeout multiplier register */ \nreg = OMAP_MMC_READ ( host , SDIO );", "mmm drivers / scsi / libsas / sas_expander . c \nppp drivers / scsi / libsas / sas_expander . c \nstatic void smp_task_timedout ( struct timer_list * t ) \nunsigned long flags ; \n \nspin_lock_irqsave (& task -> task_state_lock , flags ); \n- if (!( task -> task_state_flags & SAS_TASK_STATE_DONE )) \n+ if (!( task -> task_state_flags & SAS_TASK_STATE_DONE )) { \ntask -> task_state_flags |= SAS_TASK_STATE_ABORTED ; \n+ complete (& task -> slow_task -> completion ); \n+ } \nspin_unlock_irqrestore (& task -> task_state_lock , flags ); \n- \n- complete (& task -> slow_task -> completion ); \n} \n \nstatic void smp_task_done ( struct sas_task * task ) \n{ \n- if (! del_timer (& task -> slow_task -> timer )) \n- return ; \n+ del_timer (& task -> slow_task -> timer ); \ncomplete (& task -> slow_task -> completion ); \n} \n", "mmm sound / soc / soc - core . c \nppp sound / soc / soc - core . c \nstatic void snd_soc_instantiate_card ( struct snd_soc_card * card ) \nsnd_soc_dapm_add_routes (& card -> dapm , card -> dapm_routes , \ncard -> num_dapm_routes ); \n \n+ snd_soc_dapm_new_widgets (& card -> dapm ); \n+ \nfor ( i = 0 ; i < card -> num_links ; i ++) { \ndai_link = & card -> dai_link [ i ]; \n", "mmm sound / pci / hda / hda_codec . c \nppp sound / pci / hda / hda_codec . c \nint snd_hda_create_spdif_out_ctls ( struct hda_codec * codec , hda_nid_t nid ) \n} \nfor ( dig_mix = dig_mixes ; dig_mix -> name ; dig_mix ++) { \nkctl = snd_ctl_new1 ( dig_mix , codec ); \n+ if (! kctl ) \n+ return - ENOMEM ; \nkctl -> id . index = idx ; \nkctl -> private_value = nid ; \nerr = snd_hda_ctl_add ( codec , kctl ); \nsnd_hda_attach_pcm ( struct hda_codec * codec , struct hda_pcm * pcm ) \nstruct hda_pcm_stream * info ; \nint stream , err ; \n \n- if (! pcm -> name ) \n+ if ( snd_BUG_ON (! pcm -> name )) \nreturn - EINVAL ; \nfor ( stream = 0 ; stream < 2 ; stream ++) { \ninfo = & pcm -> stream [ stream ];", "mmm drivers / md / dm . c \nppp drivers / md / dm . c \nstatic void local_exit ( void ) \nDMINFO (\" cleaned up \"); \n} \n \n- int (* _inits [])( void ) __initdata = { \n+ static int (* _inits [])( void ) __initdata = { \nlocal_init , \ndm_target_init , \ndm_linear_init , \nint (* _inits [])( void ) __initdata = { \ndm_interface_init , \n}; \n \n- void (* _exits [])( void ) = { \n+ static void (* _exits [])( void ) = { \nlocal_exit , \ndm_target_exit , \ndm_linear_exit ,", "mmm mm / migrate . c \nppp mm / migrate . c \nstatic int do_pages_stat ( struct mm_struct * mm , unsigned long nr_pages , \nint err ; \n \nfor ( i = 0 ; i < nr_pages ; i += chunk_nr ) { \n- if ( chunk_nr + i > nr_pages ) \n+ if ( chunk_nr > nr_pages - i ) \nchunk_nr = nr_pages - i ; \n \nerr = copy_from_user ( chunk_pages , & pages [ i ],", "mmm drivers / net / can / slcan . c \nppp drivers / net / can / slcan . c \nstatic void slc_bump ( struct slcan * sl ) \nu32 tmpid ; \nchar * cmd = sl -> rbuff ; \n \n- cf . can_id = 0 ; \n+ memset (& cf , 0 , sizeof ( cf )); \n \nswitch (* cmd ) { \ncase ' r ': \nstatic void slc_bump ( struct slcan * sl ) \nelse \nreturn ; \n \n- *( u64 *) (& cf . data ) = 0 ; /* clear payload */ \n- \n/* RTR frames may have a dlc > 0 but they never have any data bytes */ \nif (!( cf . can_id & CAN_RTR_FLAG )) { \nfor ( i = 0 ; i < cf . can_dlc ; i ++) {", "mmm drivers / net / ethernet / qlogic / qlcnic / qlcnic_83xx_hw . c \nppp drivers / net / ethernet / qlogic / qlcnic / qlcnic_83xx_hw . c \nstatic void qlcnic_83xx_mailbox_worker ( struct work_struct * work ) \n__func__ , cmd -> cmd_op , cmd -> type , ahw -> pci_func , \nahw -> op_mode ); \nclear_bit ( QLC_83XX_MBX_READY , & mbx -> status ); \n+ qlcnic_dump_mbx ( adapter , cmd ); \nqlcnic_83xx_idc_request_reset ( adapter , \nQLCNIC_FORCE_FW_DUMP_KEY ); \ncmd -> rsp_opcode = QLCNIC_RCODE_TIMEOUT ;", "mmm sound / usb / quirks . c \nppp sound / usb / quirks . c \nstatic int snd_usb_fasttrackpro_boot_quirk ( struct usb_device * dev ) \n* rules \n*/ \nerr = usb_driver_set_configuration ( dev , 2 ); \n- if ( err < 0 ) { \n+ if ( err < 0 ) \nsnd_printdd (\" error usb_driver_set_configuration : % d \\ n \", \nerr ); \n- return - ENODEV ; \n- } \n+ /* Always return an error , so that we stop creating a device \n+ that will just be destroyed and recreated with a new \n+ configuration */ \n+ return - ENODEV ; \n} else \nsnd_printk ( KERN_INFO \" usb - audio : Fast Track Pro config OK \\ n \"); \n", "mmm fs / xfs / libxfs / xfs_iext_tree . c \nppp fs / xfs / libxfs / xfs_iext_tree . c \nxfs_iext_remove_node ( \nnode -> ptrs [ nr_entries ] = NULL ; \n \nif ( pos == 0 && nr_entries > 0 ) { \n- xfs_iext_update_node ( ifp , offset , node -> keys [ 0 ], level , \n- node ); \n+ xfs_iext_update_node ( ifp , offset , node -> keys [ 0 ], level , node ); \noffset = node -> keys [ 0 ]; \n} \n", "mmm drivers / dma / imx - sdma . c \nppp drivers / dma / imx - sdma . c \nstruct sdma_firmware_header { \n \nstruct sdma_engine { \nstruct device * dev ; \n+ struct device_dma_parameters dma_parms ; \nstruct sdma_channel channel [ MAX_DMA_CHANNELS ]; \nstruct sdma_channel_control * channel_control ; \nvoid __iomem * regs ; \nstatic int __init sdma_probe ( struct platform_device * pdev ) \nsdma -> dma_device . device_prep_dma_cyclic = sdma_prep_dma_cyclic ; \nsdma -> dma_device . device_control = sdma_control ; \nsdma -> dma_device . device_issue_pending = sdma_issue_pending ; \n+ sdma -> dma_device . dev -> dma_parms = & sdma -> dma_parms ; \n+ dma_set_max_seg_size ( sdma -> dma_device . dev , 65535 ); \n \nret = dma_async_device_register (& sdma -> dma_device ); \nif ( ret ) {", "mmm drivers / dma / tegra20 - apb - dma . c \nppp drivers / dma / tegra20 - apb - dma . c \nstatic struct tegra_dma_desc * tegra_dma_desc_get ( \nif ( async_tx_test_ack (& dma_desc -> txd )) { \nlist_del (& dma_desc -> node ); \nspin_unlock_irqrestore (& tdc -> lock , flags ); \n+ dma_desc -> txd . flags = 0 ; \nreturn dma_desc ; \n} \n} \nstruct dma_async_tx_descriptor * tegra_dma_prep_dma_cyclic ( \nTEGRA_APBDMA_AHBSEQ_WRAP_SHIFT ; \nahb_seq |= TEGRA_APBDMA_AHBSEQ_BUS_WIDTH_32 ; \n \n- csr |= TEGRA_APBDMA_CSR_FLOW | TEGRA_APBDMA_CSR_IE_EOC ; \n+ csr |= TEGRA_APBDMA_CSR_FLOW ; \n+ if ( flags & DMA_PREP_INTERRUPT ) \n+ csr |= TEGRA_APBDMA_CSR_IE_EOC ; \ncsr |= tdc -> dma_sconfig . slave_id << TEGRA_APBDMA_CSR_REQ_SEL_SHIFT ; \n \napb_seq |= TEGRA_APBDMA_APBSEQ_WRAP_WORD_1 ; \nstruct dma_async_tx_descriptor * tegra_dma_prep_dma_cyclic ( \nmem += len ; \n} \nsg_req -> last_sg = true ; \n- dma_desc -> txd . flags = 0 ; \n+ if ( flags & DMA_CTRL_ACK ) \n+ dma_desc -> txd . flags = DMA_CTRL_ACK ; \n \n/* \n* Make sure that mode should not be conflicting with currently", "mmm fs / btrfs / transaction . c \nppp fs / btrfs / transaction . c \nstruct btrfs_trans_handle * btrfs_start_ioctl_transaction ( struct btrfs_root * root \n} \n \n/* wait for a transaction commit to be fully complete */ \n- static noinline int wait_for_commit ( struct btrfs_root * root , \n+ static noinline void wait_for_commit ( struct btrfs_root * root , \nstruct btrfs_transaction * commit ) \n{ \nwait_event ( commit -> commit_wait , commit -> commit_done ); \n- return 0 ; \n} \n \nint btrfs_wait_for_commit ( struct btrfs_root * root , u64 transid ) \nint btrfs_commit_transaction ( struct btrfs_trans_handle * trans , \natomic_inc (& cur_trans -> use_count ); \nbtrfs_end_transaction ( trans , root ); \n \n- ret = wait_for_commit ( root , cur_trans ); \n- BUG_ON ( ret ); \n+ wait_for_commit ( root , cur_trans ); \n \nput_transaction ( cur_trans ); \n", "mmm kernel / signal . c \nppp kernel / signal . c \ndo_send_specific ( pid_t tgid , pid_t pid , int sig , struct siginfo * info ) \n \nstatic int do_tkill ( pid_t tgid , pid_t pid , int sig ) \n{ \n- struct siginfo info ; \n+ struct siginfo info = {}; \n \ninfo . si_signo = sig ; \ninfo . si_errno = 0 ;", "mmm drivers / gpu / drm / drm_drv . c \nppp drivers / gpu / drm / drm_drv . c \nlong drm_ioctl ( struct file * filp , \nretcode = - EFAULT ; \ngoto err_i1 ; \n} \n- } \n+ } else \n+ memset ( kdata , 0 , _IOC_SIZE ( cmd )); \n+ \nif ( ioctl -> flags & DRM_UNLOCKED ) \nretcode = func ( dev , kdata , file_priv ); \nelse {", "mmm drivers / media / platform / vimc / vimc - core . c \nppp drivers / media / platform / vimc / vimc - core . c \nstatic int vimc_probe ( struct platform_device * pdev ) \nif ( ret ) { \nmedia_device_cleanup (& vimc -> mdev ); \nvimc_rm_subdevs ( vimc ); \n- kfree ( vimc ); \nreturn ret ; \n} \n", "mmm drivers / pci / pcie / aer / aerdrv_core . c \nppp drivers / pci / pcie / aer / aerdrv_core . c \nstatic void aer_recover_work_func ( struct work_struct * work ) \ncontinue ; \n} \ncper_print_aer ( pdev , entry . severity , entry . regs ); \n- do_recovery ( pdev , entry . severity ); \n+ if ( entry . severity != AER_CORRECTABLE ) \n+ do_recovery ( pdev , entry . severity ); \npci_dev_put ( pdev ); \n} \n}", "mmm security / selinux / hooks . c \nppp security / selinux / hooks . c \nvoid selinux_complete_init ( void ) \n \n/* Set up any superblocks initialized prior to the policy load . */ \nprintk ( KERN_INFO \" SELinux : Setting up existing superblocks .\\ n \"); \n+ spin_lock (& sb_lock ); \nspin_lock (& sb_security_lock ); \nnext_sb : \nif (! list_empty (& superblock_security_head )) { \nvoid selinux_complete_init ( void ) \nstruct superblock_security_struct , \nlist ); \nstruct super_block * sb = sbsec -> sb ; \n- spin_lock (& sb_lock ); \nsb -> s_count ++; \n- spin_unlock (& sb_lock ); \nspin_unlock (& sb_security_lock ); \n+ spin_unlock (& sb_lock ); \ndown_read (& sb -> s_umount ); \nif ( sb -> s_root ) \nsuperblock_doinit ( sb , NULL ); \ndrop_super ( sb ); \n+ spin_lock (& sb_lock ); \nspin_lock (& sb_security_lock ); \nlist_del_init (& sbsec -> list ); \ngoto next_sb ; \n} \nspin_unlock (& sb_security_lock ); \n+ spin_unlock (& sb_lock ); \n} \n \n/* SELinux requires early initialization in order to label", "mmm drivers / char / tpm / tpm - chip . c \nppp drivers / char / tpm / tpm - chip . c \nstruct tpm_chip * tpmm_chip_alloc ( struct device * dev , \n \ndevice_initialize (& chip -> dev ); \n \n- chip -> cdev . owner = chip -> pdev -> driver -> owner ; \ncdev_init (& chip -> cdev , & tpm_fops ); \n+ chip -> cdev . owner = chip -> pdev -> driver -> owner ; \n+ chip -> cdev . kobj . parent = & chip -> dev . kobj ; \n \nreturn chip ; \n}", "mmm virt / kvm / irqchip . c \nppp virt / kvm / irqchip . c \nint kvm_set_irq_routing ( struct kvm * kvm , \ngoto out ; \n \nr = - EINVAL ; \n- if ( ue -> flags ) \n+ if ( ue -> flags ) { \n+ kfree ( e ); \ngoto out ; \n+ } \nr = setup_routing_entry ( new , e , ue ); \n- if ( r ) \n+ if ( r ) { \n+ kfree ( e ); \ngoto out ; \n+ } \n++ ue ; \n} \n", "mmm kernel / relay . c \nppp kernel / relay . c \nstruct rchan * relay_open ( const char * base_filename , \n \nkref_put (& chan -> kref , relay_destroy_channel ); \nmutex_unlock (& relay_channels_mutex ); \n+ kfree ( chan ); \nreturn NULL ; \n} \nEXPORT_SYMBOL_GPL ( relay_open );", "mmm net / bridge / br_ioctl . c \nppp net / bridge / br_ioctl . c \nstatic int get_fdb_entries ( struct net_bridge * br , void __user * userbuf , \n{ \nint num ; \nvoid * buf ; \n- size_t size = maxnum * sizeof ( struct __fdb_entry ); \n+ size_t size ; \n \n- if ( size > PAGE_SIZE ) { \n- size = PAGE_SIZE ; \n+ /* Clamp size to PAGE_SIZE , test maxnum to avoid overflow */ \n+ if ( maxnum > PAGE_SIZE / sizeof ( struct __fdb_entry )) \nmaxnum = PAGE_SIZE / sizeof ( struct __fdb_entry ); \n- } \n+ \n+ size = maxnum * sizeof ( struct __fdb_entry ); \n \nbuf = kmalloc ( size , GFP_USER ); \nif (! buf )", "mmm drivers / tty / serial / serial_core . c \nppp drivers / tty / serial / serial_core . c \nstatic void uart_close ( struct tty_struct * tty , struct file * filp ) \n \npr_debug (\" uart_close (% d ) called \\ n \", uport -> line ); \n \n- mutex_lock (& port -> mutex ); \nspin_lock_irqsave (& port -> lock , flags ); \n \nif ( tty_hung_up_p ( filp )) { \nstatic void uart_close ( struct tty_struct * tty , struct file * filp ) \nuart_wait_until_sent ( tty , uport -> timeout ); \n} \n \n+ mutex_lock (& port -> mutex ); \nuart_shutdown ( tty , state ); \nuart_flush_buffer ( tty ); \n", "mmm include / linux / mm . h \nppp include / linux / mm . h \nunsigned long vmalloc_to_pfn ( const void * addr ); \n* On nommu , vmalloc / vfree wrap through kmalloc / kfree directly , so there \n* is no special casing required . \n*/ \n- static inline int is_vmalloc_addr ( const void * x ) \n+ static inline bool is_vmalloc_addr ( const void * x ) \n{ \n# ifdef CONFIG_MMU \nunsigned long addr = ( unsigned long ) x ; \n \nreturn addr >= VMALLOC_START && addr < VMALLOC_END ; \n# else \n- return 0 ; \n+ return false ; \n# endif \n} \n# ifdef CONFIG_MMU", "mmm arch / powerpc / perf / core - book3s . c \nppp arch / powerpc / perf / core - book3s . c \nstatic void power_pmu_bhrb_read ( struct cpu_hw_events * cpuhw ) \n/* invalid entry */ \ncontinue ; \n \n+ /* \n+ * BHRB rolling buffer could very much contain the kernel \n+ * addresses at this point . Check the privileges before \n+ * exporting it to userspace ( avoid exposure of regions \n+ * where we could have speculative execution ) \n+ */ \n+ if ( perf_paranoid_kernel () && ! capable ( CAP_SYS_ADMIN ) && \n+ is_kernel_addr ( addr )) \n+ continue ; \n+ \n/* Branches are read most recent first ( ie . mfbhrb 0 is \n* the most recent branch ). \n* There are two types of valid entries :", "mmm drivers / cpufreq / cpufreq_stats . c \nppp drivers / cpufreq / cpufreq_stats . c \ncpufreq_stat_notifier_trans ( struct notifier_block * nb , unsigned long val , \nreturn 0 ; \n} \n \n- static int __cpuinit cpufreq_stat_cpu_callback ( struct notifier_block * nfb , \n+ static int cpufreq_stat_cpu_callback ( struct notifier_block * nfb , \nunsigned long action , void * hcpu ) \n{ \nunsigned int cpu = ( unsigned long ) hcpu ;", "mmm fs / afs / write . c \nppp fs / afs / write . c \nint afs_prepare_write ( struct file * file , struct page * page , \n_leave (\" = % d [ prep ]\", ret ); \nreturn ret ; \n} \n- SetPageUptodate ( page ); \n} \n \ntry_again : \nint afs_commit_write ( struct file * file , struct page * page , \nspin_unlock (& vnode -> writeback_lock ); \n} \n \n+ SetPageUptodate ( page ); \nset_page_dirty ( page ); \n- \nif ( PageDirty ( page )) \n_debug (\" dirtied \"); \n", "mmm fs / xfs / libxfs / xfs_attr_leaf . c \nppp fs / xfs / libxfs / xfs_attr_leaf . c \nxfs_attr_shortform_to_leaf ( \nASSERT ( blkno == 0 ); \nerror = xfs_attr3_leaf_create ( args , blkno , & bp ); \nif ( error ) { \n- error = xfs_da_shrink_inode ( args , 0 , bp ); \n- bp = NULL ; \n- if ( error ) \n+ /* xfs_attr3_leaf_create may not have instantiated a block */ \n+ if ( bp && ( xfs_da_shrink_inode ( args , 0 , bp ) != 0 )) \ngoto out ; \nxfs_idata_realloc ( dp , size , XFS_ATTR_FORK ); /* try to put */ \nmemcpy ( ifp -> if_u1 . if_data , tmpbuffer , size ); /* it back */", "mmm mm / memcontrol . c \nppp mm / memcontrol . c \nstatic int mem_cgroup_resize_max ( struct mem_cgroup * memcg , \nunsigned long max , bool memsw ) \n{ \nbool enlarge = false ; \n+ bool drained = false ; \nint ret ; \nbool limits_invariant ; \nstruct page_counter * counter = memsw ? & memcg -> memsw : & memcg -> memory ; \nstatic int mem_cgroup_resize_max ( struct mem_cgroup * memcg , \nif (! ret ) \nbreak ; \n \n+ if (! drained ) { \n+ drain_all_stock ( memcg ); \n+ drained = true ; \n+ continue ; \n+ } \n+ \nif (! try_to_free_mem_cgroup_pages ( memcg , 1 , \nGFP_KERNEL , ! memsw )) { \nret = - EBUSY ;", "mmm fs / xfs / xfs_attr_remote . c \nppp fs / xfs / xfs_attr_remote . c \nxfs_attr3_rmt_verify ( \nif ( be32_to_cpu ( rmt -> rm_bytes ) > fsbsize - sizeof (* rmt )) \nreturn false ; \nif ( be32_to_cpu ( rmt -> rm_offset ) + \n- be32_to_cpu ( rmt -> rm_bytes ) >= XATTR_SIZE_MAX ) \n+ be32_to_cpu ( rmt -> rm_bytes ) > XATTR_SIZE_MAX ) \nreturn false ; \nif ( rmt -> rm_owner == 0 ) \nreturn false ;", "mmm drivers / net / ethernet / intel / ixgbe / ixgbe_x550 . c \nppp drivers / net / ethernet / intel / ixgbe / ixgbe_x550 . c \nstatic s32 ixgbe_reset_hw_X550em ( struct ixgbe_hw * hw ) \nhw -> phy . sfp_setup_needed = false ; \n} \n \n+ if ( status == IXGBE_ERR_SFP_NOT_SUPPORTED ) \n+ return status ; \n+ \n/* Reset PHY */ \nif (! hw -> phy . reset_disable && hw -> phy . ops . reset ) \nhw -> phy . ops . reset ( hw );", "mmm fs / hpfs / file . c \nppp fs / hpfs / file . c \nstatic void hpfs_write_failed ( struct address_space * mapping , loff_t to ) \n{ \nstruct inode * inode = mapping -> host ; \n \n+ hpfs_lock ( inode -> i_sb ); \n+ \nif ( to > inode -> i_size ) { \ntruncate_pagecache ( inode , to , inode -> i_size ); \nhpfs_truncate ( inode ); \n} \n+ \n+ hpfs_unlock ( inode -> i_sb ); \n} \n \nstatic int hpfs_write_begin ( struct file * file , struct address_space * mapping ,", "mmm fs / xfs / xfs_super . c \nppp fs / xfs / xfs_super . c \nxfs_fs_remount ( \n \n/* ro -> rw */ \nif (( mp -> m_flags & XFS_MOUNT_RDONLY ) && !(* flags & MS_RDONLY )) { \n+ if ( mp -> m_flags & XFS_MOUNT_NORECOVERY ) { \n+ xfs_warn ( mp , \n+ \" ro -> rw transition prohibited on norecovery mount \"); \n+ return - EINVAL ; \n+ } \n+ \nmp -> m_flags &= ~ XFS_MOUNT_RDONLY ; \n \n/*", "mmm drivers / gpu / drm / amd / display / dc / dcn10 / dcn10_dpp . c \nppp drivers / gpu / drm / amd / display / dc / dcn10 / dcn10_dpp . c \nstatic void dpp1_cm_set_regamma_pwl ( \nstruct dpp * dpp_base , const struct pwl_params * params , enum opp_regamma mode ) \n{ \nstruct dcn10_dpp * dpp = TO_DCN10_DPP ( dpp_base ); \n- uint32_t re_mode ; \n+ uint32_t re_mode = 0 ; \n \nswitch ( mode ) { \ncase OPP_REGAMMA_BYPASS :", "mmm drivers / iommu / intel - svm . c \nppp drivers / iommu / intel - svm . c \nint intel_svm_bind_mm ( struct device * dev , int * pasid , int flags , struct svm_dev_ \npasid_max - 1 , GFP_KERNEL ); \nif ( ret < 0 ) { \nkfree ( svm ); \n+ kfree ( sdev ); \ngoto out ; \n} \nsvm -> pasid = ret ;", "mmm drivers / rpmsg / rpmsg_char . c \nppp drivers / rpmsg / rpmsg_char . c \nstatic ssize_t rpmsg_eptdev_write_iter ( struct kiocb * iocb , \nif (! kbuf ) \nreturn - ENOMEM ; \n \n- if (! copy_from_iter_full ( kbuf , len , from )) \n- return - EFAULT ; \n+ if (! copy_from_iter_full ( kbuf , len , from )) { \n+ ret = - EFAULT ; \n+ goto free_kbuf ; \n+ } \n \nif ( mutex_lock_interruptible (& eptdev -> ept_lock )) { \nret = - ERESTARTSYS ;", "mmm drivers / uwb / uwbd . c \nppp drivers / uwb / uwbd . c \nstatic int uwbd ( void * param ) \n/** Start the UWB daemon */ \nvoid uwbd_start ( struct uwb_rc * rc ) \n{ \n- rc -> uwbd . task = kthread_run ( uwbd , rc , \" uwbd \"); \n- if ( rc -> uwbd . task == NULL ) \n+ struct task_struct * task = kthread_run ( uwbd , rc , \" uwbd \"); \n+ if ( IS_ERR ( task )) { \n+ rc -> uwbd . task = NULL ; \nprintk ( KERN_ERR \" UWB : Cannot start management daemon ; \" \n\" UWB won ' t work \\ n \"); \n- else \n+ } else { \n+ rc -> uwbd . task = task ; \nrc -> uwbd . pid = rc -> uwbd . task -> pid ; \n+ } \n} \n \n/* Stop the UWB daemon and free any unprocessed events */ \nvoid uwbd_stop ( struct uwb_rc * rc ) \n{ \n- kthread_stop ( rc -> uwbd . task ); \n+ if ( rc -> uwbd . task ) \n+ kthread_stop ( rc -> uwbd . task ); \nuwbd_flush ( rc ); \n} \n", "mmm drivers / xen / blkback / vbd . c \nppp drivers / xen / blkback / vbd . c \nint vbd_create ( blkif_t * blkif , blkif_vdev_t handle , unsigned major , \n \nvbd -> pdevice = MKDEV ( major , minor ); \n \n- bdev = open_by_devnum ( vbd -> pdevice , \n- vbd -> readonly ? FMODE_READ : FMODE_WRITE ); \n+ bdev = blkdev_get_by_dev ( vbd -> pdevice , vbd -> readonly ? \n+ FMODE_READ : FMODE_WRITE , NULL ); \n \nif ( IS_ERR ( bdev )) { \nDPRINTK (\" vbd_creat : device % 08x could not be opened .\\ n \",", "mmm net / ipv4 / ip_tunnel_core . c \nppp net / ipv4 / ip_tunnel_core . c \nint iptunnel_xmit ( struct sock * sk , struct rtable * rt , struct sk_buff * skb , \n__be32 src , __be32 dst , __u8 proto , \n__u8 tos , __u8 ttl , __be16 df , bool xnet ) \n{ \n- int pkt_len = skb -> len ; \n+ int pkt_len = skb -> len - skb_inner_network_offset ( skb ); \nstruct iphdr * iph ; \nint err ; \n", "mmm drivers / platform / x86 / hp - wmi . c \nppp drivers / platform / x86 / hp - wmi . c \nstatic int __init hp_wmi_input_setup ( void ) \nint err ; \n \nhp_wmi_input_dev = input_allocate_device (); \n+ if (! hp_wmi_input_dev ) \n+ return - ENOMEM ; \n \nhp_wmi_input_dev -> name = \" HP WMI hotkeys \"; \nhp_wmi_input_dev -> phys = \" wmi / input0 \";", "mmm net / ipv4 / route . c \nppp net / ipv4 / route . c \nstatic int inet_rtm_getroute ( struct sk_buff * in_skb , struct nlmsghdr * nlh , \nif ( rtm -> rtm_flags & RTM_F_LOOKUP_TABLE ) \ntable_id = rt -> rt_table_id ; \n \n- if ( rtm -> rtm_flags & RTM_F_FIB_MATCH ) \n+ if ( rtm -> rtm_flags & RTM_F_FIB_MATCH ) { \n+ if (! res . fi ) { \n+ err = fib_props [ res . type ]. error ; \n+ if (! err ) \n+ err = - EHOSTUNREACH ; \n+ goto errout_free ; \n+ } \nerr = fib_dump_info ( skb , NETLINK_CB ( in_skb ). portid , \nnlh -> nlmsg_seq , RTM_NEWROUTE , table_id , \nrt -> rt_type , res . prefix , res . prefixlen , \nfl4 . flowi4_tos , res . fi , 0 ); \n- else \n+ } else { \nerr = rt_fill_info ( net , dst , src , table_id , & fl4 , skb , \nNETLINK_CB ( in_skb ). portid , nlh -> nlmsg_seq ); \n+ } \nif ( err < 0 ) \ngoto errout_free ; \n", "mmm net / bluetooth / hci_event . c \nppp net / bluetooth / hci_event . c \nstatic void hci_cc_le_set_scan_enable ( struct hci_dev * hdev , \n \nschedule_delayed_work (& hdev -> adv_work , ADV_CLEAR_TIMEOUT ); \n \n- if ( hdev -> discovery . type == DISCOV_TYPE_INTERLEAVED ) { \n+ if ( hdev -> discovery . type == DISCOV_TYPE_INTERLEAVED && \n+ hdev -> discovery . state == DISCOVERY_FINDING ) { \nmgmt_interleaved_discovery ( hdev ); \n} else { \nhci_dev_lock ( hdev );", "mmm drivers / net / ethernet / intel / ixgbe / ixgbe_main . c \nppp drivers / net / ethernet / intel / ixgbe / ixgbe_main . c \nstatic void * ixgbe_fwd_add ( struct net_device * pdev , struct net_device * vdev ) \n( adapter -> num_rx_pools > IXGBE_MAX_MACVLANS )) \nreturn ERR_PTR (- EBUSY ); \n \n- fwd_adapter = kcalloc ( 1 , sizeof ( struct ixgbe_fwd_adapter ), GFP_KERNEL ); \n+ fwd_adapter = kzalloc ( sizeof (* fwd_adapter ), GFP_KERNEL ); \nif (! fwd_adapter ) \nreturn ERR_PTR (- ENOMEM ); \n", "mmm drivers / media / rc / ir - lirc - codec . c \nppp drivers / media / rc / ir - lirc - codec . c \nstatic long ir_lirc_ioctl ( struct file * filep , unsigned int cmd , \nval ); \n \ncase LIRC_SET_REC_CARRIER_RANGE : \n+ if (! dev -> s_rx_carrier_range ) \n+ return - ENOTTY ; \n+ \nif ( val <= 0 ) \nreturn - EINVAL ; \n \nstatic long ir_lirc_ioctl ( struct file * filep , unsigned int cmd , \nbreak ; \n \ncase LIRC_SET_REC_TIMEOUT_REPORTS : \n+ if (! dev -> timeout ) \n+ return - ENOTTY ; \n+ \nlirc -> send_timeout_reports = !! val ; \nbreak ; \n", "mmm drivers / staging / media / imx / imx - media - capture . c \nppp drivers / staging / media / imx / imx - media - capture . c \nstatic int vidioc_querycap ( struct file * file , void * fh , \n{ \nstruct capture_priv * priv = video_drvdata ( file ); \n \n- strncpy ( cap -> driver , \" imx - media - capture \", sizeof ( cap -> driver ) - 1 ); \n- strncpy ( cap -> card , \" imx - media - capture \", sizeof ( cap -> card ) - 1 ); \n+ strlcpy ( cap -> driver , \" imx - media - capture \", sizeof ( cap -> driver )); \n+ strlcpy ( cap -> card , \" imx - media - capture \", sizeof ( cap -> card )); \nsnprintf ( cap -> bus_info , sizeof ( cap -> bus_info ), \n\" platform :% s \", priv -> src_sd -> name ); \n", "mmm drivers / gpu / drm / radeon / radeon_display . c \nppp drivers / gpu / drm / radeon / radeon_display . c \nstatic void radeon_compute_pll_legacy ( struct radeon_pll * pll , \nmax_fractional_feed_div = pll -> max_frac_feedback_div ; \n} \n \n- for ( post_div = min_post_div ; post_div <= max_post_div ; ++ post_div ) { \n+ for ( post_div = max_post_div ; post_div >= min_post_div ; -- post_div ) { \nuint32_t ref_div ; \n \nif (( pll -> flags & RADEON_PLL_NO_ODD_POST_DIV ) && ( post_div & 1 ))", "mmm tools / hv / hv_kvp_daemon . c \nppp tools / hv / hv_kvp_daemon . c \nint main ( void ) \npfd . fd = fd ; \n \nwhile ( 1 ) { \n+ struct sockaddr * addr_p = ( struct sockaddr *) & addr ; \n+ socklen_t addr_l = sizeof ( addr ); \npfd . events = POLLIN ; \npfd . revents = 0 ; \npoll (& pfd , 1 , - 1 ); \n \n- len = recv ( fd , kvp_recv_buffer , sizeof ( kvp_recv_buffer ), 0 ); \n+ len = recvfrom ( fd , kvp_recv_buffer , sizeof ( kvp_recv_buffer ), 0 , \n+ addr_p , & addr_l ); \n \n- if ( len < 0 ) { \n- syslog ( LOG_ERR , \" recv failed ; error :% d \", len ); \n+ if ( len < 0 || addr . nl_pid ) { \n+ syslog ( LOG_ERR , \" recvfrom failed ; pid :% u error :% d % s \", \n+ addr . nl_pid , errno , strerror ( errno )); \nclose ( fd ); \nreturn - 1 ; \n}", "mmm drivers / scsi / scsi_scan . c \nppp drivers / scsi / scsi_scan . c \nstatic int scsi_report_lun_scan ( struct scsi_target * starget , int bflags , \nout_err : \nkfree ( lun_data ); \nout : \n- scsi_device_put ( sdev ); \nif ( scsi_device_created ( sdev )) \n/* \n* the sdev we used didn ' t appear in the report luns scan \n*/ \n__scsi_remove_device ( sdev ); \n+ scsi_device_put ( sdev ); \nreturn ret ; \n} \n", "mmm net / core / pktgen . c \nppp net / core / pktgen . c \nstatic void spin ( struct pktgen_dev * pkt_dev , ktime_t spin_until ) \nhrtimer_set_expires (& t . timer , spin_until ); \n \nremaining = ktime_to_ns ( hrtimer_expires_remaining (& t . timer )); \n- if ( remaining <= 0 ) { \n- pkt_dev -> next_tx = ktime_add_ns ( spin_until , pkt_dev -> delay ); \n- return ; \n- } \n+ if ( remaining <= 0 ) \n+ goto out ; \n \nstart_time = ktime_get (); \nif ( remaining < 100000 ) { \nstatic void spin ( struct pktgen_dev * pkt_dev , ktime_t spin_until ) \n} \n \npkt_dev -> idle_acc += ktime_to_ns ( ktime_sub ( end_time , start_time )); \n+ out : \npkt_dev -> next_tx = ktime_add_ns ( spin_until , pkt_dev -> delay ); \n+ destroy_hrtimer_on_stack (& t . timer ); \n} \n \nstatic inline void set_pkt_overhead ( struct pktgen_dev * pkt_dev )", "mmm net / xfrm / xfrm_input . c \nppp net / xfrm / xfrm_input . c \nEXPORT_SYMBOL ( xfrm_prepare_input ); \n \nint xfrm_input ( struct sk_buff * skb , int nexthdr , __be32 spi , int encap_type ) \n{ \n+ struct net * net = dev_net ( skb -> dev ); \nint err ; \n__be32 seq ; \nstruct xfrm_state * x ; \nint xfrm_input ( struct sk_buff * skb , int nexthdr , __be32 spi , int encap_type ) \ngoto drop ; \n} \n \n- x = xfrm_state_lookup (& init_net , daddr , spi , nexthdr , family ); \n+ x = xfrm_state_lookup ( net , daddr , spi , nexthdr , family ); \nif ( x == NULL ) { \nXFRM_INC_STATS ( LINUX_MIB_XFRMINNOSTATES ); \nxfrm_audit_state_notfound ( skb , family , spi , seq );", "mmm drivers / virt / vboxguest / vboxguest_linux . c \nppp drivers / virt / vboxguest / vboxguest_linux . c \nstatic long vbg_misc_device_ioctl ( struct file * filp , unsigned int req , \nif (! buf ) \nreturn - ENOMEM ; \n \n- if ( copy_from_user ( buf , ( void *) arg , hdr . size_in )) { \n+ *(( struct vbg_ioctl_hdr *) buf ) = hdr ; \n+ if ( copy_from_user ( buf + sizeof ( hdr ), ( void *) arg + sizeof ( hdr ), \n+ hdr . size_in - sizeof ( hdr ))) { \nret = - EFAULT ; \ngoto out ; \n}", "mmm net / bridge / br_multicast . c \nppp net / bridge / br_multicast . c \nstatic int br_multicast_ipv4_rcv ( struct net_bridge * br , \nif ( unlikely ( ip_fast_csum (( u8 *) iph , iph -> ihl ))) \nreturn - EINVAL ; \n \n- if ( iph -> protocol != IPPROTO_IGMP ) \n+ if ( iph -> protocol != IPPROTO_IGMP ) { \n+ if (( iph -> daddr & IGMP_LOCAL_GROUP_MASK ) != IGMP_LOCAL_GROUP ) \n+ BR_INPUT_SKB_CB ( skb )-> mrouters_only = 1 ; \nreturn 0 ; \n+ } \n \nlen = ntohs ( iph -> tot_len ); \nif ( skb -> len < len || len < ip_hdrlen ( skb ))", "mmm kernel / printk / printk . c \nppp kernel / printk / printk . c \nEXPORT_SYMBOL ( vprintk_emit ); \n \nasmlinkage int vprintk ( const char * fmt , va_list args ) \n{ \n- return vprintk_emit ( 0 , LOGLEVEL_DEFAULT , NULL , 0 , fmt , args ); \n+ return vprintk_func ( fmt , args ); \n} \nEXPORT_SYMBOL ( vprintk ); \n", "mmm drivers / vhost / vhost . c \nppp drivers / vhost / vhost . c \nstatic int translate_desc ( struct vhost_dev * dev , u64 addr , u32 len , \n} \n_iov = iov + ret ; \nsize = reg -> memory_size - addr + reg -> guest_phys_addr ; \n- _iov -> iov_len = min (( u64 ) len , size ); \n+ _iov -> iov_len = min (( u64 ) len - s , size ); \n_iov -> iov_base = ( void __user *)( unsigned long ) \n( reg -> userspace_addr + addr - reg -> guest_phys_addr ); \ns += size ;", "mmm drivers / usb / serial / console . c \nppp drivers / usb / serial / console . c \nstatic struct console usbcons = { \n \nvoid usb_serial_console_disconnect ( struct usb_serial * serial ) \n{ \n- if ( serial -> port [ 0 ] == usbcons_info . port ) { \n+ if ( serial -> port [ 0 ] && serial -> port [ 0 ] == usbcons_info . port ) { \nusb_serial_console_exit (); \nusb_serial_put ( serial ); \n}", "mmm drivers / gpu / drm / nouveau / nouveau_display . c \nppp drivers / gpu / drm / nouveau / nouveau_display . c \nnouveau_framebuffer_init ( struct drm_device * dev , \nreturn - EINVAL ; \n} \n \n+ if ( nvbo -> tile_flags & NOUVEAU_GEM_TILE_NONCONTIG ) { \n+ NV_ERROR ( drm , \" framebuffer requires contiguous bo \\ n \"); \n+ return - EINVAL ; \n+ } \n+ \nif ( nv_device ( drm -> device )-> chipset == 0x50 ) \nnv_fb -> r_format |= ( tile_flags << 8 ); \n", "mmm drivers / staging / batman - adv / aggregation . c \nppp drivers / staging / batman - adv / aggregation . c \nstatic bool can_aggregate_with ( struct batman_packet * new_batman_packet , \n* interface only - we still can aggregate */ \nif (( directlink ) && \n( new_batman_packet -> ttl == 1 ) && \n- ( forw_packet -> if_incoming == if_incoming )) \n+ ( forw_packet -> if_incoming == if_incoming ) && \n+ \n+ /* packets from direct neighbors or \n+ * own secondary interface packets \n+ * (= secondary interface packets in general ) */ \n+ ( batman_packet -> flags & DIRECTLINK || \n+ ( forw_packet -> own && \n+ forw_packet -> if_incoming -> if_num != 0 ))) \nreturn true ; \n- \n} \n \nreturn false ; \nvoid add_bat_packet_to_list ( unsigned char * packet_buff , int packet_len , \n* later on \n*/ \nif ((! own_packet ) && \n- ( atomic_read (& bat_priv -> aggregation_enabled ))) \n+ ( atomic_read (& aggregation_enabled ))) \nsend_time += msecs_to_jiffies ( MAX_AGGREGATION_MS ); \n \nnew_aggregated_packet ( packet_buff , packet_len ,", "mmm drivers / usb / storage / uas . c \nppp drivers / usb / storage / uas . c \nstatic int uas_probe ( struct usb_interface * intf , const struct usb_device_id * id ) \n \nshost -> max_cmd_len = 16 + 252 ; \nshost -> max_id = 1 ; \n+ shost -> max_lun = 256 ; \n+ shost -> max_channel = 0 ; \nshost -> sg_tablesize = udev -> bus -> sg_tablesize ; \n \ndevinfo -> intf = intf ;", "mmm fs / nfs / pnfs . c \nppp fs / nfs / pnfs . c \nvoid pnfs_error_mark_layout_for_return ( struct inode * inode , \nbool return_now = false ; \n \nspin_lock (& inode -> i_lock ); \n+ if (! pnfs_layout_is_valid ( lo )) { \n+ spin_unlock (& inode -> i_lock ); \n+ return ; \n+ } \npnfs_set_plh_return_info ( lo , range . iomode , 0 ); \n/* Block LAYOUTGET */ \nset_bit ( NFS_LAYOUT_RETURN , & lo -> plh_flags );", "mmm drivers / infiniband / core / cma . c \nppp drivers / infiniband / core / cma . c \nstatic struct rdma_id_private * cma_id_from_event ( struct ib_cm_id * cm_id , \nbind_list = cma_ps_find ( rdma_ps_from_service_id ( req . service_id ), \ncma_port_from_service_id ( req . service_id )); \nid_priv = cma_find_listener ( bind_list , cm_id , ib_event , & req , * net_dev ); \n+ if ( IS_ERR ( id_priv )) { \n+ dev_put (* net_dev ); \n+ * net_dev = NULL ; \n+ } \n \nreturn id_priv ; \n}", "mmm sound / aoa / core / snd - aoa - gpio - pmf . c \nppp sound / aoa / core / snd - aoa - gpio - pmf . c \nstatic void pmf_gpio_set_ ## name ( struct gpio_runtime * rt , int on )\\ \n\\ \nif ( unlikely (! rt )) return ; \\ \nrc = pmf_call_function ( rt -> node , # name \"- mute \", & args ); \\ \n- if ( rc ) \\ \n+ if ( rc && rc != - ENODEV ) \\ \nprintk ( KERN_WARNING \" pmf_gpio_set_ \" # name \\ \n\" failed , rc : % d \\ n \", rc ); \\ \nrt -> implementation_private &= ~( 1 << bit ); \\", "mmm drivers / mtd / ubi / fastmap . c \nppp drivers / mtd / ubi / fastmap . c \nstatic int count_fastmap_pebs ( struct ubi_attach_info * ai ) \nlist_for_each_entry ( aeb , & ai -> free , u . list ) \nn ++; \n \n- ubi_rb_for_each_entry ( rb1 , av , & ai -> volumes , rb ) \n+ ubi_rb_for_each_entry ( rb1 , av , & ai -> volumes , rb ) \nubi_rb_for_each_entry ( rb2 , aeb , & av -> root , u . rb ) \nn ++; \n", "mmm fs / btrfs / inode . c \nppp fs / btrfs / inode . c \nstatic noinline int cow_file_range ( struct inode * inode , \nif ( IS_ERR ( trans )) { \nextent_clear_unlock_delalloc ( inode , \n& BTRFS_I ( inode )-> io_tree , \n- start , end , NULL , \n+ start , end , locked_page , \nEXTENT_CLEAR_UNLOCK_PAGE | \nEXTENT_CLEAR_UNLOCK | \nEXTENT_CLEAR_DELALLOC | \nstatic noinline int cow_file_range ( struct inode * inode , \nout_unlock : \nextent_clear_unlock_delalloc ( inode , \n& BTRFS_I ( inode )-> io_tree , \n- start , end , NULL , \n+ start , end , locked_page , \nEXTENT_CLEAR_UNLOCK_PAGE | \nEXTENT_CLEAR_UNLOCK | \nEXTENT_CLEAR_DELALLOC |", "mmm fs / namei . c \nppp fs / namei . c \nint vfs_unlink ( struct inode * dir , struct dentry * dentry ) \nerror = - EBUSY ; \nelse { \nerror = security_inode_unlink ( dir , dentry ); \n- if (! error ) \n+ if (! error ) { \nerror = dir -> i_op -> unlink ( dir , dentry ); \n+ if (! error ) \n+ dentry -> d_inode -> i_flags |= S_DEAD ; \n+ } \n} \nmutex_unlock (& dentry -> d_inode -> i_mutex ); \n \nstatic int vfs_rename_other ( struct inode * old_dir , struct dentry * old_dentry , \nelse \nerror = old_dir -> i_op -> rename ( old_dir , old_dentry , new_dir , new_dentry ); \nif (! error ) { \n+ if ( target ) \n+ target -> i_flags |= S_DEAD ; \nif (!( old_dir -> i_sb -> s_type -> fs_flags & FS_RENAME_DOES_D_MOVE )) \nd_move ( old_dentry , new_dentry ); \n}", "mmm fs / btrfs / volumes . c \nppp fs / btrfs / volumes . c \nint btrfs_balance ( struct btrfs_balance_control * bctl , \nmutex_lock (& fs_info -> balance_mutex ); \natomic_dec (& fs_info -> balance_running ); \n \n+ if ( bctl -> sys . flags & BTRFS_BALANCE_ARGS_CONVERT ) { \n+ fs_info -> num_tolerated_disk_barrier_failures = \n+ btrfs_calc_num_tolerated_disk_barrier_failures ( fs_info ); \n+ } \n+ \nif ( bargs ) { \nmemset ( bargs , 0 , sizeof (* bargs )); \nupdate_ioctl_balance_args ( fs_info , 0 , bargs ); \nint btrfs_balance ( struct btrfs_balance_control * bctl , \n__cancel_balance ( fs_info ); \n} \n \n- if ( bctl -> sys . flags & BTRFS_BALANCE_ARGS_CONVERT ) { \n- fs_info -> num_tolerated_disk_barrier_failures = \n- btrfs_calc_num_tolerated_disk_barrier_failures ( fs_info ); \n- } \n- \nwake_up (& fs_info -> balance_wait_q ); \n \nreturn ret ;", "mmm drivers / net / cassini . c \nppp drivers / net / cassini . c \nstatic int __devinit cas_init_one ( struct pci_dev * pdev , \nINIT_WORK (& cp -> reset_task , cas_reset_task ); \n \n/* Default link parameters */ \n- if ( link_mode >= 0 && link_mode <= 6 ) \n+ if ( link_mode >= 0 && link_mode < 6 ) \ncp -> link_cntl = link_modes [ link_mode ]; \nelse \ncp -> link_cntl = BMCR_ANENABLE ;", "mmm net / sctp / sm_statefuns . c \nppp net / sctp / sm_statefuns . c \nsctp_disposition_t sctp_sf_ootb ( struct net * net , \nreturn sctp_sf_violation_chunklen ( net , ep , asoc , type , arg , \ncommands ); \n \n+ /* Report violation if chunk len overflows */ \n+ ch_end = (( __u8 *) ch ) + SCTP_PAD4 ( ntohs ( ch -> length )); \n+ if ( ch_end > skb_tail_pointer ( skb )) \n+ return sctp_sf_violation_chunklen ( net , ep , asoc , type , arg , \n+ commands ); \n+ \n/* Now that we know we at least have a chunk header , \n* do things that are type appropriate . \n*/ \nsctp_disposition_t sctp_sf_ootb ( struct net * net , \n} \n} \n \n- /* Report violation if chunk len overflows */ \n- ch_end = (( __u8 *) ch ) + SCTP_PAD4 ( ntohs ( ch -> length )); \n- if ( ch_end > skb_tail_pointer ( skb )) \n- return sctp_sf_violation_chunklen ( net , ep , asoc , type , arg , \n- commands ); \n- \nch = ( sctp_chunkhdr_t *) ch_end ; \n} while ( ch_end < skb_tail_pointer ( skb )); \n", "mmm drivers / net / wireless / ti / wlcore / tx . c \nppp drivers / net / wireless / ti / wlcore / tx . c \nstatic int wl1271_prepare_tx_frame ( struct wl1271 * wl , struct wl12xx_vif * wlvif , \nis_wep = ( cipher == WLAN_CIPHER_SUITE_WEP40 ) || \n( cipher == WLAN_CIPHER_SUITE_WEP104 ); \n \n- if ( WARN_ON ( is_wep && wlvif -> default_key != idx )) { \n+ if ( WARN_ON ( is_wep && wlvif && wlvif -> default_key != idx )) { \nret = wl1271_set_default_wep_key ( wl , wlvif , idx ); \nif ( ret < 0 ) \nreturn ret ;", "mmm drivers / gpu / drm / drm_crtc_helper . c \nppp drivers / gpu / drm / drm_crtc_helper . c \nint drm_crtc_helper_set_config ( struct drm_mode_set * set ) \nint count = 0 , ro , fail = 0 ; \nstruct drm_crtc_helper_funcs * crtc_funcs ; \nint ret = 0 ; \n+ int i ; \n \nDRM_DEBUG_KMS (\"\\ n \"); \n \nint drm_crtc_helper_set_config ( struct drm_mode_set * set ) \nif ( ret != 0 ) \ngoto fail ; \n} \n+ DRM_DEBUG_KMS (\" Setting connector DPMS state to on \\ n \"); \n+ for ( i = 0 ; i < set -> num_connectors ; i ++) { \n+ DRM_DEBUG_KMS (\"\\ t [ CONNECTOR :% d :% s ] set DPMS on \\ n \", set -> connectors [ i ]-> base . id , \n+ drm_get_connector_name ( set -> connectors [ i ])); \n+ set -> connectors [ i ]-> dpms = DRM_MODE_DPMS_ON ; \n+ } \n \nkfree ( save_connectors ); \nkfree ( save_encoders );", "mmm drivers / staging / greybus / hd . c \nppp drivers / staging / greybus / hd . c \nstruct gb_host_device * gb_hd_create ( struct gb_hd_driver * driver , \nreturn ERR_PTR (- EINVAL ); \n} \n \n- if ( num_cports == 0 || num_cports > CPORT_ID_MAX ) { \n+ if ( num_cports == 0 || num_cports > CPORT_ID_MAX + 1 ) { \ndev_err ( parent , \" Invalid number of CPorts : % zu \\ n \", num_cports ); \nreturn ERR_PTR (- EINVAL ); \n}", "mmm fs / hfsplus / super . c \nppp fs / hfsplus / super . c \nstatic int hfsplus_sync_fs ( struct super_block * sb , int wait ) \n \nstatic void delayed_sync_fs ( struct work_struct * work ) \n{ \n+ int err ; \nstruct hfsplus_sb_info * sbi ; \n \nsbi = container_of ( work , struct hfsplus_sb_info , sync_work . work ); \nstatic void delayed_sync_fs ( struct work_struct * work ) \nsbi -> work_queued = 0 ; \nspin_unlock (& sbi -> work_lock ); \n \n- hfsplus_sync_fs ( sbi -> alloc_file -> i_sb , 1 ); \n+ err = hfsplus_sync_fs ( sbi -> alloc_file -> i_sb , 1 ); \n+ if ( err ) \n+ printk ( KERN_ERR \" hfs : delayed sync fs err % d \\ n \", err ); \n} \n \nvoid hfsplus_mark_mdb_dirty ( struct super_block * sb )", "mmm drivers / nvdimm / region_devs . c \nppp drivers / nvdimm / region_devs . c \nint nvdimm_has_flush ( struct nd_region * nd_region ) \n{ \nint i ; \n \n- /* no nvdimm == flushing capability unknown */ \n- if ( nd_region -> ndr_mappings == 0 ) \n+ /* no nvdimm or pmem api == flushing capability unknown */ \n+ if ( nd_region -> ndr_mappings == 0 \n+ || ! IS_ENABLED ( CONFIG_ARCH_HAS_PMEM_API )) \nreturn - ENXIO ; \n \nfor ( i = 0 ; i < nd_region -> ndr_mappings ; i ++) {", "mmm samples / bpf / xdpsock_user . c \nppp samples / bpf / xdpsock_user . c \nstatic void kick_tx ( int fd ) \nint ret ; \n \nret = sendto ( fd , NULL , 0 , MSG_DONTWAIT , NULL , 0 ); \n- if ( ret >= 0 || errno == ENOBUFS || errno == EAGAIN ) \n+ if ( ret >= 0 || errno == ENOBUFS || errno == EAGAIN || errno == EBUSY ) \nreturn ; \nlassert ( 0 ); \n}", "mmm crypto / crypto_user_stat . c \nppp crypto / crypto_user_stat . c \nint crypto_reportstat ( struct sk_buff * in_skb , struct nlmsghdr * in_nlh , \ndrop_alg : \ncrypto_mod_put ( alg ); \n \n- if ( err ) \n+ if ( err ) { \n+ kfree_skb ( skb ); \nreturn err ; \n+ } \n \nreturn nlmsg_unicast ( net -> crypto_nlsk , skb , NETLINK_CB ( in_skb ). portid ); \n}", "mmm drivers / gpu / drm / bochs / bochs_fbdev . c \nppp drivers / gpu / drm / bochs / bochs_fbdev . c \nvoid bochs_fbdev_fini ( struct bochs_device * bochs ) \nif ( bochs -> fb . initialized ) \nbochs_fbdev_destroy ( bochs ); \n \n- drm_fb_helper_fini (& bochs -> fb . helper ); \n+ if ( bochs -> fb . helper . fbdev ) \n+ drm_fb_helper_fini (& bochs -> fb . helper ); \n+ \nbochs -> fb . initialized = false ; \n}", "mmm tools / perf / util / annotate . c \nppp tools / perf / util / annotate . c \nint __annotation__scnprintf_samples_period ( struct annotation * notes , \nbool show_freq ) \n{ \nconst char * ev_name = perf_evsel__name ( evsel ); \n- char ref [ 30 ] = \" show reference callgraph , \"; \n+ char buf [ 1024 ], ref [ 30 ] = \" show reference callgraph , \"; \nchar sample_freq_str [ 64 ] = \"\"; \nunsigned long nr_samples = 0 ; \nint nr_members = 1 ; \nint __annotation__scnprintf_samples_period ( struct annotation * notes , \nchar unit ; \nint i ; \n \n- if ( perf_evsel__is_group_event ( evsel )) \n+ if ( perf_evsel__is_group_event ( evsel )) { \n+ perf_evsel__group_desc ( evsel , buf , sizeof ( buf )); \n+ ev_name = buf ; \nnr_members = evsel -> nr_members ; \n+ } \n \nfor ( i = 0 ; i < nr_members ; i ++) { \nstruct sym_hist * ah = annotation__histogram ( notes , evsel -> idx + i );", "mmm drivers / net / usb / rtl8150 . c \nppp drivers / net / usb / rtl8150 . c \nstatic int read_mii_word ( rtl8150_t * dev , u8 phy , __u8 indx , u16 * reg ) \nget_registers ( dev , PHYCNT , 1 , data ); \n} while (( data [ 0 ] & PHY_GO ) && ( i ++ < MII_TIMEOUT )); \n \n- if ( i < MII_TIMEOUT ) { \n+ if ( i <= MII_TIMEOUT ) { \nget_registers ( dev , PHYDAT , 2 , data ); \n* reg = data [ 0 ] | ( data [ 1 ] << 8 ); \nreturn 0 ; \nstatic int write_mii_word ( rtl8150_t * dev , u8 phy , __u8 indx , u16 reg ) \nget_registers ( dev , PHYCNT , 1 , data ); \n} while (( data [ 0 ] & PHY_GO ) && ( i ++ < MII_TIMEOUT )); \n \n- if ( i < MII_TIMEOUT ) \n+ if ( i <= MII_TIMEOUT ) \nreturn 0 ; \nelse \nreturn 1 ;", "mmm tools / perf / util / intel - pt - decoder / intel - pt - decoder . c \nppp tools / perf / util / intel - pt - decoder / intel - pt - decoder . c \nstatic const char * intel_pt_err_msgs [] = { \n \nint intel_pt__strerror ( int code , char * buf , size_t buflen ) \n{ \n- if ( code < 1 || code > INTEL_PT_ERR_MAX ) \n+ if ( code < 1 || code >= INTEL_PT_ERR_MAX ) \ncode = INTEL_PT_ERR_UNK ; \nstrlcpy ( buf , intel_pt_err_msgs [ code ], buflen ); \nreturn 0 ;", "mmm sound / soc / sof / debug . c \nppp sound / soc / sof / debug . c \nstatic ssize_t sof_dfsentry_write ( struct file * file , const char __user * buffer , \n*/ \ndentry = file -> f_path . dentry ; \nif ( strcmp ( dentry -> d_name . name , \" ipc_flood_count \") && \n- strcmp ( dentry -> d_name . name , \" ipc_flood_duration_ms \")) \n- return - EINVAL ; \n+ strcmp ( dentry -> d_name . name , \" ipc_flood_duration_ms \")) { \n+ ret = - EINVAL ; \n+ goto out ; \n+ } \n \nif (! strcmp ( dentry -> d_name . name , \" ipc_flood_duration_ms \")) \nflood_duration_test = true ;", "mmm drivers / media / i2c / s5k5baf . c \nppp drivers / media / i2c / s5k5baf . c \nstatic void s5k5baf_synchronize ( struct s5k5baf * state , int timeout , u16 addr ) \nstatic u16 * s5k5baf_fw_get_seq ( struct s5k5baf * state , u16 seq_id ) \n{ \nstruct s5k5baf_fw * fw = state -> fw ; \n- u16 * data = fw -> data + 2 * fw -> count ; \n+ u16 * data ; \nint i ; \n \nif ( fw == NULL ) \nreturn NULL ; \n \n+ data = fw -> data + 2 * fw -> count ; \n+ \nfor ( i = 0 ; i < fw -> count ; ++ i ) { \nif ( fw -> seq [ i ]. id == seq_id ) \nreturn data + fw -> seq [ i ]. offset ;", "mmm drivers / isdn / hardware / eicon / message . c \nppp drivers / isdn / hardware / eicon / message . c \nstatic byte connect_res ( dword Id , word Number , DIVA_CAPI_ADAPTER * a , \nadd_ai ( plci , & parms [ 5 ]); \nsig_req ( plci , REJECT , 0 ); \n} \n- else if ( Reject == 1 || Reject > 9 ) \n+ else if ( Reject == 1 || Reject >= 9 ) \n{ \nadd_ai ( plci , & parms [ 5 ]); \nsig_req ( plci , HANGUP , 0 );", "mmm sound / pci / rme9652 / hdspm . c \nppp sound / pci / rme9652 / hdspm . c \nstatic void hdspm_set_dds_value ( struct hdspm * hdspm , int rate ) \n{ \nu64 n ; \n \n+ if ( snd_BUG_ON ( rate <= 0 )) \n+ return ; \n+ \nif ( rate >= 112000 ) \nrate /= 4 ; \nelse if ( rate >= 56000 ) \nstatic int hdspm_get_system_sample_rate ( struct hdspm * hdspm ) \n} else { \n/* slave mode , return external sample rate */ \nrate = hdspm_external_sample_rate ( hdspm ); \n+ if (! rate ) \n+ rate = hdspm -> system_sample_rate ; \n} \n} \n \nstatic int snd_hdspm_put_system_sample_rate ( struct snd_kcontrol * kcontrol , \nucontrol ) \n{ \nstruct hdspm * hdspm = snd_kcontrol_chip ( kcontrol ); \n+ int rate = ucontrol -> value . integer . value [ 0 ]; \n \n+ if ( rate < 27000 || rate > 207000 ) \n+ return - EINVAL ; \nhdspm_set_dds_value ( hdspm , ucontrol -> value . integer . value [ 0 ]); \nreturn 0 ; \n}", "mmm drivers / infiniband / hw / nes / nes_cm . c \nppp drivers / infiniband / hw / nes / nes_cm . c \n# include < net / neighbour . h > \n# include < net / route . h > \n# include < net / ip_fib . h > \n+# include < net / tcp . h > \n \n# include \" nes . h \" \n \nstatic int check_seq ( struct nes_cm_node * cm_node , struct tcphdr * tcph , \nrcv_wnd = cm_node -> tcp_cntxt . rcv_wnd ; \nif ( ack_seq != loc_seq_num ) \nerr = 1 ; \n- else if (( seq + rcv_wnd ) < rcv_nxt ) \n+ else if (! between ( seq , rcv_nxt , ( rcv_nxt + rcv_wnd ))) \nerr = 1 ; \nif ( err ) { \nnes_debug ( NES_DBG_CM , \"% s [% u ] create abort for cm_node =% p \"", "mmm drivers / net / ethernet / amd / xgbe / xgbe - desc . c \nppp drivers / net / ethernet / amd / xgbe / xgbe - desc . c \nstatic int xgbe_map_tx_skb ( struct xgbe_channel * channel , struct sk_buff * skb ) \n} \n} \n \n- /* Save the skb address in the last entry */ \n+ /* Save the skb address in the last entry . We always have some data \n+ * that has been mapped so rdata is always advanced past the last \n+ * piece of mapped data - use the entry pointed to by cur_index - 1 . \n+ */ \n+ rdata = XGBE_GET_DESC_DATA ( ring , cur_index - 1 ); \nrdata -> skb = skb ; \n \n/* Save the number of descriptor entries used */", "mmm sound / soc / intel / skylake / skl - topology . c \nppp sound / soc / intel / skylake / skl - topology . c \nstatic int skl_manifest_load ( struct snd_soc_component * cmpnt , \nstruct skl * skl = ebus_to_skl ( ebus ); \nint ret = 0 ; \n \n+ /* proceed only if we have private data defined */ \n+ if ( manifest -> priv . size == 0 ) \n+ return 0 ; \n+ \nminfo = & skl -> skl_sst -> manifest ; \n \nskl_tplg_get_manifest_data ( manifest , bus -> dev , minfo );", "mmm drivers / staging / greybus / module . c \nppp drivers / staging / greybus / module . c \nstatic struct attribute * module_attrs [] = { \n}; \nATTRIBUTE_GROUPS ( module ); \n \n- static void greybus_module_release ( struct device * dev ) \n+ static void gb_module_release ( struct device * dev ) \n{ \nstruct gb_module * module = to_gb_module ( dev ); \n \nstatic void greybus_module_release ( struct device * dev ) \n \nstruct device_type greybus_module_type = { \n. name = \" greybus_module \", \n- . release = greybus_module_release , \n+ . release = gb_module_release , \n}; \n \nstruct module_find {", "mmm arch / powerpc / kernel / ptrace . c \nppp arch / powerpc / kernel / ptrace . c \nstatic void flush_tmregs_to_thread ( struct task_struct * tsk ) \n* in the appropriate thread structures from live . \n*/ \n \n- if ( tsk != current ) \n+ if ((! cpu_has_feature ( CPU_FTR_TM )) || ( tsk != current )) \nreturn ; \n \nif ( MSR_TM_SUSPENDED ( mfmsr ())) {", "mmm drivers / net / ethernet / broadcom / bcmsysport . c \nppp drivers / net / ethernet / broadcom / bcmsysport . c \nstatic int bcm_sysport_init_tx_ring ( struct bcm_sysport_priv * priv , \n \nring -> cbs = kcalloc ( size , sizeof ( struct bcm_sysport_cb ), GFP_KERNEL ); \nif (! ring -> cbs ) { \n+ dma_free_coherent ( kdev , sizeof ( struct dma_desc ), \n+ ring -> desc_cpu , ring -> desc_dma ); \nnetif_err ( priv , hw , priv -> netdev , \" CB allocation failed \\ n \"); \nreturn - ENOMEM ; \n}", "mmm drivers / net / ixgb / ixgb_main . c \nppp drivers / net / ixgb / ixgb_main . c \nixgb_unmap_and_free_tx_resource ( struct ixgb_adapter * adapter , \npci_unmap_page ( pdev , buffer_info -> dma , buffer_info -> length , \nPCI_DMA_TODEVICE ); \n \n+ /* okay to call kfree_skb here instead of kfree_skb_any because \n+ * this is never called in interrupt context */ \nif ( buffer_info -> skb ) \n- dev_kfree_skb_any ( buffer_info -> skb ); \n+ dev_kfree_skb ( buffer_info -> skb ); \n \nbuffer_info -> skb = NULL ; \nbuffer_info -> dma = 0 ; \nixgb_xmit_frame ( struct sk_buff * skb , struct net_device * netdev ) \n} \n \nif ( skb -> len <= 0 ) { \n- dev_kfree_skb_any ( skb ); \n+ dev_kfree_skb ( skb ); \nreturn 0 ; \n} \n \nixgb_xmit_frame ( struct sk_buff * skb , struct net_device * netdev ) \n \ntso = ixgb_tso ( adapter , skb ); \nif ( tso < 0 ) { \n- dev_kfree_skb_any ( skb ); \n+ dev_kfree_skb ( skb ); \nreturn NETDEV_TX_OK ; \n} \n", "mmm net / rds / ib . c \nppp net / rds / ib . c \nstatic int rds_ib_laddr_check ( __be32 addr ) \nret = rdma_bind_addr ( cm_id , ( struct sockaddr *)& sin ); \n/* due to this , we will claim to support iWARP devices unless we \ncheck node_type . */ \n- if ( ret || cm_id -> device -> node_type != RDMA_NODE_IB_CA ) \n+ if ( ret || ! cm_id -> device || \n+ cm_id -> device -> node_type != RDMA_NODE_IB_CA ) \nret = - EADDRNOTAVAIL ; \n \nrdsdebug (\" addr % pI4 ret % d node type % d \\ n \",", "mmm drivers / gpu / drm / virtio / virtgpu_object . c \nppp drivers / gpu / drm / virtio / virtgpu_object . c \nstatic int virtio_gpu_object_shmem_init ( struct virtio_gpu_device * vgdev , \n* since virtio_gpu doesn ' t support dma - buf import from other devices . \n*/ \nshmem -> pages = drm_gem_shmem_get_sg_table (& bo -> base ); \n- if (! shmem -> pages ) { \n+ if ( IS_ERR ( shmem -> pages )) { \ndrm_gem_shmem_unpin (& bo -> base ); \n- return - EINVAL ; \n+ return PTR_ERR ( shmem -> pages ); \n} \n \nif ( use_dma_api ) {", "mmm drivers / tty / tty_io . c \nppp drivers / tty / tty_io . c \nstatic int tty_open ( struct inode * inode , struct file * filp ) \nif ( IS_ERR ( tty )) { \ntty_unlock (); \nmutex_unlock (& tty_mutex ); \n+ tty_driver_kref_put ( driver ); \nreturn PTR_ERR ( tty ); \n} \n}", "mmm drivers / staging / ozwpan / ozcdev . c \nppp drivers / staging / ozwpan / ozcdev . c \nstatic ssize_t oz_cdev_write ( struct file * filp , const char __user * buf , \nstruct oz_app_hdr * app_hdr ; \nstruct oz_serial_ctx * ctx ; \n \n+ if ( count > sizeof ( ei -> data ) - sizeof (* elt ) - sizeof (* app_hdr )) \n+ return - EINVAL ; \n+ \nspin_lock_bh (& g_cdev . lock ); \npd = g_cdev . active_pd ; \nif ( pd )", "mmm drivers / rpmsg / virtio_rpmsg_bus . c \nppp drivers / rpmsg / virtio_rpmsg_bus . c \nstatic int rpmsg_probe ( struct virtio_device * vdev ) \n \nerr = rpmsg_ns_register_device ( rpdev_ns ); \nif ( err ) \n- goto free_vch ; \n+ /* vch will be free in virtio_rpmsg_release_device () */ \n+ goto free_ctrldev ; \n} \n \n/* \nstatic int rpmsg_probe ( struct virtio_device * vdev ) \n \nreturn 0 ; \n \n- free_vch : \n- kfree ( vch ); \nfree_ctrldev : \nrpmsg_virtio_del_ctrl_dev ( rpdev_ctrl ); \nfree_coherent :", "mmm drivers / pcmcia / pcmcia_ioctl . c \nppp drivers / pcmcia / pcmcia_ioctl . c \nstatic int ds_open ( struct inode * inode , struct file * file ) \nsocket_t i = iminor ( inode ); \nstruct pcmcia_socket * s ; \nuser_info_t * user ; \n+ static int warning_printed = 0 ; \n \nds_dbg ( 0 , \" ds_open ( socket % d )\\ n \", i ); \n \nstatic int ds_open ( struct inode * inode , struct file * file ) \ns -> user = user ; \nfile -> private_data = user ; \n \n+ if (! warning_printed ) { \n+ printk ( KERN_INFO \" pcmcia : Detected deprecated PCMCIA ioctl \" \n+ \" usage .\\ n \"); \n+ printk ( KERN_INFO \" pcmcia : This interface will soon be removed from \" \n+ \" the kernel ; please expect breakage unless you upgrade \" \n+ \" to new tools .\\ n \"); \n+ printk ( KERN_INFO \" pcmcia : see http :// www . kernel . org / pub / linux /\" \n+ \" utils / kernel / pcmcia / pcmcia . html for details .\\ n \"); \n+ warning_printed = 1 ; \n+ } \n+ \nif ( s -> pcmcia_state . present ) \nqueue_event ( user , CS_EVENT_CARD_INSERTION ); \nreturn 0 ;", "mmm fs / proc / base . c \nppp fs / proc / base . c \nstatic void proc_flush_task_mnt ( struct vfsmount * mnt , pid_t pid , pid_t tgid ) \ndput ( dentry ); \n} \n \n+ if ( pid == tgid ) \n+ return ; \n+ \nname . name = buf ; \nname . len = snprintf ( buf , sizeof ( buf ), \"% d \", tgid ); \nleader = d_hash_and_lookup ( mnt -> mnt_root , & name );", "mmm drivers / cpufreq / exynos - cpufreq . c \nppp drivers / cpufreq / exynos - cpufreq . c \nstatic int exynos_cpufreq_scale ( unsigned int target_freq ) \nif ( ret ) { \npr_err (\"% s : failed to set cpu voltage to % d \\ n \", \n__func__ , arm_volt ); \n- goto out ; \n+ freqs . new = freqs . old ; \n+ goto post_notify ; \n} \n} \n \nstatic int exynos_cpufreq_scale ( unsigned int target_freq ) \nif ( ret ) { \npr_err (\"% s : failed to set cpu voltage to % d \\ n \", \n__func__ , safe_arm_volt ); \n- goto out ; \n+ freqs . new = freqs . old ; \n+ goto post_notify ; \n} \n} \n \nexynos_info -> set_freq ( old_index , index ); \n \n+ post_notify : \ncpufreq_notify_transition ( policy , & freqs , CPUFREQ_POSTCHANGE ); \n \n+ if ( ret ) \n+ goto out ; \n+ \n/* When the new frequency is lower than current frequency */ \nif (( freqs . new < freqs . old ) || \n(( freqs . new > freqs . old ) && safe_arm_volt )) {", "mmm kernel / signal . c \nppp kernel / signal . c \nenum siginfo_layout siginfo_layout ( int sig , int si_code ) \n[ SIGSEGV ] = { NSIGSEGV , SIL_FAULT }, \n[ SIGBUS ] = { NSIGBUS , SIL_FAULT }, \n[ SIGTRAP ] = { NSIGTRAP , SIL_FAULT }, \n-# if defined ( SIGMET ) && defined ( NSIGEMT ) \n+# if defined ( SIGEMT ) && defined ( NSIGEMT ) \n[ SIGEMT ] = { NSIGEMT , SIL_FAULT }, \n# endif \n[ SIGCHLD ] = { NSIGCHLD , SIL_CHLD },", "mmm drivers / xen / events . c \nppp drivers / xen / events . c \nint evtchn_get ( unsigned int evtchn ) \nstruct irq_info * info ; \nint err = - ENOENT ; \n \n+ if ( evtchn >= NR_EVENT_CHANNELS ) \n+ return - EINVAL ; \n+ \nmutex_lock (& irq_mapping_update_lock ); \n \nirq = evtchn_to_irq [ evtchn ];", "mmm drivers / iommu / amd_iommu . c \nppp drivers / iommu / amd_iommu . c \nstatic void dma_ops_domain_free ( struct dma_ops_domain * dom ) \n \nfree_pagetable (& dom -> domain ); \n \n+ if ( dom -> domain . id ) \n+ domain_id_free ( dom -> domain . id ); \n+ \nkfree ( dom ); \n} \n", "mmm fs / namei . c \nppp fs / namei . c \nstruct file * do_filp_open ( int dfd , const char * pathname , \nmutex_lock (& dir -> d_inode -> i_mutex ); \npath . dentry = lookup_hash (& nd ); \npath . mnt = nd . path . mnt ; \n- __putname ( nd . last . name ); \nfilp = do_last (& nd , & path , open_flag , flag , acc_mode , mode , \npathname , dir , & is_link ); \n+ __putname ( nd . last . name ); \nif ( is_link ) \ngoto do_link ; \nif ( nd . root . mnt )", "mmm fs / xfs / libxfs / xfs_ialloc . c \nppp fs / xfs / libxfs / xfs_ialloc . c \nxfs_dialloc_ag_inobt ( \n \n/* free inodes to the left ? */ \nif ( useleft && trec . ir_freecount ) { \n- rec = trec ; \nxfs_btree_del_cursor ( cur , XFS_BTREE_NOERROR ); \ncur = tcur ; \n \npag -> pagl_leftrec = trec . ir_startino ; \npag -> pagl_rightrec = rec . ir_startino ; \npag -> pagl_pagino = pagino ; \n+ rec = trec ; \ngoto alloc_inode ; \n} \n", "mmm drivers / serial / imx . c \nppp drivers / serial / imx . c \nstatic int serial_imx_probe ( struct platform_device * pdev ) \nif ( pdata && ( pdata -> flags & IMXUART_HAVE_RTSCTS )) \nsport -> have_rtscts = 1 ; \n \n- if ( pdata -> init ) \n- pdata -> init ( pdev ); \n+ if ( pdata -> init ) { \n+ ret = pdata -> init ( pdev ); \n+ if ( ret ) \n+ goto clkput ; \n+ } \n \nuart_add_one_port (& imx_reg , & sport -> port ); \nplatform_set_drvdata ( pdev , & sport -> port ); \n \nreturn 0 ; \n+ clkput : \n+ clk_put ( sport -> clk ); \n+ clk_disable ( sport -> clk ); \nunmap : \niounmap ( sport -> port . membase ); \nfree :", "mmm drivers / char / virtio_console . c \nppp drivers / char / virtio_console . c \nstatic int put_chars ( u32 vtermno , const char * buf , int count ) \n{ \nstruct port * port ; \nstruct scatterlist sg [ 1 ]; \n+ void * data ; \n+ int ret ; \n \nif ( unlikely ( early_put_chars )) \nreturn early_put_chars ( vtermno , buf , count ); \nstatic int put_chars ( u32 vtermno , const char * buf , int count ) \nif (! port ) \nreturn - EPIPE ; \n \n- sg_init_one ( sg , buf , count ); \n- return __send_to_port ( port , sg , 1 , count , ( void *) buf , false ); \n+ data = kmemdup ( buf , count , GFP_ATOMIC ); \n+ if (! data ) \n+ return - ENOMEM ; \n+ \n+ sg_init_one ( sg , data , count ); \n+ ret = __send_to_port ( port , sg , 1 , count , data , false ); \n+ kfree ( data ); \n+ return ret ; \n} \n \n/*", "mmm net / bluetooth / sco . c \nppp net / bluetooth / sco . c \nstatic int sco_sock_getsockopt_old ( struct socket * sock , int optname , char __user \nbreak ; \n} \n \n+ memset (& cinfo , 0 , sizeof ( cinfo )); \ncinfo . hci_handle = sco_pi ( sk )-> conn -> hcon -> handle ; \nmemcpy ( cinfo . dev_class , sco_pi ( sk )-> conn -> hcon -> dev_class , 3 ); \n", "mmm drivers / mfd / palmas . c \nppp drivers / mfd / palmas . c \nstatic int palmas_i2c_probe ( struct i2c_client * i2c , \nret = - ENOMEM ; \ngoto err ; \n} \n+ palmas -> i2c_clients [ i ]-> dev . of_node = of_node_get ( node ); \n} \npalmas -> regmap [ i ] = devm_regmap_init_i2c ( palmas -> i2c_clients [ i ], \n& palmas_regmap_config [ i ]);", "mmm net / tipc / socket . c \nppp net / tipc / socket . c \nstatic int get_name ( struct socket * sock , struct sockaddr * uaddr , \n* socket state flags set \n* ------------ --------- \n* unconnected no read flags \n- * no write flags \n+ * POLLOUT if port is not congested \n* \n* connecting POLLIN / POLLRDNORM if ACK / NACK in rx queue \n* no write flags \nstatic unsigned int poll ( struct file * file , struct socket * sock , \nsock_poll_wait ( file , sk_sleep ( sk ), wait ); \n \nswitch (( int ) sock -> state ) { \n+ case SS_UNCONNECTED : \n+ if (! tipc_sk_port ( sk )-> congested ) \n+ mask |= POLLOUT ; \n+ break ; \ncase SS_READY : \ncase SS_CONNECTED : \nif (! tipc_sk_port ( sk )-> congested )", "mmm drivers / target / target_core_sbc . c \nppp drivers / target / target_core_sbc . c \nsbc_parse_cdb ( struct se_cmd * cmd , struct sbc_ops * ops ) \nbreak ; \ncase VERIFY : \nsize = 0 ; \n+ sectors = transport_get_sectors_10 ( cdb ); \n+ cmd -> t_task_lba = transport_lba_32 ( cdb ); \ncmd -> execute_cmd = sbc_emulate_noop ; \n- break ; \n+ goto check_lba ; \ncase REZERO_UNIT : \ncase SEEK_6 : \ncase SEEK_10 :", "mmm drivers / net / ethernet / qlogic / qlcnic / qlcnic_sriov_common . c \nppp drivers / net / ethernet / qlogic / qlcnic / qlcnic_sriov_common . c \nstatic int qlcnic_sriov_get_vf_acl ( struct qlcnic_adapter * adapter ) \nstruct qlcnic_cmd_args cmd ; \nint ret = 0 ; \n \n+ memset (& cmd , 0 , sizeof ( cmd )); \nret = qlcnic_sriov_alloc_bc_mbx_args (& cmd , QLCNIC_BC_CMD_GET_ACL ); \nif ( ret ) \nreturn ret ; \nstatic int qlcnic_sriov_channel_cfg_cmd ( struct qlcnic_adapter * adapter , u8 cmd_o \nstruct qlcnic_vf_info * vf = & adapter -> ahw -> sriov -> vf_info [ 0 ]; \nint ret ; \n \n+ memset (& cmd , 0 , sizeof ( cmd )); \nif ( qlcnic_sriov_alloc_bc_mbx_args (& cmd , cmd_op )) \nreturn - ENOMEM ; \n \nint qlcnic_sriov_cfg_vf_guest_vlan ( struct qlcnic_adapter * adapter , \nstruct qlcnic_cmd_args cmd ; \nint ret ; \n \n+ memset (& cmd , 0 , sizeof ( cmd )); \nif ( vid == 0 ) \nreturn 0 ; \n", "mmm tools / perf / util / ui / browsers / hists . c \nppp tools / perf / util / ui / browsers / hists . c \nint hists__browse ( struct hists * self , const char * helpline , const char * ev_name ) \n \nswitch ( key ) { \ncase ' a ': \n- if ( browser -> selection -> map == NULL && \n+ if ( browser -> selection -> map == NULL || \nbrowser -> selection -> map -> dso -> annotate_warned ) \ncontinue ; \ngoto do_annotate ;", "mmm drivers / mfd / pm8921 - core . c \nppp drivers / mfd / pm8921 - core . c \nstatic const struct regmap_config ssbi_regmap_config = { \n. reg_write = ssbi_reg_write \n}; \n \n+ static const struct of_device_id pm8921_id_table [] = { \n+ { . compatible = \" qcom , pm8058 \", }, \n+ { . compatible = \" qcom , pm8921 \", }, \n+ { } \n+}; \n+ MODULE_DEVICE_TABLE ( of , pm8921_id_table ); \n+ \nstatic int pm8921_probe ( struct platform_device * pdev ) \n{ \nstruct pm8921 * pmic ; \nstatic struct platform_driver pm8921_driver = { \n. driver = { \n. name = \" pm8921 - core \", \n. owner = THIS_MODULE , \n+ . of_match_table = pm8921_id_table , \n}, \n}; \n", "mmm net / netfilter / nfnetlink . c \nppp net / netfilter / nfnetlink . c \nstatic void nfnetlink_rcv_batch ( struct sk_buff * skb , struct nlmsghdr * nlh , \nnlh = nlmsg_hdr ( skb ); \nerr = 0 ; \n \n- if ( nlmsg_len ( nlh ) < sizeof ( struct nfgenmsg ) || \n- skb -> len < nlh -> nlmsg_len ) { \n- err = - EINVAL ; \n- goto ack ; \n+ if ( nlh -> nlmsg_len < NLMSG_HDRLEN || \n+ skb -> len < nlh -> nlmsg_len || \n+ nlmsg_len ( nlh ) < sizeof ( struct nfgenmsg )) { \n+ nfnl_err_reset (& err_list ); \n+ status |= NFNL_BATCH_FAILURE ; \n+ goto done ; \n} \n \n/* Only requests are handled by the kernel */", "mmm drivers / clk / clk - gpio . c \nppp drivers / clk / clk - gpio . c \nstatic struct clk * of_clk_gpio_delayed_register_get ( \nnum_parents = of_clk_get_parent_count ( data -> node ); \n \nparent_names = kcalloc ( num_parents , sizeof ( char *), GFP_KERNEL ); \n- if (! parent_names ) \n- return ERR_PTR (- ENOMEM ); \n+ if (! parent_names ) { \n+ clk = ERR_PTR (- ENOMEM ); \n+ goto out ; \n+ } \n \nfor ( i = 0 ; i < num_parents ; i ++) \nparent_names [ i ] = of_clk_get_parent_name ( data -> node , i );", "mmm drivers / mailbox / mtk - cmdq - mailbox . c \nppp drivers / mailbox / mtk - cmdq - mailbox . c \nstatic void __exit cmdq_drv_exit ( void ) \n \nsubsys_initcall ( cmdq_drv_init ); \nmodule_exit ( cmdq_drv_exit ); \n+ \n+ MODULE_LICENSE (\" GPL v2 \");", "mmm arch / powerpc / mm / hash_utils_64 . c \nppp arch / powerpc / mm / hash_utils_64 . c \nvoid hash__setup_initial_memory_limit ( phys_addr_t first_memblock_base , \n* non - virtualized 64 - bit hash MMU systems don ' t have a limitation \n* on real mode access . \n* \n- * We also clamp it to 1G to avoid some funky things \n- * such as RTAS bugs etc ... \n+ * For guests on platforms before POWER9 , we clamp the it limit to 1G \n+ * to avoid some funky things such as RTAS bugs etc ... \n*/ \nif (! early_cpu_has_feature ( CPU_FTR_HVMODE )) { \n- ppc64_rma_size = min_t ( u64 , first_memblock_size , 0x40000000 ); \n+ ppc64_rma_size = first_memblock_size ; \n+ if (! early_cpu_has_feature ( CPU_FTR_ARCH_300 )) \n+ ppc64_rma_size = min_t ( u64 , ppc64_rma_size , 0x40000000 ); \n \n/* Finally limit subsequent allocations */ \nmemblock_set_current_limit ( ppc64_rma_size );", "mmm fs / xfs / xfs_vnodeops . c \nppp fs / xfs / xfs_vnodeops . c \nxfs_zero_remaining_bytes ( \nbp = xfs_buf_get_noaddr ( mp -> m_sb . sb_blocksize , \nXFS_IS_REALTIME_INODE ( ip ) ? \nmp -> m_rtdev_targp : mp -> m_ddev_targp ); \n+ if (! bp ) \n+ return XFS_ERROR ( ENOMEM ); \n \nfor ( offset = startoff ; offset <= endoff ; offset = lastoffset + 1 ) { \noffset_fsb = XFS_B_TO_FSBT ( mp , offset );", "mmm lib / rhashtable . c \nppp lib / rhashtable . c \nint rhashtable_walk_start_check ( struct rhashtable_iter * iter ) \nskip ++; \nif ( list == iter -> list ) { \niter -> p = p ; \n- skip = skip ; \n+ iter -> skip = skip ; \ngoto found ; \n} \n}", "mmm drivers / net / ethernet / sun / sunvnet . c \nppp drivers / net / ethernet / sun / sunvnet . c \nvnet_select_queue ( struct net_device * dev , struct sk_buff * skb , \nstruct vnet * vp = netdev_priv ( dev ); \nstruct vnet_port * port = __tx_port_find ( vp , skb ); \n \n+ if ( port == NULL ) \n+ return 0 ; \nreturn port -> q_index ; \n} \n", "mmm lib / kobject_uevent . c \nppp lib / kobject_uevent . c \nint kobject_uevent_env ( struct kobject * kobj , enum kobject_action action , \n/* keys passed in from the caller */ \nif ( envp_ext ) { \nfor ( i = 0 ; envp_ext [ i ]; i ++) { \n- retval = add_uevent_var ( env , envp_ext [ i ]); \n+ retval = add_uevent_var ( env , \"% s \", envp_ext [ i ]); \nif ( retval ) \ngoto exit ; \n}", "mmm kernel / power / snapshot . c \nppp kernel / power / snapshot . c \nstatic struct page * saveable_highmem_page ( struct zone * zone , unsigned long pfn ) \nPageReserved ( page )) \nreturn NULL ; \n \n+ if ( page_is_guard ( page )) \n+ return NULL ; \n+ \nreturn page ; \n} \n \nstatic struct page * saveable_page ( struct zone * zone , unsigned long pfn ) \n&& (! kernel_page_present ( page ) || pfn_is_nosave ( pfn ))) \nreturn NULL ; \n \n+ if ( page_is_guard ( page )) \n+ return NULL ; \n+ \nreturn page ; \n} \n", "mmm arch / metag / kernel / perf / perf_event . c \nppp arch / metag / kernel / perf / perf_event . c \nint metag_pmu_event_set_period ( struct perf_event * event , \nif ( left > ( s64 ) metag_pmu -> max_period ) \nleft = metag_pmu -> max_period ; \n \n- if ( metag_pmu -> write ) \n- metag_pmu -> write ( idx , ( u64 )(- left ) & MAX_PERIOD ); \n+ if ( metag_pmu -> write ) { \n+ local64_set (& hwc -> prev_count , -( s32 ) left ); \n+ metag_pmu -> write ( idx , - left & MAX_PERIOD ); \n+ } \n \nperf_event_update_userpage ( event ); \n \nstatic void metag_pmu_enable_counter ( struct hw_perf_event * event , int idx ) \n* set to a specific value that needs preserving . \n*/ \ntmp |= metag_in32 ( PERF_COUNT ( idx )) & 0x00ffffff ; \n+ else \n+ /* \n+ * Older cores reset the counter on write , so prev_count needs \n+ * resetting too so we can calculate a correct delta . \n+ */ \n+ local64_set (& event -> prev_count , 0 ); \n \nmetag_out32 ( tmp , PERF_COUNT ( idx )); \nunlock :", "mmm net / bluetooth / hci_core . c \nppp net / bluetooth / hci_core . c \nstatic int hci_dev_do_open ( struct hci_dev * hdev ) \n* be able to determine if there is a public address \n* or not . \n* \n+ * In case of user channel usage , it is not important \n+ * if a public address or static random address is \n+ * available . \n+ * \n* This check is only valid for BR / EDR controllers \n* since AMP controllers do not have an address . \n*/ \n- if ( hdev -> dev_type == HCI_BREDR && \n+ if (! test_bit ( HCI_USER_CHANNEL , & hdev -> dev_flags ) && \n+ hdev -> dev_type == HCI_BREDR && \n! bacmp (& hdev -> bdaddr , BDADDR_ANY ) && \n! bacmp (& hdev -> static_addr , BDADDR_ANY )) { \nret = - EADDRNOTAVAIL ;", "mmm kernel / cgroup . c \nppp kernel / cgroup . c \nstatic void cgroup_enable_task_cg_lists ( void ) \n} \n \nvoid cgroup_iter_start ( struct cgroup * cgrp , struct cgroup_iter * it ) \n+ __acquires ( css_set_lock ) \n{ \n/* \n* The first time anyone tries to iterate across a cgroup , \nstruct task_struct * cgroup_iter_next ( struct cgroup * cgrp , \n} \n \nvoid cgroup_iter_end ( struct cgroup * cgrp , struct cgroup_iter * it ) \n+ __releases ( css_set_lock ) \n{ \nread_unlock (& css_set_lock ); \n}", "mmm sound / soc / generic / simple - card . c \nppp sound / soc / generic / simple - card . c \nstatic int asoc_simple_card_probe ( struct platform_device * pdev ) \nsnd_soc_card_set_drvdata ( card , priv ); \n \nret = devm_snd_soc_register_card ( dev , card ); \n- if ( ret >= 0 ) \n- return ret ; \n+ if ( ret < 0 ) \n+ goto err ; \n+ \n+ return 0 ; \nerr : \nasoc_simple_card_clean_reference ( card ); \n", "mmm arch / x86 / xen / mmu . c \nppp arch / x86 / xen / mmu . c \nxmaddr_t arbitrary_virt_to_machine ( void * vaddr ) \n} \nEXPORT_SYMBOL_GPL ( arbitrary_virt_to_machine ); \n \n- void xen_flush_tlb_all ( void ) \n+ static void xen_flush_tlb_all ( void ) \n{ \nstruct mmuext_op * op ; \nstruct multicall_space mcs ;", "mmm drivers / nvme / target / admin - cmd . c \nppp drivers / nvme / target / admin - cmd . c \nstatic void nvmet_execute_identify_ctrl ( struct nvmet_req * req ) \nid -> vid = 0 ; \nid -> ssvid = 0 ; \n \n+ memset ( id -> sn , ' ', sizeof ( id -> sn )); \nbin2hex ( id -> sn , & ctrl -> subsys -> serial , \nmin ( sizeof ( ctrl -> subsys -> serial ), sizeof ( id -> sn ) / 2 )); \nmemcpy_and_pad ( id -> mn , sizeof ( id -> mn ), model , sizeof ( model ) - 1 , ' ');", "mmm arch / arm / plat - mxc / devices . c \nppp arch / arm / plat - mxc / devices . c \nstruct platform_device * __init imx_add_platform_device_dmamask ( \nret = platform_device_add ( pdev ); \nif ( ret ) { \nerr : \n+ if ( dmamask ) \n+ kfree ( pdev -> dev . dma_mask ); \nplatform_device_put ( pdev ); \nreturn ERR_PTR ( ret ); \n}", "mmm net / llc / af_llc . c \nppp net / llc / af_llc . c \nstatic int llc_ui_recvmsg ( struct kiocb * iocb , struct socket * sock , \nint target ; /* Read at least this many bytes */ \nlong timeo ; \n \n+ msg -> msg_namelen = 0 ; \n+ \nlock_sock ( sk ); \ncopied = - ENOTCONN ; \nif ( unlikely ( sk -> sk_type == SOCK_STREAM && sk -> sk_state == TCP_LISTEN ))", "mmm kernel / perf_event . c \nppp kernel / perf_event . c \nstatic int perf_mmap ( struct file * file , struct vm_area_struct * vma ) \nlong user_extra , extra ; \nint ret = 0 ; \n \n+ /* \n+ * Don ' t allow mmap () of inherited per - task counters . This would \n+ * create a performance issue due to all children writing to the \n+ * same buffer . \n+ */ \n+ if ( event -> cpu == - 1 && event -> attr . inherit ) \n+ return - EINVAL ; \n+ \nif (!( vma -> vm_flags & VM_SHARED )) \nreturn - EINVAL ; \n", "mmm drivers / staging / lustre / lustre / llite / file . c \nppp drivers / staging / lustre / lustre / llite / file . c \nint ll_fid2path ( struct inode * inode , void __user * arg ) \nif ( get_user ( pathlen , & gfin -> gf_pathlen )) \nreturn - EFAULT ; \n \n+ if ( pathlen > PATH_MAX ) \n+ return - EINVAL ; \n+ \noutsize = sizeof (* gfout ) + pathlen ; \n \nOBD_ALLOC ( gfout , outsize );", "mmm net / netrom / af_netrom . c \nppp net / netrom / af_netrom . c \nstatic int nr_recvmsg ( struct kiocb * iocb , struct socket * sock , \n} \n \nif ( sax != NULL ) { \n- memset ( sax , 0 , sizeof ( sax )); \n+ memset ( sax , 0 , sizeof (* sax )); \nsax -> sax25_family = AF_NETROM ; \nskb_copy_from_linear_data_offset ( skb , 7 , sax -> sax25_call . ax25_call , \nAX25_ADDR_LEN );", "mmm drivers / staging / frontier / alphatrack . c \nppp drivers / staging / frontier / alphatrack . c \nstatic void usb_alphatrack_disconnect ( struct usb_interface * intf ) \nmutex_unlock (& dev -> mtx ); \nusb_alphatrack_delete ( dev ); \n} else { \n+ atomic_set (& dev -> writes_pending , 0 ); \ndev -> intf = NULL ; \nmutex_unlock (& dev -> mtx ); \n} \n \n- atomic_set (& dev -> writes_pending , 0 ); \nmutex_unlock (& disconnect_mutex ); \n \ndev_info (& intf -> dev , \" Alphatrack Surface #% d now disconnected \\ n \",", "mmm drivers / net / wireless / ath / ath10k / wmi - tlv . c \nppp drivers / net / wireless / ath / ath10k / wmi - tlv . c \nath10k_wmi_tlv_op_gen_start_scan ( struct ath10k * ar , \nbssid_len = arg -> n_bssids * sizeof ( struct wmi_mac_addr ); \nie_len = roundup ( arg -> ie_len , 4 ); \nlen = ( sizeof (* tlv ) + sizeof (* cmd )) + \n- ( arg -> n_channels ? sizeof (* tlv ) + chan_len : 0 ) + \n- ( arg -> n_ssids ? sizeof (* tlv ) + ssid_len : 0 ) + \n- ( arg -> n_bssids ? sizeof (* tlv ) + bssid_len : 0 ) + \n- ( arg -> ie_len ? sizeof (* tlv ) + ie_len : 0 ); \n+ sizeof (* tlv ) + chan_len + \n+ sizeof (* tlv ) + ssid_len + \n+ sizeof (* tlv ) + bssid_len + \n+ sizeof (* tlv ) + ie_len ; \n \nskb = ath10k_wmi_alloc_skb ( ar , len ); \nif (! skb )", "mmm drivers / mfd / mfd - core . c \nppp drivers / mfd / mfd - core . c \nstatic int mfd_add_device ( struct platform_device * parent , \nif ( ret ) \ngoto fail_device ; \n \n- memzero ( res , sizeof ( res )); \n+ memset ( res , 0 , sizeof ( res )); \nfor ( r = 0 ; r < cell -> num_resources ; r ++) { \nres [ r ]. name = cell -> resources [ r ]. name ; \nres [ r ]. flags = cell -> resources [ r ]. flags ;", "mmm kernel / events / uprobes . c \nppp kernel / events / uprobes . c \nint uprobe_write_opcode ( struct mm_struct * mm , unsigned long vaddr , \n \nretry : \n/* Read the page with vaddr into memory */ \n- ret = get_user_pages_remote ( NULL , mm , vaddr , 1 , FOLL_FORCE , & old_page , \n- & vma , NULL ); \n+ ret = get_user_pages_remote ( NULL , mm , vaddr , 1 , \n+ FOLL_FORCE | FOLL_SPLIT , & old_page , & vma , NULL ); \nif ( ret <= 0 ) \nreturn ret ; \n", "mmm fs / f2fs / super . c \nppp fs / f2fs / super . c \nstatic int f2fs_fill_super ( struct super_block * sb , void * data , int silent ) \nint n = ( i == META ) ? 1 : NR_TEMP_TYPE ; \nint j ; \n \n- sbi -> write_io [ i ] = f2fs_kmalloc ( sbi , \n- n * sizeof ( struct f2fs_bio_info ), \n- GFP_KERNEL ); \n+ sbi -> write_io [ i ] = \n+ f2fs_kmalloc ( sbi , \n+ array_size ( n , \n+ sizeof ( struct f2fs_bio_info )), \n+ GFP_KERNEL ); \nif (! sbi -> write_io [ i ]) { \nerr = - ENOMEM ; \ngoto free_options ;", "mmm fs / xfs / xfs_da_btree . c \nppp fs / xfs / xfs_da_btree . c \nxfs_da3_fixhashpath ( \nnode = blk -> bp -> b_addr ; \ndp -> d_ops -> node_hdr_from_disk (& nodehdr , node ); \nbtree = dp -> d_ops -> node_tree_p ( node ); \n- if ( be32_to_cpu ( btree -> hashval ) == lasthash ) \n+ if ( be32_to_cpu ( btree [ blk -> index ]. hashval ) == lasthash ) \nbreak ; \nblk -> hashval = lasthash ; \nbtree [ blk -> index ]. hashval = cpu_to_be32 ( lasthash );", "mmm drivers / media / media - device . c \nppp drivers / media / media - device . c \nstatic long __media_device_enum_links ( struct media_device * mdev , \n \nfor ( p = 0 ; p < entity -> num_pads ; p ++) { \nstruct media_pad_desc pad ; \n+ \n+ memset (& pad , 0 , sizeof ( pad )); \nmedia_device_kpad_to_upad (& entity -> pads [ p ], & pad ); \nif ( copy_to_user (& links -> pads [ p ], & pad , sizeof ( pad ))) \nreturn - EFAULT ; \nstatic long __media_device_enum_links ( struct media_device * mdev , \nif ( entity -> links [ l ]. source -> entity != entity ) \ncontinue ; \n \n+ memset (& link , 0 , sizeof ( link )); \nmedia_device_kpad_to_upad ( entity -> links [ l ]. source , \n& link . source ); \nmedia_device_kpad_to_upad ( entity -> links [ l ]. sink ,", "mmm net / sctp / auth . c \nppp net / sctp / auth . c \nstatic struct sctp_auth_bytes * sctp_auth_create_key ( __u32 key_len , gfp_t gfp ) \nstruct sctp_auth_bytes * key ; \n \n/* Verify that we are not going to overflow INT_MAX */ \n- if (( INT_MAX - key_len ) < sizeof ( struct sctp_auth_bytes )) \n+ if ( key_len > ( INT_MAX - sizeof ( struct sctp_auth_bytes ))) \nreturn NULL ; \n \n/* Allocate the shared key */", "mmm include / linux / kvm_host . h \nppp include / linux / kvm_host . h \nstatic inline struct kvm_vcpu * kvm_get_vcpu_by_id ( struct kvm * kvm , int id ) \nstruct kvm_vcpu * vcpu ; \nint i ; \n \n+ if ( id < 0 || id >= KVM_MAX_VCPUS ) \n+ return NULL ; \n+ vcpu = kvm_get_vcpu ( kvm , id ); \n+ if ( vcpu && vcpu -> vcpu_id == id ) \n+ return vcpu ; \nkvm_for_each_vcpu ( i , vcpu , kvm ) \nif ( vcpu -> vcpu_id == id ) \nreturn vcpu ;", "mmm drivers / net / ethernet / ibm / ibmvnic . c \nppp drivers / net / ethernet / ibm / ibmvnic . c \nstatic int reset_one_sub_crq_queue ( struct ibmvnic_adapter * adapter , \nscrq -> irq = 0 ; \n} \n \n- memset ( scrq -> msgs , 0 , 2 * PAGE_SIZE ); \n+ memset ( scrq -> msgs , 0 , 4 * PAGE_SIZE ); \nscrq -> cur = 0 ; \n \nrc = h_reg_sub_crq ( adapter -> vdev -> unit_address , scrq -> msg_token ,", "mmm net / bluetooth / sco . c \nppp net / bluetooth / sco . c \nstatic int sco_sock_recvmsg ( struct kiocb * iocb , struct socket * sock , \ntest_bit ( BT_SK_DEFER_SETUP , & bt_sk ( sk )-> flags )) { \nhci_conn_accept ( pi -> conn -> hcon , 0 ); \nsk -> sk_state = BT_CONFIG ; \n+ msg -> msg_namelen = 0 ; \n \nrelease_sock ( sk ); \nreturn 0 ;", "mmm net / dsa / dsa . c \nppp net / dsa / dsa . c \nstatic int dsa_of_probe ( struct device * dev ) \ncontinue ; \n \ncd -> sw_addr = be32_to_cpup ( sw_addr ); \n- if ( cd -> sw_addr > PHY_MAX_ADDR ) \n+ if ( cd -> sw_addr >= PHY_MAX_ADDR ) \ncontinue ; \n \nif (! of_property_read_u32 ( child , \" eeprom - length \", & eeprom_len ))", "mmm kernel / sched / core . c \nppp kernel / sched / core . c \nvoid partition_sched_domains ( int ndoms_new , cpumask_var_t doms_new [], \n; \n} \n \n+ n = ndoms_cur ; \nif ( doms_new == NULL ) { \n- ndoms_cur = 0 ; \n+ n = 0 ; \ndoms_new = & fallback_doms ; \ncpumask_andnot ( doms_new [ 0 ], cpu_active_mask , cpu_isolated_map ); \nWARN_ON_ONCE ( dattr_new ); \nvoid partition_sched_domains ( int ndoms_new , cpumask_var_t doms_new [], \n \n/* Build new domains */ \nfor ( i = 0 ; i < ndoms_new ; i ++) { \n- for ( j = 0 ; j < ndoms_cur && ! new_topology ; j ++) { \n+ for ( j = 0 ; j < n && ! new_topology ; j ++) { \nif ( cpumask_equal ( doms_new [ i ], doms_cur [ j ]) \n&& dattrs_equal ( dattr_new , i , dattr_cur , j )) \ngoto match2 ;", "mmm drivers / mmc / core / sdio_cis . c \nppp drivers / mmc / core / sdio_cis . c \nstatic int sdio_read_cis ( struct mmc_card * card , struct sdio_func * func ) \nif ( tpl_code == 0xff ) \nbreak ; \n \n+ /* null entries have no link field or data */ \n+ if ( tpl_code == 0x00 ) \n+ continue ; \n+ \nret = mmc_io_rw_direct ( card , 0 , 0 , ptr ++, 0 , & tpl_link ); \nif ( ret ) \nbreak ;", "mmm drivers / net / irda / w83977af_ir . c \nppp drivers / net / irda / w83977af_ir . c \nstatic netdev_tx_t w83977af_hard_xmit ( struct sk_buff * skb , \n \nmtt = irda_get_mtt ( skb ); \npr_debug (\"% s (% ld ), mtt =% d \\ n \", __func__ , jiffies , mtt ); \n- if ( mtt ) \n+ if ( mtt > 1000 ) \n+ mdelay ( mtt / 1000 ); \n+ else if ( mtt ) \nudelay ( mtt ); \n \n/* Enable DMA interrupt */", "mmm drivers / net / wireless / iwlwifi / mvm / fw . c \nppp drivers / net / wireless / iwlwifi / mvm / fw . c \nint iwl_mvm_rx_card_state_notif ( struct iwl_mvm * mvm , \n( flags & CT_KILL_CARD_DISABLED ) ? \n\" Reached \" : \" Not reached \"); \n \n- if ( flags & CARD_DISABLED_MSK ) \n- iwl_write32 ( mvm -> trans , CSR_UCODE_DRV_GP1_SET , \n- CSR_UCODE_DRV_GP1_BIT_CMD_BLOCKED ); \n- \nreturn 0 ; \n} \n", "mmm fs / xfs / xfs_super . c \nppp fs / xfs / xfs_super . c \nxfs_fs_fill_super ( \nout_close_devices : \nxfs_close_devices ( mp ); \nout_free_fsname : \n+ sb -> s_fs_info = NULL ; \nxfs_free_fsname ( mp ); \nkfree ( mp ); \nout : \nxfs_fs_put_super ( \n{ \nstruct xfs_mount * mp = XFS_M ( sb ); \n \n+ /* if -> fill_super failed , we have no mount to tear down */ \n+ if (! sb -> s_fs_info ) \n+ return ; \n+ \nxfs_notice ( mp , \" Unmounting Filesystem \"); \nxfs_filestream_unmount ( mp ); \nxfs_unmountfs ( mp ); \nxfs_fs_put_super ( \nxfs_destroy_percpu_counters ( mp ); \nxfs_destroy_mount_workqueues ( mp ); \nxfs_close_devices ( mp ); \n+ \n+ sb -> s_fs_info = NULL ; \nxfs_free_fsname ( mp ); \nkfree ( mp ); \n} \nxfs_fs_nr_cached_objects ( \nstruct super_block * sb , \nstruct shrink_control * sc ) \n{ \n+ /* Paranoia : catch incorrect calls during mount setup or teardown */ \n+ if ( WARN_ON_ONCE (! sb -> s_fs_info )) \n+ return 0 ; \nreturn xfs_reclaim_inodes_count ( XFS_M ( sb )); \n} \n", "mmm drivers / net / ethernet / netronome / nfp / bpf / cmsg . c \nppp drivers / net / ethernet / netronome / nfp / bpf / cmsg . c \nnfp_bpf_cmsg_wait_reply ( struct nfp_app_bpf * bpf , enum nfp_bpf_cmsg_type type , \nint tag ) \n{ \nstruct sk_buff * skb ; \n- int err ; \n+ int i , err ; \n+ \n+ for ( i = 0 ; i < 50 ; i ++) { \n+ udelay ( 4 ); \n+ skb = nfp_bpf_reply ( bpf , tag ); \n+ if ( skb ) \n+ return skb ; \n+ } \n \nerr = wait_event_interruptible_timeout ( bpf -> cmsg_wq , \nskb = nfp_bpf_reply ( bpf , tag ),", "mmm block / blk - cgroup . c \nppp block / blk - cgroup . c \nstatic int blkcg_print_stat ( struct seq_file * sf , void * v ) \nstruct cftype blkcg_files [] = { \n{ \n. name = \" stat \", \n+ . flags = CFTYPE_NOT_ON_ROOT , \n. seq_show = blkcg_print_stat , \n}, \n{ } /* terminate */", "mmm kernel / sched . c \nppp kernel / sched . c \nstatic int __build_sched_domains ( const cpumask_t * cpu_map , \nerror : \nfree_sched_groups ( cpu_map , tmpmask ); \nSCHED_CPUMASK_FREE (( void *) allmasks ); \n+ kfree ( rd ); \nreturn - ENOMEM ; \n# endif \n}", "mmm security / keys / keyring . c \nppp security / keys / keyring . c \nvoid __key_link_end ( struct key * keyring , \nif ( index_key -> type == & key_type_keyring ) \nup_write (& keyring_serialise_link_sem ); \n \n- if ( edit && ! edit -> dead_leaf ) { \n- key_payload_reserve ( keyring , \n- keyring -> datalen - KEYQUOTA_LINK_BYTES ); \n+ if ( edit ) { \n+ if (! edit -> dead_leaf ) { \n+ key_payload_reserve ( keyring , \n+ keyring -> datalen - KEYQUOTA_LINK_BYTES ); \n+ } \nassoc_array_cancel_edit ( edit ); \n} \nup_write (& keyring -> sem );", "mmm net / ipv4 / ip_sockglue . c \nppp net / ipv4 / ip_sockglue . c \nstatic void ip_cmsg_recv_checksum ( struct msghdr * msg , struct sk_buff * skb , \nif ( skb -> ip_summed != CHECKSUM_COMPLETE ) \nreturn ; \n \n- if ( offset != 0 ) \n- csum = csum_sub ( csum , \n- csum_partial ( skb_transport_header ( skb ) + tlen , \n- offset , 0 )); \n+ if ( offset != 0 ) { \n+ int tend_off = skb_transport_offset ( skb ) + tlen ; \n+ csum = csum_sub ( csum , skb_checksum ( skb , tend_off , offset , 0 )); \n+ } \n \nput_cmsg ( msg , SOL_IP , IP_CHECKSUM , sizeof ( __wsum ), & csum ); \n}", "mmm drivers / net / ethernet / marvell / skge . c \nppp drivers / net / ethernet / marvell / skge . c \nstatic int skge_down ( struct net_device * dev ) \nstruct skge_hw * hw = skge -> hw ; \nint port = skge -> port ; \n \n- if ( skge -> mem == NULL ) \n+ if (! skge -> mem ) \nreturn 0 ; \n \nnetif_info ( skge , ifdown , skge -> netdev , \" disabling interface \\ n \");", "mmm drivers / pci / hotplug / cpqphp_ctrl . c \nppp drivers / pci / hotplug / cpqphp_ctrl . c \nstatic struct pci_resource * get_max_resource ( struct pci_resource ** head , u32 siz \ntemp = temp -> next ; \n} \n \n- temp -> next = max -> next ; \n+ if ( temp ) \n+ temp -> next = max -> next ; \n} \n \nmax -> next = NULL ;", "mmm drivers / usb / serial / visor . c \nppp drivers / usb / serial / visor . c \nstatic int treo_attach ( struct usb_serial * serial ) \n( serial -> num_interrupt_in == 0 )) \nreturn 0 ; \n \n+ if ( serial -> num_bulk_in < 2 || serial -> num_interrupt_in < 2 ) { \n+ dev_err (& serial -> interface -> dev , \" missing endpoints \\ n \"); \n+ return - ENODEV ; \n+ } \n+ \n/* \n* It appears that Treos and Kyoceras want to use the \n* 1st bulk in endpoint to communicate with the 2nd bulk out endpoint ,", "mmm fs / partitions / ldm . c \nppp fs / partitions / ldm . c \nstatic bool ldm_frag_add ( const u8 * data , int size , struct list_head * frags ) \n \nlist_add_tail (& f -> list , frags ); \nfound : \n+ if ( rec >= f -> num ) { \n+ ldm_error (\" REC value (% d ) exceeds NUM value (% d )\", rec , f -> num ); \n+ return false ; \n+ } \n+ \nif ( f -> map & ( 1 << rec )) { \nldm_error (\" Duplicate VBLK , part % d .\", rec ); \nf -> map &= 0x7F ; /* Mark the group as broken */", "mmm drivers / net / ethernet / intel / igb / igb_main . c \nppp drivers / net / ethernet / intel / igb / igb_main . c \nstatic void igb_reset_q_vector ( struct igb_adapter * adapter , int v_idx ) \n{ \nstruct igb_q_vector * q_vector = adapter -> q_vector [ v_idx ]; \n \n+ /* Coming from igb_set_interrupt_capability , the vectors are not yet \n+ * allocated . So , q_vector is NULL so we should stop here . \n+ */ \n+ if (! q_vector ) \n+ return ; \n+ \nif ( q_vector -> tx . ring ) \nadapter -> tx_ring [ q_vector -> tx . ring -> queue_index ] = NULL ; \n", "mmm drivers / hwmon / xgene - hwmon . c \nppp drivers / hwmon / xgene - hwmon . c \nstatic int xgene_hwmon_remove ( struct platform_device * pdev ) \n{ \nstruct xgene_hwmon_dev * ctx = platform_get_drvdata ( pdev ); \n \n+ cancel_work_sync (& ctx -> workq ); \nhwmon_device_unregister ( ctx -> hwmon_dev ); \nkfifo_free (& ctx -> async_msg_fifo ); \nif ( acpi_disabled )", "mmm net / netfilter / nf_conntrack_netlink . c \nppp net / netfilter / nf_conntrack_netlink . c \nctnetlink_create_conntrack ( struct nlattr * cda [], \nrcu_read_lock (); \nhelper = __nf_ct_helper_find ( rtuple ); \nif ( helper ) { \n- help = nf_ct_helper_ext_add ( ct , GFP_KERNEL ); \n+ help = nf_ct_helper_ext_add ( ct , GFP_ATOMIC ); \nif ( help == NULL ) { \nrcu_read_unlock (); \nerr = - ENOMEM ;", "mmm drivers / scsi / storvsc_drv . c \nppp drivers / scsi / storvsc_drv . c \nstatic int storvsc_queuecommand ( struct Scsi_Host * host , struct scsi_cmnd * scmnd ) \nvm_srb -> data_in = READ_TYPE ; \nvm_srb -> win8_extension . srb_flags |= SRB_FLAGS_DATA_IN ; \nbreak ; \n- default : \n+ case DMA_NONE : \nvm_srb -> data_in = UNKNOWN_TYPE ; \nvm_srb -> win8_extension . srb_flags |= SRB_FLAGS_NO_DATA_TRANSFER ; \nbreak ; \n+ default : \n+ /* \n+ * This is DMA_BIDIRECTIONAL or something else we are never \n+ * supposed to see here . \n+ */ \n+ WARN ( 1 , \" Unexpected data direction : % d \\ n \", \n+ scmnd -> sc_data_direction ); \n+ return - EINVAL ; \n} \n \n", "mmm drivers / bluetooth / btusb . c \nppp drivers / bluetooth / btusb . c \nstatic const struct usb_device_id blacklist_table [] = { \n{ USB_DEVICE ( 0x16d3 , 0x0002 ), \n. driver_info = BTUSB_SNIFFER | BTUSB_BROKEN_ISOC }, \n \n+ /* Marvell Bluetooth devices */ \n+ { USB_DEVICE ( 0x1286 , 0x2044 ), . driver_info = BTUSB_MARVELL }, \n+ { USB_DEVICE ( 0x1286 , 0x2046 ), . driver_info = BTUSB_MARVELL }, \n+ \n/* Intel Bluetooth device */ \n{ USB_DEVICE ( 0x8087 , 0x07dc ), . driver_info = BTUSB_INTEL }, \n{ USB_DEVICE ( 0x8087 , 0x0a2a ), . driver_info = BTUSB_INTEL }, \n{ USB_DEVICE ( 0x8087 , 0x0a2b ), . driver_info = BTUSB_INTEL_NEW }, \n \n- /* Marvell device */ \n- { USB_DEVICE ( 0x1286 , 0x2044 ), . driver_info = BTUSB_MARVELL }, \n- { USB_DEVICE ( 0x1286 , 0x2046 ), . driver_info = BTUSB_MARVELL }, \n \n{ } /* Terminating entry */ \n};", "mmm drivers / net / ethernet / freescale / fman / mac . c \nppp drivers / net / ethernet / freescale / fman / mac . c \nstatic int mac_probe ( struct platform_device * _of_dev ) \npriv -> fixed_link -> duplex = phy -> duplex ; \npriv -> fixed_link -> pause = phy -> pause ; \npriv -> fixed_link -> asym_pause = phy -> asym_pause ; \n+ \n+ put_device (& phy -> mdio . dev ); \n} \n \nerr = mac_dev -> init ( mac_dev );", "mmm drivers / infiniband / core / ucma . c \nppp drivers / infiniband / core / ucma . c \nstatic struct ucma_multicast * ucma_alloc_multicast ( struct ucma_context * ctx ) \nreturn NULL ; \n \nmutex_lock (& mut ); \n- mc -> id = idr_alloc (& multicast_idr , mc , 0 , 0 , GFP_KERNEL ); \n+ mc -> id = idr_alloc (& multicast_idr , NULL , 0 , 0 , GFP_KERNEL ); \nmutex_unlock (& mut ); \nif ( mc -> id < 0 ) \ngoto error ; \nstatic ssize_t ucma_process_join ( struct ucma_file * file , \ngoto err3 ; \n} \n \n+ mutex_lock (& mut ); \n+ idr_replace (& multicast_idr , mc , mc -> id ); \n+ mutex_unlock (& mut ); \n+ \nmutex_unlock (& file -> mut ); \nucma_put_ctx ( ctx ); \nreturn 0 ;", "mmm drivers / sbus / char / envctrl . c \nppp drivers / sbus / char / envctrl . c \nstatic int kenvctrld ( void * __unused ) \nreturn - ENODEV ; \n} \n \n- poll_interval = 5 * HZ ; /* TODO env_mon_interval */ \n+ poll_interval = 5000 ; /* TODO env_mon_interval */ \n \ndaemonize (\" kenvctrld \"); \nallow_signal ( SIGKILL ); \nstatic int kenvctrld ( void * __unused ) \n \nprintk ( KERN_INFO \" envctrl : % s starting ...\\ n \", current -> comm ); \nfor (;;) { \n- current -> state = TASK_INTERRUPTIBLE ; \n- schedule_timeout ( poll_interval ); \n- \n- if ( signal_pending ( current )) \n+ if ( msleep_interruptible ( poll_interval )) \nbreak ; \n \nfor ( whichcpu = 0 ; whichcpu < ENVCTRL_MAX_CPU ; ++ whichcpu ) {", "mmm tools / perf / util / probe - event . c \nppp tools / perf / util / probe - event . c \nstatic struct map * kernel_get_module_map ( const char * module ) \nmodule = \" kernel \"; \n \nfor ( pos = maps__first ( maps ); pos ; pos = map__next ( pos )) { \n+ /* short_name is \"[ module ]\" */ \nif ( strncmp ( pos -> dso -> short_name + 1 , module , \n- pos -> dso -> short_name_len - 2 ) == 0 ) { \n+ pos -> dso -> short_name_len - 2 ) == 0 && \n+ module [ pos -> dso -> short_name_len - 2 ] == '\\ 0 ') { \nreturn pos ; \n} \n}", "mmm kernel / time / timekeeping . c \nppp kernel / time / timekeeping . c \nstatic struct timespec timekeeping_suspend_time ; \n*/ \nstatic void __timekeeping_inject_sleeptime ( struct timespec * delta ) \n{ \n+ if (! timespec_valid ( delta )) { \n+ printk ( KERN_WARN \" __timekeeping_inject_sleeptime : Invalid \" \n+ \" sleep delta value !\\ n \"); \n+ return ; \n+ } \n+ \nxtime = timespec_add ( xtime , * delta ); \nwall_to_monotonic = timespec_sub ( wall_to_monotonic , * delta ); \ntotal_sleep_time = timespec_add ( total_sleep_time , * delta );", "mmm net / rds / tcp . c \nppp net / rds / tcp . c \nstatic void rds_tcp_kill_sock ( struct net * net ) \nlist_for_each_entry_safe ( tc , _tc , & rds_tcp_conn_list , t_tcp_node ) { \nstruct net * c_net = read_pnet (& tc -> t_cpath -> cp_conn -> c_net ); \n \n- if ( net != c_net || ! tc -> t_sock ) \n+ if ( net != c_net ) \ncontinue ; \nif (! list_has_conn (& tmp_list , tc -> t_cpath -> cp_conn )) { \nlist_move_tail (& tc -> t_tcp_node , & tmp_list );", "mmm arch / powerpc / platforms / cell / spufs / sched . c \nppp arch / powerpc / platforms / cell / spufs / sched . c \nvoid spuctx_switch_state ( struct spu_context * ctx , \nnode = spu -> node ; \nif ( old_state == SPU_UTIL_USER ) \natomic_dec (& cbe_spu_info [ node ]. busy_spus ); \n- if ( new_state == SPU_UTIL_USER ); \n+ if ( new_state == SPU_UTIL_USER ) \natomic_inc (& cbe_spu_info [ node ]. busy_spus ); \n} \n}", "mmm crypto / shash . c \nppp crypto / shash . c \nint shash_ahash_finup ( struct ahash_request * req , struct shash_desc * desc ) \nstruct crypto_hash_walk walk ; \nint nbytes ; \n \n- for ( nbytes = crypto_hash_walk_first ( req , & walk ); nbytes > 0 ; \n- nbytes = crypto_hash_walk_done (& walk , nbytes )) \n+ nbytes = crypto_hash_walk_first ( req , & walk ); \n+ if (! nbytes ) \n+ return crypto_shash_final ( desc , req -> result ); \n+ \n+ do { \nnbytes = crypto_hash_walk_last (& walk ) ? \ncrypto_shash_finup ( desc , walk . data , nbytes , \nreq -> result ) : \ncrypto_shash_update ( desc , walk . data , nbytes ); \n+ nbytes = crypto_hash_walk_done (& walk , nbytes ); \n+ } while ( nbytes > 0 ); \n \nreturn nbytes ; \n}", "mmm drivers / mmc / host / meson - gx - mmc . c \nppp drivers / mmc / host / meson - gx - mmc . c \nstatic int meson_mmc_probe ( struct platform_device * pdev ) \n} \n \nirq = platform_get_irq ( pdev , 0 ); \n- if (! irq ) { \n+ if ( irq <= 0 ) { \ndev_err (& pdev -> dev , \" failed to get interrupt resource .\\ n \"); \nret = - EINVAL ; \ngoto free_host ;", "mmm fs / btrfs / ioctl . c \nppp fs / btrfs / ioctl . c \nint btrfs_defrag_file ( struct inode * inode , struct file * file , \n \ndefrag_count += ret ; \nbalance_dirty_pages_ratelimited_nr ( inode -> i_mapping , ret ); \n- i += ret ; \n \nif ( newer_than ) { \nif ( newer_off == ( u64 )- 1 ) \nint btrfs_defrag_file ( struct inode * inode , struct file * file , \nbreak ; \n} \n} else { \n- i ++; \n+ if ( ret > 0 ) \n+ i += ret ; \n+ else \n+ i ++; \n} \n} \n", "mmm kernel / time / timekeeping . c \nppp kernel / time / timekeeping . c \nstatic void tk_setup_internals ( struct timekeeper * tk , struct clocksource * clock ) \ntk -> cycle_interval = interval ; \n \n/* Go back from cycles -> shifted ns */ \n- tk -> xtime_interval = ( u64 ) interval * clock -> mult ; \n+ tk -> xtime_interval = interval * clock -> mult ; \ntk -> xtime_remainder = ntpinterval - tk -> xtime_interval ; \n- tk -> raw_interval = \n- (( u64 ) interval * clock -> mult ) >> clock -> shift ; \n+ tk -> raw_interval = ( interval * clock -> mult ) >> clock -> shift ; \n \n/* if changing clocks , convert xtime_nsec shift units */ \nif ( old_clock ) {", "mmm include / asm - m68k / sun3mmu . h \nppp include / asm - m68k / sun3mmu . h \n# ifndef __SUN3_MMU_H__ \n# define __SUN3_MMU_H__ \n \n+# include < linux / types . h > \n# include < asm / movs . h > \n# include < asm / sun3 - head . h > \n \nstatic inline void sun3_put_context ( unsigned char c ) \nreturn ; \n} \n \n- extern void * sun3_ioremap ( unsigned long phys , unsigned long size , \n+ extern void __iomem * sun3_ioremap ( unsigned long phys , unsigned long size , \nunsigned long type ); \n \nextern int sun3_map_test ( unsigned long addr , char * val );", "mmm drivers / kvm / kvm_main . c \nppp drivers / kvm / kvm_main . c \nstatic long kvm_dev_ioctl ( struct file * filp , \nnum_msrs_to_save * sizeof ( u32 ))) \ngoto out ; \nr = 0 ; \n+ break ; \n} \ndefault : \n;", "mmm fs / dlm / ast . c \nppp fs / dlm / ast . c \nvoid dlm_add_cb ( struct dlm_lkb * lkb , uint32_t flags , int mode , int status , \n \nspin_lock (& dlm_cb_seq_spin ); \nnew_seq = ++ dlm_cb_seq ; \n+ if (! dlm_cb_seq ) \n+ new_seq = ++ dlm_cb_seq ; \nspin_unlock (& dlm_cb_seq_spin ); \n \nif ( lkb -> lkb_flags & DLM_IFL_USER ) {", "mmm drivers / staging / bcm / nvm . c \nppp drivers / staging / bcm / nvm . c \nint BcmGetSectionValEndOffset ( struct bcm_mini_adapter * Adapter , enum bcm_flash2x \ncase CONTROL_SECTION : \n/* Not Clear So Putting failure . confirm and fix it . */ \nSectEndOffset = STATUS_FAILURE ; \n+ break ; \ncase ISO_IMAGE1_PART2 : \nif ( Adapter -> psFlash2xCSInfo -> OffsetISOImage1Part2End != UNINIT_PTR_IN_CS ) \nSectEndOffset = ( Adapter -> psFlash2xCSInfo -> OffsetISOImage1Part2End );", "mmm net / ipv4 / tcp . c \nppp net / ipv4 / tcp . c \nssize_t tcp_splice_read ( struct socket * sock , loff_t * ppos , \nret = - EAGAIN ; \nbreak ; \n} \n+ /* if __tcp_splice_read () got nothing while we have \n+ * an skb in receive queue , we do not want to loop . \n+ * This might happen with URG data . \n+ */ \n+ if (! skb_queue_empty (& sk -> sk_receive_queue )) \n+ break ; \nsk_wait_data ( sk , & timeo , NULL ); \nif ( signal_pending ( current )) { \nret = sock_intr_errno ( timeo );", "mmm drivers / net / ethernet / renesas / ravb_main . c \nppp drivers / net / ethernet / renesas / ravb_main . c \nstatic int ravb_close ( struct net_device * ndev ) \npriv -> phydev = NULL ; \n} \n \n- if ( priv -> chip_id == RCAR_GEN3 ) \n+ if ( priv -> chip_id != RCAR_GEN2 ) { \n+ free_irq ( priv -> tx_irqs [ RAVB_NC ], ndev ); \n+ free_irq ( priv -> rx_irqs [ RAVB_NC ], ndev ); \n+ free_irq ( priv -> tx_irqs [ RAVB_BE ], ndev ); \n+ free_irq ( priv -> rx_irqs [ RAVB_BE ], ndev ); \nfree_irq ( priv -> emac_irq , ndev ); \n+ } \nfree_irq ( ndev -> irq , ndev ); \n \nnapi_disable (& priv -> napi [ RAVB_NC ]);", "mmm arch / x86 / crypto / aesni - intel_glue . c \nppp arch / x86 / crypto / aesni - intel_glue . c \nstatic int __driver_rfc4106_decrypt ( struct aead_request * req ) \nsrc = kmalloc ( req -> cryptlen + req -> assoclen , GFP_ATOMIC ); \nif (! src ) \nreturn - ENOMEM ; \n- assoc = ( src + req -> cryptlen + auth_tag_len ); \n+ assoc = ( src + req -> cryptlen ); \nscatterwalk_map_and_copy ( src , req -> src , 0 , req -> cryptlen , 0 ); \nscatterwalk_map_and_copy ( assoc , req -> assoc , 0 , \nreq -> assoclen , 0 ); \nstatic int __driver_rfc4106_decrypt ( struct aead_request * req ) \nscatterwalk_done (& src_sg_walk , 0 , 0 ); \nscatterwalk_done (& assoc_sg_walk , 0 , 0 ); \n} else { \n- scatterwalk_map_and_copy ( dst , req -> dst , 0 , req -> cryptlen , 1 ); \n+ scatterwalk_map_and_copy ( dst , req -> dst , 0 , tempCipherLen , 1 ); \nkfree ( src ); \n} \nreturn retval ;", "mmm drivers / net / igb / igb_main . c \nppp drivers / net / igb / igb_main . c \nint igb_set_spd_dplx ( struct igb_adapter * adapter , u16 spddplx ) \n \nmac -> autoneg = 0 ; \n \n+ /* Fiber NIC ' s only allow 1000 Gbps Full duplex */ \n+ if (( adapter -> hw . phy . media_type == e1000_media_type_internal_serdes ) && \n+ spddplx != ( SPEED_1000 + DUPLEX_FULL )) { \n+ dev_err (& pdev -> dev , \" Unsupported Speed / Duplex configuration \\ n \"); \n+ return - EINVAL ; \n+ } \n+ \nswitch ( spddplx ) { \ncase SPEED_10 + DUPLEX_HALF : \nmac -> forced_speed_duplex = ADVERTISE_10_HALF ;", "mmm net / kcm / kcmsock . c \nppp net / kcm / kcmsock . c \nstatic int kcm_sendmsg ( struct socket * sock , struct msghdr * msg , size_t len ) \n} else { \n/* Message not complete , save state */ \npartial_message : \n- kcm -> seq_skb = head ; \n- kcm_tx_msg ( head )-> last_skb = skb ; \n+ if ( head ) { \n+ kcm -> seq_skb = head ; \n+ kcm_tx_msg ( head )-> last_skb = skb ; \n+ } \n} \n \nKCM_STATS_ADD ( kcm -> stats . tx_bytes , copied );", "mmm drivers / spi / spi - orion . c \nppp drivers / spi / spi - orion . c \nstatic int orion_spi_transfer_one_message ( struct spi_master * master , \ngoto msg_done ; \n \nlist_for_each_entry ( t , & m -> transfers , transfer_list ) { \n- /* make sure buffer length is even when working in 16 \n- * bit mode */ \n- if (( t -> bits_per_word == 16 ) && ( t -> len & 1 )) { \n- dev_err (& spi -> dev , \n- \" message rejected : \" \n- \" odd data length % d while in 16 bit mode \\ n \", \n- t -> len ); \n- status = - EIO ; \n- goto msg_done ; \n- } \n- \nif ( par_override || t -> speed_hz || t -> bits_per_word ) { \npar_override = 1 ; \nstatus = orion_spi_setup_transfer ( spi , t );", "mmm fs / namespace . c \nppp fs / namespace . c \nstruct vfsmount * collect_mounts ( struct path * path ) \n{ \nstruct mount * tree ; \nnamespace_lock (); \n- tree = copy_tree ( real_mount ( path -> mnt ), path -> dentry , \n- CL_COPY_ALL | CL_PRIVATE ); \n+ if (! check_mnt ( real_mount ( path -> mnt ))) \n+ tree = ERR_PTR (- EINVAL ); \n+ else \n+ tree = copy_tree ( real_mount ( path -> mnt ), path -> dentry , \n+ CL_COPY_ALL | CL_PRIVATE ); \nnamespace_unlock (); \nif ( IS_ERR ( tree )) \nreturn ERR_CAST ( tree );", "mmm drivers / net / wireless / intel / iwlwifi / mvm / sta . c \nppp drivers / net / wireless / intel / iwlwifi / mvm / sta . c \nint iwl_mvm_remove_sta_key ( struct iwl_mvm * mvm , \n \n/* Get the station from the mvm local station table */ \nmvm_sta = iwl_mvm_get_key_sta ( mvm , vif , sta ); \n+ if (! mvm_sta ) { \n+ IWL_ERR ( mvm , \" Failed to find station \\ n \"); \n+ return - EINVAL ; \n+ } \n+ sta_id = mvm_sta -> sta_id ; \n \nIWL_DEBUG_WEP ( mvm , \" mvm remove dynamic key : idx =% d sta =% d \\ n \", \nkeyconf -> keyidx , sta_id ); \nint iwl_mvm_remove_sta_key ( struct iwl_mvm * mvm , \nreturn 0 ; \n} \n \n- sta_id = mvm_sta -> sta_id ; \n- \nret = __iwl_mvm_remove_sta_key ( mvm , sta_id , keyconf , mcast ); \nif ( ret ) \nreturn ret ;", "mmm sound / pci / hda / hda_generic . c \nppp sound / pci / hda / hda_generic . c \nstatic int fill_and_eval_dacs ( struct hda_codec * codec , \nmemset ( spec -> multiout . extra_out_nid , 0 , sizeof ( spec -> multiout . extra_out_nid )); \nspec -> multi_ios = 0 ; \nsnd_array_free (& spec -> paths ); \n+ \n+ /* clear path indices */ \n+ memset ( spec -> out_paths , 0 , sizeof ( spec -> out_paths )); \n+ memset ( spec -> hp_paths , 0 , sizeof ( spec -> hp_paths )); \n+ memset ( spec -> speaker_paths , 0 , sizeof ( spec -> speaker_paths )); \n+ memset ( spec -> aamix_out_paths , 0 , sizeof ( spec -> aamix_out_paths )); \n+ memset ( spec -> digout_paths , 0 , sizeof ( spec -> digout_paths )); \n+ memset ( spec -> loopback_paths , 0 , sizeof ( spec -> loopback_paths )); \n+ memset (& spec -> digin_path , 0 , sizeof ( spec -> digin_path )); \n+ \nbadness = 0 ; \n \n/* fill hard - wired DACs first */", "mmm drivers / gpio / gpio - pch . c \nppp drivers / gpio / gpio - pch . c \nstatic void pch_gpio_setup ( struct pch_gpio * chip ) \nstatic int pch_irq_type ( struct irq_data * d , unsigned int type ) \n{ \nu32 im ; \n- u32 * im_reg ; \n+ u32 __iomem * im_reg ; \nu32 ien ; \nu32 im_pos ; \nint ch ;", "mmm net / sched / sch_netem . c \nppp net / sched / sch_netem . c \nstatic struct sk_buff * netem_dequeue ( struct Qdisc * sch ) \n \n/* if more time remaining ? */ \nif ( cb -> time_to_send <= psched_get_time ()) { \n- skb = qdisc_dequeue_tail ( sch ); \n- if ( unlikely (! skb )) \n- goto qdisc_dequeue ; \n+ __skb_unlink ( skb , & sch -> q ); \n+ sch -> qstats . backlog -= qdisc_pkt_len ( skb ); \n \n# ifdef CONFIG_NET_CLS_ACT \n/* \nstatic struct sk_buff * netem_dequeue ( struct Qdisc * sch ) \nqdisc_watchdog_schedule (& q -> watchdog , cb -> time_to_send ); \n} \n \n- qdisc_dequeue : \nif ( q -> qdisc ) { \nskb = q -> qdisc -> ops -> dequeue ( q -> qdisc ); \nif ( skb )", "mmm block / blk - mq . c \nppp block / blk - mq . c \nstatic void blk_mq_usage_counter_release ( struct percpu_ref * ref ) \n*/ \nvoid blk_mq_freeze_queue ( struct request_queue * q ) \n{ \n+ bool freeze ; \n+ \nspin_lock_irq ( q -> queue_lock ); \n- q -> mq_freeze_depth ++; \n+ freeze = ! q -> mq_freeze_depth ++; \nspin_unlock_irq ( q -> queue_lock ); \n \n- percpu_ref_kill (& q -> mq_usage_counter ); \n- blk_mq_run_queues ( q , false ); \n+ if ( freeze ) { \n+ percpu_ref_kill (& q -> mq_usage_counter ); \n+ blk_mq_run_queues ( q , false ); \n+ } \nwait_event ( q -> mq_freeze_wq , percpu_ref_is_zero (& q -> mq_usage_counter )); \n} \n \nstatic void blk_mq_unfreeze_queue ( struct request_queue * q ) \n{ \n- bool wake = false ; \n+ bool wake ; \n \nspin_lock_irq ( q -> queue_lock ); \nwake = !-- q -> mq_freeze_depth ;", "mmm fs / dcache . c \nppp fs / dcache . c \nstatic int prepend_path ( const struct path * path , \n \nif ( dentry == vfsmnt -> mnt_root || IS_ROOT ( dentry )) { \nstruct mount * parent = ACCESS_ONCE ( mnt -> mnt_parent ); \n+ /* Escaped ? */ \n+ if ( dentry != vfsmnt -> mnt_root ) { \n+ bptr = * buffer ; \n+ blen = * buflen ; \n+ error = 3 ; \n+ break ; \n+ } \n/* Global root ? */ \nif ( mnt != parent ) { \ndentry = ACCESS_ONCE ( mnt -> mnt_mountpoint );", "mmm drivers / net / wireless / brcm80211 / brcmfmac / dhd_linux . c \nppp drivers / net / wireless / brcm80211 / brcmfmac / dhd_linux . c \nvoid brcmf_txflowblock ( struct device * dev , bool state ) \n \nbrcmf_dbg ( TRACE , \" Enter \\ n \"); \n \n- brcmf_fws_bus_blocked ( drvr , state ); \n- \n- for ( i = 0 ; i < BRCMF_MAX_IFS ; i ++) \n- brcmf_txflowblock_if ( drvr -> iflist [ i ], \n- BRCMF_NETIF_STOP_REASON_BLOCK_BUS , state ); \n+ if ( brcmf_fws_fc_active ( drvr -> fws )) { \n+ brcmf_fws_bus_blocked ( drvr , state ); \n+ } else { \n+ for ( i = 0 ; i < BRCMF_MAX_IFS ; i ++) \n+ brcmf_txflowblock_if ( drvr -> iflist [ i ], \n+ BRCMF_NETIF_STOP_REASON_BLOCK_BUS , \n+ state ); \n+ } \n} \n \nvoid brcmf_rx_frames ( struct device * dev , struct sk_buff_head * skb_list )", "mmm drivers / base / platform . c \nppp drivers / base / platform . c \nint platform_device_add ( struct platform_device * pdev ) \nelse \ndev_set_name (& pdev -> dev , pdev -> name ); \n \n- pdev -> platform_data = pdev -> dev . platform_data ; \n+ /* We will remove platform_data field from struct device \n+ * if all platform devices pass its platform specific data \n+ * from platform_device . The conversion is going to be a \n+ * long time , so we allow the two cases coexist to make \n+ * this kind of fix more easily */ \n+ if ( pdev -> platform_data && pdev -> dev . platform_data ) { \n+ printk ( KERN_ERR \n+ \"% s : use which platform_data ?\\ n \", \n+ dev_name (& pdev -> dev )); \n+ } else if ( pdev -> platform_data ) { \n+ pdev -> dev . platform_data = pdev -> platform_data ; \n+ } else if ( pdev -> dev . platform_data ) { \n+ pdev -> platform_data = pdev -> dev . platform_data ; \n+ } \n \nfor ( i = 0 ; i < pdev -> num_resources ; i ++) { \nstruct resource * p , * r = & pdev -> resource [ i ];", "mmm kernel / futex . c \nppp kernel / futex . c \nget_futex_key ( u32 __user * uaddr , int fshared , union futex_key * key , int rw ) \nif ( err < 0 ) \nreturn err ; \n \n+ page = compound_head ( page ); \nlock_page ( page ); \nif (! page -> mapping ) { \nunlock_page ( page );", "mmm arch / arm / mach - exynos / pmu . c \nppp arch / arm / mach - exynos / pmu . c \nstatic void exynos5_powerdown_conf ( enum sys_powerdown mode ) \nvoid exynos_sys_powerdown_conf ( enum sys_powerdown mode ) \n{ \nunsigned int i ; \n+ const struct exynos_pmu_data * pmu_data ; \n+ \n+ if (! pmu_context ) \n+ return ; \n \n- const struct exynos_pmu_data * pmu_data = pmu_context -> pmu_data ; \n+ pmu_data = pmu_context -> pmu_data ; \n \nif ( pmu_data -> powerdown_conf ) \npmu_data -> powerdown_conf ( mode );", "mmm sound / soc / soc - core . c \nppp sound / soc / soc - core . c \nstatic void soc_init_codec_debugfs ( struct snd_soc_codec * codec ) \n{ \nchar codec_root [ 128 ]; \n \n- snprintf ( codec_root , sizeof ( codec_root ), \n- \"% s -% s \", dev_name ( codec -> socdev -> dev ), codec -> name ); \n+ if ( codec -> dev ) \n+ snprintf ( codec_root , sizeof ( codec_root ), \n+ \"% s .% s \", codec -> name , dev_name ( codec -> dev )); \n+ else \n+ snprintf ( codec_root , sizeof ( codec_root ), \n+ \"% s \", codec -> name ); \n \ncodec -> debugfs_codec_root = debugfs_create_dir ( codec_root , \ndebugfs_root );", "mmm drivers / acpi / acpica / evgpeblk . c \nppp drivers / acpi / acpica / evgpeblk . c \nacpi_ev_initialize_gpe_block ( struct acpi_namespace_node * gpe_device , \n \ngpe_index = ( i * ACPI_GPE_REGISTER_WIDTH ) + j ; \ngpe_event_info = & gpe_block -> event_info [ gpe_index ]; \n+ gpe_number = gpe_index + gpe_block -> block_base_number ; \n+ \n+ /* \n+ * If the GPE has already been enabled for runtime \n+ * signaling , make sure it remains enabled , but do not \n+ * increment its reference counter . \n+ */ \n+ if ( gpe_event_info -> runtime_count ) { \n+ acpi_set_gpe ( gpe_device , gpe_number , \n+ ACPI_GPE_ENABLE ); \n+ gpe_enabled_count ++; \n+ continue ; \n+ } \n \nif ( gpe_event_info -> flags & ACPI_GPE_CAN_WAKE ) { \nwake_gpe_count ++; \nacpi_ev_initialize_gpe_block ( struct acpi_namespace_node * gpe_device , \n \n/* Enable this GPE */ \n \n- gpe_number = gpe_index + gpe_block -> block_base_number ; \nstatus = acpi_enable_gpe ( gpe_device , gpe_number , \nACPI_GPE_TYPE_RUNTIME ); \nif ( ACPI_FAILURE ( status )) {", "mmm fs / btrfs / reada . c \nppp fs / btrfs / reada . c \nstatic void __reada_start_machine ( struct btrfs_fs_info * fs_info ) \n \ndo { \nenqueued = 0 ; \n+ mutex_lock (& fs_devices -> device_list_mutex ); \nlist_for_each_entry ( device , & fs_devices -> devices , dev_list ) { \nif ( atomic_read (& device -> reada_in_flight ) < \nMAX_IN_FLIGHT ) \nenqueued += reada_start_machine_dev ( fs_info , \ndevice ); \n} \n+ mutex_unlock (& fs_devices -> device_list_mutex ); \ntotal += enqueued ; \n} while ( enqueued && total < 10000 ); \n", "mmm drivers / atm / solos - pci . c \nppp drivers / atm / solos - pci . c \nstatic void solos_bh ( unsigned long card_arg ) \ncontinue ; \n} \n \n- skb = alloc_skb ( size + 1 , GFP_ATOMIC ); \n+ /* Use netdev_alloc_skb () because it adds NET_SKB_PAD of \n+ * headroom , and ensures we can route packets back out an \n+ * Ethernet interface ( for example ) without having to \n+ * reallocate . Adding NET_IP_ALIGN also ensures that both \n+ * PPPoATM and PPPoEoBR2684 packets end up aligned . */ \n+ skb = netdev_alloc_skb_ip_align ( NULL , size + 1 ); \nif (! skb ) { \nif ( net_ratelimit ()) \ndev_warn (& card -> dev -> dev , \" Failed to allocate sk_buff for RX \\ n \"); \nstatic void solos_bh ( unsigned long card_arg ) \n/* Allocate RX skbs for any ports which need them */ \nif ( card -> using_dma && card -> atmdev [ port ] && \n! card -> rx_skb [ port ]) { \n- struct sk_buff * skb = alloc_skb ( RX_DMA_SIZE , GFP_ATOMIC ); \n+ /* Unlike the MMIO case ( qv ) we can ' t add NET_IP_ALIGN \n+ * here ; the FPGA can only DMA to addresses which are \n+ * aligned to 4 bytes . */ \n+ struct sk_buff * skb = dev_alloc_skb ( RX_DMA_SIZE ); \nif ( skb ) { \nSKB_CB ( skb )-> dma_addr = \ndma_map_single (& card -> dev -> dev , skb -> data ,", "mmm drivers / rtc / rtc - twl . c \nppp drivers / rtc / rtc - twl . c \nstatic int set_rtc_irq_bit ( unsigned char bit ) \nunsigned char val ; \nint ret ; \n \n+ /* if the bit is set , return from here */ \n+ if ( rtc_irq_bits & bit ) \n+ return 0 ; \n+ \nval = rtc_irq_bits | bit ; \nval &= ~ BIT_RTC_INTERRUPTS_REG_EVERY_M ; \nret = twl_rtc_write_u8 ( val , REG_RTC_INTERRUPTS_REG ); \nstatic int mask_rtc_irq_bit ( unsigned char bit ) \nunsigned char val ; \nint ret ; \n \n+ /* if the bit is clear , return from here */ \n+ if (!( rtc_irq_bits & bit )) \n+ return 0 ; \n+ \nval = rtc_irq_bits & ~ bit ; \nret = twl_rtc_write_u8 ( val , REG_RTC_INTERRUPTS_REG ); \nif ( ret == 0 )", "mmm drivers / xen / xen - pciback / vpci . c \nppp drivers / xen / xen - pciback / vpci . c \nstatic int __xen_pcibk_add_pci_dev ( struct xen_pcibk_device * pdev , \n/* Publish this device . */ \nif (! err ) \nerr = publish_cb ( pdev , 0 , 0 , PCI_DEVFN ( slot , func ), devid ); \n+ else \n+ kfree ( dev_entry ); \n \nout : \nreturn err ;", "mmm net / netlink / genetlink . c \nppp net / netlink / genetlink . c \nint genl_register_family ( struct genl_family * family ) \nstart , end + 1 , GFP_KERNEL ); \nif ( family -> id < 0 ) { \nerr = family -> id ; \n- goto errout_locked ; \n+ goto errout_free ; \n} \n \nerr = genl_validate_assign_mc_groups ( family ); \nint genl_register_family ( struct genl_family * family ) \n \nerrout_remove : \nidr_remove (& genl_fam_idr , family -> id ); \n+ errout_free : \nkfree ( family -> attrbuf ); \nerrout_locked : \ngenl_unlock_all ();", "mmm drivers / uwb / uwbd . c \nppp drivers / uwb / uwbd . c \nstatic int uwbd ( void * param ) \nHZ ); \nif ( should_stop ) \nbreak ; \n- try_to_freeze (); \n \nspin_lock_irqsave (& rc -> uwbd . event_list_lock , flags ); \nif (! list_empty (& rc -> uwbd . event_list )) {", "mmm kernel / perf_event . c \nppp kernel / perf_event . c \ninherit_event ( struct perf_event * parent_event , \nstruct perf_event_context * child_ctx ) \n{ \nstruct perf_event * child_event ; \n+ unsigned long flags ; \n \n/* \n* Instead of creating recursive hierarchies of events , \ninherit_event ( struct perf_event * parent_event , \n/* \n* Link it up in the child ' s context : \n*/ \n+ raw_spin_lock_irqsave (& child_ctx -> lock , flags ); \nadd_event_to_ctx ( child_event , child_ctx ); \n+ raw_spin_unlock_irqrestore (& child_ctx -> lock , flags ); \n \n/* \n* Get a reference to the parent filp - we will fput it", "mmm drivers / hid / hid - sensor - hub . c \nppp drivers / hid / hid - sensor - hub . c \nstatic int sensor_hub_probe ( struct hid_device * hdev , \nif ( name == NULL ) { \nhid_err ( hdev , \" Failed MFD device name \\ n \"); \nret = - ENOMEM ; \n+ kfree ( hsdev ); \ngoto err_no_mem ; \n} \nsd -> hid_sensor_hub_client_devs [", "mmm net / openvswitch / flow_netlink . c \nppp net / openvswitch / flow_netlink . c \nstatic struct nlattr * reserve_sfa_size ( struct sw_flow_actions ** sfa , \nnew_acts_size = max ( next_offset + req_size , ksize (* sfa ) * 2 ); \n \nif ( new_acts_size > MAX_ACTIONS_BUFSIZE ) { \n- if (( MAX_ACTIONS_BUFSIZE - next_offset ) < req_size ) { \n+ if (( next_offset + req_size ) > MAX_ACTIONS_BUFSIZE ) { \nOVS_NLERR ( log , \" Flow action size exceeds max % u \", \nMAX_ACTIONS_BUFSIZE ); \nreturn ERR_PTR (- EMSGSIZE );", "mmm drivers / firewire / core - cdev . c \nppp drivers / firewire / core - cdev . c \nstatic int ioctl_send_response ( struct client * client , void * buffer ) \nif ( copy_from_user ( r -> data , u64_to_uptr ( request -> data ), \nr -> length )) { \nret = - EFAULT ; \n+ kfree ( r -> request ); \ngoto out ; \n} \nfw_send_response ( client -> device -> card , r -> request ,", "mmm drivers / crypto / atmel - aes . c \nppp drivers / crypto / atmel - aes . c \nstatic void atmel_aes_get_cap ( struct atmel_aes_dev * dd ) \n \n/* keep only major version number */ \nswitch ( dd -> hw_version & 0xff0 ) { \n+ case 0x200 : \n+ dd -> caps . has_dualbuff = 1 ; \n+ dd -> caps . has_cfb64 = 1 ; \n+ dd -> caps . max_burst_size = 4 ; \n+ break ; \ncase 0x130 : \ndd -> caps . has_dualbuff = 1 ; \ndd -> caps . has_cfb64 = 1 ;", "mmm drivers / gpu / drm / i915 / intel_gvt . c \nppp drivers / gpu / drm / i915 / intel_gvt . c \nint intel_gvt_init ( struct drm_i915_private * dev_priv ) \ngoto bail ; \n} \n \n+ if (! i915 . enable_execlists ) { \n+ DRM_INFO (\" GPU guest virtualisation [ GVT - g ] disabled due to disabled execlist submission [ i915 . enable_execlists module parameter ]\\ n \"); \n+ goto bail ; \n+ } \n+ \n/* \n* We ' re not in host or fail to find a MPT module , disable GVT - g \n*/", "mmm drivers / gpu / drm / amd / display / dc / core / dc_stream . c \nppp drivers / gpu / drm / amd / display / dc / core / dc_stream . c \nbool dc_stream_set_cursor_position ( \n! pipe_ctx -> ipp || ! pipe_ctx -> surface ) \ncontinue ; \n \n+ if ( pipe_ctx -> surface -> public . address . type \n+ == PLN_ADDR_TYPE_VIDEO_PROGRESSIVE ) \n+ pos_cpy . enable = false ; \n+ \nif ( pipe_ctx -> top_pipe && pipe_ctx -> surface != pipe_ctx -> top_pipe -> surface ) \npos_cpy . enable = false ; \n", "mmm drivers / ide / ide - disk . c \nppp drivers / ide / ide - disk . c \nstatic ide_startstop_t __ide_do_rw_disk ( ide_drive_t * drive , struct request * rq , \ncommand = lba48 ? WIN_WRITE_EXT : WIN_WRITE ; \n} \n \n- /* FIXME : -> OUTBSYNC ? */ \n- hwif -> OUTB ( command , IDE_COMMAND_REG ); \n+ hwif -> OUTBSYNC ( drive , command , IDE_COMMAND_REG ); \n \nreturn pre_task_out_intr ( drive , rq ); \n}", "mmm drivers / scsi / ipr . c \nppp drivers / scsi / ipr . c \nstatic void ipr_handle_log_data ( struct ipr_ioa_cfg * ioa_cfg , \n \nif ( ioa_cfg -> log_level < IPR_DEFAULT_LOG_LEVEL ) \nreturn ; \n+ if ( be32_to_cpu ( hostrcb -> hcam . length ) > sizeof ( hostrcb -> hcam . u . raw )) \n+ hostrcb -> hcam . length = cpu_to_be32 ( sizeof ( hostrcb -> hcam . u . raw )); \n \nswitch ( hostrcb -> hcam . overlay_id ) { \n- case IPR_HOST_RCB_OVERLAY_ID_1 : \n- ipr_log_generic_error ( ioa_cfg , hostrcb ); \n- break ; \ncase IPR_HOST_RCB_OVERLAY_ID_2 : \nipr_log_cache_error ( ioa_cfg , hostrcb ); \nbreak ; \nstatic void ipr_handle_log_data ( struct ipr_ioa_cfg * ioa_cfg , \ncase IPR_HOST_RCB_OVERLAY_ID_6 : \nipr_log_array_error ( ioa_cfg , hostrcb ); \nbreak ; \n+ case IPR_HOST_RCB_OVERLAY_ID_1 : \ncase IPR_HOST_RCB_OVERLAY_ID_DEFAULT : \ndefault : \nipr_log_generic_error ( ioa_cfg , hostrcb );", "mmm fs / xfs / xfs_qm . c \nppp fs / xfs / xfs_qm . c \nxfs_qm_dquot_walk ( \nskipped = 0 ; \nbreak ; \n} \n+ /* we ' re done if id overflows back to zero */ \n+ if (! next_index ) \n+ break ; \n} \n \nif ( skipped ) {", "mmm net / ipv4 / tcp_output . c \nppp net / ipv4 / tcp_output . c \nint tcp_fragment ( struct sock * sk , struct sk_buff * skb , u32 len , unsigned int mss \ntp -> fackets_out -= diff ; \nif (( int ) tp -> fackets_out < 0 ) \ntp -> fackets_out = 0 ; \n+ /* SACK fastpath might overwrite it unless dealt with */ \n+ if ( tp -> fastpath_skb_hint != NULL && \n+ after ( TCP_SKB_CB ( tp -> fastpath_skb_hint )-> seq , \n+ TCP_SKB_CB ( skb )-> seq )) { \n+ tp -> fastpath_cnt_hint -= diff ; \n+ if (( int ) tp -> fastpath_cnt_hint < 0 ) \n+ tp -> fastpath_cnt_hint = 0 ; \n+ } \n} \n} \n", "mmm net / core / dev . c \nppp net / core / dev . c \nstruct net_device * alloc_netdev_mq ( int sizeof_priv , const char * name , \nalloc_size = ( sizeof (* dev ) + NETDEV_ALIGN_CONST + \n( sizeof ( struct net_device_subqueue ) * ( queue_count - 1 ))) & \n~ NETDEV_ALIGN_CONST ; \n- alloc_size += sizeof_priv + NETDEV_ALIGN_CONST ; \n+ if ( sizeof_priv ) \n+ alloc_size += sizeof_priv + NETDEV_ALIGN_CONST ; \n \np = kzalloc ( alloc_size , GFP_KERNEL ); \nif (! p ) {", "mmm net / bluetooth / smp . c \nppp net / bluetooth / smp . c \nstatic u8 smp_cmd_pairing_req ( struct l2cap_conn * conn , struct sk_buff * skb ) \n \nif (! test_and_set_bit ( HCI_CONN_LE_SMP_PEND , & conn -> hcon -> flags )) \nsmp = smp_chan_create ( conn ); \n+ else \n+ smp = conn -> smp_chan ; \n \n- smp = conn -> smp_chan ; \n+ if (! smp ) \n+ return SMP_UNSPECIFIED ; \n \nsmp -> preq [ 0 ] = SMP_CMD_PAIRING_REQ ; \nmemcpy (& smp -> preq [ 1 ], req , sizeof (* req ));", "mmm drivers / pinctrl / sh - pfc / pinctrl . c \nppp drivers / pinctrl / sh - pfc / pinctrl . c \nstatic int sh_pfc_dt_node_to_map ( struct pinctrl_dev * pctldev , \nfor_each_child_of_node ( np , child ) { \nret = sh_pfc_dt_subnode_to_map ( pctldev , child , map , num_maps , \n& index ); \n- if ( ret < 0 ) \n+ if ( ret < 0 ) { \n+ of_node_put ( child ); \ngoto done ; \n+ } \n} \n \n/* If no mapping has been found in child nodes try the config node . */", "mmm drivers / media / video / ivtv / ivtv - fileops . c \nppp drivers / media / video / ivtv / ivtv - fileops . c \nunsigned int ivtv_v4l2_dec_poll ( struct file * filp , poll_table * wait ) \nreturn res ; \n} \n \n- unsigned int ivtv_v4l2_enc_poll ( struct file * filp , poll_table * wait ) \n+ unsigned int ivtv_v4l2_enc_poll ( struct file * filp , poll_table * wait ) \n{ \n+ unsigned long req_events = poll_requested_events ( wait ); \nstruct ivtv_open_id * id = fh2id ( filp -> private_data ); \nstruct ivtv * itv = id -> itv ; \nstruct ivtv_stream * s = & itv -> streams [ id -> type ]; \nunsigned int ivtv_v4l2_enc_poll ( struct file * filp , poll_table * wait ) \nunsigned res = 0 ; \n \n/* Start a capture if there is none */ \n- if (! eof && ! test_bit ( IVTV_F_S_STREAMING , & s -> s_flags )) { \n+ if (! eof && ! test_bit ( IVTV_F_S_STREAMING , & s -> s_flags ) && \n+ ( req_events & ( POLLIN | POLLRDNORM ))) { \nint rc ; \n \nrc = ivtv_start_capture ( id );", "mmm drivers / staging / lustre / lustre / llite / llite_lib . c \nppp drivers / staging / lustre / lustre / llite / llite_lib . c \nstruct md_op_data * ll_prep_md_op_data ( struct md_op_data * op_data , \nop_data -> op_default_stripe_offset = - 1 ; \nif ( S_ISDIR ( i1 -> i_mode )) { \nop_data -> op_mea1 = ll_i2info ( i1 )-> lli_lsm_md ; \n- op_data -> op_default_stripe_offset = \n- ll_i2info ( i1 )-> lli_def_stripe_offset ; \n+ if ( opc == LUSTRE_OPC_MKDIR ) \n+ op_data -> op_default_stripe_offset = \n+ ll_i2info ( i1 )-> lli_def_stripe_offset ; \n} \n \nif ( i2 ) {", "mmm drivers / net / wireless / marvell / mwifiex / pcie . c \nppp drivers / net / wireless / marvell / mwifiex / pcie . c \nstatic int mwifiex_pcie_init_evt_ring ( struct mwifiex_adapter * adapter ) \nskb_put ( skb , MAX_EVENT_SIZE ); \n \nif ( mwifiex_map_pci_memory ( adapter , skb , MAX_EVENT_SIZE , \n- PCI_DMA_FROMDEVICE )) \n+ PCI_DMA_FROMDEVICE )) { \n+ kfree_skb ( skb ); \n+ kfree ( card -> evtbd_ring_vbase ); \nreturn - 1 ; \n+ } \n \nbuf_pa = MWIFIEX_SKB_DMA_ADDR ( skb ); \n", "mmm fs / xfs / xfs_inode . c \nppp fs / xfs / xfs_inode . c \nxfs_itruncate_start ( \nmp = ip -> i_mount ; \n \n/* wait for the completion of any pending DIOs */ \n- if ( new_size < ip -> i_size ) \n+ if ( new_size == 0 || new_size < ip -> i_size ) \nvn_iowait ( ip ); \n \n/*", "mmm drivers / staging / ozwpan / ozusbsvc1 . c \nppp drivers / staging / ozwpan / ozusbsvc1 . c \nvoid oz_usb_rx ( struct oz_pd * pd , struct oz_elt * elt ) \ncase OZ_GET_DESC_RSP : { \nstruct oz_get_desc_rsp * body = \n( struct oz_get_desc_rsp *) usb_hdr ; \n- int data_len = elt -> length - \n- sizeof ( struct oz_get_desc_rsp ) + 1 ; \n- u16 offs = le16_to_cpu ( get_unaligned (& body -> offset )); \n- u16 total_size = \n+ u16 offs , total_size ; \n+ u8 data_len ; \n+ \n+ if ( elt -> length < sizeof ( struct oz_get_desc_rsp ) - 1 ) \n+ break ; \n+ data_len = elt -> length - \n+ ( sizeof ( struct oz_get_desc_rsp ) - 1 ); \n+ offs = le16_to_cpu ( get_unaligned (& body -> offset )); \n+ total_size = \nle16_to_cpu ( get_unaligned (& body -> total_size )); \noz_dbg ( ON , \" USB_REQ_GET_DESCRIPTOR - cnf \\ n \"); \noz_hcd_get_desc_cnf ( usb_ctx -> hport , body -> req_id ,", "mmm net / ipv6 / netfilter / nf_conntrack_reasm . c \nppp net / ipv6 / netfilter / nf_conntrack_reasm . c \nfind_prev_fhdr ( struct sk_buff * skb , u8 * prevhdrp , int * prevhoff , int * fhoff ) \nif (! ipv6_ext_hdr ( nexthdr )) { \nreturn - 1 ; \n} \n- if ( len < ( int ) sizeof ( struct ipv6_opt_hdr )) { \n- pr_debug (\" too short \\ n \"); \n- return - 1 ; \n- } \nif ( nexthdr == NEXTHDR_NONE ) { \npr_debug (\" next header is none \\ n \"); \nreturn - 1 ; \n} \n+ if ( len < ( int ) sizeof ( struct ipv6_opt_hdr )) { \n+ pr_debug (\" too short \\ n \"); \n+ return - 1 ; \n+ } \nif ( skb_copy_bits ( skb , start , & hdr , sizeof ( hdr ))) \nBUG (); \nif ( nexthdr == NEXTHDR_AUTH )", "mmm arch / powerpc / mm / pgtable_64 . c \nppp arch / powerpc / mm / pgtable_64 . c \nvoid __iomem * __ioremap ( unsigned long addr , unsigned long size , \npa = addr & PAGE_MASK ; \nsize = PAGE_ALIGN ( addr + size ) - pa ; \n \n- if ( size == 0 ) \n+ if (( size == 0 ) || ( pa == 0 )) \nreturn NULL ; \n \nif ( mem_init_done ) {", "mmm drivers / net / skge . c \nppp drivers / net / skge . c \nstatic void skge_get_regs ( struct net_device * dev , struct ethtool_regs * regs , \n/* Wake on Lan only supported on Yukon chips with rev 1 or above */ \nstatic u32 wol_supported ( const struct skge_hw * hw ) \n{ \n- if ( hw -> chip_id == CHIP_ID_YUKON && hw -> chip_rev != 0 ) \n- return WAKE_MAGIC | WAKE_PHY ; \n- else \n+ if ( hw -> chip_id == CHIP_ID_GENESIS ) \nreturn 0 ; \n+ \n+ if ( hw -> chip_id == CHIP_ID_YUKON && hw -> chip_rev == 0 ) \n+ return 0 ; \n+ \n+ return WAKE_MAGIC | WAKE_PHY ; \n} \n \nstatic u32 pci_wake_enabled ( struct pci_dev * dev )", "mmm Documentation / lguest / lguest . c \nppp Documentation / lguest / lguest . c \nstatic bool service_io ( struct device * dev ) \n} \n} \n \n+ /* OK , so we noted that it was pretty poor to use an fdatasync as a \n+ * barrier . But Christoph Hellwig points out that we need a sync \n+ * * afterwards * as well : \" Barriers specify no reordering to the front \n+ * or the back .\" And Jens Axboe confirmed it , so here we are : */ \n+ if ( out -> type & VIRTIO_BLK_T_BARRIER ) \n+ fdatasync ( vblk -> fd ); \n+ \n/* We can ' t trigger an IRQ , because we ' re not the Launcher . It does \n* that when we tell it we ' re done . */ \nadd_used ( dev -> vq , head , wlen );", "mmm kernel / cgroup / cgroup . c \nppp kernel / cgroup / cgroup . c \nstatic int cgroup_enable_threaded ( struct cgroup * cgrp ) \nif ( cgroup_is_threaded ( cgrp )) \nreturn 0 ; \n \n+ /* \n+ * If @ cgroup is populated or has domain controllers enabled , it \n+ * can ' t be switched . While the below cgroup_can_be_thread_root () \n+ * test can catch the same conditions , that ' s only when @ parent is \n+ * not mixable , so let ' s check it explicitly . \n+ */ \n+ if ( cgroup_is_populated ( cgrp ) || \n+ cgrp -> subtree_control & ~ cgrp_dfl_threaded_ss_mask ) \n+ return - EOPNOTSUPP ; \n+ \n/* we ' re joining the parent ' s domain , ensure its validity */ \nif (! cgroup_is_valid_domain ( dom_cgrp ) || \n! cgroup_can_be_thread_root ( dom_cgrp ))", "mmm drivers / staging / greybus / svc . c \nppp drivers / staging / greybus / svc . c \nstatic void gb_svc_remove_modules ( struct gb_svc * svc ) \n \nvoid gb_svc_del ( struct gb_svc * svc ) \n{ \n- gb_connection_disable ( svc -> connection ); \n+ gb_connection_disable_rx ( svc -> connection ); \n \n/* \n* The SVC device and input device may have been registered \nvoid gb_svc_del ( struct gb_svc * svc ) \nflush_workqueue ( svc -> wq ); \n \ngb_svc_remove_modules ( svc ); \n+ \n+ gb_connection_disable ( svc -> connection ); \n} \n \nvoid gb_svc_put ( struct gb_svc * svc )", "mmm arch / x86 / mm / highmem_32 . c \nppp arch / x86 / mm / highmem_32 . c \nvoid * kmap_atomic_pfn ( unsigned long pfn , enum km_type type ) \n \nreturn ( void *) vaddr ; \n} \n+ EXPORT_SYMBOL_GPL ( kmap_atomic_pfn ); /* temporarily in use by i915 GEM until vmap */ \n \nstruct page * kmap_atomic_to_page ( void * ptr ) \n{", "mmm drivers / watchdog / watchdog_dev . c \nppp drivers / watchdog / watchdog_dev . c \nstatic int watchdog_release ( struct inode * inode , struct file * file ) \nstruct watchdog_core_data * wd_data = file -> private_data ; \nstruct watchdog_device * wdd ; \nint err = - EBUSY ; \n+ bool running ; \n \nmutex_lock (& wd_data -> lock ); \n \nstatic int watchdog_release ( struct inode * inode , struct file * file ) \nclear_bit ( _WDOG_DEV_OPEN , & wd_data -> status ); \n \ndone : \n+ running = wdd && watchdog_hw_running ( wdd ); \nmutex_unlock (& wd_data -> lock ); \n/* \n* Allow the owner module to be unloaded again unless the watchdog \n* is still running . If the watchdog is still running , it can not \n* be stopped , and its driver must not be unloaded . \n*/ \n- if (! watchdog_hw_running ( wdd )) { \n- module_put ( wdd -> ops -> owner ); \n+ if (! running ) { \n+ module_put ( wd_data -> cdev . owner ); \nkref_put (& wd_data -> kref , watchdog_core_data_release ); \n} \nreturn 0 ;", "mmm drivers / hid / hidraw . c \nppp drivers / hid / hidraw . c \nstatic long hidraw_ioctl ( struct file * file , unsigned int cmd , \n \nmutex_lock (& minors_lock ); \ndev = hidraw_table [ minor ]; \n+ if (! dev ) { \n+ ret = - ENODEV ; \n+ goto out ; \n+ } \n \nswitch ( cmd ) { \ncase HIDIOCGRDESCSIZE : \nstatic long hidraw_ioctl ( struct file * file , unsigned int cmd , \n \nret = - ENOTTY ; \n} \n+ out : \nmutex_unlock (& minors_lock ); \nreturn ret ; \n}", "mmm drivers / staging / ozwpan / ozhcd . c \nppp drivers / staging / ozwpan / ozhcd . c \nstatic int oz_build_endpoints_for_interface ( struct usb_hcd * hcd , \nint request_heartbeat = 0 ; \n \noz_dbg ( ON , \" interface [% d ] = % p \\ n \", if_ix , intf ); \n+ if ( if_ix >= port -> num_iface || port -> iface == NULL ) \n+ return - ENOMEM ; \nfor ( i = 0 ; i < intf -> desc . bNumEndpoints ; i ++) { \nstruct usb_host_endpoint * hep = & intf -> endpoint [ i ]; \nu8 ep_addr = hep -> desc . bEndpointAddress ;", "mmm kernel / trace / trace_uprobe . c \nppp kernel / trace / trace_uprobe . c \nstatic int create_trace_uprobe ( int argc , char ** argv ) \ngoto fail_address_parse ; \n \ninode = igrab ( path . dentry -> d_inode ); \n+ if (! S_ISREG ( inode -> i_mode )) { \n+ ret = - EINVAL ; \n+ goto fail_address_parse ; \n+ } \n \nargc -= 2 ; \nargv += 2 ; \nstatic int create_trace_uprobe ( int argc , char ** argv ) \nif ( inode ) \niput ( inode ); \n \n- pr_info (\" Failed to parse address .\\ n \"); \n+ pr_info (\" Failed to parse address or file .\\ n \"); \n \nreturn ret ; \n}", "mmm drivers / nfc / nfcmrvl / main . c \nppp drivers / nfc / nfcmrvl / main . c \nvoid nfcmrvl_nci_unregister_dev ( struct nfcmrvl_private * priv ) \n{ \nstruct nci_dev * ndev = priv -> ndev ; \n \n+ nci_unregister_device ( ndev ); \nif ( priv -> ndev -> nfc_dev -> fw_download_in_progress ) \nnfcmrvl_fw_dnld_abort ( priv ); \n \nvoid nfcmrvl_nci_unregister_dev ( struct nfcmrvl_private * priv ) \nif ( gpio_is_valid ( priv -> config . reset_n_io )) \ngpio_free ( priv -> config . reset_n_io ); \n \n- nci_unregister_device ( ndev ); \nnci_free_device ( ndev ); \nkfree ( priv ); \n}", "mmm drivers / media / pci / saa7146 / mxb . c \nppp drivers / media / pci / saa7146 / mxb . c \nstatic int vidioc_g_register ( struct file * file , void * fh , struct v4l2_dbg_regist \n{ \nstruct saa7146_dev * dev = (( struct saa7146_fh *) fh )-> dev ; \n \n+ if ( reg -> reg > pci_resource_len ( dev -> pci , 0 ) - 4 ) \n+ return - EINVAL ; \nreg -> val = saa7146_read ( dev , reg -> reg ); \nreg -> size = 4 ; \nreturn 0 ; \nstatic int vidioc_s_register ( struct file * file , void * fh , const struct v4l2_dbg_ \n{ \nstruct saa7146_dev * dev = (( struct saa7146_fh *) fh )-> dev ; \n \n+ if ( reg -> reg > pci_resource_len ( dev -> pci , 0 ) - 4 ) \n+ return - EINVAL ; \nsaa7146_write ( dev , reg -> reg , reg -> val ); \nreturn 0 ; \n}", "mmm drivers / mfd / t7l66xb . c \nppp drivers / mfd / t7l66xb . c \nstatic int t7l66xb_probe ( struct platform_device * dev ) \nt7l66xb -> clk48m = clk_get (& dev -> dev , \" CLK_CK48M \"); \nif ( IS_ERR ( t7l66xb -> clk48m )) { \nret = PTR_ERR ( t7l66xb -> clk48m ); \n- clk_put ( t7l66xb -> clk32k ); \ngoto err_clk48m_get ; \n} \n \nstatic int t7l66xb_remove ( struct platform_device * dev ) \nret = pdata -> disable ( dev ); \nclk_disable ( t7l66xb -> clk48m ); \nclk_put ( t7l66xb -> clk48m ); \n+ clk_disable ( t7l66xb -> clk32k ); \n+ clk_put ( t7l66xb -> clk32k ); \nt7l66xb_detach_irq ( dev ); \niounmap ( t7l66xb -> scr ); \nrelease_resource (& t7l66xb -> rscr );", "mmm kernel / user_namespace . c \nppp kernel / user_namespace . c \nstatic ssize_t map_write ( struct file * file , const char __user * buf , \nif (! new_idmap_permitted ( file , ns , cap_setid , & new_map )) \ngoto out ; \n \n- ret = sort_idmaps (& new_map ); \n- if ( ret < 0 ) \n- goto out ; \n- \nret = - EPERM ; \n/* Map the lower ids from the parent user namespace to the \n* kernel global id space . \nstatic ssize_t map_write ( struct file * file , const char __user * buf , \ne -> lower_first = lower_first ; \n} \n \n+ /* \n+ * If we want to use binary search for lookup , this clones the extent \n+ * array and sorts both copies . \n+ */ \n+ ret = sort_idmaps (& new_map ); \n+ if ( ret < 0 ) \n+ goto out ; \n+ \n/* Install the map */ \nif ( new_map . nr_extents <= UID_GID_MAP_MAX_BASE_EXTENTS ) { \nmemcpy ( map -> extent , new_map . extent ,", "mmm net / sctp / sm_statefuns . c \nppp net / sctp / sm_statefuns . c \nsctp_disposition_t sctp_sf_eat_auth ( const struct sctp_endpoint * ep , \nstruct sctp_chunk * err_chunk ; \nsctp_ierror_t error ; \n \n+ /* Make sure that the peer has AUTH capable */ \n+ if (! asoc -> peer . auth_capable ) \n+ return sctp_sf_unk_chunk ( ep , asoc , type , arg , commands ); \n+ \nif (! sctp_vtag_verify ( chunk , asoc )) { \nsctp_add_cmd_sf ( commands , SCTP_CMD_REPORT_BAD_TAG , \nSCTP_NULL ());", "mmm drivers / acpi / scan . c \nppp drivers / acpi / scan . c \nint acpi_bus_start ( struct acpi_device * device ) \n{ \nstruct acpi_bus_ops ops ; \n \n+ if (! device ) \n+ return - EINVAL ; \n+ \nmemset (& ops , 0 , sizeof ( ops )); \nops . acpi_op_start = 1 ; \n", "mmm net / sched / cls_flower . c \nppp net / sched / cls_flower . c \nstatic int fl_dump ( struct net * net , struct tcf_proto * tp , void * fh , \nif ( fl_dump_key_vlan ( skb , & key -> vlan , & mask -> vlan )) \ngoto nla_put_failure ; \n \n+ if ( mask -> vlan . vlan_tpid && \n+ nla_put_be16 ( skb , TCA_FLOWER_KEY_VLAN_ETH_TYPE , key -> basic . n_proto )) \n+ goto nla_put_failure ; \n+ \nif (( key -> basic . n_proto == htons ( ETH_P_IP ) || \nkey -> basic . n_proto == htons ( ETH_P_IPV6 )) && \n( fl_dump_key_val ( skb , & key -> basic . ip_proto , TCA_FLOWER_KEY_IP_PROTO ,", "mmm drivers / net / ethernet / netronome / nfp / flower / action . c \nppp drivers / net / ethernet / netronome / nfp / flower / action . c \nnfp_fl_output ( struct nfp_fl_output * output , const struct tc_action * action , \n*/ \nif (! switchdev_port_same_parent_id ( in_dev , out_dev )) \nreturn - EOPNOTSUPP ; \n+ if (! nfp_netdev_is_nfp_repr ( out_dev )) \n+ return - EOPNOTSUPP ; \n \noutput -> port = cpu_to_be32 ( nfp_repr_get_port_id ( out_dev )); \nif (! output -> port )", "mmm drivers / usb / core / devio . c \nppp drivers / usb / core / devio . c \nstatic int proc_do_submiturb ( struct usb_dev_state * ps , struct usbdevfs_urb * uurb \nu = ( is_in ? URB_DIR_IN : URB_DIR_OUT ); \nif ( uurb -> flags & USBDEVFS_URB_ISO_ASAP ) \nu |= URB_ISO_ASAP ; \n- if ( uurb -> flags & USBDEVFS_URB_SHORT_NOT_OK ) \n+ if ( uurb -> flags & USBDEVFS_URB_SHORT_NOT_OK && is_in ) \nu |= URB_SHORT_NOT_OK ; \nif ( uurb -> flags & USBDEVFS_URB_NO_FSBR ) \nu |= URB_NO_FSBR ;", "mmm drivers / gpu / drm / msm / hdmi / hdmi_audio . c \nppp drivers / gpu / drm / msm / hdmi / hdmi_audio . c \n# include < linux / hdmi . h > \n# include \" hdmi . h \" \n \n- \n-/* Supported HDMI Audio channels */ \n-# define MSM_HDMI_AUDIO_CHANNEL_2 0 \n-# define MSM_HDMI_AUDIO_CHANNEL_4 1 \n-# define MSM_HDMI_AUDIO_CHANNEL_6 2 \n-# define MSM_HDMI_AUDIO_CHANNEL_8 3 \n- \n/* maps MSM_HDMI_AUDIO_CHANNEL_n consts used by audio driver to # of channels : */ \nstatic int nchannels [] = { 2 , 4 , 6 , 8 }; \n", "mmm drivers / misc / cxl / irq . c \nppp drivers / misc / cxl / irq . c \nint afu_register_irqs ( struct cxl_context * ctx , u32 count ) \n*/ \nINIT_LIST_HEAD (& ctx -> irq_names ); \nfor ( r = 1 ; r < CXL_IRQ_RANGES ; r ++) { \n- for ( i = 0 ; i < ctx -> irqs . range [ r ]; hwirq ++, i ++) { \n+ for ( i = 0 ; i < ctx -> irqs . range [ r ]; i ++) { \nirq_name = kmalloc ( sizeof ( struct cxl_irq_name ), \nGFP_KERNEL ); \nif (! irq_name )", "mmm drivers / phy / phy - rockchip - usb . c \nppp drivers / phy / phy - rockchip - usb . c \nstatic int rockchip_usb_phy_init ( struct rockchip_usb_phy_base * base , \ngoto err_clk_prov ; \n} \n \n- err = devm_add_action ( base -> dev , rockchip_usb_phy_action , rk_phy ); \n+ err = devm_add_action_or_reset ( base -> dev , rockchip_usb_phy_action , \n+ rk_phy ); \nif ( err ) \n- goto err_devm_action ; \n+ return err ; \n \nrk_phy -> phy = devm_phy_create ( base -> dev , child , & ops ); \nif ( IS_ERR ( rk_phy -> phy )) { \nstatic int rockchip_usb_phy_init ( struct rockchip_usb_phy_base * base , \nelse \nreturn rockchip_usb_phy_power ( rk_phy , 1 ); \n \n- err_devm_action : \n- if (! rk_phy -> uart_enabled ) \n- of_clk_del_provider ( child ); \nerr_clk_prov : \nif (! rk_phy -> uart_enabled ) \nclk_unregister ( rk_phy -> clk480m );", "mmm drivers / media / rc / imon . c \nppp drivers / media / rc / imon . c \nstatic void imon_incoming_packet ( struct imon_context * ictx , \nif ( press_type == 0 ) \nrc_keyup ( ictx -> rdev ); \nelse { \n- if ( ictx -> rc_type == RC_BIT_RC6_MCE ) \n+ if ( ictx -> rc_type == RC_BIT_RC6_MCE || \n+ ictx -> rc_type == RC_BIT_OTHER ) \nrc_keydown ( ictx -> rdev , \nictx -> rc_type == RC_BIT_RC6_MCE ? RC_TYPE_RC6_MCE : RC_TYPE_OTHER , \nictx -> rc_scancode , ictx -> rc_toggle );", "mmm net / irda / iriap . c \nppp net / irda / iriap . c \nstatic void iriap_getvaluebyclass_indication ( struct iriap_cb * self , \nn = 1 ; \n \nname_len = fp [ n ++]; \n+ \n+ IRDA_ASSERT ( name_len < IAS_MAX_CLASSNAME + 1 , return ;); \n+ \nmemcpy ( name , fp + n , name_len ); n += name_len ; \nname [ name_len ] = '\\ 0 '; \n \nattr_len = fp [ n ++]; \n+ \n+ IRDA_ASSERT ( attr_len < IAS_MAX_ATTRIBNAME + 1 , return ;); \n+ \nmemcpy ( attr , fp + n , attr_len ); n += attr_len ; \nattr [ attr_len ] = '\\ 0 '; \n", "mmm sound / soc / fsl / imx - pcm - dma . c \nppp sound / soc / fsl / imx - pcm - dma . c \nstatic int snd_imx_open ( struct snd_pcm_substream * substream ) \ndma_params = snd_soc_dai_get_dma_data ( rtd -> cpu_dai , substream ); \n \ndma_data = kzalloc ( sizeof (* dma_data ), GFP_KERNEL ); \n+ if (! dma_data ) \n+ return - ENOMEM ; \n+ \ndma_data -> peripheral_type = dma_params -> shared_peripheral ? \nIMX_DMATYPE_SSI_SP : IMX_DMATYPE_SSI ; \ndma_data -> priority = DMA_PRIO_HIGH ;", "mmm drivers / nfc / port100 . c \nppp drivers / nfc / port100 . c \nstatic const struct port100_in_rf_setting in_rf_settings [] = { \n. in_recv_set_number = 15 , \n. in_recv_comm_type = PORT100_COMM_TYPE_IN_106A , \n}, \n+ /* Ensures the array has NFC_DIGITAL_RF_TECH_LAST elements */ \n+ [ NFC_DIGITAL_RF_TECH_LAST ] = { 0 }, \n}; \n \n/** \nstatic const struct port100_tg_rf_setting tg_rf_settings [] = { \n. tg_set_number = 8 , \n. tg_comm_type = PORT100_COMM_TYPE_TG_424F , \n}, \n+ /* Ensures the array has NFC_DIGITAL_RF_TECH_LAST elements */ \n+ [ NFC_DIGITAL_RF_TECH_LAST ] = { 0 }, \n+ \n}; \n \n# define PORT100_IN_PROT_INITIAL_GUARD_TIME 0x00 \nin_protocols [][ PORT100_IN_MAX_NUM_PROTOCOLS + 1 ] = { \n[ NFC_DIGITAL_FRAMING_NFC_DEP_ACTIVATED ] = { \n{ PORT100_IN_PROT_END , 0 }, \n}, \n+ /* Ensures the array has NFC_DIGITAL_FRAMING_LAST elements */ \n+ [ NFC_DIGITAL_FRAMING_LAST ] = { \n+ { PORT100_IN_PROT_END , 0 }, \n+ }, \n}; \n \nstatic struct port100_protocol \ntg_protocols [][ PORT100_TG_MAX_NUM_PROTOCOLS + 1 ] = { \n{ PORT100_TG_PROT_RF_OFF , 1 }, \n{ PORT100_TG_PROT_END , 0 }, \n}, \n+ /* Ensures the array has NFC_DIGITAL_FRAMING_LAST elements */ \n+ [ NFC_DIGITAL_FRAMING_LAST ] = { \n+ { PORT100_TG_PROT_END , 0 }, \n+ }, \n}; \n \nstruct port100 {", "mmm drivers / net / ethernet / netronome / nfp / nfp_net_common . c \nppp drivers / net / ethernet / netronome / nfp / nfp_net_common . c \nstatic void nfp_net_tx_complete ( struct nfp_net_tx_ring * tx_ring ) \nint fidx ; \nint idx ; \n \n+ if ( tx_ring -> wr_p == tx_ring -> rd_p ) \n+ return ; \n+ \n/* Work out how many descriptors have been transmitted */ \nqcp_rd_p = nfp_qcp_rd_ptr_read ( tx_ring -> qcp_q ); \n \nstatic void nfp_net_xdp_complete ( struct nfp_net_tx_ring * tx_ring ) \nint idx , todo ; \nu32 qcp_rd_p ; \n \n+ if ( tx_ring -> wr_p == tx_ring -> rd_p ) \n+ return ; \n+ \n/* Work out how many descriptors have been transmitted */ \nqcp_rd_p = nfp_qcp_rd_ptr_read ( tx_ring -> qcp_q ); \n", "mmm drivers / spi / spi - gpio . c \nppp drivers / spi / spi - gpio . c \nstatic int spi_gpio_probe ( struct platform_device * pdev ) \nreturn - ENOMEM ; \n \nstatus = devm_add_action_or_reset (& pdev -> dev , spi_gpio_put , master ); \n- if ( status ) \n+ if ( status ) { \n+ spi_master_put ( master ); \nreturn status ; \n+ } \n \nif ( of_id ) \nstatus = spi_gpio_probe_dt ( pdev , master );", "mmm lib / seq_buf . c \nppp lib / seq_buf . c \nint seq_buf_putmem_hex ( struct seq_buf * s , const void * mem , \n \nWARN_ON ( s -> size == 0 ); \n \n+ BUILD_BUG_ON ( MAX_MEMHEX_BYTES * 2 >= HEX_CHARS ); \n+ \nwhile ( len ) { \n- start_len = min ( len , HEX_CHARS - 1 ); \n+ start_len = min ( len , MAX_MEMHEX_BYTES ); \n# ifdef __BIG_ENDIAN \nfor ( i = 0 , j = 0 ; i < start_len ; i ++) { \n# else", "mmm drivers / block / drbd / drbd_worker . c \nppp drivers / block / drbd / drbd_worker . c \nvoid drbd_start_resync ( struct drbd_device * device , enum drbd_conns side ) \nreturn ; \n} \n \n+ if (! connection ) { \n+ drbd_err ( device , \" No connection to peer , aborting !\\ n \"); \n+ return ; \n+ } \n+ \nif (! test_bit ( B_RS_H_DONE , & device -> flags )) { \nif ( side == C_SYNC_TARGET ) { \n/* Since application IO was locked out during C_WF_BITMAP_T and", "mmm drivers / acpi / processor_idle . c \nppp drivers / acpi / processor_idle . c \nstatic unsigned int max_cstate __read_mostly = ACPI_PROCESSOR_MAX_POWER ; \nmodule_param ( max_cstate , uint , 0000 ); \nstatic unsigned int nocst __read_mostly ; \nmodule_param ( nocst , uint , 0000 ); \n+ static int bm_check_disable __read_mostly ; \n+ module_param ( bm_check_disable , uint , 0000 ); \n \nstatic unsigned int latency_factor __read_mostly = 2 ; \nmodule_param ( latency_factor , uint , 0644 ); \nstatic int acpi_idle_bm_check ( void ) \n{ \nu32 bm_status = 0 ; \n \n+ if ( bm_check_disable ) \n+ return 0 ; \n+ \nacpi_read_bit_register ( ACPI_BITREG_BUS_MASTER_STATUS , & bm_status ); \nif ( bm_status ) \nacpi_write_bit_register ( ACPI_BITREG_BUS_MASTER_STATUS , 1 );", "mmm drivers / accessibility / speakup / spk_ttyio . c \nppp drivers / accessibility / speakup / spk_ttyio . c \nstatic int spk_ttyio_ldisc_open ( struct tty_struct * tty ) \n \nif (! tty -> ops -> write ) \nreturn - EOPNOTSUPP ; \n+ \n+ mutex_lock (& speakup_tty_mutex ); \n+ if ( speakup_tty ) { \n+ mutex_unlock (& speakup_tty_mutex ); \n+ return - EBUSY ; \n+ } \nspeakup_tty = tty ; \n \nldisc_data = kmalloc ( sizeof (* ldisc_data ), GFP_KERNEL ); \n- if (! ldisc_data ) \n+ if (! ldisc_data ) { \n+ speakup_tty = NULL ; \n+ mutex_unlock (& speakup_tty_mutex ); \nreturn - ENOMEM ; \n+ } \n \ninit_completion (& ldisc_data -> completion ); \nldisc_data -> buf_free = true ; \nspeakup_tty -> disc_data = ldisc_data ; \n+ mutex_unlock (& speakup_tty_mutex ); \n \nreturn 0 ; \n}", "mmm drivers / base / regmap / regmap . c \nppp drivers / base / regmap / regmap . c \nstatic int _regmap_read ( struct regmap * map , unsigned int reg , \nif ( map -> cache_only ) \nreturn - EBUSY ; \n \n+ if (! regmap_readable ( map , reg )) \n+ return - EIO ; \n+ \nret = map -> reg_read ( context , reg , val ); \nif ( ret == 0 ) { \n# ifdef LOG_DEVICE", "mmm drivers / usb / storage / uas . c \nppp drivers / usb / storage / uas . c \nstatic int uas_find_endpoints ( struct usb_host_interface * alt , \nfor ( i = 0 ; i < n_endpoints ; i ++) { \nunsigned char * extra = endpoint [ i ]. extra ; \nint len = endpoint [ i ]. extralen ; \n- while ( len > 1 ) { \n+ while ( len >= 3 ) { \nif ( extra [ 1 ] == USB_DT_PIPE_USAGE ) { \nunsigned pipe_id = extra [ 2 ]; \nif ( pipe_id > 0 && pipe_id < 5 )", "mmm mm / slab . c \nppp mm / slab . c \nstatic int __init_refok setup_cpu_cache ( struct kmem_cache * cachep , gfp_t gfp ) \nint \n__kmem_cache_create ( struct kmem_cache * cachep , unsigned long flags ) \n{ \n- size_t left_over , freelist_size , ralign ; \n+ size_t left_over , freelist_size ; \n+ size_t ralign = BYTES_PER_WORD ; \ngfp_t gfp ; \nint err ; \nsize_t size = cachep -> size ; \n__kmem_cache_create ( struct kmem_cache * cachep , unsigned long flags ) \nsize &= ~( BYTES_PER_WORD - 1 ); \n} \n \n- /* \n- * Redzoning and user store require word alignment or possibly larger . \n- * Note this will be overridden by architecture or caller mandated \n- * alignment if either is greater than BYTES_PER_WORD . \n- */ \n- if ( flags & SLAB_STORE_USER ) \n- ralign = BYTES_PER_WORD ; \n- \nif ( flags & SLAB_RED_ZONE ) { \nralign = REDZONE_ALIGN ; \n/* If redzoning , ensure that the second redzone is suitably", "mmm drivers / staging / iio / adc / mxs - lradc . c \nppp drivers / staging / iio / adc / mxs - lradc . c \nstatic int mxs_lradc_probe ( struct platform_device * pdev ) \n* of the array . \n*/ \nscale_uv = (( u64 ) lradc -> vref_mv [ i ] * 100000000 ) >> \n- ( iio -> channels [ i ]. scan_type . realbits - s ); \n+ ( LRADC_RESOLUTION - s ); \nlradc -> scale_avail [ i ][ s ]. nano = \ndo_div ( scale_uv , 100000000 ) * 10 ; \nlradc -> scale_avail [ i ][ s ]. integer = scale_uv ;", "mmm security / commoncap . c \nppp security / commoncap . c \nint cap_bprm_set_creds ( struct linux_binprm * bprm ) \n} \nskip : \n \n+ /* if we have fs caps , clear dangerous personality flags */ \n+ if (! cap_issubset ( new -> cap_permitted , old -> cap_permitted )) \n+ bprm -> per_clear |= PER_CLEAR_ON_SETID ; \n+ \n+ \n/* Don ' t let someone trace a set [ ug ] id / setpcap binary with the revised \n* credentials unless they have the appropriate permit \n*/", "mmm fs / aio . c \nppp fs / aio . c \nstatic struct kioctx * ioctx_alloc ( unsigned nr_events ) \nerr_cleanup : \naio_nr_sub ( ctx -> max_reqs ); \nerr : \n- aio_free_ring ( ctx ); \nfree_percpu ( ctx -> cpu ); \nfree_percpu ( ctx -> reqs . pcpu_count ); \nfree_percpu ( ctx -> users . pcpu_count );", "mmm drivers / net / wireless / rsi / rsi_91x_mgmt . c \nppp drivers / net / wireless / rsi / rsi_91x_mgmt . c \nstatic int rsi_send_beacon ( struct rsi_common * common ) \nskb_pull ( skb , ( 64 - dword_align_bytes )); \nif ( rsi_prepare_beacon ( common , skb )) { \nrsi_dbg ( ERR_ZONE , \" Failed to prepare beacon \\ n \"); \n+ dev_kfree_skb ( skb ); \nreturn - EINVAL ; \n} \nskb_queue_tail (& common -> tx_queue [ MGMT_BEACON_Q ], skb );", "mmm arch / arm / mach - omap2 / omap_hwmod . c \nppp arch / arm / mach - omap2 / omap_hwmod . c \nstruct powerdomain * omap_hwmod_get_pwrdm ( struct omap_hwmod * oh ) \nc = oh -> slaves [ oh -> _mpu_port_index ]-> _clk ; \n} \n \n+ if (! c -> clkdm ) \n+ return NULL ; \n+ \nreturn c -> clkdm -> pwrdm . ptr ; \n \n}", "mmm net / xfrm / xfrm_policy . c \nppp net / xfrm / xfrm_policy . c \nint xfrm_policy_flush ( u8 type , struct xfrm_audit * audit_info ) \ncontinue ; \nhlist_del (& pol -> bydst ); \nhlist_del (& pol -> byidx ); \n+ list_del (& pol -> walk . all ); \nwrite_unlock_bh (& xfrm_policy_lock ); \n \nxfrm_audit_policy_delete ( pol , 1 , audit_info -> loginuid ,", "mmm drivers / gpu / drm / amd / display / amdgpu_dm / amdgpu_dm . c \nppp drivers / gpu / drm / amd / display / amdgpu_dm / amdgpu_dm . c \nstatic int amdgpu_dm_atomic_check ( struct drm_device * dev , \n} \n} else { \nfor_each_oldnew_crtc_in_state ( state , crtc , old_crtc_state , new_crtc_state , i ) { \n- if (! drm_atomic_crtc_needs_modeset ( new_crtc_state )) \n+ if (! drm_atomic_crtc_needs_modeset ( new_crtc_state ) && \n+ ! new_crtc_state -> color_mgmt_changed ) \ncontinue ; \n \nif (! new_crtc_state -> enable )", "mmm net / vmw_vsock / af_vsock . c \nppp net / vmw_vsock / af_vsock . c \nvsock_stream_recvmsg ( struct kiocb * kiocb , \nvsk = vsock_sk ( sk ); \nerr = 0 ; \n \n+ msg -> msg_namelen = 0 ; \n+ \nlock_sock ( sk ); \n \nif ( sk -> sk_state != SS_CONNECTED ) {", "mmm drivers / pinctrl / bcm / pinctrl - nsp - gpio . c \nppp drivers / pinctrl / bcm / pinctrl - nsp - gpio . c \nstatic int nsp_gpio_get_strength ( struct nsp_gpio * chip , unsigned gpio , \nreturn 0 ; \n} \n \n- int nsp_pin_config_group_get ( struct pinctrl_dev * pctldev , unsigned selector , \n+ static int nsp_pin_config_group_get ( struct pinctrl_dev * pctldev , \n+ unsigned selector , \nunsigned long * config ) \n{ \nreturn 0 ; \n} \n \n- int nsp_pin_config_group_set ( struct pinctrl_dev * pctldev , unsigned selector , \n+ static int nsp_pin_config_group_set ( struct pinctrl_dev * pctldev , \n+ unsigned selector , \nunsigned long * configs , unsigned num_configs ) \n{ \nreturn 0 ;", "mmm sound / soc / codecs / arizona . c \nppp sound / soc / codecs / arizona . c \nint arizona_out_ev ( struct snd_soc_dapm_widget * w , \ncase ARIZONA_OUT3R_ENA_SHIFT : \npriv -> out_up_pending --; \nif (! priv -> out_up_pending ) { \n+ dev_dbg ( codec -> dev , \" Power up delay : % d \\ n \", \n+ priv -> out_up_delay ); \nmsleep ( priv -> out_up_delay ); \npriv -> out_up_delay = 0 ; \n} \nint arizona_out_ev ( struct snd_soc_dapm_widget * w , \ncase ARIZONA_OUT3R_ENA_SHIFT : \npriv -> out_down_pending --; \nif (! priv -> out_down_pending ) { \n+ dev_dbg ( codec -> dev , \" Power down delay : % d \\ n \", \n+ priv -> out_down_delay ); \nmsleep ( priv -> out_down_delay ); \npriv -> out_down_delay = 0 ; \n}", "mmm drivers / tty / serial / sh - sci . c \nppp drivers / tty / serial / sh - sci . c \nstatic int sci_init_clocks ( struct sci_port * sci_port , struct device * dev ) \ndev_dbg ( dev , \" failed to get % s (% ld )\\ n \", clk_names [ i ], \nPTR_ERR ( clk )); \nelse \n- dev_dbg ( dev , \" clk % s is % pC rate % pCr \\ n \", clk_names [ i ], \n- clk , clk ); \n+ dev_dbg ( dev , \" clk % s is % pC rate % lu \\ n \", clk_names [ i ], \n+ clk , clk_get_rate ( clk )); \nsci_port -> clks [ i ] = IS_ERR ( clk ) ? NULL : clk ; \n} \nreturn 0 ;", "mmm drivers / usb / host / ehci - sched . c \nppp drivers / usb / host / ehci - sched . c \nstatic int disable_periodic ( struct ehci_hcd * ehci ) \nehci_writel ( ehci , cmd , & ehci -> regs -> command ); \n/* posted write ... */ \n \n+ free_cached_itd_list ( ehci ); \n+ \nehci -> next_uframe = - 1 ; \nreturn 0 ; \n}", "mmm kernel / module . c \nppp kernel / module . c \nstatic const struct kernel_symbol * resolve_symbol ( struct module * mod , \nconst unsigned long * crc ; \nint err ; \n \n+ /* \n+ * The module_mutex should not be a heavily contended lock ; \n+ * if we get the occasional sleep here , we ' ll go an extra iteration \n+ * in the wait_event_interruptible (), which is harmless . \n+ */ \n+ sched_annotate_sleep (); \nmutex_lock (& module_mutex ); \nsym = find_symbol ( name , & owner , & crc , \n!( mod -> taints & ( 1 << TAINT_PROPRIETARY_MODULE )), true );", "mmm net / core / dev . c \nppp net / core / dev . c \nstatic int __netdev_upper_dev_link ( struct net_device * dev , \nif ( __netdev_find_adj ( upper_dev , dev , & upper_dev -> all_adj_list . upper )) \nreturn - EBUSY ; \n \n- if ( __netdev_find_adj ( dev , upper_dev , & dev -> all_adj_list . upper )) \n+ if ( __netdev_find_adj ( dev , upper_dev , & dev -> adj_list . upper )) \nreturn - EEXIST ; \n \nif ( master && netdev_master_upper_dev_get ( dev ))", "mmm security / apparmor / apparmorfs . c \nppp security / apparmor / apparmorfs . c \nvoid __aa_fs_profile_migrate_dents ( struct aa_profile * old , \n \nfor ( i = 0 ; i < AAFS_PROF_SIZEOF ; i ++) { \nnew -> dents [ i ] = old -> dents [ i ]; \n+ if ( new -> dents [ i ]) \n+ new -> dents [ i ]-> d_inode -> i_mtime = CURRENT_TIME ; \nold -> dents [ i ] = NULL ; \n} \n}", "mmm fs / nfs / nfs3xdr . c \nppp fs / nfs / nfs3xdr . c \nstatic void nfs3_xdr_enc_setacl3args ( struct rpc_rqst * req , \nif ( args -> npages != 0 ) \nxdr_write_pages ( xdr , args -> pages , 0 , args -> len ); \nelse \n- xdr_reserve_space ( xdr , NFS_ACL_INLINE_BUFSIZE ); \n+ xdr_reserve_space ( xdr , args -> len ); \n \nerror = nfsacl_encode ( xdr -> buf , base , args -> inode , \n( args -> mask & NFS_ACL ) ?", "mmm init / main . c \nppp init / main . c \nstatic void run_init_process ( const char * init_filename ) \nkernel_execve ( init_filename , argv_init , envp_init ); \n} \n \n-/* This is a non __init function . Force it to be noinline otherwise gcc \n- * makes it inline to init () and it becomes part of init . text section \n- */ \n- static noinline int init_post ( void ) \n+ static void __init kernel_init_freeable ( void ); \n+ \n+ static int __ref kernel_init ( void * unused ) \n{ \n+ kernel_init_freeable (); \n/* need to finish all async __init code before freeing the memory */ \nasync_synchronize_full (); \nfree_initmem (); \nstatic noinline int init_post ( void ) \n\" See Linux Documentation / init . txt for guidance .\"); \n} \n \n- static int __init kernel_init ( void * unused ) \n+ static void __init kernel_init_freeable ( void ) \n{ \n/* \n* Wait until kthreadd is all set - up . \nstatic int __init kernel_init ( void * unused ) \n* we ' re essentially up and running . Get rid of the \n* initmem segments and start the user - mode stuff .. \n*/ \n- \n- init_post (); \n- return 0 ; \n}", "mmm drivers / net / wireless / iwlwifi / mvm / rs . c \nppp drivers / net / wireless / iwlwifi / mvm / rs . c \nvoid iwl_mvm_rs_tx_status ( struct iwl_mvm * mvm , struct ieee80211_sta * sta , \n* first index into rate scale table . \n*/ \nif ( info -> flags & IEEE80211_TX_STAT_AMPDU ) { \n+ /* ampdu_ack_len = 0 marks no BA was received . In this case \n+ * treat it as a single frame loss as we don ' t want the success \n+ * ratio to dip too quickly because a BA wasn ' t received \n+ */ \n+ if ( info -> status . ampdu_ack_len == 0 ) \n+ info -> status . ampdu_len = 1 ; \n+ \nucode_rate = le32_to_cpu ( table -> rs_table [ 0 ]); \nrs_rate_from_ucode_rate ( ucode_rate , info -> band , & rate ); \nrs_collect_tx_data ( lq_sta , curr_tbl , rate . index ,", "mmm net / tipc / socket . c \nppp net / tipc / socket . c \nstatic int __tipc_sendmsg ( struct socket * sock , struct msghdr * m , size_t dlen ) \nmsg_set_syn ( hdr , 1 ); \n} \n \n+ memset (& skaddr , 0 , sizeof ( skaddr )); \n+ \n/* Determine destination */ \nif ( atype == TIPC_SERVICE_RANGE ) { \nreturn tipc_sendmcast ( sock , ua , m , dlen , timeout );", "mmm drivers / gpio / gpio - davinci . c \nppp drivers / gpio / gpio - davinci . c \nstatic int davinci_gpio_probe ( struct platform_device * pdev ) \nspin_lock_init (& chips [ i ]. lock ); \n \nregs = gpio2regs ( base ); \n+ if (! regs ) \n+ return - ENXIO ; \nchips [ i ]. regs = regs ; \nchips [ i ]. set_data = & regs -> set_data ; \nchips [ i ]. clr_data = & regs -> clr_data ;", "mmm drivers / firewire / ohci . c \nppp drivers / firewire / ohci . c \nstatic void bus_reset_work ( struct work_struct * work ) \n{ \nstruct fw_ohci * ohci = \ncontainer_of ( work , struct fw_ohci , bus_reset_work ); \n- int self_id_count , i , j , reg ; \n- int generation , new_generation ; \n+ int self_id_count , generation , new_generation , i , j ; \n+ u32 reg ; \nunsigned long flags ; \nvoid * free_rom = NULL ; \ndma_addr_t free_rom_bus = 0 ;", "mmm tools / lib / bpf / libbpf . c \nppp tools / lib / bpf / libbpf . c \nBPF_PROG_TYPE_FNS ( tracepoint , BPF_PROG_TYPE_TRACEPOINT ); \nBPF_PROG_TYPE_FNS ( xdp , BPF_PROG_TYPE_XDP ); \nBPF_PROG_TYPE_FNS ( perf_event , BPF_PROG_TYPE_PERF_EVENT ); \n \n-# define BPF_PROG_SEC ( string , type ) { string , sizeof ( string ), type } \n+# define BPF_PROG_SEC ( string , type ) { string , sizeof ( string ) - 1 , type } \nstatic const struct { \nconst char * sec ; \nsize_t len ;", "mmm fs / btrfs / send . c \nppp fs / btrfs / send . c \nverbose_printk (\" btrfs : send_create_inode % llu \\ n \", ino ); \nTLV_PUT_PATH ( sctx , BTRFS_SEND_A_PATH_LINK , p ); \n} else if ( S_ISCHR ( mode ) || S_ISBLK ( mode ) || \nS_ISFIFO ( mode ) || S_ISSOCK ( mode )) { \n- TLV_PUT_U64 ( sctx , BTRFS_SEND_A_RDEV , rdev ); \n+ TLV_PUT_U64 ( sctx , BTRFS_SEND_A_RDEV , new_encode_dev ( rdev )); \n+ TLV_PUT_U64 ( sctx , BTRFS_SEND_A_MODE , mode ); \n} \n \nret = send_cmd ( sctx );", "mmm drivers / video / omap2 / dss / apply . c \nppp drivers / video / omap2 / dss / apply . c \nint dss_mgr_enable ( struct omap_overlay_manager * mgr ) \nif (! mgr_manual_update ( mgr )) \nmp -> updating = true ; \n \n+ if (! dss_data . irq_enabled && need_isr ()) \n+ dss_register_vsync_isr (); \n+ \nspin_unlock_irqrestore (& data_lock , flags ); \n \nif (! mgr_manual_update ( mgr ))", "mmm net / batman - adv / bat_iv_ogm . c \nppp net / batman - adv / bat_iv_ogm . c \nstatic void bat_iv_ogm_iface_enable ( struct hard_iface * hard_iface ) \n{ \nstruct batman_ogm_packet * batman_ogm_packet ; \n+ uint32_t random_seqno ; \n+ \n+ /* randomize initial seqno to avoid collision */ \n+ get_random_bytes (& random_seqno , sizeof ( random_seqno )); \n+ atomic_set (& hard_iface -> seqno , random_seqno ); \n \nhard_iface -> packet_len = BATMAN_OGM_LEN ; \nhard_iface -> packet_buff = kmalloc ( hard_iface -> packet_len , GFP_ATOMIC );", "mmm drivers / crypto / chelsio / chcr_algo . c \nppp drivers / crypto / chelsio / chcr_algo . c \nstatic inline void chcr_handle_ahash_resp ( struct ahash_request * req , \n \nif ( input == NULL ) \ngoto out ; \n- reqctx = ahash_request_ctx ( req ); \ndigestsize = crypto_ahash_digestsize ( crypto_ahash_reqtfm ( req )); \nif ( reqctx -> is_sg_map ) \nchcr_hash_dma_unmap (& u_ctx -> lldi . pdev -> dev , req ); \nstatic int chcr_aead_common_init ( struct aead_request * req , \nstruct chcr_aead_ctx * aeadctx = AEAD_CTX ( a_ctx ( tfm )); \nstruct chcr_aead_reqctx * reqctx = aead_request_ctx ( req ); \nint error = - EINVAL ; \n- unsigned int dst_size ; \nunsigned int authsize = crypto_aead_authsize ( tfm ); \n \n- dst_size = req -> assoclen + req -> cryptlen + ( op_type ? \n- - authsize : authsize ); \n/* validate key size */ \nif ( aeadctx -> enckey_len == 0 ) \ngoto err ;", "mmm drivers / gpu / drm / amd / amdkfd / kfd_device_queue_manager . c \nppp drivers / gpu / drm / amd / amdkfd / kfd_device_queue_manager . c \nstatic int create_queue_cpsch ( struct device_queue_manager * dqm , struct queue * q , \nreturn retval ; \n} \n \n- int fence_wait_timeout ( unsigned int * fence_addr , unsigned int fence_value , \n- unsigned long timeout ) \n+ static int fence_wait_timeout ( unsigned int * fence_addr , \n+ unsigned int fence_value , \n+ unsigned long timeout ) \n{ \nBUG_ON (! fence_addr ); \ntimeout += jiffies ;", "mmm sound / oss / soundcard . c \nppp sound / oss / soundcard . c \nint * load_mixer_volumes ( char * name , int * levels , int present ) \nint i , n ; \n \nfor ( i = 0 ; i < num_mixer_volumes ; i ++) { \n- if ( strcmp ( name , mixer_vols [ i ]. name ) == 0 ) { \n+ if ( strncmp ( name , mixer_vols [ i ]. name , 32 ) == 0 ) { \nif ( present ) \nmixer_vols [ i ]. num = i ; \nreturn mixer_vols [ i ]. levels ; \nint * load_mixer_volumes ( char * name , int * levels , int present ) \n} \nn = num_mixer_volumes ++; \n \n- strcpy ( mixer_vols [ n ]. name , name ); \n+ strncpy ( mixer_vols [ n ]. name , name , 32 ); \n \nif ( present ) \nmixer_vols [ n ]. num = n ;", "mmm drivers / vhost / net . c \nppp drivers / vhost / net . c \nstatic int get_rx_bufs ( struct vhost_virtqueue * vq , \n* iovcount = seg ; \nif ( unlikely ( log )) \n* log_num = nlogs ; \n+ \n+ /* Detect overrun */ \n+ if ( unlikely ( datalen > 0 )) { \n+ r = UIO_MAXIOV + 1 ; \n+ goto err ; \n+ } \nreturn headcount ; \nerr : \nvhost_discard_vq_desc ( vq , headcount ); \nstatic void handle_rx ( struct vhost_net * net ) \n/* On error , stop handling until the next kick . */ \nif ( unlikely ( headcount < 0 )) \nbreak ; \n+ /* On overrun , truncate and discard */ \n+ if ( unlikely ( headcount > UIO_MAXIOV )) { \n+ msg . msg_iovlen = 1 ; \n+ err = sock -> ops -> recvmsg ( NULL , sock , & msg , \n+ 1 , MSG_DONTWAIT | MSG_TRUNC ); \n+ pr_debug (\" Discarded rx packet : len % zd \\ n \", sock_len ); \n+ continue ; \n+ } \n/* OK , now we need to know about added descriptors . */ \nif (! headcount ) { \nif ( unlikely ( vhost_enable_notify (& net -> dev , vq ))) {", "mmm net / bridge / netfilter / ebtables . c \nppp net / bridge / netfilter / ebtables . c \nstatic int do_replace ( struct net * net , const void __user * user , \nif ( tmp . num_counters >= INT_MAX / sizeof ( struct ebt_counter )) \nreturn - ENOMEM ; \n \n+ tmp . name [ sizeof ( tmp . name ) - 1 ] = 0 ; \n+ \ncountersize = COUNTER_OFFSET ( tmp . nentries ) * nr_cpu_ids ; \nnewinfo = vmalloc ( sizeof (* newinfo ) + countersize ); \nif (! newinfo )", "mmm fs / btrfs / super . c \nppp fs / btrfs / super . c \nstatic struct file_system_type btrfs_fs_type = { \n}; \nMODULE_ALIAS_FS (\" btrfs \"); \n \n+ static int btrfs_control_open ( struct inode * inode , struct file * file ) \n+{ \n+ /* \n+ * The control file ' s private_data is used to hold the \n+ * transaction when it is started and is used to keep \n+ * track of whether a transaction is already in progress . \n+ */ \n+ file -> private_data = NULL ; \n+ return 0 ; \n+} \n+ \n/* \n* used by btrfsctl to scan devices when no FS is mounted \n*/ \nstatic const struct super_operations btrfs_super_ops = { \n}; \n \nstatic const struct file_operations btrfs_ctl_fops = { \n+ . open = btrfs_control_open , \n. unlocked_ioctl = btrfs_control_ioctl , \n. compat_ioctl = btrfs_control_ioctl , \n. owner = THIS_MODULE ,", "mmm drivers / block / aoe / aoenet . c \nppp drivers / block / aoe / aoenet . c \naoenet_xmit ( struct sk_buff_head * queue ) \n{ \nstruct sk_buff * skb , * tmp ; \n \n- skb_queue_walk_safe ( queue , skb , tmp ) \n+ skb_queue_walk_safe ( queue , skb , tmp ) { \n+ __skb_unlink ( skb , queue ); \ndev_queue_xmit ( skb ); \n+ } \n} \n \n/*", "mmm drivers / bus / imx - weim . c \nppp drivers / bus / imx - weim . c \nstatic const struct imx_weim_devtype imx51_weim_devtype = { \n. cs_stride = 0x18 , \n}; \n \n+# define MAX_CS_REGS_COUNT 6 \n+ \nstatic const struct of_device_id weim_id_table [] = { \n/* i . MX1 / 21 */ \n{ . compatible = \" fsl , imx1 - weim \", . data = & imx1_weim_devtype , }, \nstatic int __init imx_weim_gpr_setup ( struct platform_device * pdev ) \nstatic int __init weim_timing_setup ( struct device_node * np , void __iomem * base , \nconst struct imx_weim_devtype * devtype ) \n{ \n- u32 cs_idx , value [ devtype -> cs_regs_count ]; \n+ u32 cs_idx , value [ MAX_CS_REGS_COUNT ]; \nint i , ret ; \n \n+ if ( WARN_ON ( devtype -> cs_regs_count > MAX_CS_REGS_COUNT )) \n+ return - EINVAL ; \n+ \n/* get the CS index from this child node ' s \" reg \" property . */ \nret = of_property_read_u32 ( np , \" reg \", & cs_idx ); \nif ( ret )", "mmm drivers / platform / x86 / asus - laptop . c \nppp drivers / platform / x86 / asus - laptop . c \nstatic int asus_laptop_get_info ( struct asus_laptop * asus ) \n} \n} \nasus -> name = kstrdup ( string , GFP_KERNEL ); \n- if (! asus -> name ) \n+ if (! asus -> name ) { \n+ kfree ( buffer . pointer ); \nreturn - ENOMEM ; \n+ } \n \nif (* string ) \npr_notice (\" % s model detected \\ n \", string );", "mmm drivers / media / rc / mceusb . c \nppp drivers / media / rc / mceusb . c \nenum mceusb_model_type { \nPOLARIS_EVK , \nCX_HYBRID_TV , \nMULTIFUNCTION , \n+ TIVO_KIT , \n}; \n \nstruct mceusb_model { \nstatic const struct mceusb_model mceusb_model [] = { \n. mce_gen2 = 1 , \n. ir_intfnum = 2 , \n}, \n+ [ TIVO_KIT ] = { \n+ . mce_gen2 = 1 , \n+ . rc_map = RC_MAP_TIVO , \n+ }, \n}; \n \nstatic struct usb_device_id mceusb_dev_table [] = { \nstatic struct usb_device_id mceusb_dev_table [] = { \n/* Northstar Systems , Inc . eHome Infrared Transceiver */ \n{ USB_DEVICE ( VENDOR_NORTHSTAR , 0xe004 ) }, \n/* TiVo PC IR Receiver */ \n- { USB_DEVICE ( VENDOR_TIVO , 0x2000 ) }, \n+ { USB_DEVICE ( VENDOR_TIVO , 0x2000 ), \n+ . driver_info = TIVO_KIT }, \n/* Conexant Hybrid TV \" Shelby \" Polaris SDK */ \n{ USB_DEVICE ( VENDOR_CONEXANT , 0x58a1 ), \n. driver_info = POLARIS_EVK },", "mmm arch / parisc / mm / init . c \nppp arch / parisc / mm / init . c \nstatic void __init setup_bootmem ( void ) \n} \nmemset ( pfnnid_map , 0xff , sizeof ( pfnnid_map )); \n \n- for ( i = 0 ; i < npmem_ranges ; i ++) \n+ for ( i = 0 ; i < npmem_ranges ; i ++) { \n+ node_set_state ( i , N_NORMAL_MEMORY ); \nnode_set_online ( i ); \n+ } \n# endif \n \n/*", "mmm net / openvswitch / actions . c \nppp net / openvswitch / actions . c \nstatic int sample ( struct datapath * dp , struct sk_buff * skb , \nskb_get ( skb ); \n} else { \nsample_skb = skb_clone ( skb , GFP_ATOMIC ); \n+ if (! sample_skb ) /* Skip sample action when out of memory . */ \n+ return 0 ; \n} \n \n/* Note that do_execute_actions () never consumes skb .", "mmm drivers / atm / eni . c \nppp drivers / atm / eni . c \nstatic int eni_start ( struct atm_dev * dev ) \n/* initialize memory management */ \nbuffer_mem = eni_dev -> mem - ( buf - eni_dev -> ram ); \neni_dev -> free_list_size = buffer_mem / MID_MIN_BUF_SIZE / 2 ; \n- eni_dev -> free_list = kmalloc ( \n- sizeof ( struct eni_free )*( eni_dev -> free_list_size + 1 ), GFP_KERNEL ); \n+ eni_dev -> free_list = kmalloc_array ( eni_dev -> free_list_size + 1 , \n+ sizeof (* eni_dev -> free_list ), \n+ GFP_KERNEL ); \nif (! eni_dev -> free_list ) { \nprintk ( KERN_ERR DEV_LABEL \"( itf % d ): couldn ' t get free page \\ n \", \ndev -> number );", "mmm kernel / cgroup . c \nppp kernel / cgroup . c \nstatic long cgroup_create ( struct cgroup * parent , struct dentry * dentry , \n} \n \nerr = percpu_ref_init (& css -> refcnt , css_release ); \n- if ( err ) \n+ if ( err ) { \n+ ss -> css_free ( cgrp ); \ngoto err_free_all ; \n+ } \n \ninit_cgroup_css ( css , ss , cgrp ); \n", "mmm drivers / target / target_core_fabric_configfs . c \nppp drivers / target / target_core_fabric_configfs . c \nstatic struct config_group * target_fabric_make_mappedlun ( \nstruct se_node_acl , acl_group ); \nstruct se_portal_group * se_tpg = se_nacl -> se_tpg ; \nstruct target_fabric_configfs * tf = se_tpg -> se_tpg_wwn -> wwn_tf ; \n- struct se_lun_acl * lacl ; \n+ struct se_lun_acl * lacl = NULL ; \nstruct config_item * acl_ci ; \nstruct config_group * lacl_cg = NULL , * ml_stat_grp = NULL ; \nchar * buf ; \nstatic struct config_group * target_fabric_make_mappedlun ( \nout : \nif ( lacl_cg ) \nkfree ( lacl_cg -> default_groups ); \n+ kfree ( lacl ); \nkfree ( buf ); \nreturn ERR_PTR ( ret ); \n}", "mmm drivers / net / wireless / iwlwifi / dvm / mac80211 . c \nppp drivers / net / wireless / iwlwifi / dvm / mac80211 . c \nint iwlagn_mac_setup_register ( struct iwl_priv * priv , \nARRAY_SIZE ( iwlagn_iface_combinations_dualmode ); \n} \n \n- hw -> wiphy -> max_remain_on_channel_duration = 1000 ; \n+ hw -> wiphy -> max_remain_on_channel_duration = 500 ; \n \nhw -> wiphy -> flags |= WIPHY_FLAG_CUSTOM_REGULATORY | \nWIPHY_FLAG_DISABLE_BEACON_HINTS |", "mmm net / dsa / port . c \nppp net / dsa / port . c \nint dsa_port_vlan_add ( struct dsa_port * dp , \n. vlan = vlan , \n}; \n \n+ if ( netif_is_bridge_master ( vlan -> obj . orig_dev )) \n+ return - EOPNOTSUPP ; \n+ \nif ( br_vlan_enabled ( dp -> bridge_dev )) \nreturn dsa_port_notify ( dp , DSA_NOTIFIER_VLAN_ADD , & info ); \n \nint dsa_port_vlan_del ( struct dsa_port * dp , \n. vlan = vlan , \n}; \n \n+ if ( netif_is_bridge_master ( vlan -> obj . orig_dev )) \n+ return - EOPNOTSUPP ; \n+ \nif ( br_vlan_enabled ( dp -> bridge_dev )) \nreturn dsa_port_notify ( dp , DSA_NOTIFIER_VLAN_DEL , & info ); \n", "mmm arch / cris / kernel / time . c \nppp arch / cris / kernel / time . c \n-/* $ Id : time . c , v 1 . 18 2005 / 03 / 04 08 : 16 : 17 starvik Exp $ \n- * \n+/* \n* linux / arch / cris / kernel / time . c \n* \n* Copyright ( C ) 1991 , 1992 , 1995 Linus Torvalds \n* Linux / CRIS specific code : \n* \n* Authors : Bjorn Wesen \n- * Johan Adolfsson \n+ * Johan Adolfsson \n* \n*/ \n \ncris_do_profile ( struct pt_regs * regs ) \n# endif \n \n# ifdef CONFIG_PROFILING \n- profile_tick ( CPU_PROFILING ); \n+ profile_tick ( CPU_PROFILING , regs ); \n# endif \n} \n \n+ unsigned long long sched_clock ( void ) \n+{ \n+ return ( unsigned long long ) jiffies * ( 1000000000 / HZ ) + \n+ get_ns_in_jiffie (); \n+} \n+ \nstatic int \n__init init_udelay ( void ) \n{", "mmm sound / usb / quirks . c \nppp sound / usb / quirks . c \nstatic int snd_usb_cm106_boot_quirk ( struct usb_device * dev ) \n*/ \nstatic int snd_usb_cm6206_boot_quirk ( struct usb_device * dev ) \n{ \n- int err , reg ; \n+ int err = 0 , reg ; \nint val [] = { 0x2004 , 0x3000 , 0xf800 , 0x143f , 0x0000 , 0x3000 }; \n \nfor ( reg = 0 ; reg < ARRAY_SIZE ( val ); reg ++) {", "mmm drivers / ata / libata - core . c \nppp drivers / ata / libata - core . c \nstruct ata_host * ata_host_alloc ( struct device * dev , int max_ports ) \nreturn NULL ; \n \nif (! devres_open_group ( dev , NULL , GFP_KERNEL )) \n- return NULL ; \n+ goto err_free ; \n \ndr = devres_alloc ( ata_devres_release , 0 , GFP_KERNEL ); \nif (! dr ) \nstruct ata_host * ata_host_alloc ( struct device * dev , int max_ports ) \n \nerr_out : \ndevres_release_group ( dev , NULL ); \n+ err_free : \n+ kfree ( host ); \nreturn NULL ; \n} \n", "mmm net / rds / sysctl . c \nppp net / rds / sysctl . c \nstatic struct ctl_table rds_sysctl_rds_table [] = { \n{ \n. procname = \" max_unacked_packets \", \n. data = & rds_sysctl_max_unacked_packets , \n- . maxlen = sizeof ( unsigned long ), \n+ . maxlen = sizeof ( int ), \n. mode = 0644 , \n. proc_handler = proc_dointvec , \n}, \n{ \n. procname = \" max_unacked_bytes \", \n. data = & rds_sysctl_max_unacked_bytes , \n- . maxlen = sizeof ( unsigned long ), \n+ . maxlen = sizeof ( int ), \n. mode = 0644 , \n. proc_handler = proc_dointvec , \n},", "mmm drivers / net / wireless / mwifiex / scan . c \nppp drivers / net / wireless / mwifiex / scan . c \nmwifiex_update_curr_bss_params ( struct mwifiex_private * priv , u8 * bssid , \ns32 rssi , const u8 * ie_buf , size_t ie_len , \nu16 beacon_period , u16 cap_info_bitmap , u8 band ) \n{ \n- struct mwifiex_bssdescriptor * bss_desc = NULL ; \n+ struct mwifiex_bssdescriptor * bss_desc ; \nint ret ; \nunsigned long flags ; \nu8 * beacon_ie ; \nmwifiex_update_curr_bss_params ( struct mwifiex_private * priv , u8 * bssid , \n \nbeacon_ie = kmemdup ( ie_buf , ie_len , GFP_KERNEL ); \nif (! beacon_ie ) { \n+ kfree ( bss_desc ); \ndev_err ( priv -> adapter -> dev , \" failed to alloc beacon_ie \\ n \"); \nreturn - ENOMEM ; \n}", "mmm drivers / input / touchscreen / wm97xx - core . c \nppp drivers / input / touchscreen / wm97xx - core . c \nstatic int wm97xx_init_pen_irq ( struct wm97xx * wm ) \n* provided . */ \nBUG_ON (! wm -> mach_ops -> irq_enable ); \n \n- if ( request_irq ( wm -> pen_irq , wm97xx_pen_interrupt , IRQF_SHARED , \n+ if ( request_irq ( wm -> pen_irq , wm97xx_pen_interrupt , \n+ IRQF_SHARED | IRQF_SAMPLE_RANDOM , \n\" wm97xx - pen \", wm )) { \ndev_err ( wm -> dev , \n\" Failed to register pen down interrupt , polling \");", "mmm drivers / net / wireless / marvell / mwifiex / pcie . c \nppp drivers / net / wireless / marvell / mwifiex / pcie . c \nstatic int mwifiex_pcie_alloc_cmdrsp_buf ( struct mwifiex_adapter * adapter ) \n} \nskb_put ( skb , MWIFIEX_UPLD_SIZE ); \nif ( mwifiex_map_pci_memory ( adapter , skb , MWIFIEX_UPLD_SIZE , \n- PCI_DMA_FROMDEVICE )) \n+ PCI_DMA_FROMDEVICE )) { \n+ kfree_skb ( skb ); \nreturn - 1 ; \n+ } \n \ncard -> cmdrsp_buf = skb ; \n", "mmm net / socket . c \nppp net / socket . c \nstatic int copy_msghdr_from_user ( struct msghdr * kmsg , \n{ \nif ( copy_from_user ( kmsg , umsg , sizeof ( struct msghdr ))) \nreturn - EFAULT ; \n+ \n+ if ( kmsg -> msg_namelen < 0 ) \n+ return - EINVAL ; \n+ \nif ( kmsg -> msg_namelen > sizeof ( struct sockaddr_storage )) \nkmsg -> msg_namelen = sizeof ( struct sockaddr_storage ); \nreturn 0 ;", "mmm net / packet / af_packet . c \nppp net / packet / af_packet . c \nstatic int tpacket_snd ( struct packet_sock * po , struct msghdr * msg ) \n} \ntp_len = tpacket_fill_skb ( po , skb , ph , dev , size_max , proto , \naddr , hlen ); \n- if ( tp_len > dev -> mtu + dev -> hard_header_len ) { \n+ if ( likely ( tp_len >= 0 ) && \n+ tp_len > dev -> mtu + dev -> hard_header_len ) { \nstruct ethhdr * ehdr ; \n/* Earlier code assumed this would be a VLAN pkt , \n* double - check this now that we have the actual", "mmm drivers / staging / unisys / visorbus / visorchipset . c \nppp drivers / staging / unisys / visorbus / visorchipset . c \nstatic ssize_t toolaction_store ( struct device * dev , \nconst char * buf , size_t count ) \n{ \nu8 tool_action ; \n- int ret ; \n+ int err ; \n \nif ( kstrtou8 ( buf , 10 , & tool_action )) \nreturn - EINVAL ; \n \n- ret = visorchannel_write \n+ err = visorchannel_write \n( chipset_dev -> controlvm_channel , \noffsetof ( struct spar_controlvm_channel_protocol , \ntool_action ), \n& tool_action , sizeof ( u8 )); \n \n- if ( ret ) \n- return ret ; \n+ if ( err ) \n+ return err ; \nreturn count ; \n} \nstatic DEVICE_ATTR_RW ( toolaction );", "mmm drivers / media / usb / cx231xx / cx231xx - core . c \nppp drivers / media / usb / cx231xx / cx231xx - core . c \nint cx231xx_set_mode ( struct cx231xx * dev , enum cx231xx_mode set_mode ) \n} \n} \n \n- return errCode ? - EINVAL : 0 ; \n+ if ( errCode < 0 ) { \n+ dev_err ( dev -> dev , \" Failed to set devmode to % s : error : % i \", \n+ dev -> mode == CX231XX_DIGITAL_MODE ? \" digital \" : \" analog \", \n+ errCode ); \n+ return errCode ; \n+ } \n+ \n+ return 0 ; \n} \nEXPORT_SYMBOL_GPL ( cx231xx_set_mode ); \n", "mmm drivers / usb / host / whci / qset . c \nppp drivers / usb / host / whci / qset . c \nstatic int qset_add_urb_sg ( struct whc * whc , struct whc_qset * qset , struct urb * u \n|| ( prev_end & ( WHCI_PAGE_SIZE - 1 )) \n|| ( dma_addr & ( WHCI_PAGE_SIZE - 1 )) \n|| std -> len + WHCI_PAGE_SIZE > QTD_MAX_XFER_SIZE ) { \n- if ( std -> len % qset -> max_packet != 0 ) \n+ if ( std && std -> len % qset -> max_packet != 0 ) \nreturn - EINVAL ; \nstd = qset_new_std ( whc , qset , urb , mem_flags ); \nif ( std == NULL ) {", "mmm kernel / srcu . c \nppp kernel / srcu . c \nstatic bool srcu_readers_active_idx_check ( struct srcu_struct * sp , int idx ) \n*/ \nstatic int srcu_readers_active ( struct srcu_struct * sp ) \n{ \n- return srcu_readers_active_idx ( sp , 0 ) + srcu_readers_active_idx ( sp , 1 ); \n+ int cpu ; \n+ unsigned long sum = 0 ; \n+ \n+ for_each_possible_cpu ( cpu ) { \n+ sum += ACCESS_ONCE ( per_cpu_ptr ( sp -> per_cpu_ref , cpu )-> c [ 0 ]); \n+ sum += ACCESS_ONCE ( per_cpu_ptr ( sp -> per_cpu_ref , cpu )-> c [ 1 ]); \n+ } \n+ return sum ; \n} \n \n/**", "mmm drivers / leds / leds - mlxcpld . c \nppp drivers / leds / leds - mlxcpld . c \nstatic int __init mlxcpld_led_init ( void ) \nstruct platform_device * pdev ; \nint err ; \n \n+ if (! dmi_match ( DMI_CHASSIS_VENDOR , \" Mellanox Technologies Ltd .\")) \n+ return - ENODEV ; \n+ \npdev = platform_device_register_simple ( KBUILD_MODNAME , - 1 , NULL , 0 ); \nif ( IS_ERR ( pdev )) { \npr_err (\" Device allocation failed \\ n \"); \nmodule_exit ( mlxcpld_led_exit ); \n \nMODULE_AUTHOR (\" Vadim Pasternak < vadimp @ mellanox . com >\"); \nMODULE_DESCRIPTION (\" Mellanox board LED driver \"); \n- MODULE_LICENSE (\" GPL v2 \"); \n+ MODULE_LICENSE (\" Dual BSD / GPL \"); \nMODULE_ALIAS (\" platform : leds_mlxcpld \");", "mmm kernel / early_res . c \nppp kernel / early_res . c \nstatic void __init drop_range_partial ( int i , u64 start , u64 end ) \n/* make head segment */ \nearly_res [ i ]. end = common_start ; \nif ( old_end > common_end ) { \n+ char name [ 15 ]; \n+ \n+ /* \n+ * Save a local copy of the name , since the \n+ * early_res array could get resized inside \n+ * reserve_early_without_check () -> \n+ * __check_and_double_early_res (), which would \n+ * make the current name pointer invalid . \n+ */ \n+ strncpy ( name , early_res [ i ]. name , \n+ sizeof ( early_res [ i ]. name ) - 1 ); \n/* add another for left over on tail */ \n- reserve_early_without_check ( common_end , old_end , \n- early_res [ i ]. name ); \n+ reserve_early_without_check ( common_end , old_end , name ); \n} \nreturn ; \n} else {", "mmm drivers / net / wireless / broadcom / brcm80211 / brcmfmac / fweh . c \nppp drivers / net / wireless / broadcom / brcm80211 / brcmfmac / fweh . c \nvoid brcmf_fweh_process_event ( struct brcmf_pub * drvr , \nif ( code != BRCMF_E_IF && ! fweh -> evt_handler [ code ]) \nreturn ; \n \n- if ( datalen > BRCMF_DCMD_MAXLEN ) \n+ if ( datalen > BRCMF_DCMD_MAXLEN || \n+ datalen + sizeof (* event_packet ) > packet_len ) \nreturn ; \n \nif ( in_interrupt ())", "mmm drivers / tty / tty_ldisc . c \nppp drivers / tty / tty_ldisc . c \nEXPORT_SYMBOL_GPL ( tty_ldisc_flush ); \n* they are not on hot paths so a little discipline won ' t do \n* any harm . \n* \n+ * The line discipline - related tty_struct fields are reset to \n+ * prevent the ldisc driver from re - using stale information for \n+ * the new ldisc instance . \n+ * \n* Locking : takes termios_rwsem \n*/ \n \nstatic void tty_set_termios_ldisc ( struct tty_struct * tty , int num ) \ndown_write (& tty -> termios_rwsem ); \ntty -> termios . c_line = num ; \nup_write (& tty -> termios_rwsem ); \n+ \n+ tty -> disc_data = NULL ; \n+ tty -> receive_room = 0 ; \n} \n \n/**", "mmm drivers / net / bonding / bond_main . c \nppp drivers / net / bonding / bond_main . c \nstatic void bond_info_show_slave ( struct seq_file * seq , \nseq_printf ( seq , \"\\ nSlave Interface : % s \\ n \", slave -> dev -> name ); \nseq_printf ( seq , \" MII Status : % s \\ n \", \n( slave -> link == BOND_LINK_UP ) ? \" up \" : \" down \"); \n+ seq_printf ( seq , \" Speed : % d Mbps \\ n \", slave -> speed ); \n+ seq_printf ( seq , \" Duplex : % s \\ n \", slave -> duplex ? \" full \" : \" half \"); \nseq_printf ( seq , \" Link Failure Count : % u \\ n \", \nslave -> link_failure_count ); \n", "mmm drivers / dma / dmaengine . c \nppp drivers / dma / dmaengine . c \nvoid dma_run_dependencies ( struct dma_async_tx_descriptor * tx ) \nif (! dep ) \nreturn ; \n \n+ /* we ' ll submit tx -> next now , so clear the link */ \n+ tx -> next = NULL ; \nchan = dep -> chan ; \n \n/* keep submitting up until a channel switch is detected", "mmm net / bluetooth / mgmt . c \nppp net / bluetooth / mgmt . c \nstatic int send_pin_code_neg_reply ( struct sock * sk , struct hci_dev * hdev , \nif (! cmd ) \nreturn - ENOMEM ; \n \n+ cmd -> cmd_complete = addr_cmd_complete ; \n+ \nerr = hci_send_cmd ( hdev , HCI_OP_PIN_CODE_NEG_REPLY , \nsizeof ( cp -> addr . bdaddr ), & cp -> addr . bdaddr ); \nif ( err < 0 )", "mmm fs / btrfs / extent - tree . c \nppp fs / btrfs / extent - tree . c \nstatic int alloc_reserved_tree_block ( struct btrfs_trans_handle * trans , \nret = btrfs_insert_empty_item ( trans , fs_info -> extent_root , path , \nins , size ); \nif ( ret ) { \n+ btrfs_free_path ( path ); \nbtrfs_free_and_pin_reserved_extent ( root , ins -> objectid , \nroot -> nodesize ); \n- btrfs_free_path ( path ); \nreturn ret ; \n} \n", "mmm arch / mips / kernel / smp - cps . c \nppp arch / mips / kernel / smp - cps . c \nstatic void boot_core ( unsigned core ) \nwrite_gcr_access ( access ); \n \nif ( mips_cpc_present ()) { \n- /* Select the appropriate core */ \n- write_cpc_cl_other ( core << CPC_Cx_OTHER_CORENUM_SHF ); \n- \n/* Reset the core */ \n+ mips_cpc_lock_other ( core ); \nwrite_cpc_co_cmd ( CPC_Cx_CMD_RESET ); \n+ mips_cpc_unlock_other (); \n} else { \n/* Take the core out of reset */ \nwrite_gcr_co_reset_release ( 0 );", "mmm include / asm - mips / unistd . h \nppp include / asm - mips / unistd . h \n# define __NR_mknodat ( __NR_Linux + 290 ) \n# define __NR_fchownat ( __NR_Linux + 291 ) \n# define __NR_futimesat ( __NR_Linux + 292 ) \n-# define __NR_fstatat ( __NR_Linux + 293 ) \n+# define __NR_fstatat64 ( __NR_Linux + 293 ) \n# define __NR_unlinkat ( __NR_Linux + 294 ) \n# define __NR_renameat ( __NR_Linux + 295 ) \n# define __NR_linkat ( __NR_Linux + 296 ) \n# define __NR_mknodat ( __NR_Linux + 249 ) \n# define __NR_fchownat ( __NR_Linux + 250 ) \n# define __NR_futimesat ( __NR_Linux + 251 ) \n-# define __NR_fstatat ( __NR_Linux + 252 ) \n+# define __NR_newfstatat ( __NR_Linux + 252 ) \n# define __NR_unlinkat ( __NR_Linux + 253 ) \n# define __NR_renameat ( __NR_Linux + 254 ) \n# define __NR_linkat ( __NR_Linux + 255 ) \n# define __NR_mknodat ( __NR_Linux + 253 ) \n# define __NR_fchownat ( __NR_Linux + 254 ) \n# define __NR_futimesat ( __NR_Linux + 255 ) \n-# define __NR_fstatat ( __NR_Linux + 256 ) \n+# define __NR_newfstatat ( __NR_Linux + 256 ) \n# define __NR_unlinkat ( __NR_Linux + 257 ) \n# define __NR_renameat ( __NR_Linux + 258 ) \n# define __NR_linkat ( __NR_Linux + 259 )", "mmm drivers / dma / amba - pl08x . c \nppp drivers / dma / amba - pl08x . c \nstatic int pl08x_probe ( struct amba_device * adev , const struct amba_id * id ) \nif ( ret ) \nreturn ret ; \n \n+ /* Ensure that we can do DMA */ \n+ ret = dma_set_mask_and_coherent (& adev -> dev , DMA_BIT_MASK ( 32 )); \n+ if ( ret ) \n+ goto out_no_pl08x ; \n+ \n/* Create the driver state holder */ \npl08x = kzalloc ( sizeof (* pl08x ), GFP_KERNEL ); \nif (! pl08x ) {", "mmm lib / dma - direct . c \nppp lib / dma - direct . c \nvoid * dma_direct_alloc ( struct device * dev , size_t size , dma_addr_t * dma_handle , \n__free_pages ( page , page_order ); \npage = NULL ; \n \n+ if ( IS_ENABLED ( CONFIG_ZONE_DMA32 ) && \n+ dev -> coherent_dma_mask < DMA_BIT_MASK ( 64 ) && \n+ !( gfp & ( GFP_DMA32 | GFP_DMA ))) { \n+ gfp |= GFP_DMA32 ; \n+ goto again ; \n+ } \n+ \nif ( IS_ENABLED ( CONFIG_ZONE_DMA ) && \ndev -> coherent_dma_mask < DMA_BIT_MASK ( 32 ) && \n!( gfp & GFP_DMA )) {", "mmm drivers / target / target_core_spc . c \nppp drivers / target / target_core_spc . c \nstatic int spc_emulate_inquiry ( struct se_cmd * cmd ) \nunsigned char buf [ SE_INQUIRY_BUF ]; \nint p , ret ; \n \n+ memset ( buf , 0 , SE_INQUIRY_BUF ); \n+ \nif ( dev == tpg -> tpg_virt_lun0 . lun_se_dev ) \nbuf [ 0 ] = 0x3f ; /* Not connected */ \nelse", "mmm arch / arm / mm / dma - mapping . c \nppp arch / arm / mm / dma - mapping . c \nstatic void __dma_page_dev_to_cpu ( struct page * page , unsigned long off , \nunsigned long paddr = page_to_phys ( page ) + off ; \n \n/* FIXME : non - speculating : not required */ \n- /* don ' t bother invalidating if DMA to device */ \n- if ( dir != DMA_TO_DEVICE ) \n+ /* in any case , don ' t bother invalidating if DMA to device */ \n+ if ( dir != DMA_TO_DEVICE ) { \nouter_inv_range ( paddr , paddr + size ); \n \n- dma_cache_maint_page ( page , off , size , dir , dmac_unmap_area ); \n+ dma_cache_maint_page ( page , off , size , dir , dmac_unmap_area ); \n+ } \n \n/* \n* Mark the D - cache clean for these pages to avoid extra flushing .", "mmm sound / core / pcm_lib . c \nppp sound / core / pcm_lib . c \nstatic int snd_pcm_update_hw_ptr_interrupt ( struct snd_pcm_substream * substream ) \nnew_hw_ptr = hw_base + pos ; \nhw_ptr_interrupt = runtime -> hw_ptr_interrupt + runtime -> period_size ; \ndelta = new_hw_ptr - hw_ptr_interrupt ; \n- if ( hw_ptr_interrupt == runtime -> boundary ) \n- hw_ptr_interrupt = 0 ; \n+ if ( hw_ptr_interrupt >= runtime -> boundary ) { \n+ hw_ptr_interrupt %= runtime -> boundary ; \n+ if (! hw_base ) /* hw_base was already lapped ; recalc delta */ \n+ delta = new_hw_ptr - hw_ptr_interrupt ; \n+ } \nif ( delta < 0 ) { \ndelta += runtime -> buffer_size ; \nif ( delta < 0 ) { \nstatic int snd_pcm_update_hw_ptr_interrupt ( struct snd_pcm_substream * substream ) \n( long ) hw_ptr_interrupt ); \n/* rebase to interrupt position */ \nhw_base = new_hw_ptr = hw_ptr_interrupt ; \n+ /* align hw_base to buffer_size */ \n+ hw_base -= hw_base % runtime -> buffer_size ; \ndelta = 0 ; \n} else { \nhw_base += runtime -> buffer_size ;", "mmm drivers / net / wireless / broadcom / brcm80211 / brcmfmac / cfg80211 . c \nppp drivers / net / wireless / broadcom / brcm80211 / brcmfmac / cfg80211 . c \nbrcmf_cfg80211_start_ap ( struct wiphy * wiphy , struct net_device * ndev , \n( u8 *)& settings -> beacon . head [ ie_offset ], \nsettings -> beacon . head_len - ie_offset , \nWLAN_EID_SSID ); \n- if (! ssid_ie ) \n+ if (! ssid_ie || ssid_ie -> len > IEEE80211_MAX_SSID_LEN ) \nreturn - EINVAL ; \n \nmemcpy ( ssid_le . SSID , ssid_ie -> data , ssid_ie -> len );", "mmm drivers / infiniband / hw / hns / hns_roce_main . c \nppp drivers / infiniband / hw / hns / hns_roce_main . c \nstatic struct ib_ucontext * hns_roce_alloc_ucontext ( struct ib_device * ib_dev , \n{ \nint ret = 0 ; \nstruct hns_roce_ucontext * context ; \n- struct hns_roce_ib_alloc_ucontext_resp resp ; \n+ struct hns_roce_ib_alloc_ucontext_resp resp = {}; \nstruct hns_roce_dev * hr_dev = to_hr_dev ( ib_dev ); \n \nresp . qp_tab_size = hr_dev -> caps . num_qps ;", "mmm net / sctp / socket . c \nppp net / sctp / socket . c \nint sctp_do_peeloff ( struct sock * sk , sctp_assoc_t id , struct socket ** sockp ) \nstruct socket * sock ; \nint err = 0 ; \n \n+ /* Do not peel off from one netns to another one . */ \n+ if (! net_eq ( current -> nsproxy -> net_ns , sock_net ( sk ))) \n+ return - EINVAL ; \n+ \nif (! asoc ) \nreturn - EINVAL ; \n", "mmm net / sctp / socket . c \nppp net / sctp / socket . c \nint sctp_do_peeloff ( struct sock * sk , sctp_assoc_t id , struct socket ** sockp ) \nif (! asoc ) \nreturn - EINVAL ; \n \n+ /* If there is a thread waiting on more sndbuf space for \n+ * sending on this asoc , it cannot be peeled . \n+ */ \n+ if ( waitqueue_active (& asoc -> wait )) \n+ return - EBUSY ; \n+ \n/* An association cannot be branched off from an already peeled - off \n* socket , nor is this supported for tcp style sockets . \n*/ \nstatic int sctp_wait_for_sndbuf ( struct sctp_association * asoc , long * timeo_p , \n*/ \nrelease_sock ( sk ); \ncurrent_timeo = schedule_timeout ( current_timeo ); \n- if ( sk != asoc -> base . sk ) \n- goto do_error ; \nlock_sock ( sk ); \n \n* timeo_p = current_timeo ;", "mmm drivers / platform / x86 / samsung - laptop . c \nppp drivers / platform / x86 / samsung - laptop . c \n# include < linux / seq_file . h > \n# include < linux / debugfs . h > \n# include < linux / ctype . h > \n+# include < linux / efi . h > \n# include < acpi / video . h > \n \n/* \nstatic int __init samsung_init ( void ) \nstruct samsung_laptop * samsung ; \nint ret ; \n \n+ if ( efi_enabled ( EFI_BOOT )) \n+ return - ENODEV ; \n+ \nquirks = & samsung_unknown ; \nif (! force && ! dmi_check_system ( samsung_dmi_table )) \nreturn - ENODEV ;", "mmm drivers / video / fbdev / fsl - diu - fb . c \nppp drivers / video / fbdev / fsl - diu - fb . c \nstatic int fsl_diu_suspend ( struct platform_device * ofdev , pm_message_t state ) \nstatic int fsl_diu_resume ( struct platform_device * ofdev ) \n{ \nstruct fsl_diu_data * data ; \n+ unsigned int i ; \n \ndata = dev_get_drvdata (& ofdev -> dev ); \n- enable_lcdc ( data -> fsl_diu_info ); \n+ \n+ fsl_diu_enable_interrupts ( data ); \n+ update_lcdc ( data -> fsl_diu_info ); \n+ for ( i = 0 ; i < NUM_AOIS ; i ++) { \n+ if ( data -> mfb [ i ]. count ) \n+ fsl_diu_enable_panel (& data -> fsl_diu_info [ i ]); \n+ } \n \nreturn 0 ; \n}", "mmm drivers / net / wireless / iwlwifi / mvm / fw . c \nppp drivers / net / wireless / iwlwifi / mvm / fw . c \nint iwl_run_init_mvm_ucode ( struct iwl_mvm * mvm , bool read_nvm ) \nret = iwl_nvm_check_version ( mvm -> nvm_data , mvm -> trans ); \nWARN_ON ( ret ); \n \n+ /* Send TX valid antennas before triggering calibrations */ \n+ ret = iwl_send_tx_ant_cfg ( mvm , mvm -> nvm_data -> valid_tx_ant ); \n+ if ( ret ) \n+ goto error ; \n+ \n/* Override the calibrations from TLV and the const of fw */ \niwl_set_default_calib_trigger ( mvm ); \n", "mmm drivers / iio / industrialio - buffer . c \nppp drivers / iio / industrialio - buffer . c \nvoid iio_disable_all_buffers ( struct iio_dev * indio_dev ) \nindio_dev -> currentmode = INDIO_DIRECT_MODE ; \nif ( indio_dev -> setup_ops -> postdisable ) \nindio_dev -> setup_ops -> postdisable ( indio_dev ); \n+ \n+ if ( indio_dev -> available_scan_masks == NULL ) \n+ kfree ( indio_dev -> active_scan_mask ); \n} \n \nint iio_update_buffers ( struct iio_dev * indio_dev ,", "mmm security / tomoyo / common . c \nppp security / tomoyo / common . c \nssize_t tomoyo_write_control ( struct tomoyo_io_buffer * head , \nreturn - EFAULT ; \nif ( mutex_lock_interruptible (& head -> io_sem )) \nreturn - EINTR ; \n+ head -> read_user_buf_avail = 0 ; \nidx = tomoyo_read_lock (); \n/* Read a line and dispatch it to the policy handler . */ \nwhile ( avail_len > 0 ) {", "mmm drivers / virt / vboxguest / vboxguest_utils . c \nppp drivers / virt / vboxguest / vboxguest_utils . c \nstatic int hgcm_call_preprocess_linaddr ( \nif (! bounce_buf ) \nreturn - ENOMEM ; \n \n+ * bounce_buf_ret = bounce_buf ; \n+ \nif ( copy_in ) { \nret = copy_from_user ( bounce_buf , ( void __user *) buf , len ); \nif ( ret ) \nstatic int hgcm_call_preprocess_linaddr ( \nmemset ( bounce_buf , 0 , len ); \n} \n \n- * bounce_buf_ret = bounce_buf ; \nhgcm_call_add_pagelist_size ( bounce_buf , len , extra ); \nreturn 0 ; \n}", "mmm drivers / acpi / acpi_memhotplug . c \nppp drivers / acpi / acpi_memhotplug . c \nstatic int acpi_memory_device_add ( struct acpi_device * device ) \nif (! acpi_memory_check_device ( mem_device )) { \n/* call add_memory func */ \nresult = acpi_memory_enable_device ( mem_device ); \n- if ( result ) \n+ if ( result ) { \nprintk ( KERN_ERR PREFIX \n\" Error in acpi_memory_enable_device \\ n \"); \n+ acpi_memory_device_free ( mem_device ); \n+ } \n} \nreturn result ; \n}", "mmm kernel / sched . c \nppp kernel / sched . c \nstatic int wake_idle ( int cpu , task_t * p ) \n \nfor_each_domain ( cpu , sd ) { \nif ( sd -> flags & SD_WAKE_IDLE ) { \n- cpus_and ( tmp , sd -> span , cpu_online_map ); \n- cpus_and ( tmp , tmp , p -> cpus_allowed ); \n+ cpus_and ( tmp , sd -> span , p -> cpus_allowed ); \nfor_each_cpu_mask ( i , tmp ) { \nif ( idle_cpu ( i )) \nreturn i ; \n} \n} \n- else break ; \n+ else \n+ break ; \n} \nreturn cpu ; \n}", "mmm drivers / infiniband / hw / mthca / mthca_srq . c \nppp drivers / infiniband / hw / mthca / mthca_srq . c \nint mthca_alloc_srq ( struct mthca_dev * dev , struct mthca_pd * pd , \nsrq -> first_free = 0 ; \nsrq -> last_free = srq -> max - 1 ; \n \n- attr -> max_wr = srq -> max ; \n+ attr -> max_wr = ( mthca_is_memfree ( dev )) ? srq -> max - 1 : srq -> max ; \nattr -> max_sge = srq -> max_gs ; \n \nreturn 0 ; \nint mthca_query_srq ( struct ib_srq * ibsrq , struct ib_srq_attr * srq_attr ) \n} else \nsrq_attr -> srq_limit = 0 ; \n \n- srq_attr -> max_wr = srq -> max ; \n+ srq_attr -> max_wr = ( mthca_is_memfree ( dev )) ? srq -> max - 1 : srq -> max ; \nsrq_attr -> max_sge = srq -> max_gs ; \n \nout :", "mmm net / bluetooth / rfcomm / sock . c \nppp net / bluetooth / rfcomm / sock . c \nstatic int rfcomm_sock_recvmsg ( struct kiocb * iocb , struct socket * sock , \n \nif ( test_and_clear_bit ( RFCOMM_DEFER_SETUP , & d -> flags )) { \nrfcomm_dlc_accept ( d ); \n+ msg -> msg_namelen = 0 ; \nreturn 0 ; \n} \n", "mmm fs / xfs / xfs_reflink . c \nppp fs / xfs / xfs_reflink . c \nxfs_reflink_end_cow ( \n/* If there is a hole at end_fsb - 1 go to the previous extent */ \nif (! xfs_iext_lookup_extent ( ip , ifp , end_fsb - 1 , & idx , & got ) || \ngot . br_startoff > end_fsb ) { \n- ASSERT ( idx > 0 ); \n+ /* \n+ * In case of racing , overlapping AIO writes no COW extents \n+ * might be left by the time I / O completes for the loser of \n+ * the race . In that case we are done . \n+ */ \n+ if ( idx <= 0 ) \n+ goto out_cancel ; \nxfs_iext_get_extent ( ifp , -- idx , & got ); \n} \n \nxfs_reflink_end_cow ( \n \nout_defer : \nxfs_defer_cancel (& dfops ); \n+ out_cancel : \nxfs_trans_cancel ( tp ); \nxfs_iunlock ( ip , XFS_ILOCK_EXCL ); \nout :", "mmm drivers / of / unittest . c \nppp drivers / of / unittest . c \nstatic int __init unittest_data_add ( void ) \nof_fdt_unflatten_tree ( unittest_data , NULL , & unittest_data_node ); \nif (! unittest_data_node ) { \npr_warn (\"% s : No tree to attach ; not running tests \\ n \", __func__ ); \n+ kfree ( unittest_data ); \nreturn - ENODATA ; \n} \n", "mmm arch / blackfin / kernel / debug - mmrs . c \nppp arch / blackfin / kernel / debug - mmrs . c \nbfin_debug_mmrs_dma ( struct dentry * parent , unsigned long base , int num , char mdm \n__DMA ( CURR_DESC_PTR , curr_desc_ptr ); \n__DMA ( CURR_ADDR , curr_addr ); \n__DMA ( IRQ_STATUS , irq_status ); \n- __DMA ( PERIPHERAL_MAP , peripheral_map ); \n+ if ( strcmp ( pfx , \" IMDMA \") != 0 ) \n+ __DMA ( PERIPHERAL_MAP , peripheral_map ); \n__DMA ( CURR_X_COUNT , curr_x_count ); \n__DMA ( CURR_Y_COUNT , curr_y_count ); \n}", "mmm mm / vmpressure . c \nppp mm / vmpressure . c \nstatic enum vmpressure_levels vmpressure_calc_level ( unsigned long scanned , \nunsigned long reclaimed ) \n{ \nunsigned long scale = scanned + reclaimed ; \n- unsigned long pressure ; \n+ unsigned long pressure = 0 ; \n \n+ /* \n+ * reclaimed can be greater than scanned in cases \n+ * like THP , where the scanned is 1 and reclaimed \n+ * could be 512 \n+ */ \n+ if ( reclaimed >= scanned ) \n+ goto out ; \n/* \n* We calculate the ratio ( in percents ) of how many pages were \n* scanned vs . reclaimed in a given time frame ( window ). Note that \nstatic enum vmpressure_levels vmpressure_calc_level ( unsigned long scanned , \npressure = scale - ( reclaimed * scale / scanned ); \npressure = pressure * 100 / scale ; \n \n+ out : \npr_debug (\"% s : % 3lu ( s : % lu r : % lu )\\ n \", __func__ , pressure , \nscanned , reclaimed ); \n", "mmm fs / udf / inode . c \nppp fs / udf / inode . c \nstatic int udf_read_inode ( struct inode * inode , bool hidden_inode ) \n} \ninode -> i_generation = iinfo -> i_unique ; \n \n+ /* Sanity checks for files in ICB so that we don ' t get confused later */ \n+ if ( iinfo -> i_alloc_type == ICBTAG_FLAG_AD_IN_ICB ) { \n+ /* \n+ * For file in ICB data is stored in allocation descriptor \n+ * so sizes should match \n+ */ \n+ if ( iinfo -> i_lenAlloc != inode -> i_size ) \n+ goto out ; \n+ /* File in ICB has to fit in there ... */ \n+ if ( inode -> i_size > inode -> i_sb -> s_blocksize - \n+ udf_file_entry_alloc_offset ( inode )) \n+ goto out ; \n+ } \n+ \nswitch ( fe -> icbTag . fileType ) { \ncase ICBTAG_FILE_TYPE_DIRECTORY : \ninode -> i_op = & udf_dir_inode_operations ;", "mmm net / bluetooth / af_bluetooth . c \nppp net / bluetooth / af_bluetooth . c \nvoid bt_accept_enqueue ( struct sock * parent , struct sock * sk ) \nBT_DBG (\" parent % p , sk % p \", parent , sk ); \n \nsock_hold ( sk ); \n+ lock_sock ( sk ); \nlist_add_tail (& bt_sk ( sk )-> accept_q , & bt_sk ( parent )-> accept_q ); \nbt_sk ( sk )-> parent = parent ; \n+ release_sock ( sk ); \nparent -> sk_ack_backlog ++; \n} \nEXPORT_SYMBOL ( bt_accept_enqueue );", "mmm include / uapi / linux / usb / ch9 . h \nppp include / uapi / linux / usb / ch9 . h \n# define USB_REQ_LOOPBACK_DATA_READ 0x16 \n# define USB_REQ_SET_INTERFACE_DS 0x17 \n \n+/* specific requests for USB Power Delivery */ \n+# define USB_REQ_GET_PARTNER_PDO 20 \n+# define USB_REQ_GET_BATTERY_STATUS 21 \n+# define USB_REQ_SET_PDO 22 \n+# define USB_REQ_GET_VDM 23 \n+# define USB_REQ_SEND_VDM 24 \n+ \n/* The Link Power Management ( LPM ) ECN defines USB_REQ_TEST_AND_SET command , \n* used by hubs to put ports into a new L1 suspend state , except that it \n* forgot to define its number ...", "mmm fs / orangefs / file . c \nppp fs / orangefs / file . c \nstatic ssize_t wait_for_direct_io ( enum ORANGEFS_io_type type , struct inode * inod \n*/ \nif ( ret == - EAGAIN && op_state_purged ( new_op )) { \norangefs_bufmap_put ( bufmap , buffer_index ); \n+ buffer_index = - 1 ; \ngossip_debug ( GOSSIP_FILE_DEBUG , \n\"% s : going to repopulate_shared_memory .\\ n \", \n__func__ );", "mmm arch / x86 / kvm / i8254 . c \nppp arch / x86 / kvm / i8254 . c \nstruct kvm_pit * kvm_create_pit ( struct kvm * kvm ) \nmutex_lock (& kvm -> lock ); \npit -> irq_source_id = kvm_request_irq_source_id ( kvm ); \nmutex_unlock (& kvm -> lock ); \n- if ( pit -> irq_source_id < 0 ) \n+ if ( pit -> irq_source_id < 0 ) { \n+ kfree ( pit ); \nreturn NULL ; \n+ } \n \nmutex_init (& pit -> pit_state . lock ); \nmutex_lock (& pit -> pit_state . lock );", "mmm drivers / vfio / pci / vfio_pci . c \nppp drivers / vfio / pci / vfio_pci . c \nstatic int vfio_pci_mmap ( void * device_data , struct vm_area_struct * vma ) \nreturn ret ; \n \nvdev -> barmap [ index ] = pci_iomap ( pdev , index , 0 ); \n+ if (! vdev -> barmap [ index ]) { \n+ pci_release_selected_regions ( pdev , 1 << index ); \n+ return - ENOMEM ; \n+ } \n} \n \nvma -> vm_private_data = vdev ;", "mmm drivers / gpu / drm / radeon / radeon_atombios . c \nppp drivers / gpu / drm / radeon / radeon_atombios . c \nstatic bool radeon_atom_apply_quirks ( struct drm_device * dev , \nif (( supported_device == ATOM_DEVICE_CRT1_SUPPORT ) || \n( supported_device == ATOM_DEVICE_DFP2_SUPPORT )) \nreturn false ; \n+ if ( supported_device == ATOM_DEVICE_CRT2_SUPPORT ) \n+ * line_mux = 0x90 ; \n} \n \n/* ASUS HD 3600 XT board lists the DVI port as HDMI */", "mmm drivers / s390 / net / qeth_core_main . c \nppp drivers / s390 / net / qeth_core_main . c \nstatic inline void __qeth_fill_buffer ( struct sk_buff * skb , \nstruct qdio_buffer * buffer , int is_tso , int * next_element_to_fill , \nint offset ) \n{ \n- int length = skb -> len - offset ; \n+ int length = skb -> len ; \nint length_here ; \nint element ; \nchar * data ; \nstatic inline void __qeth_fill_buffer ( struct sk_buff * skb , \n \nif ( offset >= 0 ) { \ndata = skb -> data + offset ; \n+ length -= offset ; \nfirst_lap = 0 ; \n} \n", "mmm net / openvswitch / vport - internal_dev . c \nppp net / openvswitch / vport - internal_dev . c \nstatic int internal_dev_recv ( struct vport * vport , struct sk_buff * skb ) \nstruct net_device * netdev = netdev_vport_priv ( vport )-> dev ; \nint len ; \n \n+ if ( unlikely (!( netdev -> flags & IFF_UP ))) { \n+ kfree_skb ( skb ); \n+ return 0 ; \n+ } \n+ \nlen = skb -> len ; \n \nskb_dst_drop ( skb );", "mmm drivers / net / wireless / ath / ath10k / wmi . c \nppp drivers / net / wireless / ath / ath10k / wmi . c \nint ath10k_wmi_beacon_send_nowait ( struct ath10k * ar , \n{ \nstruct wmi_bcn_tx_cmd * cmd ; \nstruct sk_buff * skb ; \n+ int ret ; \n \nskb = ath10k_wmi_alloc_skb ( sizeof (* cmd ) + arg -> bcn_len ); \nif (! skb ) \nint ath10k_wmi_beacon_send_nowait ( struct ath10k * ar , \ncmd -> hdr . bcn_len = __cpu_to_le32 ( arg -> bcn_len ); \nmemcpy ( cmd -> bcn , arg -> bcn , arg -> bcn_len ); \n \n- return ath10k_wmi_cmd_send_nowait ( ar , skb , ar -> wmi . cmd -> bcn_tx_cmdid ); \n+ ret = ath10k_wmi_cmd_send_nowait ( ar , skb , ar -> wmi . cmd -> bcn_tx_cmdid ); \n+ if ( ret ) \n+ dev_kfree_skb ( skb ); \n+ \n+ return ret ; \n} \n \nstatic void ath10k_wmi_pdev_set_wmm_param ( struct wmi_wmm_params * params ,", "mmm kernel / sched / rt . c \nppp kernel / sched / rt . c \nstatic int do_sched_rt_period_timer ( struct rt_bandwidth * rt_b , int overrun ) \nconst struct cpumask * span ; \n \nspan = sched_rt_period_mask (); \n+# ifdef CONFIG_RT_GROUP_SCHED \n+ /* \n+ * FIXME : isolated CPUs should really leave the root task group , \n+ * whether they are isolcpus or were isolated via cpusets , lest \n+ * the timer run on a CPU which does not service all runqueues , \n+ * potentially leaving other CPUs indefinitely throttled . If \n+ * isolation is really required , the user will turn the throttle \n+ * off to kill the perturbations it causes anyway . Meanwhile , \n+ * this maintains functionality for boot and / or troubleshooting . \n+ */ \n+ if ( rt_b == & root_task_group . rt_bandwidth ) \n+ span = cpu_online_mask ; \n+# endif \nfor_each_cpu ( i , span ) { \nint enqueue = 0 ; \nstruct rt_rq * rt_rq = sched_rt_period_rt_rq ( rt_b , i );", "mmm drivers / media / usb / usbtv / usbtv - video . c \nppp drivers / media / usb / usbtv / usbtv - video . c \nstatic struct urb * usbtv_setup_iso_transfer ( struct usbtv * usbtv ) \nip -> transfer_flags = URB_ISO_ASAP ; \nip -> transfer_buffer = kzalloc ( size * USBTV_ISOC_PACKETS , \nGFP_KERNEL ); \n+ if (! ip -> transfer_buffer ) { \n+ usb_free_urb ( ip ); \n+ return NULL ; \n+ } \nip -> complete = usbtv_iso_cb ; \nip -> number_of_packets = USBTV_ISOC_PACKETS ; \nip -> transfer_buffer_length = size * USBTV_ISOC_PACKETS ;", "mmm drivers / gpu / drm / radeon / r600_cs . c \nppp drivers / gpu / drm / radeon / r600_cs . c \nstatic int r600_cs_packet_next_reloc_nomm ( struct radeon_cs_parser * p , \nidx , relocs_chunk -> length_dw ); \nreturn - EINVAL ; \n} \n- * cs_reloc = & p -> relocs [ 0 ]; \n+ * cs_reloc = p -> relocs ; \n(* cs_reloc )-> lobj . gpu_offset = ( u64 ) relocs_chunk -> kdata [ idx + 3 ] << 32 ; \n(* cs_reloc )-> lobj . gpu_offset |= relocs_chunk -> kdata [ idx + 0 ]; \nreturn 0 ; \nstatic int r600_cs_parser_relocs_legacy ( struct radeon_cs_parser * p ) \nif ( p -> chunk_relocs_idx == - 1 ) { \nreturn 0 ; \n} \n- p -> relocs = kcalloc ( 1 , sizeof ( struct radeon_cs_reloc ), GFP_KERNEL ); \n+ p -> relocs = kzalloc ( sizeof ( struct radeon_cs_reloc ), GFP_KERNEL ); \nif ( p -> relocs == NULL ) { \nreturn - ENOMEM ; \n}", "mmm drivers / net / macvlan . c \nppp drivers / net / macvlan . c \nstatic int macvlan_set_mac_address ( struct net_device * dev , void * p ) \nif (! is_valid_ether_addr ( addr -> sa_data )) \nreturn - EADDRNOTAVAIL ; \n \n+ /* If the addresses are the same , this is a no - op */ \n+ if ( ether_addr_equal ( dev -> dev_addr , addr -> sa_data )) \n+ return 0 ; \n+ \nif ( vlan -> mode == MACVLAN_MODE_PASSTHRU ) { \ndev_set_mac_address ( vlan -> lowerdev , addr ); \nreturn 0 ;", "mmm fs / btrfs / tree - log . c \nppp fs / btrfs / tree - log . c \nstatic int btrfs_add_log_tree ( struct btrfs_trans_handle * trans , \n*/ \nnew_root -> ref_cows = 0 ; \nnew_root -> last_trans = trans -> transid ; \n+ \n+ /* \n+ * we need to make sure the root block for this new tree \n+ * is marked as dirty in the dirty_log_pages tree . This \n+ * is how it gets flushed down to disk at tree log commit time . \n+ * \n+ * the tree logging mutex keeps others from coming in and changing \n+ * the new_root -> node , so we can safely access it here \n+ */ \n+ set_extent_dirty (& new_root -> dirty_log_pages , new_root -> node -> start , \n+ new_root -> node -> start + new_root -> node -> len - 1 , \n+ GFP_NOFS ); \n+ \nfail : \nreturn ret ; \n}", "mmm drivers / acpi / video . c \nppp drivers / acpi / video . c \nstatic int acpi_video_bus_put_one_device ( struct acpi_video_device * device ) \nstatus = acpi_remove_notify_handler ( device -> dev -> handle , \nACPI_DEVICE_NOTIFY , \nacpi_video_device_notify ); \n- sysfs_remove_link (& device -> backlight -> dev . kobj , \" device \"); \n- backlight_device_unregister ( device -> backlight ); \n+ if ( device -> backlight ) { \n+ sysfs_remove_link (& device -> backlight -> dev . kobj , \" device \"); \n+ backlight_device_unregister ( device -> backlight ); \n+ device -> backlight = NULL ; \n+ } \nif ( device -> cdev ) { \nsysfs_remove_link (& device -> dev -> dev . kobj , \n\" thermal_cooling \");", "mmm drivers / regulator / core . c \nppp drivers / regulator / core . c \nstatic int set_supply ( struct regulator_dev * rdev , \n \nrdev_info ( rdev , \" supplied by % s \\ n \", rdev_get_name ( supply_rdev )); \n \n+ if (! try_module_get ( supply_rdev -> owner )) \n+ return - ENODEV ; \n+ \nrdev -> supply = create_regulator ( supply_rdev , & rdev -> dev , \" SUPPLY \"); \nif ( rdev -> supply == NULL ) { \nerr = - ENOMEM ;", "mmm drivers / media / usb / usbvision / usbvision - video . c \nppp drivers / media / usb / usbvision / usbvision - video . c \nstatic int usbvision_v4l2_close ( struct file * file ) \nusbvision_scratch_free ( usbvision ); \n \nusbvision -> user --; \n+ mutex_unlock (& usbvision -> v4l2_lock ); \n \nif ( usbvision -> remove_pending ) { \nprintk ( KERN_INFO \"% s : Final disconnect \\ n \", __func__ ); \nusbvision_release ( usbvision ); \nreturn 0 ; \n} \n- mutex_unlock (& usbvision -> v4l2_lock ); \n \nPDEBUG ( DBG_IO , \" success \"); \nreturn v4l2_fh_release ( file );", "mmm net / bluetooth / hci_request . c \nppp net / bluetooth / hci_request . c \nint hci_req_sync ( struct hci_dev * hdev , int (* req )( struct hci_request * req , \n{ \nint ret ; \n \n- if (! test_bit ( HCI_UP , & hdev -> flags )) \n- return - ENETDOWN ; \n- \n/* Serialize all requests */ \nhci_req_sync_lock ( hdev ); \n- ret = __hci_req_sync ( hdev , req , opt , timeout , hci_status ); \n+ /* check the state after obtaing the lock to protect the HCI_UP \n+ * against any races from hci_dev_do_close when the controller \n+ * gets removed . \n+ */ \n+ if ( test_bit ( HCI_UP , & hdev -> flags )) \n+ ret = __hci_req_sync ( hdev , req , opt , timeout , hci_status ); \n+ else \n+ ret = - ENETDOWN ; \nhci_req_sync_unlock ( hdev ); \n \nreturn ret ;", "mmm drivers / video / modedb . c \nppp drivers / video / modedb . c \nint fb_find_mode ( struct fb_var_screeninfo * var , \n\"\", ( margins ) ? \" with margins \" : \"\", ( interlace ) ? \n\" interlaced \" : \"\"); \n \n+ memset (& cvt_mode , 0 , sizeof ( cvt_mode )); \ncvt_mode . xres = xres ; \ncvt_mode . yres = yres ; \ncvt_mode . refresh = ( refresh ) ? refresh : 60 ;", "mmm fs / btrfs / inode . c \nppp fs / btrfs / inode . c \nstruct extent_map * btrfs_get_extent ( struct inode * inode , struct page * page , \ngoto not_found ; \nif ( start + len <= found_key . offset ) \ngoto not_found ; \n+ if ( start > found_key . offset ) \n+ goto next ; \nem -> start = start ; \nem -> orig_start = start ; \nem -> len = found_key . offset - start ;", "mmm drivers / acpi / acpi_video . c \nppp drivers / acpi / acpi_video . c \nstatic int acpi_video_device_enumerate ( struct acpi_video_bus * video ) \nunion acpi_object * dod = NULL ; \nunion acpi_object * obj ; \n \n+ if (! video -> cap . _DOD ) \n+ return AE_NOT_EXIST ; \n+ \nstatus = acpi_evaluate_object ( video -> device -> handle , \" _DOD \", NULL , & buffer ); \nif (! ACPI_SUCCESS ( status )) { \nACPI_EXCEPTION (( AE_INFO , status , \" Evaluating _DOD \"));", "mmm net / bluetooth / mgmt . c \nppp net / bluetooth / mgmt . c \nstatic int set_connectable ( struct sock * sk , struct hci_dev * hdev , void * data , \n \nhci_req_add (& req , HCI_OP_WRITE_SCAN_ENABLE , 1 , & scan ); \n \n+ if (! cp -> val && test_bit ( HCI_FAST_CONNECTABLE , & hdev -> dev_flags )) \n+ write_fast_connectable (& req , false ); \n+ \nerr = hci_req_run (& req , set_connectable_complete ); \nif ( err < 0 ) \nmgmt_pending_remove ( cmd );", "mmm drivers / acpi / ioapic . c \nppp drivers / acpi / ioapic . c \nstatic acpi_status setup_res ( struct acpi_resource * acpi_res , void * data ) \nstruct resource * res = data ; \nstruct resource_win win ; \n \n+ /* \n+ * We might assign this to ' res ' later , make sure all pointers are \n+ * cleared before the resource is added to the global list \n+ */ \n+ memset (& win , 0 , sizeof ( win )); \n+ \nres -> flags = 0 ; \nif ( acpi_dev_filter_resource_type ( acpi_res , IORESOURCE_MEM )) \nreturn AE_OK ;", "mmm drivers / net / wireless / intel / iwlwifi / mvm / sta . c \nppp drivers / net / wireless / intel / iwlwifi / mvm / sta . c \nstatic int iwl_mvm_free_inactive_queue ( struct iwl_mvm * mvm , int queue , \nspin_unlock_bh (& mvm -> queue_info_lock ); \n \nmvmsta = iwl_mvm_sta_from_staid_protected ( mvm , sta_id ); \n+ if ( WARN_ON (! mvmsta )) \n+ return - EINVAL ; \n \ndisable_agg_tids = iwl_mvm_remove_sta_queue_marking ( mvm , queue ); \n/* Disable the queue */", "mmm net / sctp / sm_make_chunk . c \nppp net / sctp / sm_make_chunk . c \nstatic int sctp_process_param ( struct sctp_association * asoc , \naddr_param = param . v + sizeof ( sctp_addip_param_t ); \n \naf = sctp_get_af_specific ( param_type2af ( param . p -> type )); \n+ if ( af == NULL ) \n+ break ; \n+ \naf -> from_addr_param (& addr , addr_param , \nhtons ( asoc -> peer . port ), 0 ); \n", "mmm fs / afs / volume . c \nppp fs / afs / volume . c \nstatic struct afs_volume * afs_alloc_volume ( struct afs_mount_params * params , \nerror_2 : \nafs_put_serverlist ( params -> net , slist ); \nerror_1 : \n+ afs_put_cell ( params -> net , volume -> cell ); \nkfree ( volume ); \nerror_0 : \nreturn ERR_PTR ( ret );", "mmm fs / btrfs / volumes . c \nppp fs / btrfs / volumes . c \nint btrfs_rm_device ( struct btrfs_fs_info * fs_info , const char * device_path , \n \nif ( IS_ERR ( device )) { \nif ( PTR_ERR ( device ) == - ENOENT && \n- strcmp ( device_path , \" missing \") == 0 ) \n+ device_path && strcmp ( device_path , \" missing \") == 0 ) \nret = BTRFS_ERROR_DEV_MISSING_NOT_FOUND ; \nelse \nret = PTR_ERR ( device );", "mmm include / linux / phy . h \nppp include / linux / phy . h \nstatic inline bool phy_is_internal ( struct phy_device * phydev ) \nreturn phydev -> is_internal ; \n} \n \n+/** \n+ * phy_interface_is_rgmii - Convenience function for testing if a PHY interface \n+ * is RGMII ( all variants ) \n+ * @ phydev : the phy_device struct \n+ */ \n+ static inline bool phy_interface_is_rgmii ( struct phy_device * phydev ) \n+{ \n+ return phydev -> interface >= PHY_INTERFACE_MODE_RGMII && \n+ phydev -> interface <= PHY_INTERFACE_MODE_RGMII_TXID ; \n+} \n+ \n/** \n* phy_write_mmd - Convenience function for writing a register \n* on an MMD on a given PHY .", "mmm arch / powerpc / platforms / powernv / pci - ioda . c \nppp arch / powerpc / platforms / powernv / pci - ioda . c \nvoid __init pnv_pci_init_ioda1_phb ( struct device_node * np ) \n/* Allocate aux data & arrays */ \nsize = _ALIGN_UP ( phb -> ioda . total_pe / 8 , sizeof ( unsigned long )); \nm32map_off = size ; \n- size += phb -> ioda . total_pe ; \n+ size += phb -> ioda . total_pe * sizeof ( phb -> ioda . m32_segmap [ 0 ]); \niomap_off = size ; \n- size += phb -> ioda . total_pe ; \n+ size += phb -> ioda . total_pe * sizeof ( phb -> ioda . io_segmap [ 0 ]); \npemap_off = size ; \nsize += phb -> ioda . total_pe * sizeof ( struct pnv_ioda_pe ); \naux = alloc_bootmem ( size );", "mmm fs / befs / linuxvfs . c \nppp fs / befs / linuxvfs . c \nstatic void init_once ( void * foo ) \n \nstatic struct inode * befs_iget ( struct super_block * sb , unsigned long ino ) \n{ \n- struct buffer_head * bh = NULL ; \n+ struct buffer_head * bh ; \nbefs_inode * raw_inode = NULL ; \nstruct befs_sb_info * befs_sb = BEFS_SB ( sb ); \nstruct befs_inode_info * befs_ino = NULL ;", "mmm drivers / staging / lustre / lustre / libcfs / module . c \nppp drivers / staging / lustre / lustre / libcfs / module . c \nstatic int __proc_dobitmasks ( void * data , int write , \n} else { \nrc = cfs_trace_copyin_string ( tmpstr , tmpstrlen , buffer , nob ); \nif ( rc < 0 ) { \n- cfs_trace_free_string_buffer ( tmpstr , tmpstrlen ); \n+ kfree ( tmpstr ); \nreturn rc ; \n} \n \nstatic int __proc_dobitmasks ( void * data , int write , \n* mask |= D_EMERG ; \n} \n \n- cfs_trace_free_string_buffer ( tmpstr , tmpstrlen ); \n+ kfree ( tmpstr ); \nreturn rc ; \n} \n", "mmm sound / core / timer . c \nppp sound / core / timer . c \nstatic void snd_timer_user_tinterrupt ( struct snd_timer_instance * timeri , \n} \nif (( tu -> filter & ( 1 << SNDRV_TIMER_EVENT_RESOLUTION )) && \ntu -> last_resolution != resolution ) { \n+ memset (& r1 , 0 , sizeof ( r1 )); \nr1 . event = SNDRV_TIMER_EVENT_RESOLUTION ; \nr1 . tstamp = tstamp ; \nr1 . val = resolution ;", "mmm drivers / cdrom / cdrom . c \nppp drivers / cdrom / cdrom . c \nstatic int cdrom_ioctl_select_disc ( struct cdrom_device_info * cdi , \nreturn - ENOSYS ; \n \nif ( arg != CDSL_CURRENT && arg != CDSL_NONE ) { \n- if (( int ) arg >= cdi -> capacity ) \n+ if ( arg >= cdi -> capacity ) \nreturn - EINVAL ; \n} \n", "mmm mm / memory . c \nppp mm / memory . c \nint handle_mm_fault ( struct mm_struct * mm , struct vm_area_struct * vma , \nif ( pmd_trans_huge ( orig_pmd )) { \nunsigned int dirty = flags & FAULT_FLAG_WRITE ; \n \n+ /* \n+ * If the pmd is splitting , return and retry the \n+ * the fault . Alternative : wait until the split \n+ * is done , and goto retry . \n+ */ \n+ if ( pmd_trans_splitting ( orig_pmd )) \n+ return 0 ; \n+ \nif ( pmd_numa ( orig_pmd )) \nreturn do_huge_pmd_numa_page ( mm , vma , address , \norig_pmd , pmd );", "mmm net / core / sock . c \nppp net / core / sock . c \nEXPORT_SYMBOL ( sock_kmalloc ); \n*/ \nvoid sock_kfree_s ( struct sock * sk , void * mem , int size ) \n{ \n+ if ( WARN_ON_ONCE (! mem )) \n+ return ; \nkfree ( mem ); \natomic_sub ( size , & sk -> sk_omem_alloc ); \n}", "mmm fs / proc / root . c \nppp fs / proc / root . c \nstatic struct dentry * proc_mount ( struct file_system_type * fs_type , \nif ( IS_ERR ( sb )) \nreturn ERR_CAST ( sb ); \n \n+ /* \n+ * procfs isn ' t actually a stacking filesystem ; however , there is \n+ * too much magic going on inside it to permit stacking things on \n+ * top of it \n+ */ \n+ sb -> s_stack_depth = FILESYSTEM_MAX_STACK_DEPTH ; \n+ \nif (! proc_parse_options ( options , ns )) { \ndeactivate_locked_super ( sb ); \nreturn ERR_PTR (- EINVAL );", "mmm drivers / mtd / nand / diskonchip . c \nppp drivers / mtd / nand / diskonchip . c \n* \n* Interface to generic NAND code for M - Systems DiskOnChip devices \n* \n- * $ Id : diskonchip . c , v 1 . 50 2005 / 03 / 29 20 : 57 : 45 dbrown Exp $ \n+ * $ Id : diskonchip . c , v 1 . 51 2005 / 04 / 06 18 : 10 : 20 dbrown Exp $ \n*/ \n \n# include < linux / kernel . h > \nstatic struct nand_oobinfo doc200x_oobinfo = { \n. useecc = MTD_NANDECC_AUTOPLACE , \n. eccbytes = 6 , \n. eccpos = { 0 , 1 , 2 , 3 , 4 , 5 }, \n- . oobfree = { { 8 , 8 } } \n+ . oobfree = { { 6 , 10 } } \n}; \n \n/* Find the ( I ) NFTL Media Header , and optionally also the mirror media header .", "mmm drivers / net / wireless / ath / ath10k / wmi . c \nppp drivers / net / wireless / ath / ath10k / wmi . c \nath10k_wmi_10_4_gen_update_fw_tdls_state ( struct ath10k * ar , u32 vdev_id , \nif (! skb ) \nreturn ERR_PTR (- ENOMEM ); \n \n- if ( test_bit ( WMI_SERVICE_TDLS_EXPLICIT_MODE_ONLY , ar -> wmi . svc_map )) \n+ if ( test_bit ( WMI_SERVICE_TDLS_EXPLICIT_MODE_ONLY , ar -> wmi . svc_map ) && \n+ state == WMI_TDLS_ENABLE_ACTIVE ) \nstate = WMI_TDLS_ENABLE_PASSIVE ; \n \nif ( test_bit ( WMI_SERVICE_TDLS_UAPSD_BUFFER_STA , ar -> wmi . svc_map ))", "mmm drivers / mtd / mtdpart . c \nppp drivers / mtd / mtdpart . c \nint add_mtd_partitions ( struct mtd_info * master , \n \nfor ( i = 0 ; i < nbparts ; i ++) { \nslave = allocate_partition ( master , parts + i , i , cur_offset ); \n- if ( IS_ERR ( slave )) \n+ if ( IS_ERR ( slave )) { \n+ del_mtd_partitions ( master ); \nreturn PTR_ERR ( slave ); \n+ } \n \nmutex_lock (& mtd_partitions_mutex ); \nlist_add (& slave -> list , & mtd_partitions );", "mmm arch / powerpc / platforms / cell / spufs / sched . c \nppp arch / powerpc / platforms / cell / spufs / sched . c \nvoid spu_deactivate ( struct spu_context * ctx ) \n*/ \nvoid spu_yield ( struct spu_context * ctx ) \n{ \n- mutex_lock (& ctx -> state_mutex ); \n- __spu_deactivate ( ctx , 0 , MAX_PRIO ); \n- mutex_unlock (& ctx -> state_mutex ); \n+ if (!( ctx -> flags & SPU_CREATE_NOSCHED )) { \n+ mutex_lock (& ctx -> state_mutex ); \n+ __spu_deactivate ( ctx , 0 , MAX_PRIO ); \n+ mutex_unlock (& ctx -> state_mutex ); \n+ } \n} \n \nvoid spu_sched_tick ( struct work_struct * work )", "mmm drivers / gpu / drm / vmwgfx / vmwgfx_kms . c \nppp drivers / gpu / drm / vmwgfx / vmwgfx_kms . c \nint vmw_du_crtc_cursor_set ( struct drm_crtc * crtc , struct drm_file * file_priv , \nif (! ret ) { \nif (! surface -> snooper . image ) { \nDRM_ERROR (\" surface not suitable for cursor \\ n \"); \n+ vmw_surface_unreference (& surface ); \nreturn - EINVAL ; \n} \n} else {", "mmm drivers / media / platform / coda / coda - bit . c \nppp drivers / media / platform / coda / coda - bit . c \nstatic int coda_alloc_framebuffers ( struct coda_ctx * ctx , \ndev -> devtype -> product != CODA_DX6 ) \nsize += ysize / 4 ; \nname = kasprintf ( GFP_KERNEL , \" fb % d \", i ); \n+ if (! name ) { \n+ coda_free_framebuffers ( ctx ); \n+ return - ENOMEM ; \n+ } \nret = coda_alloc_context_buf ( ctx , & ctx -> internal_frames [ i ], \nsize , name ); \nkfree ( name );", "mmm drivers / media / video / cx23885 / cx23885 - dvb . c \nppp drivers / media / video / cx23885 / cx23885 - dvb . c \nint cx23885_dvb_unregister ( struct cx23885_tsport * port ) \n* implement MFE support . \n*/ \nfe0 = videobuf_dvb_get_frontend (& port -> frontends , 1 ); \n- if ( fe0 -> dvb . frontend ) \n+ if ( fe0 && fe0 -> dvb . frontend ) \nvideobuf_dvb_unregister_bus (& port -> frontends ); \n \nswitch ( port -> dev -> board ) {", "mmm drivers / video / console / fbcon . c \nppp drivers / video / console / fbcon . c \nstatic void fbcon_deinit ( struct vc_data * vc ) \nfinished : \n \nfbcon_free_font ( p , free_font ); \n+ if ( free_font ) \n+ vc -> vc_font . data = NULL ; \n \nif (! con_is_bound (& fb_con )) \nfbcon_exit ();", "mmm drivers / gpu / drm / amd / display / dc / core / dc_resource . c \nppp drivers / gpu / drm / amd / display / dc / core / dc_resource . c \nstatic void set_avi_info_frame ( \ninfo_packet -> hb2 = \ninfo_frame . avi_info_packet . info_packet_hdmi . packet_raw_data . hb2 ; \n \n- for ( byte_index = 0 ; byte_index < sizeof ( info_packet -> sb ); byte_index ++) \n+ for ( byte_index = 0 ; byte_index < sizeof ( info_frame . avi_info_packet . \n+ info_packet_hdmi . packet_raw_data . sb ); byte_index ++) \ninfo_packet -> sb [ byte_index ] = info_frame . avi_info_packet . \n- info_packet_hdmi . packet_raw_data . sb [ byte_index ]; \n+ info_packet_hdmi . packet_raw_data . sb [ byte_index ]; \n \ninfo_packet -> valid = true ; \n}", "mmm net / socket . c \nppp net / socket . c \nstatic ssize_t sock_sendpage ( struct file * file , struct page * page , \nif ( more ) \nflags |= MSG_MORE ; \n \n- return sock -> ops -> sendpage ( sock , page , offset , size , flags ); \n+ return kernel_sendpage ( sock , page , offset , size , flags ); \n} \n \nstatic ssize_t sock_splice_read ( struct file * file , loff_t * ppos ,", "mmm kernel / sched . c \nppp kernel / sched . c \nstatic inline void ttwu_post_activation ( struct task_struct * p , struct rq * rq , \nif ( p -> sched_class -> task_woken ) \np -> sched_class -> task_woken ( rq , p ); \n \n- if ( unlikely ( rq -> idle_stamp )) { \n+ if ( rq -> idle_stamp ) { \nu64 delta = rq -> clock - rq -> idle_stamp ; \nu64 max = 2 * sysctl_sched_migration_cost ; \n", "mmm drivers / ssb / main . c \nppp drivers / ssb / main . c \nstatic int __init ssb_modinit ( void ) \nssb_buses_lock (); \nerr = ssb_attach_queued_buses (); \nssb_buses_unlock (); \n- if ( err ) \n+ if ( err ) { \nbus_unregister (& ssb_bustype ); \n+ goto out ; \n+ } \n \nerr = b43_pci_ssb_bridge_init (); \nif ( err ) { \nstatic int __init ssb_modinit ( void ) \n/* don ' t fail SSB init because of this */ \nerr = 0 ; \n} \n- \n+ out : \nreturn err ; \n} \n/* ssb must be initialized after PCI but before the ssb drivers .", "mmm drivers / cpufreq / pcc - cpufreq . c \nppp drivers / cpufreq / pcc - cpufreq . c \nstatic int pcc_get_offset ( int cpu ) \npr = per_cpu ( processors , cpu ); \npcc_cpu_data = per_cpu_ptr ( pcc_cpu_info , cpu ); \n \n+ if (! pr ) \n+ return - ENODEV ; \n+ \nstatus = acpi_evaluate_object ( pr -> handle , \" PCCP \", NULL , & buffer ); \nif ( ACPI_FAILURE ( status )) \nreturn - ENODEV ;", "mmm drivers / input / input . c \nppp drivers / input / input . c \nvoid input_unregister_device ( struct input_dev * dev ) \nsysfs_remove_group (& dev -> cdev . kobj , & input_dev_caps_attr_group ); \nsysfs_remove_group (& dev -> cdev . kobj , & input_dev_id_attr_group ); \nsysfs_remove_group (& dev -> cdev . kobj , & input_dev_attr_group ); \n- class_device_unregister (& dev -> cdev ); \n \nmutex_lock (& dev -> mutex ); \ndev -> name = dev -> phys = dev -> uniq = NULL ; \nmutex_unlock (& dev -> mutex ); \n \n+ class_device_unregister (& dev -> cdev ); \n+ \ninput_wakeup_procfs_readers (); \n} \nEXPORT_SYMBOL ( input_unregister_device );", "mmm drivers / input / misc / uinput . c \nppp drivers / input / misc / uinput . c \nstatic inline int uinput_request_reserve_slot ( struct uinput_device * udev , struct \n \nstatic void uinput_request_done ( struct uinput_device * udev , struct uinput_request * request ) \n{ \n- complete (& request -> done ); \n- \n/* Mark slot as available */ \nudev -> requests [ request -> id ] = NULL ; \nwake_up_interruptible (& udev -> requests_waitq ); \n+ \n+ complete (& request -> done ); \n} \n \nstatic int uinput_request_submit ( struct input_dev * dev , struct uinput_request * request )", "mmm include / asm - um / mmu_context . h \nppp include / asm - um / mmu_context . h \nstatic inline void activate_mm ( struct mm_struct * old , struct mm_struct * new ) \n* possible . \n*/ \nif ( old != new && ( current -> flags & PF_BORROWED_MM )) \n- force_flush_all (); \n+ CHOOSE_MODE ( force_flush_all (), \n+ switch_mm_skas (& new -> context . skas . id )); \n} \n \nstatic inline void switch_mm ( struct mm_struct * prev , struct mm_struct * next ,", "mmm drivers / ata / libata - core . c \nppp drivers / ata / libata - core . c \nunsigned ata_exec_internal_sg ( struct ata_device * dev , \nqc -> tf = * tf ; \nif ( cdb ) \nmemcpy ( qc -> cdb , cdb , ATAPI_CDB_LEN ); \n+ \n+ /* some SATA bridges need us to indicate data xfer direction */ \n+ if ( tf -> protocol == ATAPI_PROT_DMA && ( dev -> flags & ATA_DFLAG_DMADIR ) && \n+ dma_dir == DMA_FROM_DEVICE ) \n+ qc -> tf . feature |= ATAPI_DMADIR ; \n+ \nqc -> flags |= ATA_QCFLAG_RESULT_TF ; \nqc -> dma_dir = dma_dir ; \nif ( dma_dir != DMA_NONE ) {", "mmm drivers / scsi / sg . c \nppp drivers / scsi / sg . c \nsg_unlink_reserve ( Sg_fd * sfp , Sg_request * srp ) \nreq_schp -> page_order = 0 ; \nreq_schp -> sglist_len = 0 ; \nsrp -> res_used = 0 ; \n+ /* Called without mutex lock to avoid deadlock */ \n+ sfp -> res_in_use = 0 ; \n} \n \nstatic Sg_request *", "mmm drivers / hid / hid - corsair . c \nppp drivers / hid / hid - corsair . c \nstatic int corsair_input_mapping ( struct hid_device * dev , \n{ \nint gkey ; \n \n+ if (( usage -> hid & HID_USAGE_PAGE ) != HID_UP_KEYBOARD ) \n+ return 0 ; \n+ \ngkey = corsair_usage_to_gkey ( usage -> hid & HID_USAGE ); \nif ( gkey != 0 ) { \nhid_map_usage_clear ( input , usage , bit , max , EV_KEY ,", "mmm sound / core / timer . c \nppp sound / core / timer . c \nint snd_timer_open ( struct snd_timer_instance ** ti , \ngoto unlock ; \n} \nif (! list_empty (& timer -> open_list_head )) { \n- timeri = list_entry ( timer -> open_list_head . next , \n+ struct snd_timer_instance * t = \n+ list_entry ( timer -> open_list_head . next , \nstruct snd_timer_instance , open_list ); \n- if ( timeri -> flags & SNDRV_TIMER_IFLG_EXCLUSIVE ) { \n+ if ( t -> flags & SNDRV_TIMER_IFLG_EXCLUSIVE ) { \nerr = - EBUSY ; \n- timeri = NULL ; \ngoto unlock ; \n} \n}", "mmm kernel / cgroup . c \nppp kernel / cgroup . c \nint cgroup_scan_tasks ( struct cgroup_scanner * scan ) \n*/ \nstatic int pid_array_load ( pid_t * pidarray , int npids , struct cgroup * cgrp ) \n{ \n- int n = 0 ; \n+ int n = 0 , pid ; \nstruct cgroup_iter it ; \nstruct task_struct * tsk ; \ncgroup_iter_start ( cgrp , & it ); \nwhile (( tsk = cgroup_iter_next ( cgrp , & it ))) { \nif ( unlikely ( n == npids )) \nbreak ; \n- pidarray [ n ++] = task_pid_vnr ( tsk ); \n+ pid = task_pid_vnr ( tsk ); \n+ if ( pid > 0 ) \n+ pidarray [ n ++] = pid ; \n} \ncgroup_iter_end ( cgrp , & it ); \nreturn n ;", "mmm drivers / usb / class / cdc - acm . c \nppp drivers / usb / class / cdc - acm . c \nstatic int acm_probe ( struct usb_interface * intf , \ni = device_create_file (& intf -> dev , & dev_attr_wCountryCodes ); \nif ( i < 0 ) { \nkfree ( acm -> country_codes ); \n+ acm -> country_codes = NULL ; \n+ acm -> country_code_size = 0 ; \ngoto skip_countries ; \n} \n \nstatic int acm_probe ( struct usb_interface * intf , \nif ( i < 0 ) { \ndevice_remove_file (& intf -> dev , & dev_attr_wCountryCodes ); \nkfree ( acm -> country_codes ); \n+ acm -> country_codes = NULL ; \n+ acm -> country_code_size = 0 ; \ngoto skip_countries ; \n} \n}", "mmm sound / usb / endpoint . c \nppp sound / usb / endpoint . c \nstruct snd_usb_endpoint * snd_usb_add_endpoint ( struct snd_usb_audio * chip , \nstruct snd_usb_endpoint * ep ; \nint is_playback = direction == SNDRV_PCM_STREAM_PLAYBACK ; \n \n+ if ( WARN_ON (! alts )) \n+ return NULL ; \n+ \nmutex_lock (& chip -> mutex ); \n \nlist_for_each_entry ( ep , & chip -> ep_list , list ) {", "mmm drivers / mmc / host / mmci . c \nppp drivers / mmc / host / mmci . c \nstatic irqreturn_t mmci_irq ( int irq , void * dev_id ) \n \ndev_dbg ( mmc_dev ( host -> mmc ), \" irq0 ( data + cmd ) % 08x \\ n \", status ); \n \n+ cmd = host -> cmd ; \n+ if ( status & ( MCI_CMDCRCFAIL | MCI_CMDTIMEOUT | MCI_CMDSENT | \n+ MCI_CMDRESPEND ) && cmd ) \n+ mmci_cmd_irq ( host , cmd , status ); \n+ \ndata = host -> data ; \nif ( status & ( MCI_DATACRCFAIL | MCI_DATATIMEOUT | MCI_STARTBITERR | \nMCI_TXUNDERRUN | MCI_RXOVERRUN | MCI_DATAEND | \nMCI_DATABLOCKEND ) && data ) \nmmci_data_irq ( host , data , status ); \n \n- cmd = host -> cmd ; \n- if ( status & ( MCI_CMDCRCFAIL | MCI_CMDTIMEOUT | MCI_CMDSENT | MCI_CMDRESPEND ) && cmd ) \n- mmci_cmd_irq ( host , cmd , status ); \n- \nret = 1 ; \n} while ( status ); \n", "mmm arch / x86 / kvm / vmx . c \nppp arch / x86 / kvm / vmx . c \nstatic void add_atomic_switch_msr ( struct vcpu_vmx * vmx , unsigned msr , \nif ( m -> guest [ i ]. index == msr ) \nbreak ; \n \n- if ( i == m -> nr ) { \n+ if ( i == NR_AUTOLOAD_MSRS ) { \n+ printk_once ( KERN_WARNING \" Not enough mst switch entries . \" \n+ \" Can ' t add msr % x \\ n \", msr ); \n+ return ; \n+ } else if ( i == m -> nr ) { \n++ m -> nr ; \nvmcs_write32 ( VM_ENTRY_MSR_LOAD_COUNT , m -> nr ); \nvmcs_write32 ( VM_EXIT_MSR_LOAD_COUNT , m -> nr );", "mmm kernel / trace / trace_events . c \nppp kernel / trace / trace_events . c \nsubsystem_filter_write ( struct file * filp , const char __user * ubuf , size_t cnt , \n \nerr = filter_add_subsystem_pred ( system , pred ); \nif ( err < 0 ) { \n- filter_free_subsystem_preds ( system ); \nfilter_free_pred ( pred ); \nreturn err ; \n}", "mmm drivers / gpu / drm / i915 / i915_gem_gtt . c \nppp drivers / gpu / drm / i915 / i915_gem_gtt . c \nstatic bool gen8_ppgtt_clear_pt ( struct i915_address_space * vm , \nGEM_BUG_ON ( pte_end > GEN8_PTES ); \n \nbitmap_clear ( pt -> used_ptes , pte , num_entries ); \n- \n- if ( bitmap_empty ( pt -> used_ptes , GEN8_PTES )) \n- return true ; \n+ if ( USES_FULL_PPGTT ( vm -> i915 )) { \n+ if ( bitmap_empty ( pt -> used_ptes , GEN8_PTES )) \n+ return true ; \n+ } \n \npt_vaddr = kmap_px ( pt ); \n", "mmm drivers / net / ethernet / broadcom / bcmsysport . c \nppp drivers / net / ethernet / broadcom / bcmsysport . c \nstatic u16 bcm_sysport_select_queue ( struct net_device * dev , struct sk_buff * skb , \nport = BRCM_TAG_GET_PORT ( queue ); \ntx_ring = priv -> ring_map [ q + port * priv -> per_port_num_tx_queues ]; \n \n+ if ( unlikely (! tx_ring )) \n+ return fallback ( dev , skb ); \n+ \nreturn tx_ring -> index ; \n} \n", "mmm fs / nfsd / nfssvc . c \nppp fs / nfsd / nfssvc . c \nstatic int nfsd_startup ( unsigned short port , int nrservs ) \nret = nfs4_state_start (); \nif ( ret ) \ngoto out_lockd ; \n- nfsd_reset_versions (); \nnfsd_up = true ; \nreturn 0 ; \nout_lockd : \nint nfsd_create_serv ( void ) \nnfsd_max_blksize >= 8 * 1024 * 2 ) \nnfsd_max_blksize /= 2 ; \n} \n+ nfsd_reset_versions (); \n \nnfsd_serv = svc_create_pooled (& nfsd_program , nfsd_max_blksize , \nnfsd_last_thread , nfsd , THIS_MODULE );", "mmm fs / dax . c \nppp fs / dax . c \nint __dax_zero_page_range ( struct block_device * bdev , \nvoid * kaddr ; \npfn_t pfn ; \n \n- rc = bdev_dax_pgoff ( bdev , sector , size , & pgoff ); \n+ rc = bdev_dax_pgoff ( bdev , sector , PAGE_SIZE , & pgoff ); \nif ( rc ) \nreturn rc ; \n \nid = dax_read_lock (); \n- rc = dax_direct_access ( dax_dev , pgoff , PHYS_PFN ( size ), & kaddr , \n+ rc = dax_direct_access ( dax_dev , pgoff , 1 , & kaddr , \n& pfn ); \nif ( rc < 0 ) { \ndax_read_unlock ( id );", "mmm fs / btrfs / transaction . c \nppp fs / btrfs / transaction . c \nstatic struct btrfs_trans_handle * start_transaction ( struct btrfs_root * root , \n*/ \nif ( type != TRANS_JOIN_NOLOCK && \n! __sb_start_write ( root -> fs_info -> sb , SB_FREEZE_FS , false )) { \n- if ( type == TRANS_JOIN_FREEZE ) \n+ if ( type == TRANS_JOIN_FREEZE ) { \n+ kmem_cache_free ( btrfs_trans_handle_cachep , h ); \nreturn ERR_PTR (- EPERM ); \n+ } \nsb_start_intwrite ( root -> fs_info -> sb ); \n} \n", "mmm net / batman - adv / bridge_loop_avoidance . c \nppp net / batman - adv / bridge_loop_avoidance . c \nint batadv_bla_tx ( struct batadv_priv * bat_priv , struct sk_buff * skb , \nif (! atomic_read (& bat_priv -> bridge_loop_avoidance )) \ngoto allow ; \n \n- /* in VLAN case , the mac header might not be set . */ \n- skb_reset_mac_header ( skb ); \n- \nif ( batadv_bla_process_claim ( bat_priv , primary_if , skb )) \ngoto handled ; \n", "mmm sound / soc / intel / skylake / skl - topology . c \nppp sound / soc / intel / skylake / skl - topology . c \nstatic int skl_tplg_tlv_control_get ( struct snd_kcontrol * kcontrol , \nif ( bc -> params ) { \nif ( copy_to_user ( data , & bc -> param_id , sizeof ( u32 ))) \nreturn - EFAULT ; \n- if ( copy_to_user ( data + sizeof ( u32 ), & size , sizeof ( u32 ))) \n+ if ( copy_to_user ( data + 1 , & size , sizeof ( u32 ))) \nreturn - EFAULT ; \n- if ( copy_to_user ( data + 2 * sizeof ( u32 ), bc -> params , size )) \n+ if ( copy_to_user ( data + 2 , bc -> params , size )) \nreturn - EFAULT ; \n} \n", "mmm net / rxrpc / ar - internal . h \nppp net / rxrpc / ar - internal . h \nstatic inline bool rxrpc_set_call_completion ( struct rxrpc_call * call , \nu32 abort_code , \nint error ) \n{ \n- int ret ; \n+ bool ret ; \n \nwrite_lock_bh (& call -> state_lock ); \nret = __rxrpc_set_call_completion ( call , compl , abort_code , error ); \nstatic inline bool rxrpc_set_call_completion ( struct rxrpc_call * call , \n/* \n* Record that a call successfully completed . \n*/ \n- static inline void __rxrpc_call_completed ( struct rxrpc_call * call ) \n+ static inline bool __rxrpc_call_completed ( struct rxrpc_call * call ) \n{ \n- __rxrpc_set_call_completion ( call , RXRPC_CALL_SUCCEEDED , 0 , 0 ); \n+ return __rxrpc_set_call_completion ( call , RXRPC_CALL_SUCCEEDED , 0 , 0 ); \n} \n \n- static inline void rxrpc_call_completed ( struct rxrpc_call * call ) \n+ static inline bool rxrpc_call_completed ( struct rxrpc_call * call ) \n{ \n+ bool ret ; \n+ \nwrite_lock_bh (& call -> state_lock ); \n- __rxrpc_call_completed ( call ); \n+ ret = __rxrpc_call_completed ( call ); \nwrite_unlock_bh (& call -> state_lock ); \n+ return ret ; \n} \n \n/*", "mmm kernel / rcu / rcutorture . c \nppp kernel / rcu / rcutorture . c \nrcu_torture_init ( void ) \nif ( firsterr ) \ngoto unwind ; \n} \n- if ( test_no_idle_hz ) { \n+ if ( test_no_idle_hz && shuffle_interval > 0 ) { \nfirsterr = torture_shuffle_init ( shuffle_interval * HZ ); \nif ( firsterr ) \ngoto unwind ;", "mmm drivers / media / rc / ir - lirc - codec . c \nppp drivers / media / rc / ir - lirc - codec . c \nstatic long ir_lirc_ioctl ( struct file * filep , unsigned int cmd , \nreturn 0 ; \n \ncase LIRC_GET_REC_RESOLUTION : \n+ if (! dev -> rx_resolution ) \n+ return - ENOTTY ; \n+ \nval = dev -> rx_resolution ; \nbreak ; \n \nstatic int ir_lirc_register ( struct rc_dev * dev ) \nif ( rc ) \ngoto rbuf_init_failed ; \n \n- if ( dev -> driver_type != RC_DRIVER_IR_RAW_TX ) \n+ if ( dev -> driver_type != RC_DRIVER_IR_RAW_TX ) { \nfeatures |= LIRC_CAN_REC_MODE2 ; \n+ if ( dev -> rx_resolution ) \n+ features |= LIRC_CAN_GET_REC_RESOLUTION ; \n+ } \nif ( dev -> tx_ir ) { \nfeatures |= LIRC_CAN_SEND_PULSE ; \nif ( dev -> s_tx_mask )", "mmm drivers / net / ethernet / mellanox / mlxsw / spectrum . c \nppp drivers / net / ethernet / mellanox / mlxsw / spectrum . c \nmlxsw_sp_port_add_cls_matchall_mirror ( struct mlxsw_sp_port * mlxsw_sp_port , \n \nif (! mlxsw_sp_port_dev_check ( to_dev )) { \nnetdev_err ( mlxsw_sp_port -> dev , \" Cannot mirror to a non - spectrum port \"); \n- return - ENOTSUPP ; \n+ return - EOPNOTSUPP ; \n} \nto_port = netdev_priv ( to_dev ); \n \nstatic int mlxsw_sp_port_add_cls_matchall ( struct mlxsw_sp_port * mlxsw_sp_port , \n \nif (! tc_single_action ( cls -> exts )) { \nnetdev_err ( mlxsw_sp_port -> dev , \" only singular actions are supported \\ n \"); \n- return - ENOTSUPP ; \n+ return - EOPNOTSUPP ; \n} \n \nmall_tc_entry = kzalloc ( sizeof (* mall_tc_entry ), GFP_KERNEL ); \nstatic int mlxsw_sp_setup_tc ( struct net_device * dev , u32 handle , \n} \n} \n \n- return - ENOTSUPP ; \n+ return - EOPNOTSUPP ; \n} \n \nstatic const struct net_device_ops mlxsw_sp_port_netdev_ops = { \nmlxsw_sp_get_hw_stats_by_group ( struct mlxsw_sp_port_hw_stats ** p_hw_stats , \nbreak ; \ndefault : \nWARN_ON ( 1 ); \n- return - ENOTSUPP ; \n+ return - EOPNOTSUPP ; \n} \nreturn 0 ; \n}", "mmm fs / xfs / xfs_sysfs . c \nppp fs / xfs / xfs_sysfs . c \nxfs_error_get_cfg ( \n{ \nstruct xfs_error_cfg * cfg ; \n \n+ if ( error < 0 ) \n+ error = - error ; \n+ \nswitch ( error ) { \ncase EIO : \ncfg = & mp -> m_error_cfg [ error_class ][ XFS_ERR_EIO ];", "mmm net / tipc / discover . c \nppp net / tipc / discover . c \nvoid tipc_disc_rcv ( struct net * net , struct sk_buff * skb , \nu16 caps = msg_node_capabilities ( hdr ); \nbool respond = false ; \nbool dupl_addr = false ; \n+ int err ; \n \n- bearer -> media -> msg2addr ( bearer , & maddr , msg_media_addr ( hdr )); \n+ err = bearer -> media -> msg2addr ( bearer , & maddr , msg_media_addr ( hdr )); \nkfree_skb ( skb ); \n+ if ( err ) \n+ return ; \n \n/* Ensure message from node is valid and communication is permitted */ \nif ( net_id != tn -> net_id )", "mmm fs / logfs / logfs . h \nppp fs / logfs / logfs . h \nstatic inline int logfs_get_sb_bdev ( struct logfs_super * s , \n \n/* dev_mtd . c */ \n# ifdef CONFIG_MTD \n- int logfs_get_sb_mtd ( struct logfs_super * s , int mtdnr ) \n+ int logfs_get_sb_mtd ( struct logfs_super * s , int mtdnr ); \n# else \nstatic inline int logfs_get_sb_mtd ( struct logfs_super * s , int mtdnr ) \n{", "mmm fs / namespace . c \nppp fs / namespace . c \nstatic int do_loopback ( struct path * path , const char * old_name , \n \nif ( IS_ERR ( mnt )) { \nerr = PTR_ERR ( mnt ); \n- goto out ; \n+ goto out2 ; \n} \n \nerr = graft_tree ( mnt , path );", "mmm kernel / bpf / verifier . c \nppp kernel / bpf / verifier . c \nstatic int check_stack_boundary ( struct bpf_verifier_env * env , int regno , \ntnum_strn ( tn_buf , sizeof ( tn_buf ), regs [ regno ]. var_off ); \nverbose ( env , \" invalid variable stack read R % d var_off =% s \\ n \", \nregno , tn_buf ); \n+ return - EACCES ; \n} \noff = regs [ regno ]. off + regs [ regno ]. var_off . value ; \nif ( off >= 0 || off < - MAX_BPF_STACK || off + access_size > 0 ||", "mmm drivers / staging / unisys / visorbus / visorchipset . c \nppp drivers / staging / unisys / visorbus / visorchipset . c \nstatic ssize_t error_store ( struct device * dev , struct device_attribute * attr , \nconst char * buf , size_t count ) \n{ \nu32 error ; \n- int ret ; \n+ int err ; \n \nif ( kstrtou32 ( buf , 10 , & error )) \nreturn - EINVAL ; \n \n- ret = visorchannel_write \n+ err = visorchannel_write \n( chipset_dev -> controlvm_channel , \noffsetof ( struct spar_controlvm_channel_protocol , \ninstallation_error ), \n& error , sizeof ( u32 )); \n- if ( ret ) \n- return ret ; \n+ if ( err ) \n+ return err ; \nreturn count ; \n} \nstatic DEVICE_ATTR_RW ( error );", "mmm include / linux / topology . h \nppp include / linux / topology . h \nvoid arch_update_cpu_topology ( void ); \n. busy_idx = 3 , \\ \n. idle_idx = 3 , \\ \n. flags = SD_LOAD_BALANCE \\ \n- | SD_SERIALIZE , \\ \n+ | SD_BALANCE_NEWIDLE \\ \n+ | SD_WAKE_AFFINE \\ \n+ | SD_SERIALIZE , \\ \n. last_balance = jiffies , \\ \n. balance_interval = 64 , \\ \n}", "mmm block / partitions / efi . c \nppp block / partitions / efi . c \nstatic gpt_entry * alloc_read_gpt_entries ( struct parsed_partitions * state , \nle32_to_cpu ( gpt -> sizeof_partition_entry ); \nif (! count ) \nreturn NULL ; \n- pte = kzalloc ( count , GFP_KERNEL ); \n+ pte = kmalloc ( count , GFP_KERNEL ); \nif (! pte ) \nreturn NULL ; \n \nstatic gpt_header * alloc_read_gpt_header ( struct parsed_partitions * state , \ngpt_header * gpt ; \nunsigned ssz = bdev_logical_block_size ( state -> bdev ); \n \n- gpt = kzalloc ( ssz , GFP_KERNEL ); \n+ gpt = kmalloc ( ssz , GFP_KERNEL ); \nif (! gpt ) \nreturn NULL ; \n", "mmm fs / cifs / transport . c \nppp fs / cifs / transport . c \nsmb_send_kvec ( struct TCP_Server_Info * server , struct kvec * iov , size_t n_vec , \n \n* sent = 0 ; \n \n- if ( ssocket == NULL ) \n- return - ENOTSOCK ; /* BB eventually add reconnect code here */ \n- \nsmb_msg . msg_name = ( struct sockaddr *) & server -> dstaddr ; \nsmb_msg . msg_namelen = sizeof ( struct sockaddr ); \nsmb_msg . msg_control = NULL ; \nsmb_send_rqst ( struct TCP_Server_Info * server , struct smb_rqst * rqst ) \nstruct socket * ssocket = server -> ssocket ; \nint val = 1 ; \n \n+ if ( ssocket == NULL ) \n+ return - ENOTSOCK ; \n+ \ncFYI ( 1 , \" Sending smb : smb_len =% u \", smb_buf_length ); \ndump_smb ( iov [ 0 ]. iov_base , iov [ 0 ]. iov_len ); \n", "mmm drivers / scsi / lpfc / lpfc_attr . c \nppp drivers / scsi / lpfc / lpfc_attr . c \nlpfc_nvme_info_show ( struct device * dev , struct device_attribute * attr , \nwwn_to_u64 ( vport -> fc_nodename . u . wwn ), \nphba -> targetport -> port_id ); \n \n- len += snprintf ( buf + len , PAGE_SIZE , \n+ len += snprintf ( buf + len , PAGE_SIZE - len , \n\"\\ nNVME Target : Statistics \\ n \"); \ntgtp = ( struct lpfc_nvmet_tgtport *) phba -> targetport -> private ; \nlen += snprintf ( buf + len , PAGE_SIZE - len , \nlpfc_nvme_info_show ( struct device * dev , struct device_attribute * attr , \n} \nspin_unlock_irq ( shost -> host_lock ); \n \n- len += snprintf ( buf + len , PAGE_SIZE , \"\\ nNVME Statistics \\ n \"); \n+ len += snprintf ( buf + len , PAGE_SIZE - len , \"\\ nNVME Statistics \\ n \"); \nlen += snprintf ( buf + len , PAGE_SIZE - len , \n\" LS : Xmt % 016llx Cmpl % 016llx \\ n \", \nphba -> fc4NvmeLsRequests ,", "mmm sound / pci / hda / hda_codec . c \nppp sound / pci / hda / hda_codec . c \nint snd_hda_multi_out_analog_open ( struct hda_codec * codec , \nif ( mout -> spdif_maxbps < hinfo -> maxbps ) \nhinfo -> maxbps = mout -> spdif_maxbps ; \n} \n+ mutex_unlock (& codec -> spdif_mutex ); \n} \n- mutex_unlock (& codec -> spdif_mutex ); \nreturn snd_pcm_hw_constraint_step ( substream -> runtime , 0 , \nSNDRV_PCM_HW_PARAM_CHANNELS , 2 ); \n}", "mmm drivers / infiniband / core / uverbs_main . c \nppp drivers / infiniband / core / uverbs_main . c \nstatic ssize_t ib_uverbs_write ( struct file * filp , const char __user * buf , \ngoto out ; \n} \n \n+ if (! file -> ucontext && \n+ command != IB_USER_VERBS_CMD_GET_CONTEXT ) { \n+ ret = - EINVAL ; \n+ goto out ; \n+ } \n+ \nflags = ( hdr . command & \nIB_USER_VERBS_CMD_FLAGS_MASK ) >> IB_USER_VERBS_CMD_FLAGS_SHIFT ; \n \nstatic ssize_t ib_uverbs_write ( struct file * filp , const char __user * buf , \ngoto out ; \n} \n \n- if (! file -> ucontext && \n- command != IB_USER_VERBS_CMD_GET_CONTEXT ) { \n- ret = - EINVAL ; \n- goto out ; \n- } \n- \nif ( hdr . in_words * 4 != count ) { \nret = - EINVAL ; \ngoto out ;", "mmm mm / hugetlb . c \nppp mm / hugetlb . c \nstatic int dissolve_free_huge_page ( struct page * page ) \nint dissolve_free_huge_pages ( unsigned long start_pfn , unsigned long end_pfn ) \n{ \nunsigned long pfn ; \n+ struct page * page ; \nint rc = 0 ; \n \nif (! hugepages_supported ()) \nreturn rc ; \n \n- for ( pfn = start_pfn ; pfn < end_pfn ; pfn += 1 << minimum_order ) \n- if ( rc = dissolve_free_huge_page ( pfn_to_page ( pfn ))) \n- break ; \n+ for ( pfn = start_pfn ; pfn < end_pfn ; pfn += 1 << minimum_order ) { \n+ page = pfn_to_page ( pfn ); \n+ if ( PageHuge ( page ) && ! page_count ( page )) { \n+ rc = dissolve_free_huge_page ( page ); \n+ if ( rc ) \n+ break ; \n+ } \n+ } \n \nreturn rc ; \n}", "mmm drivers / gpu / drm / amd / amdgpu / amdgpu_cs . c \nppp drivers / gpu / drm / amd / amdgpu / amdgpu_cs . c \nstatic int amdgpu_cs_wait_any_fence ( struct amdgpu_device * adev , \nwait -> out . status = ( r > 0 ); \nwait -> out . first_signaled = first ; \n \n- if ( array [ first ]) \n+ if ( first < fence_count && array [ first ]) \nr = array [ first ]-> error ; \nelse \nr = 0 ;", "mmm fs / ceph / mds_client . c \nppp fs / ceph / mds_client . c \nstatic int __do_request ( struct ceph_mds_client * mdsc , \nint mds = - 1 ; \nint err = - EAGAIN ; \n \n- if ( req -> r_err || req -> r_got_result ) \n+ if ( req -> r_err || req -> r_got_result ) { \n+ if ( req -> r_aborted ) \n+ __unregister_request ( mdsc , req ); \ngoto out ; \n+ } \n \nif ( req -> r_timeout && \ntime_after_eq ( jiffies , req -> r_started + req -> r_timeout )) {", "mmm fs / btrfs / volumes . c \nppp fs / btrfs / volumes . c \nstatic int __btrfs_map_block ( struct btrfs_fs_info * fs_info , int rw , \n} \nbbio = kzalloc ( btrfs_bio_size ( num_alloc_stripes ), GFP_NOFS ); \nif (! bbio ) { \n+ kfree ( raid_map ); \nret = - ENOMEM ; \ngoto out ; \n}", "mmm kernel / cgroup . c \nppp kernel / cgroup . c \nstatic struct dentry * cgroup_mount ( struct file_system_type * fs_type , \nmutex_lock (& cgroup_mutex ); \nmutex_lock (& cgroup_root_mutex ); \n \n- root_cgrp -> id = idr_alloc (& root -> cgroup_idr , root_cgrp , \n- 0 , 1 , GFP_KERNEL ); \n- if ( root_cgrp -> id < 0 ) \n+ ret = idr_alloc (& root -> cgroup_idr , root_cgrp , 0 , 1 , GFP_KERNEL ); \n+ if ( ret < 0 ) \ngoto unlock_drop ; \n+ root_cgrp -> id = ret ; \n \n/* Check for name clashes with existing mounts */ \nret = - EBUSY ;", "mmm net / rds / tcp_connect . c \nppp net / rds / tcp_connect . c \nint rds_tcp_conn_connect ( struct rds_connection * conn ) \nrds_tcp_set_callbacks ( sock , conn ); \nret = sock -> ops -> connect ( sock , ( struct sockaddr *)& dest , sizeof ( dest ), \nO_NONBLOCK ); \n- sock = NULL ; \n \nrdsdebug (\" connect to address % pI4 returned % d \\ n \", & conn -> c_faddr , ret ); \nif ( ret == - EINPROGRESS ) \nret = 0 ; \n+ if ( ret == 0 ) \n+ sock = NULL ; \n+ else \n+ rds_tcp_restore_callbacks ( sock , conn -> c_transport_data ); \n \nout : \nif ( sock )", "mmm sound / pci / hda / patch_realtek . c \nppp sound / pci / hda / patch_realtek . c \nstatic const char * alc_get_line_out_pfx ( const struct auto_pin_cfg * cfg , \n \nswitch ( cfg -> line_out_type ) { \ncase AUTO_PIN_SPEAKER_OUT : \n- return \" Speaker \"; \n+ if ( cfg -> line_outs == 1 ) \n+ return \" Speaker \"; \n+ break ; \ncase AUTO_PIN_HP_OUT : \nreturn \" Headphone \"; \ndefault :", "mmm drivers / input / serio / ams_delta_serio . c \nppp drivers / input / serio / ams_delta_serio . c \nstatic void __exit ams_delta_serio_exit ( void ) \nfree_irq ( OMAP_GPIO_IRQ ( AMS_DELTA_GPIO_PIN_KEYBRD_CLK ), 0 ); \ngpio_free ( AMS_DELTA_GPIO_PIN_KEYBRD_CLK ); \ngpio_free ( AMS_DELTA_GPIO_PIN_KEYBRD_DATA ); \n- kfree ( ams_delta_serio ); \n} \nmodule_exit ( ams_delta_serio_exit );", "mmm net / phonet / af_phonet . c \nppp net / phonet / af_phonet . c \nstatic int pn_send ( struct sk_buff * skb , struct net_device * dev , \nstruct phonethdr * ph ; \nint err ; \n \n- if ( skb -> len + 2 > 0xffff ) { \n- /* Phonet length field would overflow */ \n+ if ( skb -> len + 2 > 0xffff /* Phonet length field limit */ || \n+ skb -> len + sizeof ( struct phonethdr ) > dev -> mtu ) { \nerr = - EMSGSIZE ; \ngoto drop ; \n}", "mmm net / sctp / sm_statefuns . c \nppp net / sctp / sm_statefuns . c \nsctp_disposition_t sctp_sf_do_5_1D_ce ( struct net * net , \nstruct sctp_chunk auth ; \nsctp_ierror_t ret ; \n \n+ /* Make sure that we and the peer are AUTH capable */ \n+ if (! net -> sctp . auth_enable || ! new_asoc -> peer . auth_capable ) { \n+ kfree_skb ( chunk -> auth_chunk ); \n+ sctp_association_free ( new_asoc ); \n+ return sctp_sf_pdiscard ( net , ep , asoc , type , arg , commands ); \n+ } \n+ \n/* set - up our fake chunk so that we can process it */ \nauth . skb = chunk -> auth_chunk ; \nauth . asoc = chunk -> asoc ;", "mmm drivers / gpu / drm / ttm / ttm_memory . c \nppp drivers / gpu / drm / ttm / ttm_memory . c \nstatic int ttm_mem_init_dma32_zone ( struct ttm_mem_global * glob , \n* No special dma32 zone needed . \n*/ \n \n- if ( mem <= (( uint64_t ) 1ULL << 32 )) \n+ if ( mem <= (( uint64_t ) 1ULL << 32 )) { \n+ kfree ( zone ); \nreturn 0 ; \n+ } \n \n/* \n* Limit max dma32 memory to 4GB for now", "mmm drivers / net / slip / slip . c \nppp drivers / net / slip / slip . c \nstatic void sl_tx_timeout ( struct net_device * dev , unsigned int txqueue ) \nspin_lock (& sl -> lock ); \n \nif ( netif_queue_stopped ( dev )) { \n- if (! netif_running ( dev )) \n+ if (! netif_running ( dev ) || ! sl -> tty ) \ngoto out ; \n \n/* May be we must check transmitter timeout here ?", "mmm drivers / iommu / amd_iommu . c \nppp drivers / iommu / amd_iommu . c \nstatic struct protection_domain * get_domain ( struct device * dev ) \ndomain = to_pdomain ( io_domain ); \nattach_device ( dev , domain ); \n} \n+ if ( domain == NULL ) \n+ return ERR_PTR (- EBUSY ); \n+ \nif (! dma_ops_domain ( domain )) \nreturn ERR_PTR (- EBUSY ); \n", "mmm fs / ecryptfs / crypto . c \nppp fs / ecryptfs / crypto . c \necryptfs_process_key_cipher ( struct crypto_blkcipher ** key_tfm , \nchar * cipher_name , size_t * key_size ) \n{ \nchar dummy_key [ ECRYPTFS_MAX_KEY_BYTES ]; \n- char * full_alg_name ; \n+ char * full_alg_name = NULL ; \nint rc ; \n \n* key_tfm = NULL ; \necryptfs_process_key_cipher ( struct crypto_blkcipher ** key_tfm , \nif ( rc ) \ngoto out ; \n* key_tfm = crypto_alloc_blkcipher ( full_alg_name , 0 , CRYPTO_ALG_ASYNC ); \n- kfree ( full_alg_name ); \nif ( IS_ERR (* key_tfm )) { \nrc = PTR_ERR (* key_tfm ); \nprintk ( KERN_ERR \" Unable to allocate crypto cipher with name \" \necryptfs_process_key_cipher ( struct crypto_blkcipher ** key_tfm , \ngoto out ; \n} \nout : \n+ kfree ( full_alg_name ); \nreturn rc ; \n} \n", "mmm fs / btrfs / ioctl . c \nppp fs / btrfs / ioctl . c \nstatic noinline int btrfs_ioctl_resize ( struct btrfs_root * root , \n} \nret = btrfs_grow_device ( trans , device , new_size ); \nbtrfs_commit_transaction ( trans , root ); \n- } else { \n+ } else if ( new_size < old_size ) { \nret = btrfs_shrink_device ( device , new_size ); \n} \n", "mmm drivers / infiniband / hw / nes / nes_cm . c \nppp drivers / infiniband / hw / nes / nes_cm . c \nint schedule_nes_timer ( struct nes_cm_node * cm_node , struct sk_buff * skb , \nint ret = 0 ; \nu32 was_timer_set ; \n \n+ if (! cm_node ) \n+ return - EINVAL ; \nnew_send = kzalloc ( sizeof (* new_send ), GFP_ATOMIC ); \nif (! new_send ) \nreturn - 1 ; \n- if (! cm_node ) \n- return - EINVAL ; \n \n/* new_send -> timetosend = currenttime */ \nnew_send -> retrycount = NES_DEFAULT_RETRYS ;", "mmm drivers / nvdimm / btt . c \nppp drivers / nvdimm / btt . c \nint nvdimm_namespace_attach_btt ( struct nd_namespace_common * ndns ) \n} \n \nbtt_sb = devm_kzalloc (& nd_btt -> dev , sizeof (* btt_sb ), GFP_KERNEL ); \n+ if (! btt_sb ) \n+ return - ENOMEM ; \n \n/* \n* If this returns < 0 , that is ok as it just means there wasn ' t", "mmm arch / tile / mm / init . c \nppp arch / tile / mm / init . c \nstatic long __write_once initfree = 1 ; \nstatic int __init set_initfree ( char * str ) \n{ \nlong val ; \n- if ( strict_strtol ( str , 0 , & val )) { \n+ if ( strict_strtol ( str , 0 , & val ) == 0 ) { \ninitfree = val ; \npr_info (\" initfree : % s free init pages \\ n \", \ninitfree ? \" will \" : \" won ' t \");", "mmm arch / x86 / xen / apic . c \nppp arch / x86 / xen / apic . c \nstatic u32 xen_apic_read ( u32 reg ) \n \nret = HYPERVISOR_platform_op (& op ); \nif ( ret ) \n- return 0 ; \n+ op . u . pcpu_info . apic_id = BAD_APICID ; \n \nreturn op . u . pcpu_info . apic_id << 24 ; \n} \nstatic void xen_silent_inquire ( int apicid ) \n{ \n} \n \n+ static int xen_cpu_present_to_apicid ( int cpu ) \n+{ \n+ if ( cpu_present ( cpu )) \n+ return xen_get_apic_id ( xen_apic_read ( APIC_ID )); \n+ else \n+ return BAD_APICID ; \n+} \n+ \nstatic struct apic xen_pv_apic = { \n. name = \" Xen PV \", \n. probe = xen_apic_probe_pv , \nstatic struct apic xen_pv_apic = { \n \n. ioapic_phys_id_map = default_ioapic_phys_id_map , /* Used on 32 - bit */ \n. setup_apic_routing = NULL , \n- . cpu_present_to_apicid = default_cpu_present_to_apicid , \n+ . cpu_present_to_apicid = xen_cpu_present_to_apicid , \n. apicid_to_cpu_present = physid_set_mask_of_physid , /* Used on 32 - bit */ \n. check_phys_apicid_present = default_check_phys_apicid_present , /* smp_sanity_check needs it */ \n. phys_pkg_id = xen_phys_pkg_id , /* detect_ht */", "mmm drivers / ssb / scan . c \nppp drivers / ssb / scan . c \nint ssb_bus_scan ( struct ssb_bus * bus , \nbus -> pcicore . dev = dev ; \n# endif /* CONFIG_SSB_DRIVER_PCICORE */ \nbreak ; \n+ case SSB_DEV_ETHERNET : \n+ if ( bus -> bustype == SSB_BUSTYPE_PCI ) { \n+ if ( bus -> host_pci -> vendor == PCI_VENDOR_ID_BROADCOM && \n+ ( bus -> host_pci -> device & 0xFF00 ) == 0x4300 ) { \n+ /* This is a dangling ethernet core on a \n+ * wireless device . Ignore it . */ \n+ continue ; \n+ } \n+ } \n+ break ; \ndefault : \nbreak ; \n}", "mmm sound / usb / quirks . c \nppp sound / usb / quirks . c \nu64 snd_usb_interface_dsd_format_quirks ( struct snd_usb_audio * chip , \n} \n} \nbreak ; \n+ case USB_ID ( 0x16d0 , 0x0a23 ): \n+ if ( fp -> altsetting == 2 ) \n+ return SNDRV_PCM_FMTBIT_DSD_U32_BE ; \n+ break ; \n \ndefault : \nbreak ;", "mmm drivers / media / platform / vivid / vivid - osd . c \nppp drivers / media / platform / vivid / vivid - osd . c \nstatic int vivid_fb_ioctl ( struct fb_info * info , unsigned cmd , unsigned long arg ) \ncase FBIOGET_VBLANK : { \nstruct fb_vblank vblank ; \n \n+ memset (& vblank , 0 , sizeof ( vblank )); \nvblank . flags = FB_VBLANK_HAVE_COUNT | FB_VBLANK_HAVE_VCOUNT | \nFB_VBLANK_HAVE_VSYNC ; \nvblank . count = 0 ;", "mmm drivers / cpuidle / cpuidle . c \nppp drivers / cpuidle / cpuidle . c \nstatic cpuidle_enter_t cpuidle_enter_ops ; \n/** \n* cpuidle_play_dead - cpu off - lining \n* \n- * Only returns in case of an error \n+ * Returns in case of an error or no driver \n*/ \nint cpuidle_play_dead ( void ) \n{ \nint cpuidle_play_dead ( void ) \nint i , dead_state = - 1 ; \nint power_usage = - 1 ; \n \n+ if (! drv ) \n+ return - ENODEV ; \n+ \n/* Find lowest - power state that supports long - term idle */ \nfor ( i = CPUIDLE_DRIVER_STATE_START ; i < drv -> state_count ; i ++) { \nstruct cpuidle_state * s = & drv -> states [ i ];", "mmm net / ipx / af_ipx . c \nppp net / ipx / af_ipx . c \nstatic int ipxitf_ioctl ( unsigned int cmd , void __user * arg ) \nsipx -> sipx_network = ipxif -> if_netnum ; \nmemcpy ( sipx -> sipx_node , ipxif -> if_node , \nsizeof ( sipx -> sipx_node )); \n- rc = - EFAULT ; \n+ rc = 0 ; \nif ( copy_to_user ( arg , & ifr , sizeof ( ifr ))) \n- break ; \n+ rc = - EFAULT ; \nipxitf_put ( ipxif ); \n- rc = 0 ; \nbreak ; \n} \ncase SIOCAIPXITFCRT :", "mmm drivers / net / skge . c \nppp drivers / net / skge . c \nstatic int skge_xmit_frame ( struct sk_buff * skb , struct net_device * dev ) \n} \n \nif ( unlikely ( skge -> tx_avail < skb_shinfo ( skb )-> nr_frags + 1 )) { \n- netif_stop_queue ( dev ); \n- spin_unlock_irqrestore (& skge -> tx_lock , flags ); \n+ if (! netif_stopped ( dev )) { \n+ netif_stop_queue ( dev ); \n \n- printk ( KERN_WARNING PFX \"% s : ring full when queue awake !\\ n \", \n- dev -> name ); \n+ printk ( KERN_WARNING PFX \"% s : ring full when queue awake !\\ n \", \n+ dev -> name ); \n+ } \n+ spin_unlock_irqrestore (& skge -> tx_lock , flags ); \nreturn NETDEV_TX_BUSY ; \n} \n", "mmm net / xfrm / xfrm_user . c \nppp net / xfrm / xfrm_user . c \nstatic int build_expire ( struct sk_buff * skb , struct xfrm_state * x , int hard ) \nstatic int xfrm_exp_state_notify ( struct xfrm_state * x , struct km_event * c ) \n{ \nstruct sk_buff * skb ; \n+ int len = NLMSG_LENGTH ( sizeof ( struct xfrm_user_expire )); \n \n- /* fix to do alloc using NLM macros */ \n- skb = alloc_skb ( sizeof ( struct xfrm_user_expire ) + 16 , GFP_ATOMIC ); \n+ skb = alloc_skb ( len , GFP_ATOMIC ); \nif ( skb == NULL ) \nreturn - ENOMEM ; \n", "mmm drivers / net / bonding / bond_main . c \nppp drivers / net / bonding / bond_main . c \nstatic int __bond_release_one ( struct net_device * bond_dev , \nreturn - EINVAL ; \n} \n \n- /* release the slave from its bond */ \n- bond -> slave_cnt --; \n- \nbond_sysfs_slave_del ( slave ); \n \nbond_upper_dev_unlink ( bond_dev , slave_dev ); \nstatic int __bond_release_one ( struct net_device * bond_dev , \n \nunblock_netpoll_tx (); \nsynchronize_rcu (); \n+ bond -> slave_cnt --; \n \nif (! bond_has_slaves ( bond )) { \ncall_netdevice_notifiers ( NETDEV_CHANGEADDR , bond -> dev );", "mmm arch / x86 / kvm / i8254 . c \nppp arch / x86 / kvm / i8254 . c \nstatic int pit_ioport_read ( struct kvm_io_device * this , \nreturn - EOPNOTSUPP ; \n \naddr &= KVM_PIT_CHANNEL_MASK ; \n+ if ( addr == 3 ) \n+ return 0 ; \n+ \ns = & pit_state -> channels [ addr ]; \n \nmutex_lock (& pit_state -> lock );", "mmm drivers / input / tablet / kbtab . c \nppp drivers / input / tablet / kbtab . c \nstatic int kbtab_probe ( struct usb_interface * intf , const struct usb_device_id * i \nreturn 0 ; \n \nfail3 : usb_free_urb ( kbtab -> irq ); \n- fail2 : usb_buffer_free ( dev , 10 , kbtab -> data , kbtab -> data_dma ); \n+ fail2 : usb_buffer_free ( dev , 8 , kbtab -> data , kbtab -> data_dma ); \nfail1 : input_free_device ( input_dev ); \nkfree ( kbtab ); \nreturn error ; \nstatic void kbtab_disconnect ( struct usb_interface * intf ) \nusb_kill_urb ( kbtab -> irq ); \ninput_unregister_device ( kbtab -> dev ); \nusb_free_urb ( kbtab -> irq ); \n- usb_buffer_free ( interface_to_usbdev ( intf ), 10 , kbtab -> data , kbtab -> data_dma ); \n+ usb_buffer_free ( interface_to_usbdev ( intf ), 8 , kbtab -> data , kbtab -> data_dma ); \nkfree ( kbtab ); \n} \n}", "mmm sound / core / timer . c \nppp sound / core / timer . c \nvoid snd_timer_interrupt ( struct snd_timer * timer , unsigned long ticks_left ) \n} else { \nti -> flags &= ~ SNDRV_TIMER_IFLG_RUNNING ; \nif (-- timer -> running ) \n- list_del (& ti -> active_list ); \n+ list_del_init (& ti -> active_list ); \n} \nif (( timer -> hw . flags & SNDRV_TIMER_HW_TASKLET ) || \n( ti -> flags & SNDRV_TIMER_IFLG_FAST ))", "mmm fs / sysfs / dir . c \nppp fs / sysfs / dir . c \nstatic struct sysfs_dirent * sysfs_new_dirent ( struct sysfs_dirent * parent_sd , \n \nmemset ( sd , 0 , sizeof (* sd )); \natomic_set (& sd -> s_count , 1 ); \n- atomic_set (& sd -> s_event , 0 ); \n+ atomic_set (& sd -> s_event , 1 ); \nINIT_LIST_HEAD (& sd -> s_children ); \nlist_add (& sd -> s_sibling , & parent_sd -> s_children ); \nsd -> s_element = element ;", "mmm drivers / net / wireless / iwlwifi / iwl - tx . c \nppp drivers / net / wireless / iwlwifi / iwl - tx . c \nint iwl_enqueue_hcmd ( struct iwl_priv * priv , struct iwl_host_cmd * cmd ) \nreturn - EIO ; \n} \n \n+ if (( priv -> ucode_owner == IWL_OWNERSHIP_TM ) && \n+ !( cmd -> flags & CMD_ON_DEMAND )) { \n+ IWL_DEBUG_HC ( priv , \" tm own the uCode , no regular hcmd send \\ n \"); \n+ return - EIO ; \n+ } \n+ \ncopy_size = sizeof ( out_cmd -> hdr ); \ncmd_size = sizeof ( out_cmd -> hdr ); \n", "mmm security / keys / key . c \nppp security / keys / key . c \nstatic int __key_instantiate_and_link ( struct key * key , \n \n/* and link it into the destination keyring */ \nif ( keyring ) { \n- set_bit ( KEY_FLAG_KEEP , & key -> flags ); \n+ if ( test_bit ( KEY_FLAG_KEEP , & keyring -> flags )) \n+ set_bit ( KEY_FLAG_KEEP , & key -> flags ); \n \n__key_link ( key , _edit ); \n}", "mmm fs / ubifs / lprops . c \nppp fs / ubifs / lprops . c \nstatic int scan_check_cb ( struct ubifs_info * c , \n} \n} \n \n- buf = __vmalloc ( c -> leb_size , GFP_NOFS , PAGE_KERNEL ); \n- if (! buf ) \n- return - ENOMEM ; \n- \n/* \n* After an unclean unmount , empty and freeable LEBs \n* may contain garbage - do not scan them . \nstatic int scan_check_cb ( struct ubifs_info * c , \nreturn LPT_SCAN_CONTINUE ; \n} \n \n+ buf = __vmalloc ( c -> leb_size , GFP_NOFS , PAGE_KERNEL ); \n+ if (! buf ) \n+ return - ENOMEM ; \n+ \nsleb = ubifs_scan ( c , lnum , 0 , buf , 0 ); \nif ( IS_ERR ( sleb )) { \nret = PTR_ERR ( sleb );", "mmm sound / soc / intel / common / sst - firmware . c \nppp sound / soc / intel / common / sst - firmware . c \nvoid sst_dsp_dma_put_channel ( struct sst_dsp * dsp ) \n} \nEXPORT_SYMBOL_GPL ( sst_dsp_dma_put_channel ); \n \n- int sst_dma_new ( struct sst_dsp * sst ) \n+ static int sst_dma_new ( struct sst_dsp * sst ) \n{ \nstruct sst_pdata * sst_pdata = sst -> pdata ; \nstruct sst_dma * dma ; \nint sst_dma_new ( struct sst_dsp * sst ) \ndevm_kfree ( sst -> dev , dma ); \nreturn ret ; \n} \n- EXPORT_SYMBOL ( sst_dma_new ); \n \n- void sst_dma_free ( struct sst_dma * dma ) \n+ static void sst_dma_free ( struct sst_dma * dma ) \n{ \n \nif ( dma == NULL ) \nvoid sst_dma_free ( struct sst_dma * dma ) \ndw_remove ( dma -> chip ); \n \n} \n- EXPORT_SYMBOL ( sst_dma_free ); \n \n/* create new generic firmware object */ \nstruct sst_fw * sst_fw_new ( struct sst_dsp * dsp ,", "mmm fs / btrfs / async - thread . c \nppp fs / btrfs / async - thread . c \nvoid btrfs_destroy_workqueue ( struct btrfs_workqueue * wq ) \nif ( wq -> high ) \n__btrfs_destroy_workqueue ( wq -> high ); \n__btrfs_destroy_workqueue ( wq -> normal ); \n+ kfree ( wq ); \n} \n \nvoid btrfs_workqueue_set_max ( struct btrfs_workqueue * wq , int max )", "mmm tools / perf / util / ui / browsers / annotate . c \nppp tools / perf / util / ui / browsers / annotate . c \nstatic int annotate_browser__run ( struct annotate_browser * self , int evidx , \nnd = self -> curr_hot ; \nbreak ; \ncase ' H ': \n+ case ' h ': \nnd = self -> curr_hot ; \nbreak ; \ncase ' S ': \n+ case ' s ': \nif ( annotate_browser__toggle_source ( self )) \nui_helpline__puts ( help ); \ncontinue ;", "mmm drivers / block / floppy . c \nppp drivers / block / floppy . c \nstatic int raw_cmd_copyin ( int cmd , void __user * param , \nreturn - ENOMEM ; \n* rcmd = ptr ; \nret = copy_from_user ( ptr , param , sizeof (* ptr )); \n- if ( ret ) \n- return - EFAULT ; \nptr -> next = NULL ; \nptr -> buffer_length = 0 ; \n+ ptr -> kernel_data = NULL ; \n+ if ( ret ) \n+ return - EFAULT ; \nparam += sizeof ( struct floppy_raw_cmd ); \nif ( ptr -> cmd_count > 33 ) \n/* the command may now also take up the space \nstatic int raw_cmd_copyin ( int cmd , void __user * param , \nfor ( i = 0 ; i < 16 ; i ++) \nptr -> reply [ i ] = 0 ; \nptr -> resultcode = 0 ; \n- ptr -> kernel_data = NULL ; \n \nif ( ptr -> flags & ( FD_RAW_READ | FD_RAW_WRITE )) { \nif ( ptr -> length <= 0 )", "mmm fs / nfsd / nfs4recover . c \nppp fs / nfsd / nfs4recover . c \ncld_pipe_downcall ( struct file * filp , const char __user * src , size_t mlen ) \nstruct cld_upcall * tmp , * cup ; \nstruct cld_msg __user * cmsg = ( struct cld_msg __user *) src ; \nuint32_t xid ; \n- struct nfsd_net * nn = net_generic ( filp -> f_dentry -> d_sb -> s_fs_info , \n+ struct nfsd_net * nn = net_generic ( file_inode ( filp )-> i_sb -> s_fs_info , \nnfsd_net_id ); \nstruct cld_net * cn = nn -> cld_net ; \n", "mmm drivers / scsi / hpsa . c \nppp drivers / scsi / hpsa . c \nstatic int hpsa_eh_device_reset_handler ( struct scsi_cmnd * scsicmd ) \nreturn FAILED ; \n} \n \n+ if ( dev -> devtype == TYPE_ENCLOSURE ) \n+ return SUCCESS ; \n+ \n/* if controller locked up , we can guarantee command won ' t complete */ \nif ( lockup_detected ( h )) { \nsnprintf ( msg , sizeof ( msg ),", "mmm fs / hfsplus / catalog . c \nppp fs / hfsplus / catalog . c \nint hfsplus_find_cat ( struct super_block * sb , u32 cnid , \nreturn - EIO ; \n} \n \n+ if ( be16_to_cpu ( tmp . thread . nodeName . length ) > 255 ) { \n+ printk ( KERN_ERR \" hfs : catalog name length corrupted \\ n \"); \n+ return - EIO ; \n+ } \n+ \nhfsplus_cat_build_key_uni ( fd -> search_key , be32_to_cpu ( tmp . thread . parentID ), \n& tmp . thread . nodeName ); \nreturn hfs_brec_find ( fd );", "mmm drivers / staging / most / dim2 / dim2 . c \nppp drivers / staging / most / dim2 / dim2 . c \nstatic int dim2_probe ( struct platform_device * pdev ) \nif ( ret ) \nreturn ret ; \n \n- dev -> disable_platform = pdata ? pdata -> disable : 0 ; \n+ dev -> disable_platform = pdata ? pdata -> disable : NULL ; \n \ndev_info (& pdev -> dev , \" sync : num of frames per sub - buffer : % u \\ n \", fcnt ); \nhal_ret = dim_startup ( dev -> io_base , dev -> clk_speed , fcnt );", "mmm drivers / net / wireless / marvell / mwifiex / scan . c \nppp drivers / net / wireless / marvell / mwifiex / scan . c \nint mwifiex_ret_802_11_scan ( struct mwifiex_private * priv , \n \npmatch = adapter -> nd_info -> matches [ idx ]; \n \n- if (! pmatch ) { \n+ if ( pmatch ) { \nmemset ( pmatch , 0 , sizeof (* pmatch )); \nif ( chan_band_tlv ) { \npmatch -> n_channels = 1 ;", "mmm drivers / net / wireless / iwlwifi / iwl - trans - pcie . c \nppp drivers / net / wireless / iwlwifi / iwl - trans - pcie . c \nstatic int iwl_trans_pcie_start_hw ( struct iwl_trans * trans ) \nerr = iwl_prepare_card_hw ( trans ); \nif ( err ) { \nIWL_ERR ( trans , \" Error while preparing HW : % d \", err ); \n- goto error ; \n+ goto err_free_irq ; \n} \n \niwl_apm_init ( trans ); \nstatic int iwl_trans_pcie_start_hw ( struct iwl_trans * trans ) \n \nreturn err ; \n \n+ err_free_irq : \n+ free_irq ( trans -> irq , trans ); \nerror : \niwl_free_isr_ict ( trans ); \ntasklet_kill (& trans_pcie -> irq_tasklet );", "mmm security / keys / gc . c \nppp security / keys / gc . c \nstatic noinline void key_gc_unused_keys ( struct list_head * keys ) \nkdebug (\"- % u \", key -> serial ); \nkey_check ( key ); \n \n- /* Throw away the key data */ \n- if ( key -> type -> destroy ) \n+ /* Throw away the key data if the key is instantiated */ \n+ if ( test_bit ( KEY_FLAG_INSTANTIATED , & key -> flags ) && \n+ ! test_bit ( KEY_FLAG_NEGATIVE , & key -> flags ) && \n+ key -> type -> destroy ) \nkey -> type -> destroy ( key ); \n \nsecurity_key_free ( key );", "mmm drivers / hwtracing / coresight / coresight - etm - perf . c \nppp drivers / hwtracing / coresight / coresight - etm - perf . c \nstatic void * etm_setup_aux ( int event_cpu , void ** pages , \nif (! sink_ops ( sink )-> alloc_buffer ) \ngoto err ; \n \n+ cpu = cpumask_first ( mask ); \n/* Get the AUX specific data from the sink buffer */ \nevent_data -> snk_config = \nsink_ops ( sink )-> alloc_buffer ( sink , cpu , pages ,", "mmm net / bridge / br_multicast . c \nppp net / bridge / br_multicast . c \nstatic void __br_multicast_send_query ( struct net_bridge * br , \nreturn ; \n \nif ( port ) { \n- __skb_push ( skb , sizeof ( struct ethhdr )); \nskb -> dev = port -> dev ; \nNF_HOOK ( NFPROTO_BRIDGE , NF_BR_LOCAL_OUT , skb , NULL , skb -> dev , \n- dev_queue_xmit ); \n+ br_dev_queue_push_xmit ); \n} else { \nbr_multicast_select_own_querier ( br , ip , skb ); \nnetif_rx ( skb );", "mmm drivers / char / ftape / zftape / zftape - buffers . c \nppp drivers / char / ftape / zftape / zftape - buffers . c \nint zft_vmalloc_once ( void * new , size_t size ) \npeak_memory = used_memory ; \n} \nTRACE_ABORT ( 0 , ft_t_noise , \n- \" allocated buffer @ % p , % d bytes \", *( void **) new , size ); \n+ \" allocated buffer @ % p , % zd bytes \", *( void **) new , size ); \n} \nint zft_vmalloc_always ( void * new , size_t size ) \n{ \nvoid zft_vfree ( void * old , size_t size ) \nif (*( void **) old ) { \nvfree (*( void **) old ); \nused_memory -= size ; \n- TRACE ( ft_t_noise , \" released buffer @ % p , % d bytes \", \n+ TRACE ( ft_t_noise , \" released buffer @ % p , % zd bytes \", \n*( void **) old , size ); \n*( void **) old = NULL ; \n}", "mmm tools / perf / builtin - sched . c \nppp tools / perf / builtin - sched . c \nstatic int perf_sched__read_events ( struct perf_sched * sched ) \nstruct perf_data_file file = { \n. path = input_name , \n. mode = PERF_DATA_MODE_READ , \n+ . force = sched -> force , \n}; \nint rc = - 1 ; \n", "mmm drivers / acpi / tables . c \nppp drivers / acpi / tables . c \nint __init acpi_table_init ( void ) \n \nstatic int __init acpi_parse_apic_instance ( char * str ) \n{ \n+ if (! str ) \n+ return - EINVAL ; \n \nacpi_apic_instance = simple_strtoul ( str , NULL , 0 ); \n", "mmm drivers / usb / serial / option . c \nppp drivers / usb / serial / option . c \nstatic void option_instat_callback ( struct urb * urb ) \ndev_dbg ( dev , \"% s : type % x req % x \\ n \", __func__ , \nreq_pkt -> bRequestType , req_pkt -> bRequest ); \n} \n+ } else if ( status == - ENOENT || status == - ESHUTDOWN ) { \n+ dev_dbg ( dev , \"% s : urb stopped : % d \\ n \", __func__ , status ); \n} else \ndev_err ( dev , \"% s : error % d \\ n \", __func__ , status ); \n", "mmm kernel / tsacct . c \nppp kernel / tsacct . c \nvoid bacct_add_tsk ( struct taskstats * stats , struct task_struct * tsk ) \n*/ \nvoid xacct_add_tsk ( struct taskstats * stats , struct task_struct * p ) \n{ \n+ struct mm_struct * mm ; \n+ \n/* convert pages - jiffies to Mbyte - usec */ \nstats -> coremem = jiffies_to_usecs ( p -> acct_rss_mem1 ) * PAGE_SIZE / MB ; \nstats -> virtmem = jiffies_to_usecs ( p -> acct_vm_mem1 ) * PAGE_SIZE / MB ; \n- if ( p -> mm ) { \n+ mm = get_task_mm ( p ); \n+ if ( mm ) { \n/* adjust to KB unit */ \n- stats -> hiwater_rss = p -> mm -> hiwater_rss * PAGE_SIZE / KB ; \n- stats -> hiwater_vm = p -> mm -> hiwater_vm * PAGE_SIZE / KB ; \n+ stats -> hiwater_rss = mm -> hiwater_rss * PAGE_SIZE / KB ; \n+ stats -> hiwater_vm = mm -> hiwater_vm * PAGE_SIZE / KB ; \n+ mmput ( mm ); \n} \nstats -> read_char = p -> rchar ; \nstats -> write_char = p -> wchar ;", "mmm fs / eventpoll . c \nppp fs / eventpoll . c \nstatic void ep_free ( struct eventpoll * ep ) \n} \n \nmutex_unlock (& epmutex ); \n- \nmutex_destroy (& ep -> mtx ); \n+ kfree ( ep ); \n} \n \nstatic int ep_eventpoll_release ( struct inode * inode , struct file * file ) \n{ \nstruct eventpoll * ep = file -> private_data ; \n \n- if ( ep ) { \n+ if ( ep ) \nep_free ( ep ); \n- kfree ( ep ); \n- } \n \nDNPRINTK ( 3 , ( KERN_INFO \"[% p ] eventpoll : close () ep =% p \\ n \", current , ep )); \nreturn 0 ; \nasmlinkage long sys_epoll_create ( int size ) \n \nerror_free : \nep_free ( ep ); \n- kfree ( ep ); \nerror_return : \nDNPRINTK ( 3 , ( KERN_INFO \"[% p ] eventpoll : sys_epoll_create (% d ) = % d \\ n \", \ncurrent , size , error ));", "mmm drivers / staging / android / ion / ion_carveout_heap . c \nppp drivers / staging / android / ion / ion_carveout_heap . c \nstatic int ion_carveout_heap_allocate ( struct ion_heap * heap , \nunsigned long size , unsigned long align , \nunsigned long flags ) \n{ \n+ if ( align > PAGE_SIZE ) \n+ return - EINVAL ; \n+ \nbuffer -> priv_phys = ion_carveout_allocate ( heap , size , align ); \nreturn buffer -> priv_phys == ION_CARVEOUT_ALLOCATE_FAIL ? - ENOMEM : 0 ; \n}", "mmm drivers / usb / gadget / f_fs . c \nppp drivers / usb / gadget / f_fs . c \nstatic ssize_t ffs_epfile_io ( struct file * file , \nchar __user * buf , size_t len , int read ) \n{ \nstruct ffs_epfile * epfile = file -> private_data ; \n- struct usb_gadget * gadget = epfile -> ffs -> gadget ; \nstruct ffs_ep * ep ; \nchar * data = NULL ; \nssize_t ret , data_len ; \nstatic ssize_t ffs_epfile_io ( struct file * file , \n \n/* Allocate & copy */ \nif (! halt ) { \n+ /* \n+ * if we _do_ wait above , the epfile -> ffs -> gadget might be NULL \n+ * before the waiting completes , so do not assign to ' gadget ' earlier \n+ */ \n+ struct usb_gadget * gadget = epfile -> ffs -> gadget ; \n+ \n/* \n* Controller may require buffer size to be aligned to \n* maxpacketsize of an out endpoint .", "mmm fs / ecryptfs / file . c \nppp fs / ecryptfs / file . c \nstatic int read_or_initialize_metadata ( struct dentry * dentry ) \nreturn rc ; \n} \n \n+ static int ecryptfs_mmap ( struct file * file , struct vm_area_struct * vma ) \n+{ \n+ struct file * lower_file = ecryptfs_file_to_lower ( file ); \n+ /* \n+ * Don ' t allow mmap on top of file systems that don ' t support it \n+ * natively . If FILESYSTEM_MAX_STACK_DEPTH > 2 or ecryptfs \n+ * allows recursive mounting , this will need to be extended . \n+ */ \n+ if (! lower_file -> f_op -> mmap ) \n+ return - ENODEV ; \n+ return generic_file_mmap ( file , vma ); \n+} \n+ \n/** \n* ecryptfs_open \n* @ inode : inode specifying file to open \nconst struct file_operations ecryptfs_main_fops = { \n# ifdef CONFIG_COMPAT \n. compat_ioctl = ecryptfs_compat_ioctl , \n# endif \n- . mmap = generic_file_mmap , \n+ . mmap = ecryptfs_mmap , \n. open = ecryptfs_open , \n. flush = ecryptfs_flush , \n. release = ecryptfs_release ,", "mmm kernel / fork . c \nppp kernel / fork . c \nnoinline struct pt_regs * __cpuinit __attribute__ (( weak )) idle_regs ( struct pt_re \nreturn regs ; \n} \n \n+ static inline void init_idle_pids ( struct pid_link * links ) \n+{ \n+ enum pid_type type ; \n+ \n+ for ( type = PIDTYPE_PID ; type < PIDTYPE_MAX ; ++ type ) { \n+ INIT_HLIST_NODE (& links [ type ]. node ); /* not really needed */ \n+ links [ type ]. pid = & init_struct_pid ; \n+ } \n+} \n+ \nstruct task_struct * __cpuinit fork_idle ( int cpu ) \n{ \nstruct task_struct * task ; \nstruct task_struct * __cpuinit fork_idle ( int cpu ) \n \ntask = copy_process ( CLONE_VM , 0 , idle_regs (& regs ), 0 , NULL , \n& init_struct_pid , 0 ); \n- if (! IS_ERR ( task )) \n+ if (! IS_ERR ( task )) { \n+ init_idle_pids ( task -> pids ); \ninit_idle ( task , cpu ); \n+ } \n \nreturn task ; \n}", "mmm fs / btrfs / send . c \nppp fs / btrfs / send . c \nstatic int iterate_dir_item ( struct btrfs_root * root , struct btrfs_path * path , \nbuf = tmp ; \n} \nif (! buf ) { \n- buf = vmalloc ( buf_len ); \n+ buf = kvmalloc ( buf_len , GFP_KERNEL ); \nif (! buf ) { \nret = - ENOMEM ; \ngoto out ;", "mmm kernel / events / core . c \nppp kernel / events / core . c \nstatic int perf_copy_attr ( struct perf_event_attr __user * uattr , \nif ( ret ) \nreturn - EFAULT ; \n \n+ attr -> size = size ; \n+ \nif ( attr -> __reserved_1 ) \nreturn - EINVAL ; \n", "mmm drivers / spi / spi - imx . c \nppp drivers / spi / spi - imx . c \nstatic int spi_imx_probe ( struct platform_device * pdev ) \ngoto out_clk_put ; \n} \n \n+ if (! master -> cs_gpios ) { \n+ dev_err (& pdev -> dev , \" No CS GPIOs available \\ n \"); \n+ goto out_clk_put ; \n+ } \n+ \nfor ( i = 0 ; i < master -> num_chipselect ; i ++) { \nif (! gpio_is_valid ( master -> cs_gpios [ i ])) \ncontinue ;", "mmm fs / namei . c \nppp fs / namei . c \nstatic struct file * path_openat ( int dfd , struct filename * pathname , \n \nif ( unlikely ( file -> f_flags & __O_TMPFILE )) { \nerror = do_tmpfile ( dfd , pathname , nd , flags , op , file , & opened ); \n- goto out ; \n+ goto out2 ; \n} \n \nerror = path_init ( dfd , pathname , flags , nd ); \nstatic struct file * path_openat ( int dfd , struct filename * pathname , \n} \nout : \npath_cleanup ( nd ); \n+ out2 : \nif (!( opened & FILE_OPENED )) { \nBUG_ON (! error ); \nput_filp ( file );", "mmm drivers / crypto / chelsio / chtls / chtls_main . c \nppp drivers / crypto / chelsio / chtls / chtls_main . c \nstatic int do_chtls_setsockopt ( struct sock * sk , int optname , \n \nswitch ( tmp_crypto_info . cipher_type ) { \ncase TLS_CIPHER_AES_GCM_128 : { \n- rc = copy_from_user ( crypto_info , optval , \n- sizeof ( struct \n- tls12_crypto_info_aes_gcm_128 )); \n+ /* Obtain version and type from previous copy */ \n+ crypto_info [ 0 ] = tmp_crypto_info ; \n+ /* Now copy the following data */ \n+ rc = copy_from_user (( char *) crypto_info + sizeof (* crypto_info ), \n+ optval + sizeof (* crypto_info ), \n+ sizeof ( struct tls12_crypto_info_aes_gcm_128 ) \n+ - sizeof (* crypto_info )); \n \nif ( rc ) { \nrc = - EFAULT ;", "mmm fs / nfs / flexfilelayout / flexfilelayoutdev . c \nppp fs / nfs / flexfilelayout / flexfilelayoutdev . c \nstatic bool ff_layout_mirror_valid ( struct pnfs_layout_segment * lseg , \n} else \ngoto outerr ; \n} \n+ \n+ if ( IS_ERR ( mirror -> mirror_ds )) \n+ goto outerr ; \n+ \nif ( mirror -> mirror_ds -> ds == NULL ) { \nstruct nfs4_deviceid_node * devid ; \ndevid = & mirror -> mirror_ds -> id_node ;", "mmm drivers / hwmon / scmi - hwmon . c \nppp drivers / hwmon / scmi - hwmon . c \nstatic int scmi_hwmon_probe ( struct scmi_device * sdev ) \nscmi_chip_info . info = ptr_scmi_ci ; \nchip_info = & scmi_chip_info ; \n \n- for ( type = 0 ; type < hwmon_max && nr_count [ type ]; type ++) { \n+ for ( type = 0 ; type < hwmon_max ; type ++) { \n+ if (! nr_count [ type ]) \n+ continue ; \n+ \nscmi_hwmon_add_chan_info ( scmi_hwmon_chan , dev , nr_count [ type ], \ntype , hwmon_attributes [ type ]); \n* ptr_scmi_ci ++ = scmi_hwmon_chan ++;", "mmm fs / xfs / xfs_itable . c \nppp fs / xfs / xfs_itable . c \nxfs_inumbers ( \nreturn error ; \n \nbcount = MIN ( left , ( int )( PAGE_SIZE / sizeof (* buffer ))); \n- buffer = kmem_alloc ( bcount * sizeof (* buffer ), KM_SLEEP ); \n+ buffer = kmem_zalloc ( bcount * sizeof (* buffer ), KM_SLEEP ); \ndo { \nstruct xfs_inobt_rec_incore r ; \nint stat ;", "mmm tools / perf / util / intel - pt - decoder / intel - pt - insn - decoder . c \nppp tools / perf / util / intel - pt - decoder / intel - pt - insn - decoder . c \nstatic void intel_pt_insn_decoder ( struct insn * insn , \nenum intel_pt_insn_branch branch = INTEL_PT_BR_NO_BRANCH ; \nint ext ; \n \n+ intel_pt_insn -> rel = 0 ; \n+ \nif ( insn_is_avx ( insn )) { \nintel_pt_insn -> op = INTEL_PT_OP_OTHER ; \nintel_pt_insn -> branch = INTEL_PT_BR_NO_BRANCH ;", "mmm mm / backing - dev . c \nppp mm / backing - dev . c \nint bdi_register ( struct backing_dev_info * bdi , struct device * parent , \nint ret = 0 ; \nstruct device * dev ; \n \n+ if ( WARN_ON ( bdi -> dev )) \n+ goto exit ; \n+ \nva_start ( args , fmt ); \ndev = device_create_vargs ( bdi_class , parent , MKDEV ( 0 , 0 ), bdi , fmt , args ); \nva_end ( args );", "mmm security / keys / request_key_auth . c \nppp security / keys / request_key_auth . c \n# include \" internal . h \" \n# include < keys / user - type . h > \n \n+ static int request_key_auth_preparse ( struct key_preparsed_payload *); \n+ static void request_key_auth_free_preparse ( struct key_preparsed_payload *); \nstatic int request_key_auth_instantiate ( struct key *, \nstruct key_preparsed_payload *); \nstatic void request_key_auth_describe ( const struct key *, struct seq_file *); \nstatic long request_key_auth_read ( const struct key *, char __user *, size_t ); \nstruct key_type key_type_request_key_auth = { \n. name = \". request_key_auth \", \n. def_datalen = sizeof ( struct request_key_auth ), \n+ . preparse = request_key_auth_preparse , \n+ . free_preparse = request_key_auth_free_preparse , \n. instantiate = request_key_auth_instantiate , \n. describe = request_key_auth_describe , \n. revoke = request_key_auth_revoke , \nstruct key_type key_type_request_key_auth = { \n. read = request_key_auth_read , \n}; \n \n+ int request_key_auth_preparse ( struct key_preparsed_payload * prep ) \n+{ \n+ return 0 ; \n+} \n+ \n+ void request_key_auth_free_preparse ( struct key_preparsed_payload * prep ) \n+{ \n+} \n+ \n/* \n* Instantiate a request - key authorisation key . \n*/", "mmm include / linux / init_task . h \nppp include / linux / init_task . h \nextern struct group_info init_groups ; \n# define INIT_STRUCT_PID { \\ \n. count = ATOMIC_INIT ( 1 ), \\ \n. tasks = { \\ \n- { . first = & init_task . pids [ PIDTYPE_PID ]. node }, \\ \n- { . first = & init_task . pids [ PIDTYPE_PGID ]. node }, \\ \n- { . first = & init_task . pids [ PIDTYPE_SID ]. node }, \\ \n+ { . first = NULL }, \\ \n+ { . first = NULL }, \\ \n+ { . first = NULL }, \\ \n}, \\ \n. level = 0 , \\ \n. numbers = { { \\ \nextern struct group_info init_groups ; \n{ \\ \n. node = { \\ \n. next = NULL , \\ \n- . pprev = & init_struct_pid . tasks [ type ]. first , \\ \n+ . pprev = NULL , \\ \n}, \\ \n. pid = & init_struct_pid , \\ \n}", "mmm drivers / mmc / host / mxcmmc . c \nppp drivers / mmc / host / mxcmmc . c \nstatic int mxcmci_probe ( struct platform_device * pdev ) \n \nres = platform_get_resource ( pdev , IORESOURCE_MEM , 0 ); \nirq = platform_get_irq ( pdev , 0 ); \n- if ( irq < 0 ) \n- return - EINVAL ; \n+ if ( irq < 0 ) { \n+ dev_err (& pdev -> dev , \" failed to get IRQ : % d \\ n \", irq ); \n+ return irq ; \n+ } \n \nmmc = mmc_alloc_host ( sizeof (* host ), & pdev -> dev ); \nif (! mmc )", "mmm drivers / pci / hotplug / pciehp_hpc . c \nppp drivers / pci / hotplug / pciehp_hpc . c \nstatic void pcie_disable_notification ( struct controller * ctrl ) \nu16 mask ; \nmask = ( PCI_EXP_SLTCTL_PDCE | PCI_EXP_SLTCTL_ABPE | \nPCI_EXP_SLTCTL_MRLSCE | PCI_EXP_SLTCTL_PFDE | \n- PCI_EXP_SLTCTL_HPIE | PCI_EXP_SLTCTL_CCIE ); \n+ PCI_EXP_SLTCTL_HPIE | PCI_EXP_SLTCTL_CCIE | \n+ PCI_EXP_SLTCTL_DLLSCE ); \nif ( pcie_write_cmd ( ctrl , 0 , mask )) \nctrl_warn ( ctrl , \" Cannot disable software notification \\ n \"); \n}", "mmm kernel / sched / fair . c \nppp kernel / sched / fair . c \n___update_load_avg ( u64 now , int cpu , struct sched_avg * sa , \n \nsa -> last_update_time += delta << 10 ; \n \n+ /* \n+ * running is a subset of runnable ( weight ) so running can ' t be set if \n+ * runnable is clear . But there are some corner cases where the current \n+ * se has been already dequeued but cfs_rq -> curr still points to it . \n+ * This means that weight will be 0 but not running for a sched_entity \n+ * but also for a cfs_rq if the latter becomes idle . As an example , \n+ * this happens during idle_balance () which calls \n+ * update_blocked_averages () \n+ */ \n+ if (! weight ) \n+ running = 0 ; \n+ \n/* \n* Now we know we crossed measurement unit boundaries . The * _avg \n* accrues by two steps :", "mmm drivers / platform / x86 / acer - wmi . c \nppp drivers / platform / x86 / acer - wmi . c \nstatic acpi_status WMID_set_capabilities ( void ) \ndevices = *(( u32 *) obj -> buffer . pointer ); \n} else if ( obj -> type == ACPI_TYPE_INTEGER ) { \ndevices = ( u32 ) obj -> integer . value ; \n+ } else { \n+ kfree ( out . pointer ); \n+ return AE_ERROR ; \n} \n} else { \nkfree ( out . pointer );", "mmm fs / exec . c \nppp fs / exec . c \nstatic int __bprm_mm_init ( struct linux_binprm * bprm ) \nif (! vma ) \nreturn - ENOMEM ; \n \n- down_write (& mm -> mmap_sem ); \n+ if ( down_write_killable (& mm -> mmap_sem )) { \n+ err = - EINTR ; \n+ goto err_free ; \n+ } \nvma -> vm_mm = mm ; \n \n/* \nstatic int __bprm_mm_init ( struct linux_binprm * bprm ) \nreturn 0 ; \nerr : \nup_write (& mm -> mmap_sem ); \n+ err_free : \nbprm -> vma = NULL ; \nkmem_cache_free ( vm_area_cachep , vma ); \nreturn err ; \nint setup_arg_pages ( struct linux_binprm * bprm , \nbprm -> loader -= stack_shift ; \nbprm -> exec -= stack_shift ; \n \n- down_write (& mm -> mmap_sem ); \n+ if ( down_write_killable (& mm -> mmap_sem )) \n+ return - EINTR ; \n+ \nvm_flags = VM_STACK_FLAGS ; \n \n/*", "mmm net / sctp / sm_statefuns . c \nppp net / sctp / sm_statefuns . c \nsctp_disposition_t sctp_sf_do_5_2_4_dupcook ( struct net * net , \n} \n \n/* Delete the tempory new association . */ \n- sctp_add_cmd_sf ( commands , SCTP_CMD_NEW_ASOC , SCTP_ASOC ( new_asoc )); \n+ sctp_add_cmd_sf ( commands , SCTP_CMD_SET_ASOC , SCTP_ASOC ( new_asoc )); \nsctp_add_cmd_sf ( commands , SCTP_CMD_DELETE_TCB , SCTP_NULL ()); \n \n/* Restore association pointer to provide SCTP command interpeter", "mmm drivers / gpu / drm / msm / msm_gem . c \nppp drivers / gpu / drm / msm / msm_gem . c \nvoid msm_gem_free_object ( struct drm_gem_object * obj ) \nif ( msm_obj -> pages ) \ndrm_free_large ( msm_obj -> pages ); \n \n+ drm_prime_gem_destroy ( obj , msm_obj -> sgt ); \n} else { \nvunmap ( msm_obj -> vaddr ); \nput_pages ( obj );", "mmm sound / soc / codecs / arizona . c \nppp sound / soc / codecs / arizona . c \nint arizona_set_sysclk ( struct snd_soc_codec * codec , int clk_id , \ncase 147456000 : \nval |= 6 << ARIZONA_SYSCLK_FREQ_SHIFT ; \nbreak ; \n+ case 0 : \n+ dev_dbg ( arizona -> dev , \"% s cleared \\ n \", name ); \n+ * clk = freq ; \n+ return 0 ; \ndefault : \nreturn - EINVAL ; \n} \nstatic int arizona_startup ( struct snd_pcm_substream * substream , \nreturn 0 ; \n} \n \n+ if ( base_rate == 0 ) \n+ return 0 ; \n+ \nif ( base_rate % 8000 ) \nconstraint = & arizona_44k1_constraint ; \nelse", "mmm drivers / media / usb / ttusb - dec / ttusbdecfe . c \nppp drivers / media / usb / ttusb - dec / ttusbdecfe . c \nstatic int ttusbdecfe_dvbs_diseqc_send_master_cmd ( struct dvb_frontend * fe , struc \n0x00 , 0x00 , 0x00 , 0x00 , \n0x00 , 0x00 }; \n \n+ if ( cmd -> msg_len > sizeof ( b ) - 4 ) \n+ return - EINVAL ; \n+ \nmemcpy (& b [ 4 ], cmd -> msg , cmd -> msg_len ); \n \nstate -> config -> send_command ( fe , 0x72 ,", "mmm include / net / cipso_ipv4 . h \nppp include / net / cipso_ipv4 . h \nstatic inline int cipso_v4_validate ( const struct sk_buff * skb , \nunsigned char err_offset = 0 ; \nu8 opt_len = opt [ 1 ]; \nu8 opt_iter ; \n+ u8 tag_len ; \n \nif ( opt_len < 8 ) { \nerr_offset = 1 ; \nstatic inline int cipso_v4_validate ( const struct sk_buff * skb , \n} \n \nfor ( opt_iter = 6 ; opt_iter < opt_len ;) { \n- if ( opt [ opt_iter + 1 ] > ( opt_len - opt_iter )) { \n+ tag_len = opt [ opt_iter + 1 ]; \n+ if (( tag_len == 0 ) || ( opt [ opt_iter + 1 ] > ( opt_len - opt_iter ))) { \nerr_offset = opt_iter + 1 ; \ngoto out ; \n} \n- opt_iter += opt [ opt_iter + 1 ]; \n+ opt_iter += tag_len ; \n} \n \nout :", "mmm sound / soc / intel / sst - haswell - ipc . c \nppp sound / soc / intel / sst - haswell - ipc . c \nint sst_hsw_stream_get_volume ( struct sst_hsw * hsw , struct sst_hsw_stream * stream \nreturn - EINVAL ; \n \nsst_dsp_read ( hsw -> dsp , volume , \n- stream -> reply . volume_register_address [ channel ], sizeof ( volume )); \n+ stream -> reply . volume_register_address [ channel ], \n+ sizeof (* volume )); \n \nreturn 0 ; \n}", "mmm net / rds / rdma . c \nppp net / rds / rdma . c \nstatic int __rds_rdma_map ( struct rds_sock * rs , struct rds_get_mr_args * args , \nlong i ; \nint ret ; \n \n- if ( rs -> rs_bound_addr == 0 ) { \n+ if ( rs -> rs_bound_addr == 0 || ! rs -> rs_transport ) { \nret = - ENOTCONN ; /* XXX not a great errno */ \ngoto out ; \n}", "mmm drivers / gpu / drm / radeon / kv_dpm . c \nppp drivers / gpu / drm / radeon / kv_dpm . c \nvoid kv_dpm_powergate_uvd ( struct radeon_device * rdev , bool gate ) \npi -> uvd_power_gated = gate ; \n \nif ( gate ) { \n- uvd_v1_0_stop ( rdev ); \n- cik_update_cg ( rdev , RADEON_CG_BLOCK_UVD , false ); \n+ if ( pi -> caps_uvd_pg ) { \n+ uvd_v1_0_stop ( rdev ); \n+ cik_update_cg ( rdev , RADEON_CG_BLOCK_UVD , false ); \n+ } \nkv_update_uvd_dpm ( rdev , gate ); \nif ( pi -> caps_uvd_pg ) \nkv_notify_message_to_smu ( rdev , PPSMC_MSG_UVDPowerOFF ); \n} else { \n- if ( pi -> caps_uvd_pg ) \n+ if ( pi -> caps_uvd_pg ) { \nkv_notify_message_to_smu ( rdev , PPSMC_MSG_UVDPowerON ); \n- uvd_v4_2_resume ( rdev ); \n- uvd_v1_0_start ( rdev ); \n- cik_update_cg ( rdev , RADEON_CG_BLOCK_UVD , true ); \n+ uvd_v4_2_resume ( rdev ); \n+ uvd_v1_0_start ( rdev ); \n+ cik_update_cg ( rdev , RADEON_CG_BLOCK_UVD , true ); \n+ } \nkv_update_uvd_dpm ( rdev , gate ); \n} \n}", "mmm fs / cifs / cifs_dfs_ref . c \nppp fs / cifs / cifs_dfs_ref . c \nchar * cifs_compose_mount_options ( const char * sb_mountdata , \n* string to the length of the original string to allow for worst case . \n*/ \nmd_len = strlen ( sb_mountdata ) + INET6_ADDRSTRLEN ; \n- mountdata = kzalloc ( md_len + 1 , GFP_KERNEL ); \n+ mountdata = kzalloc ( md_len + sizeof (\" ip =\") + 1 , GFP_KERNEL ); \nif ( mountdata == NULL ) { \nrc = - ENOMEM ; \ngoto compose_mount_options_err ;", "mmm drivers / block / floppy . c \nppp drivers / block / floppy . c \nstatic void setup_format_params ( int track ) \nraw_cmd -> kernel_data = floppy_track_buffer ; \nraw_cmd -> length = 4 * F_SECT_PER_TRACK ; \n \n+ if (! F_SECT_PER_TRACK ) \n+ return ; \n+ \n/* allow for about 30ms for data transport per track */ \nhead_shift = ( F_SECT_PER_TRACK + 5 ) / 6 ; \n \nstatic int set_geometry ( unsigned int cmd , struct floppy_struct * g , \n/* sanity checking for parameters . */ \nif ( g -> sect <= 0 || \ng -> head <= 0 || \n+ /* check for zero in F_SECT_PER_TRACK */ \n+ ( unsigned char )(( g -> sect << 2 ) >> FD_SIZECODE ( g )) == 0 || \ng -> track <= 0 || g -> track > UDP -> tracks >> STRETCH ( g ) || \n/* check if reserved bits are set */ \n( g -> stretch & ~( FD_STRETCH | FD_SWAPSIDES | FD_SECTBASEMASK )) != 0 )", "mmm drivers / net / ethernet / broadcom / cnic . c \nppp drivers / net / ethernet / broadcom / cnic . c \nstatic int cnic_start_hw ( struct cnic_dev * dev ) \nreturn 0 ; \n \nerr1 : \n- cp -> free_resc ( dev ); \n+ if ( ethdev -> drv_state & CNIC_DRV_STATE_HANDLES_IRQ ) \n+ cp -> stop_hw ( dev ); \n+ else \n+ cp -> free_resc ( dev ); \npci_dev_put ( dev -> pcidev ); \nreturn err ; \n}", "mmm drivers / gpu / drm / etnaviv / etnaviv_gpu . c \nppp drivers / gpu / drm / etnaviv / etnaviv_gpu . c \nint etnaviv_gpu_submit ( struct etnaviv_gpu * gpu , \ngoto out_pm_put ; \n} \n \n+ mutex_lock (& gpu -> lock ); \n+ \nfence = etnaviv_gpu_fence_alloc ( gpu ); \nif (! fence ) { \nevent_free ( gpu , event ); \nint etnaviv_gpu_submit ( struct etnaviv_gpu * gpu , \ngoto out_pm_put ; \n} \n \n- mutex_lock (& gpu -> lock ); \n- \ngpu -> event [ event ]. fence = fence ; \nsubmit -> fence = fence -> seqno ; \ngpu -> active_fence = submit -> fence ;", "mmm drivers / char / virtio_console . c \nppp drivers / char / virtio_console . c \nstatic ssize_t port_fops_write ( struct file * filp , const char __user * ubuf , \nif ( ret < 0 ) \nreturn ret ; \n} \n+ /* Port got hot - unplugged . */ \n+ if (! port -> guest_connected ) \n+ return - ENODEV ; \n \ncount = min (( size_t )( 32 * 1024 ), count ); \n", "mmm drivers / net / hamradio / mkiss . c \nppp drivers / net / hamradio / mkiss . c \nstatic int mkiss_ioctl ( struct tty_struct * tty , struct file * file , \nunsigned int cmd , unsigned long arg ) \n{ \nstruct mkiss * ax = mkiss_get ( tty ); \n- struct net_device * dev = ax -> dev ; \n+ struct net_device * dev ; \nunsigned int tmp , err ; \n \n/* First make sure we ' re connected . */ \nif ( ax == NULL ) \nreturn - ENXIO ; \n+ dev = ax -> dev ; \n \nswitch ( cmd ) { \ncase SIOCGIFNAME :", "mmm drivers / soc / tegra / pmc . c \nppp drivers / soc / tegra / pmc . c \nstatic int tegra_io_pad_prepare ( enum tegra_io_pad id , unsigned long * request , \n} \n \nrate = clk_get_rate ( pmc -> clk ); \n+ if (! rate ) \n+ return - ENODEV ; \n \ntegra_pmc_writel ( DPD_SAMPLE_ENABLE , DPD_SAMPLE ); \n", "mmm drivers / net / ethernet / intel / ixgbe / ixgbe_main . c \nppp drivers / net / ethernet / intel / ixgbe / ixgbe_main . c \nstatic void ixgbe_tx_map ( struct ixgbe_ring * tx_ring , \ntx_buffer_info -> dma = dma ; \n \ntx_desc -> read . buffer_addr = cpu_to_le64 ( dma + offset ); \n+ if ( unlikely ( skb -> no_fcs )) \n+ cmd_type &= ~( cpu_to_le32 ( IXGBE_ADVTXD_DCMD_IFCS )); \ntx_desc -> read . cmd_type_len = cmd_type | cpu_to_le32 ( size ); \ntx_desc -> read . olinfo_status = olinfo_status ; \n \nstatic int __devinit ixgbe_probe ( struct pci_dev * pdev , \nnetdev -> vlan_features |= NETIF_F_SG ; \n \nnetdev -> priv_flags |= IFF_UNICAST_FLT ; \n+ netdev -> priv_flags |= IFF_SUPP_NOFCS ; \n \nif ( adapter -> flags & IXGBE_FLAG_SRIOV_ENABLED ) \nadapter -> flags &= ~( IXGBE_FLAG_RSS_ENABLED |", "mmm drivers / cpufreq / cpufreq . c \nppp drivers / cpufreq / cpufreq . c \nstatic int cpufreq_online ( unsigned int cpu ) \nif ( new_policy ) { \n/* related_cpus should at least include policy -> cpus . */ \ncpumask_copy ( policy -> related_cpus , policy -> cpus ); \n- /* Clear mask of registered CPUs */ \n- cpumask_clear ( policy -> real_cpus ); \n} \n \n/*", "mmm net / rxrpc / af_rxrpc . c \nppp net / rxrpc / af_rxrpc . c \nstruct rxrpc_call * rxrpc_kernel_begin_call ( struct socket * sock , \nstruct rxrpc_transport * trans ; \nstruct rxrpc_call * call ; \nstruct rxrpc_sock * rx = rxrpc_sk ( sock -> sk ); \n+ int ret ; \n \n_enter (\",,% x ,% lx \", key_serial ( key ), user_call_ID ); \n \n+ ret = rxrpc_validate_address ( rx , srx , sizeof (* srx )); \n+ if ( ret < 0 ) \n+ return ERR_PTR ( ret ); \n+ \nlock_sock (& rx -> sk ); \n \nif (! key )", "mmm drivers / usb / mon / mon_text . c \nppp drivers / usb / mon / mon_text . c \nint __init mon_text_init ( void ) \n{ \nstruct dentry * mondir ; \n \n- mondir = debugfs_create_dir (\" usbmon \", NULL ); \n+ mondir = debugfs_create_dir (\" usbmon \", usb_debug_root ); \nif ( IS_ERR ( mondir )) { \nprintk ( KERN_NOTICE TAG \": debugfs is not available \\ n \"); \nreturn - ENODEV ;", "mmm drivers / net / ethernet / intel / ixgbe / ixgbe_x550 . c \nppp drivers / net / ethernet / intel / ixgbe / ixgbe_x550 . c \nstatic s32 ixgbe_setup_kr_x550em ( struct ixgbe_hw * hw ) \nif ( hw -> phy . autoneg_advertised & IXGBE_LINK_SPEED_2_5GB_FULL ) \nreturn 0 ; \n \n+ if ( ixgbe_check_reset_blocked ( hw )) \n+ return 0 ; \n+ \nreturn ixgbe_setup_kr_speed_x550em ( hw , hw -> phy . autoneg_advertised ); \n} \n", "mmm fs / btrfs / file . c \nppp fs / btrfs / file . c \nint btrfs_add_inode_defrag ( struct btrfs_trans_handle * trans , \nspin_lock (& root -> fs_info -> defrag_inodes_lock ); \nif (! BTRFS_I ( inode )-> in_defrag ) \n__btrfs_add_inode_defrag ( inode , defrag ); \n+ else \n+ kfree ( defrag ); \nspin_unlock (& root -> fs_info -> defrag_inodes_lock ); \nreturn 0 ; \n}", "mmm drivers / infiniband / hw / ipath / ipath_rc . c \nppp drivers / infiniband / hw / ipath / ipath_rc . c \nstatic int do_rc_ack ( struct ipath_qp * qp , u32 aeth , u32 psn , int opcode , \n/* If this is a partial ACK , reset the retransmit timer . */ \nif ( qp -> s_last != qp -> s_tail ) { \nspin_lock (& dev -> pending_lock ); \n- list_add_tail (& qp -> timerwait , \n- & dev -> pending [ dev -> pending_index ]); \n+ if ( list_empty (& qp -> timerwait )) \n+ list_add_tail (& qp -> timerwait , \n+ & dev -> pending [ dev -> pending_index ]); \nspin_unlock (& dev -> pending_lock ); \n/* \n* If we get a partial ACK for a resent operation ,", "mmm drivers / rpmsg / rpmsg_core . c \nppp drivers / rpmsg / rpmsg_core . c \nstatic ssize_t modalias_show ( struct device * dev , \nstruct device_attribute * attr , char * buf ) \n{ \nstruct rpmsg_device * rpdev = to_rpmsg_device ( dev ); \n+ ssize_t len ; \n+ \n+ len = of_device_modalias ( dev , buf , PAGE_SIZE ); \n+ if ( len != - ENODEV ) \n+ return len ; \n \nreturn sprintf ( buf , RPMSG_DEVICE_MODALIAS_FMT \"\\ n \", rpdev -> id . name ); \n} \nstatic int rpmsg_dev_match ( struct device * dev , struct device_driver * drv ) \nstatic int rpmsg_uevent ( struct device * dev , struct kobj_uevent_env * env ) \n{ \nstruct rpmsg_device * rpdev = to_rpmsg_device ( dev ); \n+ int ret ; \n+ \n+ ret = of_device_uevent_modalias ( dev , env ); \n+ if ( ret != - ENODEV ) \n+ return ret ; \n \nreturn add_uevent_var ( env , \" MODALIAS =\" RPMSG_DEVICE_MODALIAS_FMT , \nrpdev -> id . name );", "mmm drivers / usb / net / usbnet . c \nppp drivers / usb / net / usbnet . c \nstatic int blan_mdlm_bind ( struct usbnet * dev , struct usb_interface * intf ) \n} \n/* expect bcdVersion 1 . 0 , ignore */ \nif ( memcmp (& desc -> bGUID , blan_guid , 16 ) \n- && memcmp (& desc -> bGUID , blan_guid , 16 ) ) { \n+ && memcmp (& desc -> bGUID , safe_guid , 16 ) ) { \n/* hey , this one might _really_ be MDLM ! */ \ndev_dbg (& intf -> dev , \" MDLM guid \\ n \"); \ngoto bad_desc ;", "mmm drivers / gpu / drm / atmel - hlcdc / atmel_hlcdc_dc . c \nppp drivers / gpu / drm / atmel - hlcdc / atmel_hlcdc_dc . c \nstatic int atmel_hlcdc_dc_atomic_commit ( struct drm_device * dev , \ndc -> commit . pending = true ; \nspin_unlock (& dc -> commit . wait . lock ); \n \n- if ( ret ) { \n- kfree ( commit ); \n- goto error ; \n- } \n+ if ( ret ) \n+ goto err_free ; \n \n- /* Swap the state , this is the point of no return . */ \n- drm_atomic_helper_swap_state ( state , true ); \n+ /* We have our own synchronization through the commit lock . */ \n+ BUG_ON ( drm_atomic_helper_swap_state ( state , false ) < 0 ); \n \n+ /* Swap state succeeded , this is the point of no return . */ \ndrm_atomic_state_get ( state ); \nif ( async ) \nqueue_work ( dc -> wq , & commit -> work ); \nstatic int atmel_hlcdc_dc_atomic_commit ( struct drm_device * dev , \n \nreturn 0 ; \n \n+ err_free : \n+ kfree ( commit ); \nerror : \ndrm_atomic_helper_cleanup_planes ( dev , state ); \nreturn ret ;", "mmm drivers / staging / android / ion / ion_system_heap . c \nppp drivers / staging / android / ion / ion_system_heap . c \nstatic struct page_info * alloc_largest_available ( struct ion_system_heap * heap , \nstruct page_info * info ; \nint i ; \n \n+ info = kmalloc ( sizeof ( struct page_info ), GFP_KERNEL ); \n+ if (! info ) \n+ return NULL ; \n+ \nfor ( i = 0 ; i < num_orders ; i ++) { \nif ( size < order_to_size ( orders [ i ])) \ncontinue ; \nstatic struct page_info * alloc_largest_available ( struct ion_system_heap * heap , \nif (! page ) \ncontinue ; \n \n- info = kmalloc ( sizeof ( struct page_info ), GFP_KERNEL ); \ninfo -> page = page ; \ninfo -> order = orders [ i ]; \nreturn info ; \n} \n+ kfree ( info ); \n+ \nreturn NULL ; \n} \n", "mmm crypto / shash . c \nppp crypto / shash . c \nstatic int shash_update_unaligned ( struct shash_desc * desc , const u8 * data , \nu8 buf [ shash_align_buffer_size ( unaligned_len , alignmask )] \n__attribute__ (( aligned )); \n \n+ if ( unaligned_len > len ) \n+ unaligned_len = len ; \n+ \nmemcpy ( buf , data , unaligned_len ); \n \nreturn shash -> update ( desc , buf , unaligned_len ) ?:", "mmm drivers / gpu / drm / exynos / exynos_drm_dmabuf . c \nppp drivers / gpu / drm / exynos / exynos_drm_dmabuf . c \nstruct dma_buf * exynos_dmabuf_prime_export ( struct drm_device * drm_dev , \nstruct exynos_drm_gem_obj * exynos_gem_obj = to_exynos_gem_obj ( obj ); \n \nreturn dma_buf_export ( exynos_gem_obj , & exynos_dmabuf_ops , \n- exynos_gem_obj -> base . size , 0600 ); \n+ exynos_gem_obj -> base . size , flags ); \n} \n \nstruct drm_gem_object * exynos_dmabuf_prime_import ( struct drm_device * drm_dev ,", "mmm fs / namespace . c \nppp fs / namespace . c \nvoid __detach_mounts ( struct dentry * dentry ) \n \nnamespace_lock (); \nmp = lookup_mountpoint ( dentry ); \n- if (! mp ) \n+ if ( IS_ERR_OR_NULL ( mp )) \ngoto out_unlock ; \n \nlock_mount_hash ();", "mmm fs / isofs / rock . c \nppp fs / isofs / rock . c \nstruct rock_state { \nint cont_size ; \nint cont_extent ; \nint cont_offset ; \n+ int cont_loops ; \nstruct inode * inode ; \n}; \n \nstatic void init_rock_state ( struct rock_state * rs , struct inode * inode ) \nrs -> inode = inode ; \n} \n \n+/* Maximum number of Rock Ridge continuation entries */ \n+# define RR_MAX_CE_ENTRIES 32 \n+ \n/* \n* Returns 0 if the caller should continue scanning , 1 if the scan must end \n* and - ve on error . \nstatic int rock_continue ( struct rock_state * rs ) \ngoto out ; \n} \nret = - EIO ; \n+ if (++ rs -> cont_loops >= RR_MAX_CE_ENTRIES ) \n+ goto out ; \nbh = sb_bread ( rs -> inode -> i_sb , rs -> cont_extent ); \nif ( bh ) { \nmemcpy ( rs -> buffer , bh -> b_data + rs -> cont_offset ,", "mmm net / wireless / radiotap . c \nppp net / wireless / radiotap . c \nint ieee80211_radiotap_iterator_init ( \nstruct ieee80211_radiotap_header * radiotap_header , \nint max_length , const struct ieee80211_radiotap_vendor_namespaces * vns ) \n{ \n+ /* check the radiotap header can actually be present */ \n+ if ( max_length < sizeof ( struct ieee80211_radiotap_header )) \n+ return - EINVAL ; \n+ \n/* Linux only supports version 0 radiotap format */ \nif ( radiotap_header -> it_version ) \nreturn - EINVAL ; \nint ieee80211_radiotap_iterator_init ( \n*/ \n \nif (( unsigned long ) iterator -> _arg - \n- ( unsigned long ) iterator -> _rtheader > \n+ ( unsigned long ) iterator -> _rtheader + \n+ sizeof ( uint32_t ) > \n( unsigned long ) iterator -> _max_length ) \nreturn - EINVAL ; \n}", "mmm tools / perf / util / symbol . c \nppp tools / perf / util / symbol . c \nstatic const char * const vmlinux_paths_upd [] = { \n\"/ boot / vmlinux -% s \", \n\"/ usr / lib / debug / boot / vmlinux -% s \", \n\"/ lib / modules /% s / build / vmlinux \", \n- \"/ usr / lib / debug / lib / modules /% s / vmlinux \" \n+ \"/ usr / lib / debug / lib / modules /% s / vmlinux \", \n+ \"/ usr / lib / debug / boot / vmlinux -% s . debug \" \n}; \n \nstatic int vmlinux_path__add ( const char * new_entry )", "mmm drivers / gpu / drm / vmwgfx / vmwgfx_kms . c \nppp drivers / gpu / drm / vmwgfx / vmwgfx_kms . c \nint vmw_du_page_flip ( struct drm_crtc * crtc , \nstruct vmw_private * dev_priv = vmw_priv ( crtc -> dev ); \nstruct drm_framebuffer * old_fb = crtc -> fb ; \nstruct vmw_framebuffer * vfb = vmw_framebuffer_to_vfb ( fb ); \n- struct drm_file * file_priv = event -> base . file_priv ; \n+ struct drm_file * file_priv ; \nstruct vmw_fence_obj * fence = NULL ; \nstruct drm_clip_rect clips ; \nint ret ; \n \n+ if ( event == NULL ) \n+ return - EINVAL ; \n+ \n/* require ScreenObject support for page flipping */ \nif (! dev_priv -> sou_priv ) \nreturn - ENOSYS ; \n \n+ file_priv = event -> base . file_priv ; \nif (! vmw_kms_screen_object_flippable ( dev_priv , crtc )) \nreturn - EINVAL ; \n", "mmm drivers / usb / net / zd1201 . c \nppp drivers / usb / net / zd1201 . c \nstatic int zd1201_resume ( struct usb_interface * interface ) \n{ \nstruct zd1201 * zd = usb_get_intfdata ( interface ); \n \n+ if (! zd || ! zd -> dev ) \n+ return - ENODEV ; \n+ \nnetif_device_attach ( zd -> dev ); \n \nif ( zd -> was_enabled )", "mmm fs / btrfs / backref . c \nppp fs / btrfs / backref . c \nstatic int find_parent_nodes ( struct btrfs_trans_handle * trans , \n} \nret = find_extent_in_eb ( eb , bytenr , \n* extent_item_pos , & eie ); \n- ref -> inode_list = eie ; \nfree_extent_buffer ( eb ); \n+ if ( ret < 0 ) \n+ goto out ; \n+ ref -> inode_list = eie ; \n} \nret = ulist_add_merge ( refs , ref -> parent , \n( uintptr_t ) ref -> inode_list ,", "mmm drivers / iio / industrialio - buffer . c \nppp drivers / iio / industrialio - buffer . c \nint iio_buffer_register ( struct iio_dev * indio_dev , \nif ( channels ) { \n/* new magic */ \nfor ( i = 0 ; i < num_channels ; i ++) { \n+ if ( channels [ i ]. scan_index < 0 ) \n+ continue ; \n+ \n/* Establish necessary mask length */ \nif ( channels [ i ]. scan_index > \n( int ) indio_dev -> masklength - 1 )", "mmm drivers / scsi / megaraid / mega_common . h \nppp drivers / scsi / megaraid / mega_common . h \ntypedef struct { \nuint8_t max_lun ; \n \nuint32_t unique_id ; \n- uint8_t irq ; \n+ int irq ; \nuint8_t ito ; \ncaddr_t ibuf ; \ndma_addr_t ibuf_dma_h ;", "mmm fs / btrfs / send . c \nppp fs / btrfs / send . c \nlong btrfs_ioctl_send ( struct file * mnt_file , void __user * arg_ ) \ngoto out ; \n} \n \n+ if ( arg -> clone_sources_count > \n+ ULLONG_MAX / sizeof (* arg -> clone_sources )) { \n+ ret = - EINVAL ; \n+ goto out ; \n+ } \n+ \nif (! access_ok ( VERIFY_READ , arg -> clone_sources , \nsizeof (* arg -> clone_sources ) * \narg -> clone_sources_count )) {", "mmm drivers / infiniband / core / uverbs_ioctl . c \nppp drivers / infiniband / core / uverbs_ioctl . c \nstatic int uverbs_validate_kernel_mandatory ( const struct uverbs_method_spec * met \nreturn - EINVAL ; \n} \n \n+ for (; i < method_spec -> num_buckets ; i ++) { \n+ struct uverbs_attr_spec_hash * attr_spec_bucket = \n+ method_spec -> attr_buckets [ i ]; \n+ \n+ if (! bitmap_empty ( attr_spec_bucket -> mandatory_attrs_bitmask , \n+ attr_spec_bucket -> num_attrs )) \n+ return - EINVAL ; \n+ } \n+ \nreturn 0 ; \n} \n", "mmm fs / btrfs / free - space - cache . c \nppp fs / btrfs / free - space - cache . c \nvoid btrfs_dump_free_space ( struct btrfs_block_group_cache * block_group , \n \nfor ( n = rb_first (& ctl -> free_space_offset ); n ; n = rb_next ( n )) { \ninfo = rb_entry ( n , struct btrfs_free_space , offset_index ); \n- if ( info -> bytes >= bytes ) \n+ if ( info -> bytes >= bytes && ! block_group -> ro ) \ncount ++; \nprintk ( KERN_CRIT \" entry offset % llu , bytes % llu , bitmap % s \\ n \", \n( unsigned long long ) info -> offset ,", "mmm drivers / block / drbd / drbd_main . c \nppp drivers / block / drbd / drbd_main . c \nstatic void after_state_ch ( struct drbd_conf * mdev , union drbd_state os , \ndrbd_free_bc ( mdev -> ldev ); \nmdev -> ldev = NULL ;); \n \n- if ( mdev -> md_io_tmpp ) \n+ if ( mdev -> md_io_tmpp ) { \n__free_page ( mdev -> md_io_tmpp ); \n+ mdev -> md_io_tmpp = NULL ; \n+ } \n} \n \n/* Disks got bigger while they were detached */", "mmm fs / xfs / xfs_attr_inactive . c \nppp fs / xfs / xfs_attr_inactive . c \nxfs_attr_inactive ( \n*/ \nxfs_trans_ijoin ( trans , dp , 0 ); \n \n- /* invalidate and truncate the attribute fork extents */ \n- if ( dp -> i_d . di_aformat != XFS_DINODE_FMT_LOCAL ) { \n+ /* \n+ * Invalidate and truncate the attribute fork extents . Make sure the \n+ * fork actually has attributes as otherwise the invalidation has no \n+ * blocks to read and returns an error . In this case , just do the fork \n+ * removal below . \n+ */ \n+ if ( xfs_inode_hasattr ( dp ) && \n+ dp -> i_d . di_aformat != XFS_DINODE_FMT_LOCAL ) { \nerror = xfs_attr3_root_inactive (& trans , dp ); \nif ( error ) \ngoto out_cancel ;", "mmm net / batman - adv / bat_debugfs . c \nppp net / batman - adv / bat_debugfs . c \nint debug_log ( struct bat_priv * bat_priv , char * fmt , ...) \n \nva_start ( args , fmt ); \nvscnprintf ( tmp_log_buf , sizeof ( tmp_log_buf ), fmt , args ); \n- fdebug_log ( bat_priv -> debug_log , \"[% 10u ] % s \", \n+ fdebug_log ( bat_priv -> debug_log , \"[% 10lu ] % s \", \n( jiffies / HZ ), tmp_log_buf ); \nva_end ( args ); \n", "mmm mm / pagewalk . c \nppp mm / pagewalk . c \nint walk_page_range ( unsigned long start , unsigned long end , \nvma = vma -> vm_next ; \n \nerr = walk_page_test ( start , next , walk ); \n- if ( err > 0 ) \n+ if ( err > 0 ) { \n+ /* \n+ * positive return values are purely for \n+ * controlling the pagewalk , so should never \n+ * be passed to the callers . \n+ */ \n+ err = 0 ; \ncontinue ; \n+ } \nif ( err < 0 ) \nbreak ; \n}", "mmm drivers / isdn / i4l / isdn_ppp . c \nppp drivers / isdn / i4l / isdn_ppp . c \nstatic struct sk_buff * isdn_ppp_decompress ( struct sk_buff * skb , struct ippp_struc \nrsparm . maxdlen = IPPP_RESET_MAXDATABYTES ; \n \nskb_out = dev_alloc_skb ( is -> mru + PPP_HDRLEN ); \n+ if (! skb_out ) { \n+ kfree_skb ( skb ); \n+ printk ( KERN_ERR \" ippp : decomp memory allocation failure \\ n \"); \n+ return NULL ; \n+ } \nlen = ipc -> decompress ( stat , skb , skb_out , & rsparm ); \nkfree_skb ( skb ); \nif ( len <= 0 ) {", "mmm Documentation / lguest / lguest . c \nppp Documentation / lguest / lguest . c \nstruct virtqueue \n/* Remember the arguments to the program so we can \" reboot \" */ \nstatic char ** main_args ; \n \n-/* Since guest is UP and we don ' t run at the same time , we don ' t need barriers . \n- * But I include them in the code in case others copy it . */ \n-# define wmb () \n+/* We have to be careful with barriers : our devices are all run in separate \n+ * threads and so we need to make sure that changes visible to the Guest happen \n+ * in precise order . */ \n+# define wmb () __asm__ __volatile__ (\"\" : : : \" memory \") \n \n/* Convert an iovec element to the given type . \n*", "mmm net / sched / act_police . c \nppp net / sched / act_police . c \nstatic int tcf_act_police ( struct sk_buff * skb , const struct tc_action * a , \npolice -> tcfp_t_c = now ; \npolice -> tcfp_toks = toks ; \npolice -> tcfp_ptoks = ptoks ; \n+ if ( police -> tcfp_result == TC_ACT_SHOT ) \n+ police -> tcf_qstats . drops ++; \nspin_unlock (& police -> tcf_lock ); \nreturn police -> tcfp_result ; \n}", "mmm drivers / iommu / intel - iommu . c \nppp drivers / iommu / intel - iommu . c \nstatic int domain_context_mapping_one ( struct dmar_domain * domain , \nif ( context_copied ( context )) { \nu16 did_old = context_domain_id ( context ); \n \n- if ( did_old >= 0 && did_old < cap_ndoms ( iommu -> cap )) \n+ if ( did_old >= 0 && did_old < cap_ndoms ( iommu -> cap )) { \niommu -> flush . flush_context ( iommu , did_old , \n((( u16 ) bus ) << 8 ) | devfn , \nDMA_CCMD_MASK_NOBIT , \nDMA_CCMD_DEVICE_INVL ); \n+ iommu -> flush . flush_iotlb ( iommu , did_old , 0 , 0 , \n+ DMA_TLB_DSI_FLUSH ); \n+ } \n} \n \npgd = domain -> pgd ;", "mmm net / dccp / options . c \nppp net / dccp / options . c \nint dccp_parse_options ( struct sock * sk , struct sk_buff * skb ) \nopt_recv -> dccpor_timestamp_echo = ntohl (*( __be32 *) value ); \n \ndccp_pr_debug (\"% s rx opt : TIMESTAMP_ECHO =% u , len =% d , \" \n- \" ackno =% llu , \", dccp_role ( sk ), \n+ \" ackno =% llu \", dccp_role ( sk ), \nopt_recv -> dccpor_timestamp_echo , \nlen + 2 , \n( unsigned long long ) \nDCCP_SKB_CB ( skb )-> dccpd_ack_seq ); \n \n \n- if ( len == 4 ) \n+ if ( len == 4 ) { \n+ dccp_pr_debug_cat (\"\\ n \"); \nbreak ; \n+ } \n \nif ( len == 6 ) \nelapsed_time = ntohs (*( __be16 *)( value + 4 )); \nelse \nelapsed_time = ntohl (*( __be32 *)( value + 4 )); \n \n+ dccp_pr_debug_cat (\", ELAPSED_TIME =% d \\ n \", elapsed_time ); \n+ \n/* Give precedence to the biggest ELAPSED_TIME */ \nif ( elapsed_time > opt_recv -> dccpor_elapsed_time ) \nopt_recv -> dccpor_elapsed_time = elapsed_time ;", "mmm drivers / uwb / drp . c \nppp drivers / uwb / drp . c \nstatic void uwb_drp_handle_alien_drp ( struct uwb_rc * rc , struct uwb_ie_drp * drp_i \n \n/* alloc and initialize new uwb_cnflt_alien */ \ncnflt = kzalloc ( sizeof ( struct uwb_cnflt_alien ), GFP_KERNEL ); \n- if (! cnflt ) \n+ if (! cnflt ) { \ndev_err ( dev , \" failed to alloc uwb_cnflt_alien struct \\ n \"); \n+ return ; \n+ } \n+ \nINIT_LIST_HEAD (& cnflt -> rc_node ); \ninit_timer (& cnflt -> timer ); \ncnflt -> timer . function = uwb_cnflt_timer ;", "mmm drivers / pnp / pnpacpi / rsparser . c \nppp drivers / pnp / pnpacpi / rsparser . c \nstatic void pnpacpi_encode_ext_irq ( struct acpi_resource * resource , \nresource -> data . extended_irq . triggering = triggering ; \nresource -> data . extended_irq . polarity = polarity ; \nif ( triggering == ACPI_EDGE_SENSITIVE ) \n- resource -> data . irq . sharable = ACPI_EXCLUSIVE ; \n+ resource -> data . extended_irq . sharable = ACPI_EXCLUSIVE ; \nelse \n- resource -> data . irq . sharable = ACPI_SHARED ; \n+ resource -> data . extended_irq . sharable = ACPI_SHARED ; \nresource -> data . extended_irq . interrupt_count = 1 ; \nresource -> data . extended_irq . interrupts [ 0 ] = p -> start ; \n}", "mmm drivers / net / ethernet / calxeda / xgmac . c \nppp drivers / net / ethernet / calxeda / xgmac . c \nstatic int xgmac_hw_init ( struct net_device * dev ) \nDMA_BUS_MODE_FB | DMA_BUS_MODE_ATDS | DMA_BUS_MODE_AAL ; \nwritel ( value , ioaddr + XGMAC_DMA_BUS_MODE ); \n \n- /* Enable interrupts */ \n- writel ( DMA_INTR_DEFAULT_MASK , ioaddr + XGMAC_DMA_STATUS ); \n- writel ( DMA_INTR_DEFAULT_MASK , ioaddr + XGMAC_DMA_INTR_ENA ); \n+ writel ( 0 , ioaddr + XGMAC_DMA_INTR_ENA ); \n \n/* Mask power mgt interrupt */ \nwritel ( XGMAC_INT_STAT_PMTIM , ioaddr + XGMAC_INT_STAT ); \nstatic int xgmac_open ( struct net_device * dev ) \nnapi_enable (& priv -> napi ); \nnetif_start_queue ( dev ); \n \n+ /* Enable interrupts */ \n+ writel ( DMA_INTR_DEFAULT_MASK , ioaddr + XGMAC_DMA_STATUS ); \n+ writel ( DMA_INTR_DEFAULT_MASK , ioaddr + XGMAC_DMA_INTR_ENA ); \n+ \nreturn 0 ; \n} \n", "mmm sound / soc / intel / skylake / skl - sst . c \nppp sound / soc / intel / skylake / skl - sst . c \nstatic int skl_unload_module ( struct sst_dsp * ctx , u16 mod_id ) \ndev_err ( ctx -> dev , \" Module bad usage cnt !:% d \\ n \", usage_cnt ); \nreturn - EIO ; \n} \n+ \n+ /* if module is used by others return , no need to unload */ \n+ if ( usage_cnt > 0 ) \n+ return 0 ; \n+ \nret = skl_ipc_unload_modules (& skl -> ipc , \nSKL_NUM_MODULES , & mod_id ); \nif ( ret < 0 ) {", "mmm drivers / mtd / ubi / vtbl . c \nppp drivers / mtd / ubi / vtbl . c \nstatic int init_volumes ( struct ubi_device * ubi , const struct ubi_scan_info * si , \nif ( ubi -> autoresize_vol_id != - 1 ) { \nubi_err (\" more then one auto - resize volume (% d \" \n\" and % d )\", ubi -> autoresize_vol_id , i ); \n+ kfree ( vol ); \nreturn - EINVAL ; \n} \n", "mmm fs / btrfs / ioctl . c \nppp fs / btrfs / ioctl . c \nstatic noinline long btrfs_ioctl_clone ( struct file * file , unsigned long srcfd , \nbtrfs_wait_ordered_range ( src , off , len ); \n} \n \n+ /* truncate page cache pages from target inode range */ \n+ truncate_inode_pages_range (& inode -> i_data , off , \n+ ALIGN ( off + len , PAGE_CACHE_SIZE ) - 1 ); \n+ \n/* clone data */ \nkey . objectid = btrfs_ino ( src ); \nkey . type = BTRFS_EXTENT_DATA_KEY ;", "mmm drivers / net / wireless / wl12xx / wl1271_spi . c \nppp drivers / net / wireless / wl12xx / wl1271_spi . c \nstatic void wl1271_spi_reset ( struct wl1271 * wl ) \nspi_message_add_tail (& t , & m ); \n \nspi_sync ( wl_to_spi ( wl ), & m ); \n+ kfree ( cmd ); \n \nwl1271_dump ( DEBUG_SPI , \" spi reset -> \", cmd , WSPI_INIT_CMD_LEN ); \n} \nstatic void wl1271_spi_init ( struct wl1271 * wl ) \nspi_message_add_tail (& t , & m ); \n \nspi_sync ( wl_to_spi ( wl ), & m ); \n+ kfree ( cmd ); \n \nwl1271_dump ( DEBUG_SPI , \" spi init -> \", cmd , WSPI_INIT_CMD_LEN ); \n}", "mmm arch / powerpc / sysdev / qe_lib / ucc . c \nppp arch / powerpc / sysdev / qe_lib / ucc . c \nint ucc_set_qe_mux_rxtx ( int ucc_num , enum qe_clock clock , enum comm_dir mode ) \ncase QE_CLK18 : source = 8 ; break ; \ncase QE_CLK7 : source = 9 ; break ; \ncase QE_CLK8 : source = 10 ; break ; \n+ case QE_CLK16 : source = 11 ; break ; \ndefault : source = - 1 ; break ; \n} \nbreak ; \nint ucc_set_qe_mux_rxtx ( int ucc_num , enum qe_clock clock , enum comm_dir mode ) \ncase QE_CLK22 : source = 8 ; break ; \ncase QE_CLK7 : source = 9 ; break ; \ncase QE_CLK8 : source = 10 ; break ; \n+ case QE_CLK16 : source = 11 ; break ; \ndefault : source = - 1 ; break ; \n} \nbreak ;", "mmm drivers / scsi / aacraid / linit . c \nppp drivers / scsi / aacraid / linit . c \nstatic long aac_compat_do_ioctl ( struct aac_dev * dev , unsigned cmd , unsigned long \nstatic int aac_compat_ioctl ( struct scsi_device * sdev , int cmd , void __user * arg ) \n{ \nstruct aac_dev * dev = ( struct aac_dev *) sdev -> host -> hostdata ; \n+ if (! capable ( CAP_SYS_RAWIO )) \n+ return - EPERM ; \nreturn aac_compat_do_ioctl ( dev , cmd , ( unsigned long ) arg ); \n} \n", "mmm drivers / net / wireless / intel / iwlwifi / pcie / tx - gen2 . c \nppp drivers / net / wireless / intel / iwlwifi / pcie / tx - gen2 . c \nint iwl_trans_pcie_dyn_txq_alloc ( struct iwl_trans * trans , \nrsp = ( void *) hcmd . resp_pkt -> data ; \nqid = le16_to_cpu ( rsp -> queue_number ); \n \n- if ( qid > ARRAY_SIZE ( trans_pcie -> txq )) { \n+ if ( qid >= ARRAY_SIZE ( trans_pcie -> txq )) { \nWARN_ONCE ( 1 , \" queue index % d unsupported \", qid ); \nret = - EIO ; \ngoto error_free_resp ;", "mmm drivers / md / bcache / super . c \nppp drivers / md / bcache / super . c \nstatic void cache_set_flush ( struct closure * cl ) \nstruct btree * b ; \nunsigned i ; \n \n+ if (! c ) \n+ closure_return ( cl ); \n+ \nbch_cache_accounting_destroy (& c -> accounting ); \n \nkobject_put (& c -> internal );", "mmm drivers / gpu / drm / drm_crtc . c \nppp drivers / gpu / drm / drm_crtc . c \nvoid drm_mode_config_reset ( struct drm_device * dev ) \nif ( encoder -> funcs -> reset ) \nencoder -> funcs -> reset ( encoder ); \n \n+ mutex_lock (& dev -> mode_config . mutex ); \ndrm_for_each_connector ( connector , dev ) { \nconnector -> status = connector_status_unknown ; \n \nif ( connector -> funcs -> reset ) \nconnector -> funcs -> reset ( connector ); \n} \n+ mutex_unlock (& dev -> mode_config . mutex ); \n} \nEXPORT_SYMBOL ( drm_mode_config_reset ); \n", "mmm drivers / net / wireless / iwlwifi / dvm / power . c \nppp drivers / net / wireless / iwlwifi / dvm / power . c \n# include \" commands . h \" \n# include \" power . h \" \n \n- static bool force_cam ; \n+ static bool force_cam = true ; \nmodule_param ( force_cam , bool , 0644 ); \nMODULE_PARM_DESC ( force_cam , \" force continuously aware mode ( no power saving at all )\"); \n", "mmm net / bridge / br_netfilter . c \nppp net / bridge / br_netfilter . c \nstatic int br_parse_ip_options ( struct sk_buff * skb ) \ngoto drop ; \n} \n \n- /* Zero out the CB buffer if no options present */ \n- if ( iph -> ihl == 5 ) { \n- memset ( IPCB ( skb ), 0 , sizeof ( struct inet_skb_parm )); \n+ memset ( IPCB ( skb ), 0 , sizeof ( struct inet_skb_parm )); \n+ if ( iph -> ihl == 5 ) \nreturn 0 ; \n- } \n \nopt -> optlen = iph -> ihl * 4 - sizeof ( struct iphdr ); \nif ( ip_options_compile ( dev_net ( dev ), opt , skb ))", "mmm drivers / spi / spi - imx . c \nppp drivers / spi / spi - imx . c \nstatic int spi_imx_dma_transfer ( struct spi_imx_data * spi_imx , \ntx -> sgl , tx -> nents , DMA_MEM_TO_DEV , \nDMA_PREP_INTERRUPT | DMA_CTRL_ACK ); \nif (! desc_tx ) \n- goto no_dma ; \n+ goto tx_nodma ; \n \ndesc_tx -> callback = spi_imx_dma_tx_callback ; \ndesc_tx -> callback_param = ( void *) spi_imx ; \nstatic int spi_imx_dma_transfer ( struct spi_imx_data * spi_imx , \nrx -> sgl , rx -> nents , DMA_DEV_TO_MEM , \nDMA_PREP_INTERRUPT | DMA_CTRL_ACK ); \nif (! desc_rx ) \n- goto no_dma ; \n+ goto rx_nodma ; \n \ndesc_rx -> callback = spi_imx_dma_rx_callback ; \ndesc_rx -> callback_param = ( void *) spi_imx ; \nstatic int spi_imx_dma_transfer ( struct spi_imx_data * spi_imx , \n \nreturn ret ; \n \n- no_dma : \n+ rx_nodma : \n+ dmaengine_terminate_all ( master -> dma_tx ); \n+ tx_nodma : \npr_warn_once (\"% s % s : DMA not available , falling back to PIO \\ n \", \ndev_driver_string (& master -> dev ), \ndev_name (& master -> dev ));", "mmm drivers / scsi / libfc / fc_exch . c \nppp drivers / scsi / libfc / fc_exch . c \nstatic struct fc_exch * fc_exch_em_alloc ( struct fc_lport * lport , \n* EM is selected when a NULL match function pointer is encountered \n* or when a call to a match function returns true . \n*/ \n- static inline struct fc_exch * fc_exch_alloc ( struct fc_lport * lport , \n- struct fc_frame * fp ) \n+ static struct fc_exch * fc_exch_alloc ( struct fc_lport * lport , \n+ struct fc_frame * fp ) \n{ \nstruct fc_exch_mgr_anchor * ema ; \n+ struct fc_exch * ep ; \n \n- list_for_each_entry ( ema , & lport -> ema_list , ema_list ) \n- if (! ema -> match || ema -> match ( fp )) \n- return fc_exch_em_alloc ( lport , ema -> mp ); \n+ list_for_each_entry ( ema , & lport -> ema_list , ema_list ) { \n+ if (! ema -> match || ema -> match ( fp )) { \n+ ep = fc_exch_em_alloc ( lport , ema -> mp ); \n+ if ( ep ) \n+ return ep ; \n+ } \n+ } \nreturn NULL ; \n} \n", "mmm net / netfilter / ipvs / ip_vs_core . c \nppp net / netfilter / ipvs / ip_vs_core . c \nstatic inline bool is_new_conn_expected ( const struct ip_vs_conn * cp , \nswitch ( cp -> protocol ) { \ncase IPPROTO_TCP : \nreturn ( cp -> state == IP_VS_TCP_S_TIME_WAIT ) || \n+ ( cp -> state == IP_VS_TCP_S_CLOSE ) || \n(( conn_reuse_mode & 2 ) && \n( cp -> state == IP_VS_TCP_S_FIN_WAIT ) && \n( cp -> flags & IP_VS_CONN_F_NOOUTPUT ));", "mmm drivers / infiniband / hw / ocrdma / ocrdma_verbs . c \nppp drivers / infiniband / hw / ocrdma / ocrdma_verbs . c \nint ocrdma_arm_cq ( struct ib_cq * ibcq , enum ib_cq_notify_flags cq_flags ) \nif ( cq -> first_arm ) { \nocrdma_ring_cq_db ( dev , cq_id , arm_needed , sol_needed , 0 ); \ncq -> first_arm = false ; \n- goto skip_defer ; \n} \n- cq -> deferred_arm = true ; \n \n- skip_defer : \n+ cq -> deferred_arm = true ; \ncq -> deferred_sol = sol_needed ; \nspin_unlock_irqrestore (& cq -> cq_lock , flags ); \n", "mmm arch / x86 / xen / grant - table . c \nppp arch / x86 / xen / grant - table . c \nstatic int __init xlated_setup_gnttab_pages ( void ) \nrc = arch_gnttab_map_shared ( pfns , nr_grant_frames , nr_grant_frames , \n& xen_auto_xlat_grant_frames . vaddr ); \n \n- kfree ( pages ); \nif ( rc ) { \npr_warn (\"% s Couldn ' t map % ld pfns rc :% d \\ n \", __func__ , \nnr_grant_frames , rc ); \nfree_xenballooned_pages ( nr_grant_frames , pages ); \n+ kfree ( pages ); \nkfree ( pfns ); \nreturn rc ; \n} \n+ kfree ( pages ); \n \nxen_auto_xlat_grant_frames . pfn = pfns ; \nxen_auto_xlat_grant_frames . count = nr_grant_frames ;", "mmm net / netlink / af_netlink . c \nppp net / netlink / af_netlink . c \nnetlink_kernel_create ( struct net * net , int unit , unsigned int groups , \nnl_table [ unit ]. cb_mutex = cb_mutex ; \nnl_table [ unit ]. module = module ; \nnl_table [ unit ]. registered = 1 ; \n+ } else { \n+ kfree ( listeners ); \n} \nnetlink_table_ungrab (); \n", "mmm net / bluetooth / rfcomm / tty . c \nppp net / bluetooth / rfcomm / tty . c \nstatic int rfcomm_get_dev_list ( void __user * arg ) \n \nsize = sizeof (* dl ) + dev_num * sizeof (* di ); \n \n- dl = kmalloc ( size , GFP_KERNEL ); \n+ dl = kzalloc ( size , GFP_KERNEL ); \nif (! dl ) \nreturn - ENOMEM ; \n", "mmm drivers / ide / ide - atapi . c \nppp drivers / ide / ide - atapi . c \nide_startstop_t ide_issue_pc ( ide_drive_t * drive , unsigned int timeout , \n{ \nstruct ide_atapi_pc * pc = drive -> pc ; \nide_hwif_t * hwif = drive -> hwif ; \n+ u32 tf_flags ; \nu16 bcount ; \nu8 scsi = !!( drive -> dev_flags & IDE_DFLAG_SCSI ); \n \nide_startstop_t ide_issue_pc ( ide_drive_t * drive , unsigned int timeout , \nif (! drive -> dma ) \npc -> flags &= ~ PC_FLAG_DMA_OK ; \n \n- ide_pktcmd_tf_load ( drive , scsi ? 0 : IDE_TFLAG_OUT_DEVICE , bcount , \n- drive -> dma ); \n+ if ( scsi ) \n+ tf_flags = 0 ; \n+ else if ( drive -> media == ide_cdrom || drive -> media == ide_optical ) \n+ tf_flags = IDE_TFLAG_OUT_NSECT | IDE_TFLAG_OUT_LBAL ; \n+ else \n+ tf_flags = IDE_TFLAG_OUT_DEVICE ; \n+ \n+ ide_pktcmd_tf_load ( drive , tf_flags , bcount , drive -> dma ); \n \n/* Issue the packet command */ \nif ( drive -> atapi_flags & IDE_AFLAG_DRQ_INTERRUPT ) {", "mmm drivers / gpu / drm / ttm / ttm_tt . c \nppp drivers / gpu / drm / ttm / ttm_tt . c \nstruct ttm_tt * ttm_tt_create ( struct ttm_bo_device * bdev , unsigned long size , \nttm -> dummy_read_page = dummy_read_page ; \n \nttm_tt_alloc_page_directory ( ttm ); \n- if (! ttm -> pages ) { \n+ if (! ttm -> pages || ! ttm -> dma_address ) { \nttm_tt_destroy ( ttm ); \nprintk ( KERN_ERR TTM_PFX \" Failed allocating page table \\ n \"); \nreturn NULL ;", "mmm include / linux / mm . h \nppp include / linux / mm . h \nstatic inline bool is_pci_p2pdma_page ( const struct page * page ) \n} \n# endif /* CONFIG_DEV_PAGEMAP_OPS */ \n \n+/* 127 : arbitrary random number , small enough to assemble well */ \n+# define page_ref_zero_or_close_to_overflow ( page ) \\ \n+ (( unsigned int ) page_ref_count ( page ) + 127u <= 127u ) \n+ \nstatic inline void get_page ( struct page * page ) \n{ \npage = compound_head ( page ); \nstatic inline void get_page ( struct page * page ) \n* Getting a normal page or the head of a compound page \n* requires to already have an elevated page -> _refcount . \n*/ \n- VM_BUG_ON_PAGE ( page_ref_count ( page ) <= 0 , page ); \n+ VM_BUG_ON_PAGE ( page_ref_zero_or_close_to_overflow ( page ), page ); \npage_ref_inc ( page ); \n} \n", "mmm scripts / kconfig / nconf . c \nppp scripts / kconfig / nconf . c \nstatic void conf_message_callback ( const char * fmt , va_list ap ) \n \nstatic void show_help ( struct menu * menu ) \n{ \n- struct gstr help = str_new (); \n+ struct gstr help ; \n+ \n+ if (! menu ) \n+ return ; \n+ \n+ help = str_new (); \nmenu_get_ext_help ( menu , & help ); \nshow_scroll_win ( main_window , _ ( menu_get_prompt ( menu )), str_get (& help )); \nstr_free (& help );", "mmm drivers / net / ixgb / ixgb_main . c \nppp drivers / net / ixgb / ixgb_main . c \nixgb_restore_vlan ( struct ixgb_adapter * adapter ) \n \nstatic void ixgb_netpoll ( struct net_device * dev ) \n{ \n- struct ixgb_adapter * adapter = dev -> priv ; \n+ struct ixgb_adapter * adapter = netdev_priv ( dev ); \n \ndisable_irq ( adapter -> pdev -> irq ); \nixgb_intr ( adapter -> pdev -> irq , dev , NULL );", "mmm net / netfilter / ipset / ip_set_core . c \nppp net / netfilter / ipset / ip_set_core . c \nip_set_net_exit ( struct net * net ) \n \ninst -> is_deleted = true ; /* flag for ip_set_nfnl_put */ \n \n+ nfnl_lock ( NFNL_SUBSYS_IPSET ); \nfor ( i = 0 ; i < inst -> ip_set_max ; i ++) { \nset = ip_set ( inst , i ); \nif ( set ) { \nip_set_net_exit ( struct net * net ) \nip_set_destroy_set ( set ); \n} \n} \n+ nfnl_unlock ( NFNL_SUBSYS_IPSET ); \nkfree ( rcu_dereference_protected ( inst -> ip_set_list , 1 )); \n} \n", "mmm arch / mips / kernel / csrc - sb1250 . c \nppp arch / mips / kernel / csrc - sb1250 . c \nstatic cycle_t sb1250_hpt_read ( void ) \n} \n \nstruct clocksource bcm1250_clocksource = { \n- . name = \" MIPS \", \n+ . name = \" bcm1250 - counter - 3 \", \n. rating = 200 , \n. read = sb1250_hpt_read , \n. mask = CLOCKSOURCE_MASK ( 23 ),", "mmm net / packet / af_packet . c \nppp net / packet / af_packet . c \nstatic void * packet_lookup_frame ( struct packet_sock * po , unsigned int position , \nh . raw = po -> pg_vec [ pg_vec_pos ] + ( frame_offset * po -> frame_size ); \nswitch ( po -> tp_version ) { \ncase TPACKET_V1 : \n- if ( status != h . h1 -> tp_status ? TP_STATUS_USER : \n- TP_STATUS_KERNEL ) \n+ if ( status != ( h . h1 -> tp_status ? TP_STATUS_USER : \n+ TP_STATUS_KERNEL )) \nreturn NULL ; \nbreak ; \ncase TPACKET_V2 : \n- if ( status != h . h2 -> tp_status ? TP_STATUS_USER : \n- TP_STATUS_KERNEL ) \n+ if ( status != ( h . h2 -> tp_status ? TP_STATUS_USER : \n+ TP_STATUS_KERNEL )) \nreturn NULL ; \nbreak ; \n}", "mmm drivers / pinctrl / pinctrl - amd . c \nppp drivers / pinctrl / pinctrl - amd . c \nstatic struct irq_chip amd_gpio_irqchip = { \n. irq_set_type = amd_gpio_irq_set_type , \n}; \n \n- static void amd_gpio_irq_handler ( unsigned int irq , struct irq_desc * desc ) \n+ static void amd_gpio_irq_handler ( unsigned int __irq , struct irq_desc * desc ) \n{ \n+ unsigned int irq = irq_desc_get_irq ( desc ); \nu32 i ; \nu32 off ; \nu32 reg ;", "mmm fs / partitions / efi . c \nppp fs / partitions / efi . c \nstatic int is_gpt_valid ( struct parsed_partitions * state , u64 lba , \ngoto fail ; \n} \n \n+ /* Check that sizeof_partition_entry has the correct value */ \n+ if ( le32_to_cpu ((* gpt )-> sizeof_partition_entry ) != sizeof ( gpt_entry )) { \n+ pr_debug (\" GUID Partitition Entry Size check failed .\\ n \"); \n+ goto fail ; \n+ } \n+ \nif (!(* ptes = alloc_read_gpt_entries ( state , * gpt ))) \ngoto fail ; \n", "mmm drivers / usb / dwc3 / dwc3 - qcom . c \nppp drivers / usb / dwc3 / dwc3 - qcom . c \nstatic int dwc3_qcom_acpi_register_core ( struct platform_device * pdev ) \nqcom -> dwc3 -> dev . coherent_dma_mask = dev -> coherent_dma_mask ; \n \nchild_res = kcalloc ( 2 , sizeof (* child_res ), GFP_KERNEL ); \n- if (! child_res ) \n+ if (! child_res ) { \n+ platform_device_put ( qcom -> dwc3 ); \nreturn - ENOMEM ; \n+ } \n \nres = platform_get_resource ( pdev , IORESOURCE_MEM , 0 ); \nif (! res ) { \nstatic int dwc3_qcom_acpi_register_core ( struct platform_device * pdev ) \nif ( ret ) { \ndev_err (& pdev -> dev , \" failed to add device \\ n \"); \ndevice_remove_software_node (& qcom -> dwc3 -> dev ); \n+ goto out ; \n} \n+ kfree ( child_res ); \n+ return 0 ; \n \nout : \n+ platform_device_put ( qcom -> dwc3 ); \nkfree ( child_res ); \nreturn ret ; \n}", "mmm drivers / char / misc . c \nppp drivers / char / misc . c \nstatic int misc_open ( struct inode * inode , struct file * file ) \nold_fops = file -> f_op ; \nfile -> f_op = new_fops ; \nif ( file -> f_op -> open ) { \n+ file -> private_data = c ; \nerr = file -> f_op -> open ( inode , file ); \nif ( err ) { \nfops_put ( file -> f_op );", "mmm drivers / base / regmap / regmap . c \nppp drivers / base / regmap / regmap . c \nint regmap_raw_read ( struct regmap * map , unsigned int reg , void * val , \nreturn - EINVAL ; \nif ( reg % map -> reg_stride ) \nreturn - EINVAL ; \n+ if ( val_count == 0 ) \n+ return - EINVAL ; \n \nmap -> lock ( map -> lock_arg ); \n", "mmm arch / arm / mach - pxa / magician . c \nppp arch / arm / mach - pxa / magician . c \nstatic void samsung_lcd_power ( int on , struct fb_var_screeninfo * si ) \ngpio_set_value ( GPIO75_MAGICIAN_SAMSUNG_POWER , 1 ); \nelse \ngpio_set_value ( EGPIO_MAGICIAN_LCD_POWER , 1 ); \n- mdelay ( 10 ); \n+ mdelay ( 6 ); \ngpio_set_value ( GPIO106_MAGICIAN_LCD_DCDC_NRESET , 1 ); \n- mdelay ( 10 ); \n+ mdelay ( 6 ); /* Avdd -> Voff > 5ms */ \ngpio_set_value ( GPIO104_MAGICIAN_LCD_VOFF_EN , 1 ); \n- mdelay ( 30 ); \n+ mdelay ( 16 ); /* Voff -> Von >( 5 + 10 ) ms */ \ngpio_set_value ( GPIO105_MAGICIAN_LCD_VON_EN , 1 ); \n- mdelay ( 10 ); \n} else { \n- mdelay ( 10 ); \ngpio_set_value ( GPIO105_MAGICIAN_LCD_VON_EN , 0 ); \n- mdelay ( 30 ); \n+ mdelay ( 16 ); \ngpio_set_value ( GPIO104_MAGICIAN_LCD_VOFF_EN , 0 ); \n- mdelay ( 10 ); \n+ mdelay ( 6 ); \ngpio_set_value ( GPIO106_MAGICIAN_LCD_DCDC_NRESET , 0 ); \n- mdelay ( 10 ); \n+ mdelay ( 6 ); \nif ( system_rev < 3 ) \ngpio_set_value ( GPIO75_MAGICIAN_SAMSUNG_POWER , 0 ); \nelse", "mmm sound / soc / codecs / sgtl5000 . c \nppp sound / soc / codecs / sgtl5000 . c \nstatic int sgtl5000_set_clock ( struct snd_soc_codec * codec , int frame_rate ) \n} else { \ndev_err ( codec -> dev , \n\" PLL not supported in slave mode \\ n \"); \n+ dev_err ( codec -> dev , \"% d ratio is not supported . \" \n+ \" SYS_MCLK needs to be 256 , 384 or 512 * fs \\ n \", \n+ sgtl5000 -> sysclk / sys_fs ); \nreturn - EINVAL ; \n} \n}", "mmm sound / soc / soc - cache . c \nppp sound / soc / soc - cache . c \nstatic int snd_soc_8_16_write ( struct snd_soc_codec * codec , unsigned int reg , \ndata [ 1 ] = ( value >> 8 ) & 0xff ; \ndata [ 2 ] = value & 0xff ; \n \n- if (! snd_soc_codec_volatile_register ( codec , reg )) \n- reg_cache [ reg ] = value ; \n+ if (! snd_soc_codec_volatile_register ( codec , reg ) \n+ && reg < codec -> driver -> reg_cache_size ) \n+ reg_cache [ reg ] = value ; \n \nif ( codec -> cache_only ) { \ncodec -> cache_sync = 1 ;", "mmm drivers / char / ipmi / ipmi_devintf . c \nppp drivers / char / ipmi / ipmi_devintf . c \nstatic long compat_ipmi_ioctl ( struct file * filep , unsigned int cmd , \nstruct ipmi_recv __user * precv64 ; \nstruct ipmi_recv recv64 ; \n \n+ memset (& recv64 , 0 , sizeof ( recv64 )); \nif ( get_compat_ipmi_recv (& recv64 , compat_ptr ( arg ))) \nreturn - EFAULT ; \n", "mmm kernel / cgroup . c \nppp kernel / cgroup . c \nint cgroup_add_legacy_cftypes ( struct cgroup_subsys * ss , struct cftype * cfts ) \n{ \nstruct cftype * cft ; \n \n- for ( cft = cfts ; cft && cft -> name [ 0 ] != '\\ 0 '; cft ++) \n- cft -> flags |= __CFTYPE_NOT_ON_DFL ; \n+ /* \n+ * If legacy_flies_on_dfl , we want to show the legacy files on the \n+ * dfl hierarchy but iff the target subsystem hasn ' t been updated \n+ * for the dfl hierarchy yet . \n+ */ \n+ if (! cgroup_legacy_files_on_dfl || \n+ ss -> dfl_cftypes != ss -> legacy_cftypes ) { \n+ for ( cft = cfts ; cft && cft -> name [ 0 ] != '\\ 0 '; cft ++) \n+ cft -> flags |= __CFTYPE_NOT_ON_DFL ; \n+ } \n+ \nreturn cgroup_add_cftypes ( ss , cfts ); \n} \n", "mmm fs / xfs / xfs_acl . c \nppp fs / xfs / xfs_acl . c \nxfs_acl_from_disk ( struct xfs_acl * aclp ) \nint count , i ; \n \ncount = be32_to_cpu ( aclp -> acl_cnt ); \n+ if ( count > XFS_ACL_MAX_ENTRIES ) \n+ return ERR_PTR (- EFSCORRUPTED ); \n \nacl = posix_acl_alloc ( count , GFP_KERNEL ); \nif (! acl )", "mmm drivers / nvme / host / core . c \nppp drivers / nvme / host / core . c \nstatic void nvme_init_integrity ( struct nvme_ns * ns ) \n{ \nstruct blk_integrity integrity ; \n \n+ memset (& integrity , 0 , sizeof ( integrity )); \nswitch ( ns -> pi_type ) { \ncase NVME_NS_DPS_PI_TYPE3 : \nintegrity . profile = & t10_pi_type3_crc ;", "mmm net / netlink / af_netlink . c \nppp net / netlink / af_netlink . c \nstatic struct pernet_operations __net_initdata netlink_net_ops = { \n \nstatic int __init netlink_proto_init ( void ) \n{ \n- struct sk_buff * dummy_skb ; \nint i ; \nunsigned long limit ; \nunsigned int order ; \nstatic int __init netlink_proto_init ( void ) \nif ( err != 0 ) \ngoto out ; \n \n- BUILD_BUG_ON ( sizeof ( struct netlink_skb_parms ) > sizeof ( dummy_skb -> cb )); \n+ BUILD_BUG_ON ( sizeof ( struct netlink_skb_parms ) > FIELD_SIZEOF ( struct sk_buff , cb )); \n \nnl_table = kcalloc ( MAX_LINKS , sizeof (* nl_table ), GFP_KERNEL ); \nif (! nl_table )", "mmm kernel / torture . c \nppp kernel / torture . c \nstatic int torture_shutdown_notify ( struct notifier_block * unused1 , \nunsigned long unused2 , void * unused3 ) \n{ \nmutex_lock (& fullstop_mutex ); \n- if ( fullstop == FULLSTOP_DONTSTOP ) \n+ if ( fullstop == FULLSTOP_DONTSTOP ) { \n+ VERBOSE_TOROUT_STRING (\" Unscheduled system shutdown detected \"); \nfullstop = FULLSTOP_SHUTDOWN ; \n- else \n+ } else { \npr_warn (\" Concurrent rmmod and shutdown illegal !\\ n \"); \n+ } \nmutex_unlock (& fullstop_mutex ); \nreturn NOTIFY_DONE ; \n}", "mmm drivers / net / wireless / brcm80211 / brcmfmac / wl_cfg80211 . c \nppp drivers / net / wireless / brcm80211 / brcmfmac / wl_cfg80211 . c \nstatic int brcmf_enable_bw40_2g ( struct brcmf_cfg80211_info * cfg ) \n \nch . band = BRCMU_CHAN_BAND_2G ; \nch . bw = BRCMU_CHAN_BW_40 ; \n+ ch . sb = BRCMU_CHAN_SB_NONE ; \nch . chnum = 0 ; \ncfg -> d11inf . encchspec (& ch ); \n \nstatic int brcmf_enable_bw40_2g ( struct brcmf_cfg80211_info * cfg ) \n \nbrcmf_update_bw40_channel_flag (& band -> channels [ j ], & ch ); \n} \n+ kfree ( pbuf ); \n} \nreturn err ; \n}", "mmm sound / soc / omap / omap - pcm . c \nppp sound / soc / omap / omap - pcm . c \nstatic int omap_pcm_new ( struct snd_soc_pcm_runtime * rtd ) \n} \n \nout : \n+ /* free preallocated buffers in case of error */ \n+ if ( ret ) \n+ omap_pcm_free_dma_buffers ( pcm ); \n+ \nreturn ret ; \n} \n", "mmm drivers / input / keyboard / tegra - kbc . c \nppp drivers / input / keyboard / tegra - kbc . c \nstatic int tegra_kbc_start ( struct tegra_kbc * kbc ) \n/* Reset the KBC controller to clear all previous status .*/ \nreset_control_assert ( kbc -> rst ); \nudelay ( 100 ); \n- reset_control_assert ( kbc -> rst ); \n+ reset_control_deassert ( kbc -> rst ); \nudelay ( 100 ); \n \ntegra_kbc_config_pins ( kbc );", "mmm drivers / staging / iio / meter / ade7854 . c \nppp drivers / staging / iio / meter / ade7854 . c \nstatic int ade7854_set_irq ( struct device * dev , bool enable ) \nelse \nirqen &= ~ BIT ( 17 ); \n \n- ret = st -> write_reg_32 ( dev , ADE7854_MASK0 , irqen ); \n- \n- return ret ; \n+ return st -> write_reg_32 ( dev , ADE7854_MASK0 , irqen ); \n} \n \nstatic int ade7854_initial_setup ( struct iio_dev * indio_dev )", "mmm kernel / futex . c \nppp kernel / futex . c \nstatic int futex_requeue ( u32 __user * uaddr1 , unsigned int flags , \nstruct futex_q * this , * next ; \nDEFINE_WAKE_Q ( wake_q ); \n \n+ if ( nr_wake < 0 || nr_requeue < 0 ) \n+ return - EINVAL ; \n+ \n/* \n* When PI not supported : return - ENOSYS if requeue_pi is true , \n* consequently the compiler knows requeue_pi is always false past", "mmm fs / nfs / super . c \nppp fs / nfs / super . c \nstatic int nfs_statfs ( struct dentry * dentry , struct kstatfs * buf ) \ngoto out_err ; \n \nerror = server -> nfs_client -> rpc_ops -> statfs ( server , fh , & res ); \n+ if ( unlikely ( error == - ESTALE )) { \n+ struct dentry * pd_dentry ; \n \n+ pd_dentry = dget_parent ( dentry ); \n+ if ( pd_dentry != NULL ) { \n+ nfs_zap_caches ( pd_dentry -> d_inode ); \n+ dput ( pd_dentry ); \n+ } \n+ } \nnfs_free_fattr ( res . fattr ); \nif ( error < 0 ) \ngoto out_err ;", "mmm drivers / pci / probe . c \nppp drivers / pci / probe . c \nint pci_scan_bridge ( struct pci_bus * bus , struct pci_dev * dev , int max , int pass ) \ngoto out ; \n} \n \n+ if ( max >= bus -> busn_res . end ) { \n+ dev_warn (& dev -> dev , \" can ' t allocate child bus % 02x from % pR \\ n \", \n+ max , & bus -> busn_res ); \n+ goto out ; \n+ } \n+ \n/* Clear errors */ \npci_write_config_word ( dev , PCI_STATUS , 0xffff ); \n \n- /* Prevent assigning a bus number that already exists . \n- * This can happen when a bridge is hot - plugged , so in \n- * this case we only re - scan this bus . */ \n+ /* The bus will already exist if we are rescanning */ \nchild = pci_find_bus ( pci_domain_nr ( bus ), max + 1 ); \nif (! child ) { \nchild = pci_add_new_bus ( bus , dev , max + 1 );", "mmm sound / core / seq_device . c \nppp sound / core / seq_device . c \nvoid snd_seq_device_load_drivers ( void ) \nflush_work (& autoload_work ); \n} \nEXPORT_SYMBOL ( snd_seq_device_load_drivers ); \n+# define cancel_autoload_drivers () cancel_work_sync (& autoload_work ) \n# else \n# define queue_autoload_drivers () /* NOP */ \n+# define cancel_autoload_drivers () /* NOP */ \n# endif \n \n/* \nstatic int snd_seq_device_dev_free ( struct snd_device * device ) \n{ \nstruct snd_seq_device * dev = device -> device_data ; \n \n+ cancel_autoload_drivers (); \nput_device (& dev -> dev ); \nreturn 0 ; \n}", "mmm fs / pstore / ram . c \nppp fs / pstore / ram . c \nstatic int ramoops_probe ( struct platform_device * pdev ) \ngoto fail_out ; \n} \n \n- /* Only a single ramoops area allowed at a time , so fail extra \n+ /* \n+ * Only a single ramoops area allowed at a time , so fail extra \n* probes . \n*/ \n- if ( cxt -> max_dump_cnt ) \n+ if ( cxt -> max_dump_cnt ) { \n+ pr_err (\" already initialized \\ n \"); \ngoto fail_out ; \n+ } \n+ \n+ /* Make sure we didn ' t get bogus platform data pointer . */ \n+ if (! pdata ) { \n+ pr_err (\" NULL platform data \\ n \"); \n+ goto fail_out ; \n+ } \n \nif (! pdata -> mem_size || (! pdata -> record_size && ! pdata -> console_size && \n! pdata -> ftrace_size && ! pdata -> pmsg_size )) {", "mmm drivers / net / ethernet / qlogic / qlcnic / qlcnic_main . c \nppp drivers / net / ethernet / qlogic / qlcnic / qlcnic_main . c \nstatic int qlcnic_82xx_setup_intr ( struct qlcnic_adapter * adapter ) \nqlcnic_disable_multi_tx ( adapter ); \n \nerr = qlcnic_enable_msi_legacy ( adapter ); \n- if (! err ) \n+ if ( err ) \nreturn err ; \n} \n}", "mmm fs / nfs / super . c \nppp fs / nfs / super . c \nstatic int nfs_parse_mount_options ( char * raw , \nstring = match_strdup ( args ); \nif ( string == NULL ) \ngoto out_nomem ; \n+ kfree ( mnt -> client_address ); \nmnt -> client_address = string ; \nbreak ; \ncase Opt_mounthost : \nstring = match_strdup ( args ); \nif ( string == NULL ) \ngoto out_nomem ; \n+ kfree ( mnt -> mount_server . hostname ); \nmnt -> mount_server . hostname = string ; \nbreak ; \ncase Opt_mountaddr :", "mmm drivers / usb / gadget / fsl_udc_core . c \nppp drivers / usb / gadget / fsl_udc_core . c \nstatic int __exit fsl_udc_remove ( struct platform_device * pdev ) \nif (! udc_controller ) \nreturn - ENODEV ; \n \n- usb_del_gadget_udc (& udc_controller -> gadget ); \nudc_controller -> done = & done ; \n+ usb_del_gadget_udc (& udc_controller -> gadget ); \n \nfsl_udc_clk_release (); \n", "mmm drivers / input / evdev . c \nppp drivers / input / evdev . c \nstatic long evdev_do_ioctl ( struct file * file , unsigned int cmd , \nreturn - EFAULT ; \n \nerror = input_ff_upload ( dev , & effect , file ); \n+ if ( error ) \n+ return error ; \n \nif ( put_user ( effect . id , &((( struct ff_effect __user *) p )-> id ))) \nreturn - EFAULT ; \n \n- return error ; \n+ return 0 ; \n} \n \n/* Multi - number variable - length handlers */", "mmm drivers / misc / fastrpc . c \nppp drivers / misc / fastrpc . c \nstatic int fastrpc_dma_buf_attach ( struct dma_buf * dmabuf , \nFASTRPC_PHYS ( buffer -> phys ), buffer -> size ); \nif ( ret < 0 ) { \ndev_err ( buffer -> dev , \" failed to get scatterlist from DMA API \\ n \"); \n+ kfree ( a ); \nreturn - EINVAL ; \n} \n", "mmm drivers / net / bonding / bond_main . c \nppp drivers / net / bonding / bond_main . c \nint bond_enslave ( struct net_device * bond_dev , struct net_device * slave_dev ) \nwrite_unlock_bh (& bond -> curr_slave_lock ); \nread_unlock (& bond -> lock ); \n} \n+ slave_disable_netpoll ( new_slave ); \n \nerr_close : \nslave_dev -> priv_flags &= ~ IFF_BONDING ;", "mmm drivers / block / drbd / drbd_nl . c \nppp drivers / block / drbd / drbd_nl . c \ndrbd_determine_dev_size ( struct drbd_device * device , enum dds_flags flags , struct \nif ( la_size_changed || md_moved || rs ) { \nu32 prev_flags ; \n \n+ /* We do some synchronous IO below , which may take some time . \n+ * Clear the timer , to avoid scary \" timer expired !\" messages , \n+ * \" Superblock \" is written out at least twice below , anyways . */ \n+ del_timer (& device -> md_sync_timer ); \ndrbd_al_shrink ( device ); /* All extents inactive . */ \n \nprev_flags = md -> flags ;", "mmm kernel / sched . c \nppp kernel / sched . c \nstruct runqueue { \nunsigned long ttwu_cnt ; \nunsigned long ttwu_local ; \n# endif \n+ struct lock_class_key rq_lock_key ; \n}; \n \nstatic DEFINE_PER_CPU ( struct runqueue , runqueues ); \nvoid __init sched_init ( void ) \n \nrq = cpu_rq ( i ); \nspin_lock_init (& rq -> lock ); \n+ lockdep_set_class (& rq -> lock , & rq -> rq_lock_key ); \nrq -> nr_running = 0 ; \nrq -> active = rq -> arrays ; \nrq -> expired = rq -> arrays + 1 ;", "mmm drivers / base / component . c \nppp drivers / base / component . c \nstatic void component_detach_master ( struct master * master , struct component * c ) \nc -> master = NULL ; \n} \n \n+/* \n+ * Add a component to a master , finding the component via the compare \n+ * function and compare data . This is safe to call for duplicate matches \n+ * and will not result in the same component being added multiple times . \n+ */ \nint component_master_add_child ( struct master * master , \nint (* compare )( struct device *, void *), void * compare_data ) \n{ \nint component_master_add_child ( struct master * master , \nint ret = - ENXIO ; \n \nlist_for_each_entry ( c , & component_list , node ) { \n- if ( c -> master ) \n+ if ( c -> master && c -> master != master ) \ncontinue ; \n \nif ( compare ( c -> dev , compare_data )) { \n- component_attach_master ( master , c ); \n+ if (! c -> master ) \n+ component_attach_master ( master , c ); \nret = 0 ; \nbreak ; \n}", "mmm drivers / kvm / mmu . c \nppp drivers / kvm / mmu . c \nvoid kvm_mmu_pte_write ( struct kvm_vcpu * vcpu , gpa_t gpa , \nunsigned pte_size ; \nunsigned page_offset ; \nunsigned misaligned ; \n+ unsigned quadrant ; \nint level ; \nint flooded = 0 ; \nint npte ; \nvoid kvm_mmu_pte_write ( struct kvm_vcpu * vcpu , gpa_t gpa , \npage_offset <<= 1 ; \nnpte = 2 ; \n} \n+ quadrant = page_offset >> PAGE_SHIFT ; \npage_offset &= ~ PAGE_MASK ; \n+ if ( quadrant != page -> role . quadrant ) \n+ continue ; \n} \nspte = __va ( page -> page_hpa ); \nspte += page_offset / sizeof (* spte );", "mmm drivers / net / wireless / iwlwifi / mvm / power . c \nppp drivers / net / wireless / iwlwifi / mvm / power . c \nstatic void iwl_mvm_power_build_cmd ( struct iwl_mvm * mvm , \ncmd -> flags |= cpu_to_le16 ( POWER_FLAGS_POWER_SAVE_ENA_MSK ); \n \nif (! vif -> bss_conf . ps || iwl_mvm_vif_low_latency ( mvmvif ) || \n- ! mvmvif -> pm_enabled || iwl_mvm_tdls_sta_count ( mvm , vif )) \n+ ! mvmvif -> pm_enabled ) \nreturn ; \n \ncmd -> flags |= cpu_to_le16 ( POWER_FLAGS_POWER_MANAGEMENT_ENA_MSK ); \nstatic void iwl_mvm_power_set_pm ( struct iwl_mvm * mvm , \nif ( vifs -> ap_vif ) \nap_mvmvif = iwl_mvm_vif_from_mac80211 ( vifs -> ap_vif ); \n \n+ /* don ' t allow PM if any TDLS stations exist */ \n+ if ( iwl_mvm_tdls_sta_count ( mvm , NULL )) \n+ return ; \n+ \n/* enable PM on bss if bss stand alone */ \nif ( vifs -> bss_active && ! vifs -> p2p_active && ! vifs -> ap_active ) { \nbss_mvmvif -> pm_enabled = true ;", "mmm drivers / net / bonding / bond_main . c \nppp drivers / net / bonding / bond_main . c \nstatic u16 bond_select_queue ( struct net_device * dev , struct sk_buff * skb ) \n{ \n/* \n* This helper function exists to help dev_pick_tx get the correct \n- * destination queue . Using a helper function skips the a call to \n+ * destination queue . Using a helper function skips a call to \n* skb_tx_hash and will put the skbs in the queue we expect on their \n* way down to the bonding driver . \n*/ \n- return skb -> queue_mapping ; \n+ u16 txq = skb_rx_queue_recorded ( skb ) ? skb_get_rx_queue ( skb ) : 0 ; \n+ \n+ if ( unlikely ( txq >= dev -> real_num_tx_queues )) { \n+ do \n+ txq -= dev -> real_num_tx_queues ; \n+ while ( txq >= dev -> real_num_tx_queues ); \n+ } \n+ return txq ; \n} \n \nstatic netdev_tx_t bond_start_xmit ( struct sk_buff * skb , struct net_device * dev )", "mmm sound / soc / soc - cache . c \nppp sound / soc / soc - cache . c \nstatic bool snd_soc_set_cache_val ( void * base , unsigned int idx , \nstatic unsigned int snd_soc_get_cache_val ( const void * base , unsigned int idx , \nunsigned int word_size ) \n{ \n+ if (! base ) \n+ return - 1 ; \n+ \nswitch ( word_size ) { \ncase 1 : { \nconst u8 * cache = base ;", "mmm drivers / staging / xgifb / XGI_main_26 . c \nppp drivers / staging / xgifb / XGI_main_26 . c \nstatic int xgifb_probe ( struct pci_dev * pdev , \n \nif ( xgifb_info -> mode_idx < 0 ) { \ndev_err (& pdev -> dev , \" No supported video mode found \\ n \"); \n+ ret = - EINVAL ; \ngoto error_1 ; \n} \n", "mmm drivers / staging / speakup / kobjects . c \nppp drivers / staging / speakup / kobjects . c \nstatic ssize_t synth_store ( struct kobject * kobj , struct kobj_attribute * attr , \nlen = strlen ( buf ); \nif ( len < 2 || len > 9 ) \nreturn - EINVAL ; \n- strncpy ( new_synth_name , buf , len ); \n+ memcpy ( new_synth_name , buf , len ); \nif ( new_synth_name [ len - 1 ] == '\\ n ') \nlen --; \nnew_synth_name [ len ] = '\\ 0 '; \nstatic ssize_t punc_store ( struct kobject * kobj , struct kobj_attribute * attr , \nreturn - EINVAL ; \n} \n \n- strncpy ( punc_buf , buf , x ); \n+ memcpy ( punc_buf , buf , x ); \n \nwhile ( x && punc_buf [ x - 1 ] == '\\ n ') \nx --;", "mmm drivers / regulator / pwm - regulator . c \nppp drivers / regulator / pwm - regulator . c \nstatic int pwm_regulator_probe ( struct platform_device * pdev ) \nreturn ret ; \n} \n \n- /* \n- * FIXME : pwm_apply_args () should be removed when switching to the \n- * atomic PWM API . \n- */ \n- pwm_apply_args ( drvdata -> pwm ); \n+ ret = pwm_adjust_config ( drvdata -> pwm ); \n+ if ( ret ) \n+ return ret ; \n \nregulator = devm_regulator_register (& pdev -> dev , \n& drvdata -> desc , & config );", "mmm drivers / staging / lustre / lustre / obdclass / obd_config . c \nppp drivers / staging / lustre / lustre / obdclass / obd_config . c \nint class_process_proc_param ( char * prefix , struct lprocfs_vars * lvars , \n \noldfs = get_fs (); \nset_fs ( KERNEL_DS ); \n- rc = var -> fops -> write (& fakefile , sval , \n+ rc = var -> fops -> write (& fakefile , \n+ ( const char __user *) sval , \nvallen , NULL ); \nset_fs ( oldfs ); \n}", "mmm drivers / staging / imx - drm / imx - drm - core . c \nppp drivers / staging / imx - drm / imx - drm - core . c \nint imx_drm_add_crtc ( struct drm_crtc * crtc , \n \nmutex_lock (& imxdrm -> mutex ); \n \n+ /* \n+ * The vblank arrays are dimensioned by MAX_CRTC - we can ' t \n+ * pass IDs greater than this to those functions . \n+ */ \n+ if ( imxdrm -> pipes >= MAX_CRTC ) { \n+ ret = - EINVAL ; \n+ goto err_busy ; \n+ } \n+ \nif ( imxdrm -> drm -> open_count ) { \nret = - EBUSY ; \ngoto err_busy ;", "mmm include / net / udp . h \nppp include / net / udp . h \nstatic inline int copy_linear_skb ( struct sk_buff * skb , int len , int off , \n{ \nint n , copy = len - off ; \n \n+ if ( copy < 0 ) \n+ return - EINVAL ; \nn = copy_to_iter ( skb -> data + off , copy , to ); \nif ( n == copy ) \nreturn 0 ;", "mmm fs / fuse / inode . c \nppp fs / fuse / inode . c \nstatic int fuse_fill_super ( struct super_block * sb , void * data , int silent ) \nerr_put_root : \ndput ( root_dentry ); \nerr_put_conn : \n+ bdi_destroy (& fc -> bdi ); \nfuse_conn_put ( fc ); \nerr_fput : \nfput ( file );", "mmm net / mpls / af_mpls . c \nppp net / mpls / af_mpls . c \nstatic int mpls_dev_sysctl_register ( struct net_device * dev , \nfree : \nkfree ( table ); \nout : \n+ mdev -> sysctl = NULL ; \nreturn - ENOBUFS ; \n} \n \nstatic void mpls_dev_sysctl_unregister ( struct net_device * dev , \nstruct net * net = dev_net ( dev ); \nstruct ctl_table * table ; \n \n+ if (! mdev -> sysctl ) \n+ return ; \n+ \ntable = mdev -> sysctl -> ctl_table_arg ; \nunregister_net_sysctl_table ( mdev -> sysctl ); \nkfree ( table );", "mmm net / netfilter / nf_tables_core . c \nppp net / netfilter / nf_tables_core . c \nunsigned int \nnft_do_chain ( struct nft_pktinfo * pkt , const struct nf_hook_ops * ops ) \n{ \nconst struct nft_chain * chain = ops -> priv , * basechain = chain ; \n- const struct net * net = read_pnet (& nft_base_chain ( basechain )-> pnet ); \n+ const struct net * chain_net = read_pnet (& nft_base_chain ( basechain )-> pnet ); \n+ const struct net * net = dev_net ( pkt -> in ? pkt -> in : pkt -> out ); \nconst struct nft_rule * rule ; \nconst struct nft_expr * expr , * last ; \nstruct nft_regs regs ; \nnft_do_chain ( struct nft_pktinfo * pkt , const struct nf_hook_ops * ops ) \nint rulenum ; \nunsigned int gencursor = nft_genmask_cur ( net ); \n \n+ /* Ignore chains that are not for the current network namespace */ \n+ if (! net_eq ( net , chain_net )) \n+ return NF_ACCEPT ; \n+ \ndo_chain : \nrulenum = 0 ; \nrule = list_entry (& chain -> rules , struct nft_rule , list );", "mmm net / rxrpc / conn_service . c \nppp net / rxrpc / conn_service . c \nstruct rxrpc_connection * rxrpc_find_service_conn_rcu ( struct rxrpc_peer * peer , \nelse if ( conn -> proto . index_key > k . index_key ) \np = rcu_dereference_raw ( p -> rb_right ); \nelse \n- goto done ; \n+ break ; \nconn = NULL ; \n} \n} while ( need_seqretry (& peer -> service_conn_lock , seq )); \n \n- done : \ndone_seqretry (& peer -> service_conn_lock , seq ); \n_leave (\" = % d \", conn ? conn -> debug_id : - 1 ); \nreturn conn ;", "mmm drivers / net / wireless / ath / ath6kl / sdio . c \nppp drivers / net / wireless / ath / ath6kl / sdio . c \nstruct ath6kl_sdio { \n# define CMD53_ARG_FIXED_ADDRESS 0 \n# define CMD53_ARG_INCR_ADDRESS 1 \n \n+ static int ath6kl_sdio_config ( struct ath6kl * ar ); \n+ \nstatic inline struct ath6kl_sdio * ath6kl_sdio_priv ( struct ath6kl * ar ) \n{ \nreturn ar -> hif_priv ; \nstatic int ath6kl_sdio_power_on ( struct ath6kl * ar ) \n*/ \nmsleep ( 10 ); \n \n+ ret = ath6kl_sdio_config ( ar ); \n+ if ( ret ) { \n+ ath6kl_err (\" Failed to config sdio : % d \\ n \", ret ); \n+ goto out ; \n+ } \n+ \nar_sdio -> is_disabled = false ; \n \n+ out : \nreturn ret ; \n} \n", "mmm drivers / gpu / drm / radeon / radeon_cs . c \nppp drivers / gpu / drm / radeon / radeon_cs . c \nint radeon_cs_parser_init ( struct radeon_cs_parser * p , void * data ) \ncdata = ( uint32_t *)( unsigned long ) user_chunk . chunk_data ; \n \nsize = p -> chunks [ i ]. length_dw * sizeof ( uint32_t ); \n- p -> chunks [ i ]. kdata = kzalloc ( size , GFP_KERNEL ); \n+ p -> chunks [ i ]. kdata = kmalloc ( size , GFP_KERNEL ); \nif ( p -> chunks [ i ]. kdata == NULL ) { \nreturn - ENOMEM ; \n}", "mmm net / ipv4 / tcp_input . c \nppp net / ipv4 / tcp_input . c \nint tcp_rcv_state_process ( struct sock * sk , struct sk_buff * skb , \ngoto discard ; \n \nif ( th -> syn ) { \n+ if ( th -> fin ) \n+ goto discard ; \nif ( icsk -> icsk_af_ops -> conn_request ( sk , skb ) < 0 ) \nreturn 1 ; \n", "mmm tools / objtool / check . c \nppp tools / objtool / check . c \nstatic bool ignore_unreachable_insn ( struct instruction * insn ) \nif ( is_kasan_insn ( insn ) || is_ubsan_insn ( insn )) \nreturn true ; \n \n- if ( insn -> type == INSN_JUMP_UNCONDITIONAL && insn -> jump_dest ) { \n- insn = insn -> jump_dest ; \n- continue ; \n+ if ( insn -> type == INSN_JUMP_UNCONDITIONAL ) { \n+ if ( insn -> jump_dest && \n+ insn -> jump_dest -> func == insn -> func ) { \n+ insn = insn -> jump_dest ; \n+ continue ; \n+ } \n+ \n+ break ; \n} \n \nif ( insn -> offset + insn -> len >= insn -> func -> offset + insn -> func -> len ) \nbreak ; \n+ \ninsn = list_next_entry ( insn , list ); \n} \n", "mmm net / netfilter / nf_conntrack_netlink . c \nppp net / netfilter / nf_conntrack_netlink . c \nctnetlink_setup_nat ( struct nf_conn * ct , const struct nlattr * const cda []) \n# ifdef CONFIG_NF_NAT_NEEDED \nint ret ; \n \n+ if (! cda [ CTA_NAT_DST ] && ! cda [ CTA_NAT_SRC ]) \n+ return 0 ; \n+ \nret = ctnetlink_parse_nat_setup ( ct , NF_NAT_MANIP_DST , \ncda [ CTA_NAT_DST ]); \nif ( ret < 0 )", "mmm net / nfc / llcp / sock . c \nppp net / nfc / llcp / sock . c \nstatic int llcp_sock_getname ( struct socket * sock , struct sockaddr * uaddr , \nstruct nfc_llcp_sock * llcp_sock = nfc_llcp_sock ( sk ); \nDECLARE_SOCKADDR ( struct sockaddr_nfc_llcp *, llcp_addr , uaddr ); \n \n+ if ( llcp_sock == NULL || llcp_sock -> dev == NULL ) \n+ return - EBADFD ; \n+ \npr_debug (\"% p % d % d % d \\ n \", sk , llcp_sock -> target_idx , \nllcp_sock -> dsap , llcp_sock -> ssap ); \n", "mmm fs / isofs / export . c \nppp fs / isofs / export . c \nisofs_export_encode_fh ( struct inode * inode , \nlen = 3 ; \nfh32 [ 0 ] = ei -> i_iget5_block ; \nfh16 [ 2 ] = ( __u16 ) ei -> i_iget5_offset ; /* fh16 [ sic ] */ \n+ fh16 [ 3 ] = 0 ; /* avoid leaking uninitialized data */ \nfh32 [ 2 ] = inode -> i_generation ; \nif ( parent ) { \nstruct iso_inode_info * eparent ;", "mmm arch / mips / math - emu / cp1emu . c \nppp arch / mips / math - emu / cp1emu . c \nint mm_isBranchInstr ( struct pt_regs * regs , struct mm_decoded_insn dec_insn , \nunsigned int fcr31 ; \nunsigned int bit ; \n \n+ if (! cpu_has_mmips ) \n+ return 0 ; \n+ \nswitch ( insn . mm_i_format . opcode ) { \ncase mm_pool32a_op : \nif (( insn . mm_i_format . simmediate & MM_POOL32A_MINOR_MASK ) ==", "mmm drivers / macintosh / via - cuda . c \nppp drivers / macintosh / via - cuda . c \ncuda_poll ( void ) \n} \nEXPORT_SYMBOL ( cuda_poll ); \n \n+# define ARRAY_FULL ( a , p ) (( p ) - ( a ) == ARRAY_SIZE ( a )) \n+ \nstatic irqreturn_t \ncuda_interrupt ( int irq , void * arg ) \n{ \ncuda_interrupt ( int irq , void * arg ) \nbreak ; \n \ncase reading : \n- * reply_ptr ++ = in_8 (& via [ SR ]); \n+ if ( reading_reply ? ARRAY_FULL ( current_req -> reply , reply_ptr ) \n+ : ARRAY_FULL ( cuda_rbuf , reply_ptr )) \n+ ( void ) in_8 (& via [ SR ]); \n+ else \n+ * reply_ptr ++ = in_8 (& via [ SR ]); \nif (! TREQ_asserted ( status )) { \n/* that ' s all folks */ \nnegate_TIP_and_TACK ();", "mmm drivers / base / dma - contiguous . c \nppp drivers / base / dma - contiguous . c \nstatic int __init cma_activate_area ( struct cma * cma ) \nbase_pfn = pfn ; \nfor ( j = pageblock_nr_pages ; j ; -- j , pfn ++) { \nWARN_ON_ONCE (! pfn_valid ( pfn )); \n+ /* \n+ * alloc_contig_range requires the pfn range \n+ * specified to be in the same zone . Make this \n+ * simple by forcing the entire CMA resv range \n+ * to be in the same zone . \n+ */ \nif ( page_zone ( pfn_to_page ( pfn )) != zone ) \n- return - EINVAL ; \n+ goto err ; \n} \ninit_cma_reserved_pageblock ( pfn_to_page ( base_pfn )); \n} while (-- i ); \n \nmutex_init (& cma -> lock ); \nreturn 0 ; \n+ \n+ err : \n+ kfree ( cma -> bitmap ); \n+ return - EINVAL ; \n} \n \nstatic struct cma cma_areas [ MAX_CMA_AREAS ];", "mmm mm / memory . c \nppp mm / memory . c \nstatic int __access_remote_vm ( struct task_struct * tsk , struct mm_struct * mm , \n*/ \n# ifdef CONFIG_HAVE_IOREMAP_PROT \nvma = find_vma ( mm , addr ); \n- if (! vma ) \n+ if (! vma || vma -> vm_start > addr ) \nbreak ; \nif ( vma -> vm_ops && vma -> vm_ops -> access ) \nret = vma -> vm_ops -> access ( vma , addr , buf ,", "mmm kernel / trace / trace_events . c \nppp kernel / trace / trace_events . c \nint trace_define_field ( struct ftrace_event_call * call , char * type , \n{ \nstruct ftrace_event_field * field ; \n \n- field = kmalloc ( sizeof (* field ), GFP_KERNEL ); \n+ field = kzalloc ( sizeof (* field ), GFP_KERNEL ); \nif (! field ) \ngoto err ; \n+ \nfield -> name = kstrdup ( name , GFP_KERNEL ); \nif (! field -> name ) \ngoto err ; \n+ \nfield -> type = kstrdup ( type , GFP_KERNEL ); \nif (! field -> type ) \ngoto err ; \n+ \nfield -> offset = offset ; \nfield -> size = size ; \nlist_add (& field -> link , & call -> fields ); \n \nreturn 0 ; \n+ \nerr : \nif ( field ) { \nkfree ( field -> name ); \nkfree ( field -> type ); \n} \nkfree ( field ); \n+ \nreturn - ENOMEM ; \n} \n", "mmm security / keys / key . c \nppp security / keys / key . c \nstatic inline void key_alloc_serial ( struct key * key ) \nkey -> serial = 2 ; \nkey_serial_next = key -> serial + 1 ; \n \n- if (! parent -> rb_parent ) \n+ if (! rb_parent ( parent )) \np = & key_serial_tree . rb_node ; \n- else if ( parent -> rb_parent -> rb_left == parent ) \n- p = & parent -> rb_parent -> rb_left ; \n+ else if ( rb_parent ( parent )-> rb_left == parent ) \n+ p = &( rb_parent ( parent )-> rb_left ); \nelse \n- p = & parent -> rb_parent -> rb_right ; \n+ p = &( rb_parent ( parent )-> rb_right ); \n \nparent = rb_next ( parent ); \nif (! parent )", "mmm arch / powerpc / kernel / pci_64 . c \nppp arch / powerpc / kernel / pci_64 . c \nlong sys_pciconfig_iobase ( long which , unsigned long in_bus , \nunsigned long in_devfn ) \n{ \nstruct pci_controller * hose ; \n- struct pci_bus * bus = NULL ; \n+ struct pci_bus * tmp_bus , * bus = NULL ; \nstruct device_node * hose_node ; \n \n/* Argh ! Please forgive me for that hack , but that ' s the \nlong sys_pciconfig_iobase ( long which , unsigned long in_bus , \n* used on pre - domains setup . We return the first match \n*/ \n \n- list_for_each_entry ( bus , & pci_root_buses , node ) { \n- if ( in_bus >= bus -> number && in_bus <= bus -> busn_res . end ) \n+ list_for_each_entry ( tmp_bus , & pci_root_buses , node ) { \n+ if ( in_bus >= tmp_bus -> number && \n+ in_bus <= tmp_bus -> busn_res . end ) { \n+ bus = tmp_bus ; \nbreak ; \n- bus = NULL ; \n+ } \n} \nif ( bus == NULL || bus -> dev . of_node == NULL ) \nreturn - ENODEV ;", "mmm sound / usb / usbaudio . c \nppp sound / usb / usbaudio . c \nstatic int check_hw_params_convention ( struct snd_usb_substream * subs ) \n \nchannels = kcalloc ( MAX_MASK , sizeof ( u32 ), GFP_KERNEL ); \nrates = kcalloc ( MAX_MASK , sizeof ( u32 ), GFP_KERNEL ); \n+ if (! channels || ! rates ) \n+ goto __out ; \n \nlist_for_each ( p , & subs -> fmt_list ) { \nstruct audioformat * f ;", "mmm fs / cifs / smb2ops . c \nppp fs / cifs / smb2ops . c \nsmb2_query_symlink ( const unsigned int xid , struct cifs_tcon * tcon , \n& resp_buftype ); \nif (! rc || ! err_iov . iov_base ) { \nrc = - ENOENT ; \n- goto querty_exit ; \n+ goto free_path ; \n} \n \nerr_buf = err_iov . iov_base ; \nsmb2_query_symlink ( const unsigned int xid , struct cifs_tcon * tcon , \n \nquerty_exit : \nfree_rsp_buf ( resp_buftype , err_buf ); \n+ free_path : \nkfree ( utf16_path ); \nreturn rc ; \n}", "mmm drivers / input / touchscreen / sur40 . c \nppp drivers / input / touchscreen / sur40 . c \nstatic int sur40_probe ( struct usb_interface * interface , \nsur40 -> alloc_ctx = vb2_dma_sg_init_ctx ( sur40 -> dev ); \nif ( IS_ERR ( sur40 -> alloc_ctx )) { \ndev_err ( sur40 -> dev , \" Can ' t allocate buffer context \"); \n+ error = PTR_ERR ( sur40 -> alloc_ctx ); \ngoto err_unreg_v4l2 ; \n} \n", "mmm drivers / staging / goldfish / goldfish_audio . c \nppp drivers / staging / goldfish / goldfish_audio . c \nstatic int goldfish_audio_probe ( struct platform_device * pdev ) \nreturn 0 ; \n \nerr_misc_register_failed : \n+ free_irq ( data -> irq , data ); \nerr_request_irq_failed : \ndma_free_coherent (& pdev -> dev , COMBINED_BUFFER_SIZE , \ndata -> buffer_virt , data -> buffer_phys );", "mmm kernel / module . c \nppp kernel / module . c \nstatic noinline struct module * load_module ( void __user * umod , \nfree_unload : \nmodule_unload_free ( mod ); \n# if defined ( CONFIG_MODULE_UNLOAD ) && defined ( CONFIG_SMP ) \n- free_init : \npercpu_modfree ( mod -> refptr ); \n+ free_init : \n# endif \nmodule_free ( mod , mod -> module_init ); \nfree_core :", "mmm arch / arm / kernel / sched_clock . c \nppp arch / arm / kernel / sched_clock . c \nstatic unsigned long long notrace cyc_to_sched_clock ( u32 cyc , u32 mask ) \nu64 epoch_ns ; \nu32 epoch_cyc ; \n \n- if ( cd . suspended ) \n- return cd . epoch_ns ; \n- \n/* \n* Load the epoch_cyc and epoch_ns atomically . We do this by \n* ensuring that we always write epoch_cyc , epoch_ns and \nunsigned long long __read_mostly (* sched_clock_func )( void ) = sched_clock_32 ; \n \nunsigned long long notrace sched_clock ( void ) \n{ \n+ if ( cd . suspended ) \n+ return cd . epoch_ns ; \n+ \nreturn sched_clock_func (); \n} \n", "mmm crypto / crypto_user_base . c \nppp crypto / crypto_user_base . c \nstatic int crypto_report ( struct sk_buff * in_skb , struct nlmsghdr * in_nlh , \ndrop_alg : \ncrypto_mod_put ( alg ); \n \n- if ( err ) \n+ if ( err ) { \n+ kfree_skb ( skb ); \nreturn err ; \n+ } \n \nreturn nlmsg_unicast ( net -> crypto_nlsk , skb , NETLINK_CB ( in_skb ). portid ); \n}", "mmm tools / perf / util / sort . c \nppp tools / perf / util / sort . c \nstatic int hist_entry__srcline_snprintf ( struct hist_entry * self , char * bf , \nif ( path != NULL ) \ngoto out_path ; \n \n+ if (! self -> ms . map ) \n+ goto out_ip ; \n+ \nsnprintf ( cmd , sizeof ( cmd ), \" addr2line - e % s % 016 \" PRIx64 , \nself -> ms . map -> dso -> long_name , self -> ip ); \nfp = popen ( cmd , \" r \");", "mmm src / src_parser . c \nppp src / src_parser . c \nstatic int src_parser_trans_stage_1_2_3 ( const int tmp_fd , const char * src , const \n( PBUF_TMP_PREV_CHAR ( pbuf ) == ' ' || PBUF_TMP_PREV_CHAR ( pbuf ) == '\\ t ' || \nPBUF_TMP_PREV_CHAR ( pbuf ) == '\\ n ')) { \npbuf . f_indx ++; \n- } else if ( pbuf . tmp_indx && \n+ } else if ( pbuf . tmp_indx && \n( PBUF_TMP_PREV_CHAR ( pbuf ) == '\\\\')) { \npbuf . tmp_indx --; \npbuf . f_indx ++; \nstatic int src_parser_trans_stage_1_2_3 ( const int tmp_fd , const char * src , const \ncontinue ; \n \ncase '\\\\': \n+ p_buf_write_tmp (& pbuf , tmp_fd ); \np_buf_push_tmp_char (& pbuf , '\\\\'); \ncontinue ; \n \ncase '/': \n+ p_buf_write_tmp (& pbuf , tmp_fd ); \np_buf_push_tmp_char (& pbuf , '/'); \ncontinue ; \n", "mmm src / ftpcmd . c \nppp src / ftpcmd . c \nstatic void handle_PORT ( ctrl_t * ctrl , char * str ) \n \n/* Convert PORT command ' s argument to IP address + port */ \nsscanf ( str , \"% d ,% d ,% d ,% d ,% d ,% d \", & a , & b , & c , & d , & e , & f ); \n- sprintf ( addr , \"% d .% d .% d .% d \", a , b , c , d ); \n+ snprintf ( addr , sizeof ( addr ), \"% d .% d .% d .% d \", a , b , c , d ); \n \n/* Check IPv4 address using inet_aton (), throw away converted result */ \nif (! inet_aton ( addr , &( sin . sin_addr ))) {", "mmm src / common . c \nppp src / common . c \ncheck : \nstrlcat ( rpath , name , sizeof ( rpath )); \n} \n \n- if (! chrooted && strncmp ( dir , home , strlen ( home ))) { \n+ if (! chrooted && strncmp ( rpath , home , strlen ( home ))) { \nDBG (\" Failed non - chroot dir :% s vs home :% s \", dir , home ); \nreturn NULL ; \n}", "mmm src / lib / openjp2 / image . c \nppp src / lib / openjp2 / image . c \nopj_image_t * OPJ_CALLCONV opj_image_create ( OPJ_UINT32 numcmpts , \nimage -> color_space = clrspc ; \nimage -> numcomps = numcmpts ; \n/* allocate memory for the per - component information */ \n- image -> comps = ( opj_image_comp_t *) opj_calloc ( 1 , \n- image -> numcomps * sizeof ( opj_image_comp_t )); \n+ image -> comps = ( opj_image_comp_t *) opj_calloc ( image -> numcomps , \n+ sizeof ( opj_image_comp_t )); \nif (! image -> comps ) { \n/* TODO replace with event manager , breaks API */ \n/* fprintf ( stderr ,\" Unable to allocate memory for image .\\ n \"); */", "mmm src / bin / jp2 / opj_decompress . c \nppp src / bin / jp2 / opj_decompress . c \nint get_num_images ( char * imgdirpath ){ \ncontinue ; \nnum_images ++; \n} \n+ closedir ( dir ); \nreturn num_images ; \n} \n \nint load_images ( dircnt_t * dirptr , char * imgdirpath ){ \nstrcpy ( dirptr -> filename [ i ], content -> d_name ); \ni ++; \n} \n+ closedir ( dir ); \nreturn 0 ; \n} \n", "mmm codec / image_to_j2k . c \nppp codec / image_to_j2k . c \nint main ( int argc , char ** argv ) \n \n/* Remove the temporary files */ \n/* -------------------------- */ \n- if ( cp . decod_format != PGX_CFMT ) { /* PNM PGM PPM or BMP */ \n+ if ( cp . decod_format != PGX_DFMT ) { /* PNM PGM PPM or BMP */ \nfor ( i = 0 ; i < img . numcomps ; i ++) { \nchar tmp ; \nsprintf (& tmp , \" Compo % d \", i );", "mmm src / lib / openjp2 / tcd . c \nppp src / lib / openjp2 / tcd . c \nstatic INLINE OPJ_BOOL opj_tcd_init_tile ( opj_tcd_t * p_tcd , OPJ_UINT32 p_tile_no , \n \n/* compute l_data_size with overflow check */ \nl_data_size = ( OPJ_UINT32 )( l_tilec -> x1 - l_tilec -> x0 ); \n- if (((( OPJ_UINT32 )- 1 ) / l_data_size ) < ( OPJ_UINT32 )( l_tilec -> y1 - l_tilec -> y0 )) { \n+ /* issue 733 , l_data_size == 0U , probably something wrong should be checked before getting here */ \n+ if (( l_data_size > 0U ) && (((( OPJ_UINT32 )- 1 ) / l_data_size ) < ( OPJ_UINT32 )( l_tilec -> y1 - l_tilec -> y0 ))) { \nopj_event_msg ( manager , EVT_ERROR , \" Not enough memory for tile data \\ n \"); \nreturn OPJ_FALSE ; \n}", "mmm src / lib / openjp2 / tcd . c \nppp src / lib / openjp2 / tcd . c \nvoid opj_tcd_makelayer ( opj_tcd_t * tcd , \nn = passno + 1 ; \ncontinue ; \n} \n- if ( thresh - ( dd / dr ) <= DBL_EPSILON ) /* do not rely on float equality , check with DBL_EPSILON margin */ \n+ if ( thresh - ( dd / dr ) < DBL_EPSILON ) /* do not rely on float equality , check with DBL_EPSILON margin */ \nn = passno + 1 ; \n} \n", "mmm src / bin / jp2 / convert . c \nppp src / bin / jp2 / convert . c \nopj_image_t * tiftoimage ( const char * filename , opj_cparameters_t * parameters ) \n*/ \nmemset (& cmptparm [ 0 ], 0 , 4 * sizeof ( opj_image_cmptparm_t )); \n \n+ if (( tiPhoto == PHOTOMETRIC_RGB ) && ( parameters -> cp_cinema )) { \n+ fprintf ( stdout ,\" WARNING :\\ n \" \n+ \" Input image bitdepth is % d bits \\ n \" \n+ \" TIF conversion has automatically rescaled to 12 - bits \\ n \" \n+ \" to comply with cinema profiles .\\ n \", \n+ tiBps ); \n+ } \n+ \nif ( tiPhoto == PHOTOMETRIC_RGB ) /* RGB ( A ) */ \n{ \nnumcomps = 3 + has_alpha ;", "mmm v4l2loopback . c \nppp v4l2loopback . c \nstatic int vidioc_querycap ( struct file * file , void * priv , \n__u32 capabilities = V4L2_CAP_STREAMING | V4L2_CAP_READWRITE ; \n \nstrlcpy ( cap -> driver , \" v4l2 loopback \", sizeof ( cap -> driver )); \n- snprintf ( cap -> card , labellen , dev -> card_label ); \n+ snprintf ( cap -> card , labellen , \"% s \", dev -> card_label ); \nsnprintf ( cap -> bus_info , sizeof ( cap -> bus_info ), \n\" platform : v4l2loopback -% 03d \", device_nr ); \n \nstatic int v4l2_loopback_add ( struct v4l2_loopback_config * conf , int * ret_nr ) \n} \n \nMARK (); \n- snprintf ( dev -> vdev -> name , sizeof ( dev -> vdev -> name ), dev -> card_label ); \n+ snprintf ( dev -> vdev -> name , sizeof ( dev -> vdev -> name ), \"% s \", dev -> card_label ); \n \nvdev_priv -> device_nr = nr ; \n", "mmm core / master . c \nppp core / master . c \nstatic void master_check_listen_queue () { \nif ( uwsgi_sock -> queue > load ) { \nload = uwsgi_sock -> queue ; \n} \n- if ( uwsgi_sock -> queue >= uwsgi_sock -> max_queue ) { \n+ if ( uwsgi_sock -> queue > 0 && uwsgi_sock -> queue >= uwsgi_sock -> max_queue ) { \nuwsgi_log_verbose (\"*** uWSGI listen queue of socket \\\"% s \\\" ( fd : % d ) full !!! (% llu /% llu ) ***\\ n \", uwsgi_sock -> name , uwsgi_sock -> fd , ( unsigned long long ) uwsgi_sock -> queue , ( unsigned long long ) uwsgi_sock -> max_queue ); \nuwsgi . shared -> options [ UWSGI_OPTION_BACKLOG_ERRORS ]++; \n}", "mmm plugins / python / tracebacker . c \nppp plugins / python / tracebacker . c \nvoid * uwsgi_python_tracebacker_thread ( void * foobar ) { \nuwsgi . no_defer_accept = current_defer_accept ; \n \nPyObject * traceback_module = PyImport_ImportModule (\" traceback \"); \n- if (! traceback_module ) return NULL ; \n+ if (! traceback_module ) { \n+ free ( str_wid ); \n+ free ( sock_path ); \n+ close ( fd ); \n+ return NULL ; \n+ } \nPyObject * traceback_dict = PyModule_GetDict ( traceback_module ); \nPyObject * extract_stack = PyDict_GetItemString ( traceback_dict , \" extract_stack \"); \n", "mmm core / alarm . c \nppp core / alarm . c \nstatic void uwsgi_alarm_thread_loop ( struct uwsgi_thread * ut ) { \nlong ptr = 0 ; \nmemcpy (& ptr , buf , sizeof ( long )); \nstruct uwsgi_alarm_instance * uai = ( struct uwsgi_alarm_instance *) ptr ; \n- if (! uai ) return ; \n+ if (! uai ) \n+ break ; \nuwsgi_alarm_run ( uai , msg , msg_size ); \n} \n} \n} \n+ free ( buf ); \n} \n \n// initialize alarms , instances and log regexps", "mmm plugins / rawrouter / rawrouter . c \nppp plugins / rawrouter / rawrouter . c \nstatic struct uwsgi_option rawrouter_options [] = { \n{\" rawrouter - ss \", required_argument , 0 , \" run the rawrouter stats server \", uwsgi_opt_set_str , & urr . cr . stats_server , 0 }, \n{\" rawrouter - harakiri \", required_argument , 0 , \" enable rawrouter harakiri \", uwsgi_opt_set_int , & urr . cr . harakiri , 0 }, \n \n- {\" rawrouter - xclient \", no_argument , 0 , \" use the xclient protocol to pass the client addres \", uwsgi_opt_true , & urr . xclient , 0 }, \n+ {\" rawrouter - xclient \", no_argument , 0 , \" use the xclient protocol to pass the client address \", uwsgi_opt_true , & urr . xclient , 0 }, \n \n{\" rawrouter - buffer - size \", required_argument , 0 , \" set internal buffer size ( default : page size )\", uwsgi_opt_set_64bit , & urr . cr . buffer_size , 0 }, \n", "mmm plugins / stats_pusher_statsd / plugin . c \nppp plugins / stats_pusher_statsd / plugin . c \n# include < uwsgi . h > \n \n+/* \n+ \n+ this is a stats pusher plugin for the statsd server : \n+ \n+-- stats - push statsd : address [, prefix ] \n+ \n+ example : \n+ \n+-- stats - push statsd : 127 . 0 . 0 . 1 : 8125 , myinstance \n+ \n+ it is pretty minimal , but will be extended after the 2 . 0 metric subsystem will be released \n+ \n+*/ \n+ \nextern struct uwsgi_server uwsgi ; \n \n+// configuration of a statsd node \nstruct statsd_node { \nint fd ; \nunion uwsgi_sockaddr addr ;", "mmm uwsgi . c \nppp uwsgi . c \nint uwsgi_start ( void * v_argv ) { \n} \n \nuwsgi_add_sockets_to_queue ( uwsgi . async_queue ); \n- } \n \n- uwsgi . rb_async_timeouts = uwsgi_init_rb_timer (); \n+ uwsgi . rb_async_timeouts = uwsgi_init_rb_timer (); \n \n- uwsgi . async_queue_unused = uwsgi_malloc ( sizeof ( struct wsgi_request *) * uwsgi . async ); \n+ uwsgi . async_queue_unused = uwsgi_malloc ( sizeof ( struct wsgi_request *) * uwsgi . async ); \n \n- for ( i = 0 ; i < uwsgi . async ; i ++) { \n- uwsgi . async_queue_unused [ i ] = uwsgi . wsgi_requests [ i ]; \n- } \n+ for ( i = 0 ; i < uwsgi . async ; i ++) { \n+ uwsgi . async_queue_unused [ i ] = uwsgi . wsgi_requests [ i ]; \n+ } \n \n- uwsgi . async_queue_unused_ptr = uwsgi . async - 1 ; \n+ uwsgi . async_queue_unused_ptr = uwsgi . async - 1 ; \n+ } \n# endif \n \n", "mmm core / utils . c \nppp core / utils . c \nvoid uwsgi_uuid ( char * buf ) { \nint uwsgi_uuid_cmp ( char * x , char * y ) { \nint i ; \nfor ( i = 0 ; i < 36 ; i ++) { \n- if ( x [ i ] > y [ i ]) { \n- return 1 ; \n+ if ( x [ i ] != y [ i ]) { \n+ if ( x [ i ] > y [ i ]) { \n+ return 1 ; \n+ } \n+ return 0 ; \n} \n} \nreturn 0 ;", "mmm plugins / pypy / pypy_plugin . c \nppp plugins / pypy / pypy_plugin . c \nstatic void uwsgi_pypy_onload () { \n# ifdef UWSGI_PYPY_HOME \nupypy . home = UWSGI_PYPY_HOME ; \n# endif \n+ uwsgi . has_threads = 1 ; \n} \n \nstatic int uwsgi_pypy_mule ( char * opt ) {", "mmm plugins / python / pyloader . c \nppp plugins / python / pyloader . c \nPyObject * uwsgi_file_loader ( void * arg1 ) { \nPy_DECREF ( wsgi_file_dict ); \nPy_DECREF ( wsgi_file_module ); \nfree ( py_filename ); \n- uwsgi_log ( \" unable to find \\\" application \\\" callable in file % s \\ n \", filename ); \n+ uwsgi_log ( \" unable to find \\\"% s \\\" callable in file % s \\ n \", callable , filename ); \nreturn NULL ; \n} \n \nif (! PyFunction_Check ( wsgi_file_callable ) && ! PyCallable_Check ( wsgi_file_callable )) { \n- uwsgi_log ( \"\\\" application \\\" must be a callable object in file % s \\ n \", filename ); \n+ uwsgi_log ( \"\\\"% s \\\" must be a callable object in file % s \\ n \", callable , filename ); \nPy_DECREF ( wsgi_file_callable ); \nPy_DECREF ( wsgi_file_dict ); \nPy_DECREF ( wsgi_file_module );", "mmm core / logging . c \nppp core / logging . c \nvoid logto ( char * logfile ) { \nuwsgi . logfile = logfile ; \n \nif ( uwsgi . chmod_logfile_value ) { \n- if ( chmod ( uwsgi . logfile , uwsgi . chmod_logfile_value )) { \n- uwsgi_error (\" chmod ()\"); \n+ if ( fchmod ( fd , uwsgi . chmod_logfile_value )) { \n+ uwsgi_error (\" fchmod ()\"); \n} \n} \n}", "mmm core / io . c \nppp core / io . c \nstatic char * uwsgi_scheme_section ( char * url , size_t * size , int add_zero ) { \n} \n \nstruct uwsgi_string_list * uwsgi_register_scheme ( char * name , char * (* func )( char *, size_t *, int )) { \n- struct uwsgi_string_list * usl = uwsgi_string_new_list (& uwsgi . schemes , name ); \n+ struct uwsgi_string_list * usl = NULL ; \n+ uwsgi_foreach ( usl , uwsgi . schemes ) { \n+ if (! strcmp ( usl -> value , name )) goto found ; \n+ } \n+ \n+ usl = uwsgi_string_new_list (& uwsgi . schemes , name ); \n+ \n+ found : \nusl -> custom_ptr = func ; \nreturn usl ; \n}", "mmm core / legion . c \nppp core / legion . c \nstatic void legions_check_nodes_step2 () { \nmemcpy ( best_uuid , node -> uuid , 36 ); \n} \n// go on if i am not an arbiter \n- else if ( ul -> valor > 0 ) { \n- // no potential Lord is available , i will propose myself \n- // but only if i am not suspended ... \n- if ( uwsgi_now () > ul -> suspended_til ) { \n- best_valor = ul -> valor ; \n- memcpy ( best_uuid , ul -> uuid , 36 ); \n- i_am_the_best = 1 ; \n- } \n+ // no potential Lord is available , i will propose myself \n+ // but only if i am not suspended ... \n+ else if ( ul -> valor > 0 && uwsgi_now () > ul -> suspended_til ) { \n+ best_valor = ul -> valor ; \n+ memcpy ( best_uuid , ul -> uuid , 36 ); \n+ i_am_the_best = 1 ; \n} \nelse { \n// empty lord", "mmm plugins / http / http . c \nppp plugins / http / http . c \nint http_parse ( struct http_session * h_session ) { \nhv = hv -> next ; \n} \n \n+ // security check \n+ if ( c >= MAX_HTTP_VEC - 4 ) { \n+ uwsgi_log (\" too much headers in request . skipping it .\\ n \"); \n+ return 0 ; \n+ } \n+ \nreturn c ; \n \n}", "mmm master . c \nppp master . c \nvoid master_loop ( char ** argv , char ** environ ) { \n// checking logsize \nif ( uwsgi . logfile ) { \nuwsgi . shared -> logsize = lseek ( 2 , 0 , SEEK_CUR ); \n- if ( uwsgi . shared -> logsize > 4096 ) { \n+ if ( uwsgi . shared -> logsize > 8192 ) { \nuwsgi_log (\" logsize : % d \\ n \", uwsgi . shared -> logsize ); \n+ char * new_logfile = uwsgi_malloc ( strlen ( uwsgi . logfile ) + 14 + 1 ); \n+ memset ( new_logfile , 0 , strlen ( uwsgi . logfile ) + 14 + 1 ); \n+ if (! rename ( uwsgi . logfile , new_logfile )) { \n+ // close 2 , reopen logfile dup ' it and gracefully reload workers ; \n+ } \n+ free ( new_logfile ); \n} \n} \n", "mmm core / master_utils . c \nppp core / master_utils . c \nint uwsgi_calc_cheaper ( void ) { \nignore_algo = 1 ; \n} \nuwsgi . cheaper_fifo_delta = 0 ; \n+ goto safe ; \n} \n \n// if cheaper limits wants to change worker count , then skip cheaper algo \nint uwsgi_calc_cheaper ( void ) { \nneeded_workers = 0 ; \n} \n \n+ safe : \nif ( needed_workers > 0 ) { \nfor ( i = 1 ; i <= uwsgi . numproc ; i ++) { \nif ( uwsgi . workers [ i ]. cheaped == 1 && uwsgi . workers [ i ]. pid == 0 ) {", "mmm plugins / v8 / v8_commonjs . cc \nppp plugins / v8 / v8_commonjs . cc \nstatic v8 :: Handle < v8 :: Value > uwsgi_v8_commonjs_require ( const v8 :: Arguments & \nfree ( tmp_filename ); \nreturn ret ; \n} \n+ free ( tmp_filename ); \n} \n- free ( tmp_filename ); \nusl = usl -> next ; \n} \n}", "mmm uwsgi . c \nppp uwsgi . c \nint uwsgi_start ( void * v_argv ) { \n# ifndef __OpenBSD__ \n \nif ( uwsgi . rl . rlim_max > 0 ) { \n+ uwsgi . rl . rlim_cur = uwsgi . rl . rlim_max ; \nuwsgi_log (\" limiting address space of processes ...\\ n \"); \nif ( setrlimit ( RLIMIT_AS , & uwsgi . rl )) { \nuwsgi_error (\" setrlimit ()\");", "mmm uwsgi . c \nppp uwsgi . c \nvoid uwsgi_opt_set_placeholder ( char * opt , char * value , void * none ) { \n \np [ 0 ] = 0 ; \nadd_exported_option ( uwsgi_str ( value ), p + 1 , 1 ); \n- p [ 1 ] = '='; \n+ p [ 0 ] = '='; \n \n} \n", "mmm plugins / mongrel2 / mongrel2 . c \nppp plugins / mongrel2 / mongrel2 . c \nstatic void mongrel2_connect () { \n} \nchar * responder = strchr ( uwsgi_sock -> name , ','); \nif (! responder ) { \n- uwsgi_log (\" invalid zeromq address \\ n \"); \n+ uwsgi_log (\" invalid zeromq address : % s \\ n \", uwsgi_sock -> name ); \nexit ( 1 ); \n} \nuwsgi_sock -> receiver = uwsgi_concat2n ( uwsgi_sock -> name , responder - uwsgi_sock -> name , \"\", 0 );", "mmm uwsgi . c \nppp uwsgi . c \nvoid reap_them_all ( int signum ) { \n} \n \nfor ( i = 0 ; i < uwsgi . mules_cnt ; i ++) { \n+ if (! uwsgi . mules ) break ; \nif ( uwsgi . mules [ i ]. pid > 0 ) \nkill ( uwsgi . mules [ i ]. pid , SIGKILL ); \n}", "mmm uwsgi . c \nppp uwsgi . c \nint main ( int argc , char * argv [], char * envp []) { \n \nplugins_requested = getenv (\" UWSGI_PLUGINS \"); \nif ( plugins_requested ) { \n+ plugins_requested = uwsgi_concat2 ( plugins_requested , \"\"); \nchar * p = strtok ( plugins_requested , \",\"); \nwhile ( p != NULL ) { \nuwsgi_load_plugin (- 1 , p , NULL , 0 ); \nstatic int manage_base_opt ( int i , char * optarg ) { \nuwsgi . allowed_modifiers = optarg ; \nreturn 1 ; \ncase LONG_ARGS_PLUGINS : \n- p = strtok ( optarg , \",\"); \n+ p = strtok ( uwsgi_concat2 ( optarg , \"\"), \",\"); \nwhile ( p != NULL ) { \n# ifdef UWSGI_DEBUG \nuwsgi_debug (\" loading plugin % s \\ n \", p );", "mmm core / mount . c \nppp core / mount . c \nint uwsgi_mount ( char * fs , char * what , char * where , char * flags , char * data ) { \nchar * mflags = uwsgi_str ( flags ); \nchar * p , * ctx = NULL ; \nuwsgi_foreach_token ( mflags , \",\", p , ctx ) { \n+ if ( strcmp ( p , \" defaults \") == 0 ) \n+ continue ; \nunsigned long flag = ( unsigned long ) uwsgi_mount_flag ( p ); \nif (! flag ) { \nuwsgi_log (\" unknown mount flag \\\"% s \\\"\\ n \", p ); \nint uwsgi_mount ( char * fs , char * what , char * where , char * flags , char * data ) { \n} \nmountflags |= flag ; \n} \n+ if (!* fs ) fs = NULL ; \nfree ( mflags ); \nparsed : \n# ifdef __linux__", "mmm plugins / python / pyutils . c \nppp plugins / python / pyutils . c \nvoid init_pyargv () { \n# endif \n \nup . argc = 1 ; \n- char * tmp_ptr = uwsgi_str ( up . argv ); \n+ if ( up . argv ) { \n+ char * tmp_ptr = uwsgi_str ( up . argv ); \n# ifdef __sun__ \n// FIX THIS !!! \nap = strtok ( tmp_ptr , \" \"); \nvoid init_pyargv () { \n} \n} \n \n- free ( tmp_ptr ); \n+ free ( tmp_ptr ); \n+ } \n \n# ifdef PYTHREE \nup . py_argv = uwsgi_calloc ( sizeof ( wchar_t *) * up . argc + 1 );", "mmm core / uwsgi . c \nppp core / uwsgi . c \nvoid * mem_collector ( void * foobar ) { \nuwsgi_log_verbose (\" mem - collector thread started for worker % d \\ n \", uwsgi . mywid ); \nfor (;;) { \nsleep ( uwsgi . mem_collector_freq ); \n- uint64_t rss , vsz ; \n+ uint64_t rss = 0 , vsz = 0 ; \nget_memusage (& rss , & vsz ); \nuwsgi . workers [ uwsgi . mywid ]. rss_size = rss ; \nuwsgi . workers [ uwsgi . mywid ]. vsz_size = vsz ;", "mmm plugins / router_rewrite / router_rewrite . c \nppp plugins / router_rewrite / router_rewrite . c \nstatic int uwsgi_routing_func_rewrite ( struct wsgi_request * wsgi_req , struct uwsg \nchar * ptr = uwsgi_req_append ( wsgi_req , \" PATH_INFO \", 9 , path_info , path_info_len ); \nif (! ptr ) goto clear ; \n \n+ free ( path_info ); \n+ \n// set new path_info \nwsgi_req -> path_info = ptr ; \nwsgi_req -> path_info_len = path_info_len ;", "mmm plugins / cgi / cgi_plugin . c \nppp plugins / cgi / cgi_plugin . c \nchar * uwsgi_cgi_get_docroot ( char * path_info , uint16_t path_info_len , int * need_f \n} \n \nif ( choosen_udd -> status == 0 ) { \n- char * tmp_udd = realpath ( path , NULL ); \n- if (! tmp_udd ) { \n+ char * tmp_udd = uwsgi_malloc ( PATH_MAX + 1 ); \n+ if (! realpath ( path , tmp_udd )) { \nreturn NULL ; \n} \n", "mmm core / utils . c \nppp core / utils . c \nvoid uwsgi_write_pidfile_explicit ( char * pidfile_name , pid_t pid ) { \n} \n \nchar * uwsgi_expand_path ( char * dir , int dir_len , char * ptr ) { \n- char src [ PATH_MAX + 1 ]; \n- memcpy ( src , dir , dir_len ); \n- src [ dir_len ] = 0 ; \n+ if ( dir_len > PATH_MAX ) \n+ { \n+ uwsgi_log (\" invalid path size : % d ( max % d )\\ n \", dir_len , PATH_MAX ); \n+ return NULL ; \n+ } \n+ char * src = uwsgi_concat2n ( dir , dir_len , \"\", 0 ); \nchar * dst = ptr ; \nif (! dst ) \ndst = uwsgi_malloc ( PATH_MAX + 1 ); \nchar * uwsgi_expand_path ( char * dir , int dir_len , char * ptr ) { \nuwsgi_error_realpath ( src ); \nif (! ptr ) \nfree ( dst ); \n+ free ( src ); \nreturn NULL ; \n} \n+ free ( src ); \nreturn dst ; \n} \n", "mmm plugins / python / python_plugin . c \nppp plugins / python / python_plugin . c \nvoid uwsgi_python_reset_random_seed () { \nvoid uwsgi_python_atexit () { \n \n// if hijacked do not run atexit hooks \n+ if ( uwsgi . workers [ uwsgi . mywid ]. hijacked ) \n+ return ; \n \n// this time we use this higher level function \n// as this code can be executed in a signal handler", "mmm plugins / python / python_plugin . c \nppp plugins / python / python_plugin . c \nvoid uwsgi_python_harakiri ( int wid ) { \nchar * address = uwsgi_concat2 ( up . tracebacker , uwsgi_num2str ( wid )); \n \nint fd = uwsgi_connect ( address , - 1 , 0 ); \n- for (;;) { \n+ while ( fd >= 0 ) { \nint ret = uwsgi_waitfd ( fd , uwsgi . shared -> options [ UWSGI_OPTION_SOCKET_TIMEOUT ]); \nif ( ret <= 0 ) { \nbreak ;", "mmm core / emperor . c \nppp core / emperor . c \nnext : \n} \n \nvoid uwsgi_emperor_simple_do_with_attrs ( struct uwsgi_emperor_scanner * ues , char * name , char * config , time_t ts , uid_t uid , gid_t gid , char * socket_name , struct uwsgi_dyn_dict * attrs ) { \n- if (! uwsgi_emperor_is_valid ( name )) \n+ if (! uwsgi_emperor_is_valid ( name )) { \n+ if ( attrs ) \n+ uwsgi_dyn_dict_free (& attrs ); \nreturn ; \n+ } \n \nstruct uwsgi_instance * ui_current = emperor_get ( name ); \n \nif ( ui_current ) { \n+ if ( ui_current -> attrs ) { \n+ uwsgi_dyn_dict_free (& ui_current -> attrs ); \n+ } \n+ ui_current -> attrs = attrs ; \n \n// skip in case the instance is going down ... \nif ( ui_current -> status > 0 )", "mmm core / master_utils . c \nppp core / master_utils . c \nstruct uwsgi_stats * uwsgi_master_generate_stats () { \nuc = uc -> next ; \n} \n \n+ if ( uwsgi_stats_list_close ( us )) \n+ goto end ; \n+ \nif ( uwsgi_stats_comma ( us )) \ngoto end ; \n}", "mmm core / utils . c \nppp core / utils . c \nchar * uwsgi_chomp2 ( char * str ) { \n \n \nint uwsgi_tmpfd () { \n+ int fd = - 1 ; \nchar * tmpdir = getenv (\" TMPDIR \"); \nif (! tmpdir ) { \ntmpdir = \"/ tmp \"; \n} \n+# ifdef O_TMPFILE \n+ fd = open ( tmpdir , O_TMPFILE | O_RDWR ); \n+ if ( fd >= 0 ) { \n+ return fd ; \n+ } \n+ // fallback to old style \n+# endif \nchar * template = uwsgi_concat2 ( tmpdir , \"/ uwsgiXXXXXX \"); \n- int fd = mkstemp ( template ); \n+ fd = mkstemp ( template ); \nunlink ( template ); \nfree ( template ); \nreturn fd ;", "mmm core / master_utils . c \nppp core / master_utils . c \nint uwsgi_respawn_worker ( int wid ) { \nfor ( i = 0 ; i < uwsgi . cores ; i ++) { \nuwsgi . workers [ uwsgi . mywid ]. cores [ i ]. in_request = 0 ; \nmemset (& uwsgi . workers [ uwsgi . mywid ]. cores [ i ]. req , 0 , sizeof ( struct wsgi_request )); \n+ memset ( uwsgi . workers [ uwsgi . mywid ]. cores [ i ]. buffer , 0 , sizeof ( struct uwsgi_header )); \n} \n \nuwsgi_fixup_fds ( wid , 0 , NULL );", "mmm core / fork_server . c \nppp core / fork_server . c \n \nextern struct uwsgi_server uwsgi ; \n \n+/* \n+ \n+ on connection retrieve the uid , gid and pid of the connecting process , in addition to up to 3 \n+ file descriptors ( emperor pipe , emperor pipe_config , on_demand socket dup ()' ed to 0 ) \n+ \n+ if authorized , double fork , get the pid of the second child and exit () \n+ its parent ( this will force the Emperor to became its subreaper ). \n+ \n+ from now on , we can consider the new child as a full - featured vassal \n+ \n+*/ \n+ \nvoid uwsgi_fork_server ( char * socket ) { \nint fd = bind_to_unix ( socket , uwsgi . listen_queue , uwsgi . chmod_socket , uwsgi . abstract_socket ); \nif ( fd < 0 ) exit ( 1 );", "mmm auth_mellon_util . c \nppp auth_mellon_util . c \nint am_check_url ( request_rec * r , const char * url ) \n\" Control character detected in URL .\"); \nreturn HTTP_BAD_REQUEST ; \n} \n+ if (* i == '\\\\') { \n+ /* Reject backslash character , as it can be used to bypass \n+ * redirect URL validation . */ \n+ AM_LOG_RERROR ( APLOG_MARK , APLOG_ERR , HTTP_BAD_REQUEST , r , \n+ \" Backslash character detected in URL .\"); \n+ return HTTP_BAD_REQUEST ; \n+ } \n} \n \nreturn OK ;", "mmm src / UriCommon . c \nppp src / UriCommon . c \n \n \nvoid URI_FUNC ( ResetUri )( URI_TYPE ( Uri ) * uri ) { \n+ if ( uri == NULL ) { \n+ return ; \n+ } \nmemset ( uri , 0 , sizeof ( URI_TYPE ( Uri ))); \n} \n", "mmm src / Server . cpp \nppp src / Server . cpp \nServer :: Server ( int port , bool master , int options , int maxPayload , SSLContext ss \nlistenPoll = new uv_poll_t ; \nlistenPoll -> data = this ; \n \n- if ( bind ( listenFd , ( sockaddr *) & listenAddr , sizeof ( sockaddr_in )) | listen ( listenFd , 10 )) { \n+ int on = 1 ; \n+ setsockopt ( listenFd , SOL_SOCKET , SO_REUSEADDR , & on , sizeof ( on )); \n+ \n+ if ( bind ( listenFd , ( sockaddr *) & listenAddr , sizeof ( sockaddr_in )) || listen ( listenFd , 10 )) { \nthrow ERR_LISTEN ; \n} \n", "mmm tools / tiff2ps . c \nppp tools / tiff2ps . c \nTIFF2PS ( FILE * fd , TIFF * tif , \nif (! generateEPSF && ( level2 || level3 )) { \nfprintf ( fd , \n\" 1 dict begin / PageSize [ % f % f ] def currentdict end setpagedevice \\ n \", \n- pw ? pw : ( rotate ? prh : prw ), \n- ph ? ph : ( rotate ? prw : prh )); \n+ pw ? pw * PS_UNIT_SIZE : ( rotate ? prh : prw ), \n+ ph ? ph * PS_UNIT_SIZE : ( rotate ? prw : prh )); \nfputs ( \n\"<<\\ n / Policies <<\\ n / PageSize 3 \\ n >>\\ n >> setpagedevice \\ n \", \nfd );", "mmm libtiff / tif_dir . c \nppp libtiff / tif_dir . c \n_TIFFVGetField ( TIFF * tif , ttag_t tag , va_list ap ) \n* va_arg ( ap , void **) = tv -> value ; \nret_val = 1 ; \n} else { \n- int i ; \n+ int j ; \nchar * val = ( char *) tv -> value ; \n \n- for ( i = 0 ; i < tv -> count ; \n- i ++, val += _TIFFDataSize ( fip -> field_type )) { \n+ for ( j = 0 ; j < tv -> count ; \n+ j ++, val += _TIFFDataSize ( tv -> info -> field_type )) { \nswitch ( fip -> field_type ) { \ncase TIFF_BYTE : \ncase TIFF_UNDEFINED :", "mmm libtiff / tif_dirread . c \nppp libtiff / tif_dirread . c \nEstimateStripByteCounts ( TIFF * tif , TIFFDirEntry * dir , uint16 dircount ) \ntd -> td_stripbytecount = ( uint64 *) \n_TIFFCheckMalloc ( tif , td -> td_nstrips , sizeof ( uint64 ), \n\" for \\\" StripByteCounts \\\" array \"); \n+ if ( td -> td_stripbytecount == NULL ) \n+ return - 1 ; \n+ \nif ( td -> td_compression != COMPRESSION_NONE ) { \nuint64 space ; \nuint64 filesize ;", "mmm tools / tiffcp . c \nppp tools / tiffcp . c \nDECLAREcpFunc ( cpDecodedStrips ) \ntstrip_t s , ns = TIFFNumberOfStrips ( in ); \nuint32 row = 0 ; \n_TIFFmemset ( buf , 0 , stripsize ); \n- for ( s = 0 ; s < ns ; s ++) { \n+ for ( s = 0 ; s < ns && row < imagelength ; s ++) { \ntsize_t cc = ( row + rowsperstrip > imagelength ) ? \nTIFFVStripSize ( in , imagelength - row ) : stripsize ; \nif ( TIFFReadEncodedStrip ( in , s , buf , cc ) < 0", "mmm tools / tiffcp . c \nppp tools / tiffcp . c \nDECLAREreadFunc ( readContigTilesIntoBuffer ) \nuint32 colb = 0 ; \nuint32 col ; \n \n- for ( col = 0 ; col < imagewidth ; col += tw ) { \n+ for ( col = 0 ; col < imagewidth && colb < imagew ; col += tw ) { \nif ( TIFFReadTile ( in , tilebuf , col , row , 0 , 0 ) < 0 \n&& ! ignore ) { \nTIFFError ( TIFFFileName ( in ), \nDECLAREwriteFunc ( writeBufferToContigTiles ) \nuint32 colb = 0 ; \nuint32 col ; \n \n- for ( col = 0 ; col < imagewidth ; col += tw ) { \n+ for ( col = 0 ; col < imagewidth && colb < imagew ; col += tw ) { \n/* \n* Tile is clipped horizontally . Calculate \n* visible portion and skewing factors .", "mmm libtiff / tif_aux . c \nppp libtiff / tif_aux . c \ntdata_t \n_TIFFCheckMalloc ( TIFF * tif , size_t nmemb , size_t elem_size , const char * what ) \n{ \n- tdata_t * cp = NULL ; \n+ tdata_t cp = NULL ; \ntsize_t bytes = nmemb * elem_size ; \n \n/*", "mmm tools / tiffcp . c \nppp tools / tiffcp . c \nbad : \n \nstatic void \ncpStripToTile ( uint8 * out , uint8 * in , \n- uint32 rows , uint32 cols , int outskew , int inskew ) \n+ uint32 rows , uint32 cols , int outskew , int64 inskew ) \n{ \nwhile ( rows -- > 0 ) { \nuint32 j = cols ; \nDECLAREreadFunc ( readContigTilesIntoBuffer ) \ntdata_t tilebuf ; \nuint32 imagew = TIFFScanlineSize ( in ); \nuint32 tilew = TIFFTileRowSize ( in ); \n- int iskew = imagew - tilew ; \n+ int64 iskew = ( int64 ) imagew - ( int64 ) tilew ; \nuint8 * bufp = ( uint8 *) buf ; \nuint32 tw , tl ; \nuint32 row ; \nDECLAREreadFunc ( readContigTilesIntoBuffer ) \nstatus = 0 ; \ngoto done ; \n} \n- if ( colb + tilew > imagew ) { \n+ if ( colb > iskew ) { \nuint32 width = imagew - colb ; \nuint32 oskew = tilew - width ; \ncpStripToTile ( bufp + colb ,", "mmm tools / tiffcrop . c \nppp tools / tiffcrop . c \nstatic int readContigStripsIntoBuffer ( TIFF * in , uint8 * buf ) \n( unsigned long ) strip , ( unsigned long ) rows ); \nreturn 0 ; \n} \n- bufp += bytes_read ; \n+ bufp += stripsize ; \n} \n \nreturn 1 ;", "mmm tools / tiffset . c \nppp tools / tiffset . c \n****************************************************************************** \n* \n* $ Log $ \n- * Revision 1 . 11 2005 - 09 - 13 14 : 13 : 42 dron \n+ * Revision 1 . 12 2007 - 02 - 24 17 : 14 : 14 dron \n+ * Properly handle tags with TIFF_VARIABLE writecount . As per bug \n+ * http :// bugzilla . remotesensing . org / show_bug . cgi ? id = 1350 \n+ * \n+ * Revision 1 . 11 2005 / 09 / 13 14 : 13 : 42 dron \n* Avoid warnings . \n* \n* Revision 1 . 10 2005 / 02 / 24 14 : 47 : 11 fwarmerdam \nmain ( int argc , char * argv []) \nif ( TIFFSetField ( tiff , fip -> field_tag , argv [ arg_index ]) != 1 ) \nfprintf ( stderr , \" Failed to set % s =% s \\ n \", \nfip -> field_name , argv [ arg_index ] ); \n- } else if ( fip -> field_writecount > 0 ) { \n+ } else if ( fip -> field_writecount > 0 \n+ || fip -> field_writecount == TIFF_VARIABLE ) { \nint ret = 1 ; \nshort wc ; \n", "mmm libtiff / tif_jpeg . c \nppp libtiff / tif_jpeg . c \nJPEGVSetField ( TIFF * tif , ttag_t tag , va_list ap ) \ncase TIFFTAG_JPEGTABLESMODE : \nsp -> jpegtablesmode = va_arg ( ap , int ); \nreturn ( 1 ); /* pseudo tag */ \n+ case TIFFTAG_YCBCRSUBSAMPLING : \n+ /* mark the fact that we have a real ycbcrsubsampling ! */ \n+ sp -> ycbcrsampling_fetched = 1 ; \n+ return (* sp -> vsetparent )( tif , tag , ap ); \ndefault : \nreturn (* sp -> vsetparent )( tif , tag , ap ); \n} \nJPEGVSetField ( TIFF * tif , ttag_t tag , va_list ap ) \n* loaded just to get the tags right , even if the imagery is never read . \n* It would be more efficient to just load a bit of the header , and \n* initialize things from that . \n- * o This code doesn ' t know whether or not the tag actually did occur in \n- * the file . If it knew this it could skip the hack but this is hard to \n- * know since we have already set the \" field set \" bit for the subsampling \n- * TIFFInitJPEG (). \n* \n* See the bug in bugzilla for details : \n* \nJPEGFixupTestSubsampling ( TIFF * tif ) \n* jpeg data to get the sampling . \n*/ \nif ( ! sp -> cinfo . comm . is_decompressor \n- || sp -> ycbcrsampling_fetched ) \n+ || sp -> ycbcrsampling_fetched \n+ || sp -> photometric != PHOTOMETRIC_YCBCR ) \nreturn ; \n \nsp -> ycbcrsampling_fetched = 1 ;", "mmm libtiff / tiffiop . h \nppp libtiff / tiffiop . h \nstruct tiff { \n*/ \n# ifndef ReadOK \n# define ReadOK ( tif , buf , size ) \\ \n- ( TIFFReadFile ( tif , ( tdata_t ) buf , ( tsize_t ) size ) == ( tsize_t ) size ) \n+ ( TIFFReadFile ( tif , ( tdata_t ) buf , ( tsize_t )( size )) == ( tsize_t )( size )) \n# endif \n# ifndef SeekOK \n# define SeekOK ( tif , off ) \\", "mmm bin / varnishd / cache_center . c \nppp bin / varnishd / cache_center . c \ncnt_recv ( struct sess * sp ) \nreturn ( 0 ); \n} \n \n+ if ( params -> http_gzip_support && \n+ ( recv_handling != VCL_RET_PIPE ) && \n+ ( recv_handling != VCL_RET_PASS )) { \n+ if ( RFC2616_Req_Gzip ( sp )) { \n+ http_Unset ( sp -> http , H_Accept_Encoding ); \n+ http_PrintfHeader ( sp -> wrk , sp -> fd , sp -> http , \n+ \" Accept - Encoding : gzip \"); \n+ } else { \n+ http_Unset ( sp -> http , H_Accept_Encoding ); \n+ } \n+ } \n+ \nSHA256_Init ( sp -> wrk -> sha256ctx ); \nVCL_hash_method ( sp ); \nassert ( sp -> handling == VCL_RET_HASH );", "mmm lib / libvarnish / vcli_proto . c \nppp lib / libvarnish / vcli_proto . c \nread_tmo ( int fd , char * ptr , unsigned len , double tmo ) \npfd . events = POLLIN ; \nfor ( j = 0 ; len > 0 ; ) { \ni = poll (& pfd , 1 , to ); \n+ if ( i < 0 ) { \n+ errno = EINTR ; \n+ return (- 1 ); \n+ } \nif ( i == 0 ) { \nerrno = ETIMEDOUT ; \nreturn (- 1 );", "mmm bin / varnishd / cache_expire . c \nppp bin / varnishd / cache_expire . c \nEXP_Touch ( const struct object * o , double now ) \n \nCHECK_OBJ_NOTNULL ( o , OBJECT_MAGIC ); \noe = o -> objexp ; \n+ if ( oe == NULL ) \n+ return ; \nCHECK_OBJ_NOTNULL ( oe , OBJEXP_MAGIC ); \nif ( oe -> lru_stamp + params -> lru_timeout > now ) \nreturn ;", "mmm bin / varnishd / cache_waiter_poll . c \nppp bin / varnishd / cache_waiter_poll . c \nvca_main ( void * arg ) \nif ( pollfd [ fd ]. revents ) { \nv --; \ni = HTC_Rx ( sp -> htc ); \n+ if ( pollfd [ fd ]. revents != POLLIN ) \n+ VSL ( SLT_Debug , fd , \" Poll : % x / % d \", \n+ pollfd [ fd ]. revents , i ); \nVTAILQ_REMOVE (& sesshead , sp , list ); \nif ( i == 0 ) { \n/* Mov to front of list for speed */ \nvca_main ( void * arg ) \nSES_Delete ( sp ); \n} \n} \n+ assert ( v == 0 ); \n} \nNEEDLESS_RETURN ( NULL ); \n}", "mmm bin / varnishd / mgt_child . c \nppp bin / varnishd / mgt_child . c \nmgt_run ( int dflag , const char * T_arg ) \n \nsetproctitle (\" Varnish - Mgr % s \", heritage . name ); \n \n+ memset (& sac , 0 , sizeof sac ); \nsac . sa_handler = SIG_IGN ; \nsac . sa_flags = SA_RESTART ; \n", "mmm lib / libvarnish / vrnd . c \nppp lib / libvarnish / vrnd . c \nVRND_CryptoQuality ( void * ptr , size_t len ) \nssize_t l ; \n \nAN ( ptr ); \n- fd = open (\"/ dev / random \", O_RDONLY ); \n+ fd = open (\"/ dev / urandom \", O_RDONLY ); \nif ( fd < 0 ) \nreturn (- 1 ); \nfor ( p = ptr ; len > 0 ; len --, p ++) {", "mmm bin / varnishd / cache_hash . c \nppp bin / varnishd / cache_hash . c \nHSH_FindBan ( struct sess * sp , struct objcore ** oc ) \nCHECK_OBJ_NOTNULL ( oc1 , OBJCORE_MAGIC ); \noh = oc1 -> objhead ; \nCHECK_OBJ_NOTNULL ( oh , OBJHEAD_MAGIC ); \n- Lck_Lock (& oh -> mtx ); \n+ if ( Lck_Trylock (& oh -> mtx )) { \n+ * oc = NULL ; \n+ return ; \n+ } \nVTAILQ_FOREACH ( oc2 , & oh -> objcs , list ) \nif ( oc1 == oc2 ) \nbreak ;", "mmm bin / varnishd / storage_persistent_subr . c \nppp bin / varnishd / storage_persistent_subr . c \nsmp_def_sign ( const struct smp_sc * sc , struct smp_signctx * ctx , \nAZ ( off & 7 ); /* Alignment */ \nassert ( strlen ( id ) < sizeof ctx -> ss -> ident ); \n \n- memset ( ctx , 0 , sizeof ctx ); \n+ memset ( ctx , 0 , sizeof * ctx ); \nctx -> ss = ( void *)( sc -> base + off ); \nctx -> unique = sc -> unique ; \nctx -> id = id ;", "mmm bin / varnishd / cache_center . c \nppp bin / varnishd / cache_center . c \ncnt_fetch ( struct sess * sp ) \n* Space for producing a Content - Length : header including padding \n* A billion gigabytes is enough for anybody . \n*/ \n- l += strlen (\" Content - Length : XxxXxxXxxXxxXxxXxx \" + sizeof ( void *)); \n+ l += strlen (\" Content - Length : XxxXxxXxxXxxXxxXxx \") + sizeof ( void *); \n \nif ( sp -> wrk -> ttl < sp -> t_req + params -> shortlived || \nsp -> objcore == NULL )", "mmm bin / varnishd / cache / cache_backend_cfg . c \nppp bin / varnishd / cache / cache_backend_cfg . c \ncli_backend_set_health ( struct cli * cli , const char * const * av , void * priv ) \n \nstatic struct cli_proto backend_cmds [] = { \n{ \" backend . list \", \" backend . list \", \n- \"\\ tList all backends \\ n \", 0 , 1 , \" d \", cli_backend_list }, \n+ \"\\ tList all backends \\ n \", 0 , 1 , \"\", cli_backend_list }, \n{ \" backend . set_health \", \" backend . set_health matcher state \", \n- \"\\ tShow a backend \\ n \", 2 , 2 , \" d \", cli_backend_set_health }, \n+ \"\\ tShow a backend \\ n \", 2 , 2 , \"\", cli_backend_set_health }, \n{ NULL } \n}; \n", "mmm bin / varnishncsa / varnishncsa . c \nppp bin / varnishncsa / varnishncsa . c \ntrimline ( const char * str , const char * end ) \n/* nothing */ ; \n \n/* trim trailing space */ \n- while ( str [ len - 1 ] == ' ') \n+ while ( len && str [ len - 1 ] == ' ') \n-- len ; \n \n/* copy and return */", "mmm bin / varnishd / varnishd . c \nppp bin / varnishd / varnishd . c \nmain ( int argc , char * const * argv ) \nif ( b_arg != NULL && f_arg != NULL ) { \nfprintf ( stderr , \" Only one of - b or - f can be specified \\ n \"); \nusage (); \n- } else if ( S_arg == NULL && T_arg == NULL ) { \n+ } \n+ if ( S_arg == NULL && T_arg == NULL && d_flag == 0 && b_arg == NULL && \n+ f_arg == NULL ) { \nfprintf ( stderr , \n\" At least one of - d , - b , - f , - S or - T must be specified \\ n \"); \nusage ();", "mmm bin / varnishd / cache_session . c \nppp bin / varnishd / cache_session . c \nSES_RefSrcAddr ( struct sess * sp ) \nc3 = c ; \ncontinue ; \n} \n- TAILQ_REMOVE ( ch , c2 , list ); \n- free ( c2 ); \n+ TAILQ_REMOVE ( ch , c , list ); \n+ free ( c ); \nVSL_stats -> n_srcaddr --; \n} \nif ( c3 == NULL ) {", "mmm bin / varnishd / cache_httpd . c \nppp bin / varnishd / cache_httpd . c \nHttpdAnalyze ( struct sess * sp ) \n \nsp -> handling = HND_Unclass ; \n \n+ memset (& sp -> http , 0 , sizeof sp -> http ); \n+ \n/* First , isolate and possibly identify request type */ \nsp -> http . req = sp -> rcv ; \nfor ( p = sp -> rcv ; isalpha (* p ); p ++) \nHttpdAnalyze ( struct sess * sp ) \nif (* p == '\\ r ') \np ++; \n \n- memset (& sp -> http , 0 , sizeof sp -> http ); \n- \nfor (; p < sp -> rcv + sp -> rcv_len ; p = r ) { \nq = strchr ( p , '\\ n '); \nr = q + 1 ;", "mmm bin / varnishd / cache / cache_req_fsm . c \nppp bin / varnishd / cache / cache_req_fsm . c \nCNT_AcctLogCharge ( struct dstat * ds , struct req * req ) \n \na = & req -> acct ; \n \n- if (!( req -> res_mode & RES_PIPE )) { \n+ if ( req -> vsl -> wid && !( req -> res_mode & RES_PIPE )) { \nVSLb ( req -> vsl , SLT_ReqAcct , \"% ju % ju % ju % ju % ju % ju \", \n( uintmax_t ) a -> req_hdrbytes , \n( uintmax_t ) a -> req_bodybytes ,", "mmm bin / varnishd / cache_pool . c \nppp bin / varnishd / cache_pool . c \nWRK_QueueSession ( struct sess * sp ) \nunsigned onq ; \n \nonq = nq + 1 ; \n- if ( onq > nwq ) \n+ if ( onq >= nwq ) \nonq = 0 ; \nsp -> workreq . sess = sp ; \nqp = wq [ onq ];", "mmm bin / varnishd / cache_hash . c \nppp bin / varnishd / cache_hash . c \nHSH_Deref ( struct object * o ) \n} \nassert ( o -> refcnt > 0 ); \nr = -- o -> refcnt ; \n- hsh_rush ( oh ); \n+ if ( oh != NULL ) \n+ hsh_rush ( oh ); \nif ( oh != NULL ) { \nif (! r ) \nVTAILQ_REMOVE (& oh -> objects , o , list );", "mmm lib / libvmod_directors / shard_cfg . c \nppp lib / libvmod_directors / shard_cfg . c \nshardcfg_backend_cmp ( const struct shard_backend * a , \nai = a -> ident ; \nbi = b -> ident ; \n \n+ assert ( ai || a -> backend ); \n+ assert ( bi || b -> backend ); \n+ \n/* vcl_names are unique , so we can compare the backend pointers */ \nif ( ai == NULL && bi == NULL ) \nreturn a -> backend != b -> backend ; \nstatic int \nshardcfg_backend_del_cmp ( const struct shard_backend * task , \nconst struct shard_backend * b ) \n{ \n- if ( task -> backend && task -> ident == NULL ) \n+ assert ( task -> backend || task -> ident ); \n+ \n+ if ( task -> ident == NULL ) \nreturn task -> backend != b -> backend ; \n \nreturn shardcfg_backend_cmp ( task , b );", "mmm bin / varnishd / mgt_event . c \nppp bin / varnishd / mgt_event . c \nev_compact_pfd ( struct evbase * evb ) \nDBG ( evb , \"...[% d ] fd = % d \\ n \", u , p -> fd ); \nif ( p -> fd >= 0 ) \ncontinue ; \n+ if ( u == evb -> lpfd - 1 ) \n+ break ; \nlfd = evb -> pfd [ evb -> lpfd - 1 ]. fd ; \nVTAILQ_FOREACH ( ep , & evb -> events , __list ) \nif ( ep -> fd == lfd )", "mmm bin / varnishd / cache / cache_vrt . c \nppp bin / varnishd / cache / cache_vrt . c \nVRT_acl_log ( VRT_CTX , const char * msg ) \n{ \n \nCHECK_OBJ_NOTNULL ( ctx , VRT_CTX_MAGIC ); \n- VSLb ( ctx -> vsl , SLT_VCL_acl , \"% s \", msg ); \n+ AN ( msg ); \n+ if ( ctx -> vsl != NULL ) \n+ VSLb ( ctx -> vsl , SLT_VCL_acl , \"% s \", msg ); \n+ else \n+ VSL ( SLT_VCL_acl , 0 , \"% s \", msg ); \n} \n \n/*--------------------------------------------------------------------*/", "mmm bin / varnishd / cache_fetch . c \nppp bin / varnishd / cache_fetch . c \nFetchBody ( struct sess * sp ) \n} else \ncls = 0 ; \n \n+ { \n+ /* Sanity check fetch methods accounting */ \n+ struct storage * st ; \n+ unsigned uu ; \n+ \n+ uu = 0 ; \n+ TAILQ_FOREACH ( st , & sp -> obj -> store , list ) \n+ uu += st -> len ; \n+ assert ( uu == sp -> obj -> len ); \n+ } \n+ \nhttp_CopyHttp (& sp -> obj -> http , hp ); \n \nif ( http_GetHdr ( vc -> http , H_Connection , & b ) && ! strcasecmp ( b , \" close \"))", "mmm bin / varnishhist / varnishhist . c \nppp bin / varnishhist / varnishhist . c \nr_hist ( void ) \nr = y * m ; \nfor ( x = 0 ; x < HIST_W ; x ++) { \nif ( bucket_miss [ x ] > r ) \n- addch ('|'); \n- else if ( bucket_hit [ x ] + bucket_miss [ x ] > r ) \naddch ('#'); \n+ else if ( bucket_hit [ x ] + bucket_miss [ x ] > r ) \n+ addch ('|'); \nelse \naddch (' '); \n}", "mmm bin / varnishd / waiter / cache_waiter_kqueue . c \nppp bin / varnishd / waiter / cache_waiter_kqueue . c \nvwk_fini ( struct waiter * w ) \nvwk -> kq = - 1 ; \nLck_Unlock (& vwk -> mtx ); \nAZ ( pthread_join ( vwk -> thread , & vp )); \n+ Lck_Delete (& vwk -> mtx ); \n} \n \n/*--------------------------------------------------------------------*/", "mmm bin / varnishd / varnishd . c \nppp bin / varnishd / varnishd . c \nDebugStunt ( void ) \nd_child = strtoul ( buf , & p , 0 ); \nassert ( p != NULL ); \nprintf (\" New Pid % d \\ n \", d_child ); \n+ assert ( d_child != 0 ); \ni = strlen ( p ); \nj = write ( pipes [ 1 ][ 1 ], p , i ); \nassert ( j == i );", "mmm bin / varnishd / mgt / mgt_shmem . c \nppp bin / varnishd / mgt / mgt_shmem . c \nvoid \nmgt_shm_atexit ( void ) \n{ \n \n+ /* Do not let VCC kill our VSM */ \n+ if ( getpid () != mgt_pid ) \n+ return ; \nif ( heritage . vsm != NULL ) \nVSM_common_delete (& heritage . vsm ); \n}", "mmm bin / varnishd / cache / cache_vary . c \nppp bin / varnishd / cache / cache_vary . c \nVRY_Match ( struct req * req , const uint8_t * vary ) \nvsp [ ln + 1 ] = 0xff ; \nvsp [ ln + 2 ] = 0 ; \nVRY_Validate ( vsp ); \n- req -> vary_l = vsp + 3 ; \n+ req -> vary_l = vsp + ln + 3 ; \n \ni = vry_cmp ( vary , vsp ); \nassert ( i == 0 || i == 2 );", "mmm bin / varnishd / cache / cache_center . c \nppp bin / varnishd / cache / cache_center . c \ncnt_prepresp ( struct sess * sp , struct worker * wrk , struct req * req ) \nbreak ; \nif ( bo != NULL ) { \nAN ( bo -> do_stream ); \n- VDI_CloseFd (& bo -> vbc ); \nHSH_Drop ( wrk , & sp -> req -> obj ); \nVBO_DerefBusyObj ( wrk , & bo ); \n} else {", "mmm lib / libvcc / vcc_action . c \nppp lib / libvcc / vcc_action . c \nparse_new ( struct vcc * tl ) \nvcc_ErrWhere ( tl , tl -> t ); \nreturn ; \n} \n- XXXAZ ( sy1 ); \n \nsy1 = VCC_AddSymbolTok ( tl , tl -> t , SYM_NONE ); // XXX : NONE ? \nXXXAN ( sy1 );", "mmm bin / varnishd / tcp . c \nppp bin / varnishd / tcp . c \n# include < errno . h > \n# include < netdb . h > \n# include < stdio . h > \n+# include < stdlib . h > \n# include < string . h > \n# include < unistd . h > \n \naccept_filter ( int fd ) \n} \n# endif \n \n+ static char * \n+ strndup ( const char * p , unsigned n ) \n+{ \n+ char * q ; \n+ \n+ q = malloc ( n + 1 ); \n+ if ( q != NULL ) { \n+ memcpy ( q , p , n ); \n+ q [ n ] = '\\ 0 '; \n+ } \n+ return ( q ); \n+} \n+ \nint \nTCP_parse ( const char * str , char ** addr , char ** port ) \n{", "mmm bin / varnishd / cache / cache_director . c \nppp bin / varnishd / cache / cache_director . c \ndo_list ( struct cli * cli , struct director * d , void * priv ) \nif ( d -> vdir -> admin_health == VDI_AH_DELETED ) \nreturn ( 0 ); \n \n+ // XXX admin health \" probe \" for the no - probe case is confusing \nVCLI_Out ( cli , \"\\ n %- 30s %- 7s \", d -> vdir -> cli_name , VDI_Ahealth ( d )); \n \nif ( d -> vdir -> methods -> list != NULL )", "mmm bin / varnishd / cache_http . c \nppp bin / varnishd / cache_http . c \nhttp_Read ( struct http * hp , int fd , void * p , unsigned len ) \nb += u ; \nlen -= u ; \n} \n- if ( len > 0 ) { \n+ while ( len > 0 ) { \ni = read ( fd , b , len ); \n- if ( i < 0 ) \n+ if ( i <= 0 ) \nreturn ( i ); \nu += i ; \n+ len -= u ; \n} \nreturn ( u ); \n}", "mmm bin / varnishncsa / varnishncsa . c \nppp bin / varnishncsa / varnishncsa . c \ndispatch_f ( struct VSL_data * vsl , struct VSL_transaction * const pt [], \nfor ( t = pt [ 0 ]; t != NULL ; t = *++ pt ) { \nCTX . gen ++; \nif ( t -> type != VSL_t_req ) \n+ /* Only look at client requests */ \n+ continue ; \n+ if ( t -> reason == VSL_r_esi ) \n+ /* Skip ESI requests */ \ncontinue ; \nCTX . hitmiss = \"-\"; \nCTX . handling = \"-\";", "mmm src / txn . cpp \nppp src / txn . cpp \nNan :: NAN_METHOD_RETURN_TYPE TxnWrap :: putCommon ( Nan :: NAN_METHOD_ARGS_TYPE info , v \n} \n \nNAN_METHOD ( TxnWrap :: putString ) { \n+ if (! info [ 2 ]-> IsString ()) \n+ return Nan :: ThrowError (\" Value must be a string .\"); \nreturn putCommon ( info , []( Nan :: NAN_METHOD_ARGS_TYPE info , MDB_val & data ) -> void { \nCustomExternalStringResource :: writeTo ( Local < String >:: Cast ( info [ 2 ]), & data ); \n}, []( MDB_val & data ) -> void {", "mmm modules / codec / schroedinger . c \nppp modules / codec / schroedinger . c \nstatic block_t * Encode ( encoder_t * p_enc , picture_t * p_pic ) \n* is appended to the sequence header to allow guard \n* against poor streaming servers */ \n/* XXX , should this be done using the packetizer ? */ \n+ \n+ if ( len > UINT32_MAX - sizeof ( eos ) ) \n+ return NULL ; \n+ \np_enc -> fmt_out . p_extra = malloc ( len + sizeof ( eos ) ); \nif ( ! p_enc -> fmt_out . p_extra ) \nreturn NULL ;", "mmm src / misc / update . c \nppp src / misc / update . c \nstatic bool GetUpdateFile ( update_t * p_update ) \n} \n \nconst int64_t i_read = stream_Size ( p_stream ); \n+ \n+ if ( i_read < 0 || i_read >= UINT16_MAX ) \n+ { \n+ msg_Err ( p_update -> p_libvlc , \" Status file too large \"); \n+ goto error ; \n+ } \n+ \npsz_update_data = malloc ( i_read + 1 ); /* terminating '\\ 0 ' */ \nif ( ! psz_update_data ) \ngoto error ;", "mmm libyara / modules / pe . c \nppp libyara / modules / pe . c \nIMPORTED_FUNCTION * pe_parse_import_descriptor ( \nIMPORTED_FUNCTION * imported_func = ( IMPORTED_FUNCTION *) \nyr_calloc ( 1 , sizeof ( IMPORTED_FUNCTION )); \n \n+ if (! imported_func ) \n+ continue ; \n+ \nimported_func -> name = name ; \nimported_func -> next = NULL ; \n \nIMPORTED_FUNCTION * pe_parse_import_descriptor ( \nIMPORTED_FUNCTION * imported_func = ( IMPORTED_FUNCTION *) \nyr_calloc ( 1 , sizeof ( IMPORTED_FUNCTION )); \n \n+ if (! imported_func ) \n+ continue ; \n+ \nimported_func -> name = name ; \nimported_func -> next = NULL ; \n", "mmm libyara / modules / pe . c \nppp libyara / modules / pe . c \nvoid pe_parse_version_info ( \n \nversion_info = ( PVERSION_INFO ) ( pe -> data + version_info_offset ); \n \n- if (! fits_in_pe ( pe , version_info -> Key , sizeof (\" VS_VERSION_INFO \"))) \n+ if (! fits_in_pe ( pe , version_info -> Key , sizeof (\" VS_VERSION_INFO \") * 2 )) \nreturn ; \n \nif ( strcmp_w ( version_info -> Key , \" VS_VERSION_INFO \") != 0 ) \nvoid pe_parse_version_info ( \n \nstring_file_info = ADD_OFFSET ( version_info , sizeof ( VERSION_INFO ) + 86 ); \n \n- while ( fits_in_pe ( pe , string_file_info -> Key , sizeof (\" StringFileInfo \")) && \n+ while ( fits_in_pe ( pe , string_file_info -> Key , sizeof (\" StringFileInfo \") * 2 ) && \nstrcmp_w ( string_file_info -> Key , \" StringFileInfo \") == 0 ) \n{ \nPVERSION_INFO string_table = ADD_OFFSET (", "mmm libyara / ast . c \nppp libyara / ast . c \nvoid free_term ( TERM * term ) \n \nfree_term ((( TERM_STRING *) term )-> offset ); \nbreak ; \n+ \n+ case TERM_TYPE_STRING_OFFSET : \n+ \n+ free_term ((( TERM_STRING *) term )-> index ); \n+ break ; \n \ncase TERM_TYPE_STRING_IN_RANGE : \n", "mmm common . h \nppp common . h \nbool compile_files ( \n{ \nfor ( int i = 0 ; i < argc - 1 ; i ++) \n{ \n+ FILE * rule_file ; \nconst char * ns ; \nconst char * file_name ; \nchar * colon = ( char *) strchr ( argv [ i ], ':'); \nbool compile_files ( \nns = NULL ; \n} \n \n- FILE * rule_file = fopen ( file_name , \" r \"); \n+ if ( strcmp ( file_name , \"-\") == 0 ) \n+ rule_file = stdin ; \n+ else \n+ rule_file = fopen ( file_name , \" r \"); \n \nif ( rule_file == NULL ) \n{", "mmm libyara / modules / pe . c \nppp libyara / modules / pe . c \nPIMAGE_DATA_DIRECTORY pe_get_directory_entry ( \n{ \nPIMAGE_DATA_DIRECTORY result ; \n \n- if ( pe -> header -> FileHeader . Machine == 0x8664 ) // is a 64 - bit PE ? \n+ if ( pe -> header -> FileHeader . Machine == IMAGE_FILE_MACHINE_AMD64 ) \nresult = &(( PIMAGE_NT_HEADERS64 ) pe -> header )-> \nOptionalHeader . DataDirectory [ entry ]; \nelse \nvoid pe_parse ( \nchar section_name [ IMAGE_SIZEOF_SHORT_NAME + 1 ]; \n \n# define OptionalHeader ( field ) \\ \n- ( pe -> header -> FileHeader . Machine == 0x8664 ? \\ \n+ ( pe -> header -> FileHeader . Machine == IMAGE_FILE_MACHINE_AMD64 ? \\ \n(( PIMAGE_NT_HEADERS64 ) pe -> header )-> OptionalHeader . field : \\ \npe -> header -> OptionalHeader . field ) \n", "mmm libyara / modules / pe . c \nppp libyara / modules / pe . c \nIMPORTED_FUNCTION * pe_parse_import_descriptor ( \n// I ' ve seen binaries where OriginalFirstThunk is zero . In this case \n// use FirstThunk . \n \n- if ( offset < 0 ) \n+ if ( offset <= 0 ) \noffset = pe_rva_to_offset ( pe , import_descriptor -> FirstThunk ); \n \nif ( offset < 0 )", "mmm ext / redcarpet / html . c \nppp ext / redcarpet / html . c \nrndr_quote ( struct buf * ob , const struct buf * text , void * opaque ) \nif (! text || ! text -> size ) \nreturn 0 ; \n \n+ struct html_renderopt * options = opaque ; \n+ \nBUFPUTSL ( ob , \"< q >\"); \n- bufput ( ob , text -> data , text -> size ); \n+ \n+ if ( options -> flags & HTML_ESCAPE ) \n+ escape_html ( ob , text -> data , text -> size ); \n+ else \n+ bufput ( ob , text -> data , text -> size ); \n+ \nBUFPUTSL ( ob , \"</ q >\"); \n \nreturn 1 ;", "mmm src / ui . cpp \nppp src / ui . cpp \npublic : \nif ( ms_uiThread ) \n{ \nms_uiThread -> Join (); \n+ delete ms_uiThread ; \nms_uiThread = NULL ; \n} \n}", "mmm src / ui . cpp \nppp src / ui . cpp \nvoid CenterWindowOnHostApplication ( wxTopLevelWindow * win ) \nEnumWindows ( EnumProcessWindowsCallback , ( LPARAM ) & data ); \n \nif ( data . biggest . IsEmpty ()) \n- return ; // no window to center on \n+ { \n+ // no parent window to center on , so center on the screen \n+ win -> Center (); \n+ return ; \n+ } \n \nconst wxRect & host ( data . biggest ); \n", "mmm src / ui . cpp \nppp src / ui . cpp \nBOOL CALLBACK EnumProcessWindowsCallback ( HWND handle , LPARAM lParam ) \n \nRECT rwin ; \nGetWindowRect ( handle , & rwin ); \n+ if ( MonitorFromRect (& rwin , MONITOR_DEFAULTTONULL ) == NULL ) \n+ return TRUE ; // window is offscreen \n+ \nwxRect r ( rwin . left , rwin . top , rwin . right - rwin . left , rwin . bottom - rwin . top ); \nif ( r . width * r . height > data . biggest . width * data . biggest . height ) \ndata . biggest = r ;", "mmm src / gui / curses / gui - curses - chat . c \nppp src / gui / curses / gui - curses - chat . c \ngui_chat_draw ( struct t_gui_buffer * buffer , int clear_chat ) \n \nif ( clear_chat ) \n{ \n- snprintf ( format_empty , 32 , \"%%-% ds \", ptr_win -> win_chat_width ); \n+ snprintf ( format_empty , sizeof ( format_empty ), \n+ \"%%-% ds \", ptr_win -> win_chat_width ); \nfor ( i = 0 ; i < ptr_win -> win_chat_height ; i ++) \n{ \nmvwprintw ( GUI_WINDOW_OBJECTS ( ptr_win )-> win_chat , i , 0 ,", "mmm src / plugins / irc / irc - ctcp . c \nppp src / plugins / irc / irc - ctcp . c \nirc_ctcp_dcc_filename_without_quotes ( const char * filename ) \nint length ; \n \nlength = strlen ( filename ); \n- if ( length > 0 ) \n+ if ( length > 1 ) \n{ \nif (( filename [ 0 ] == '\\\"') && ( filename [ length - 1 ] == '\\\"')) \nreturn weechat_strndup ( filename + 1 , length - 2 );", "mmm src / plugins / irc / irc - mode . c \nppp src / plugins / irc / irc - mode . c \nirc_mode_channel_set ( struct t_irc_server * server , \nint smart_filter ; \nstruct t_irc_nick * ptr_nick ; \nstruct t_irc_modelist * ptr_modelist ; \n+ struct t_irc_modelist_item * ptr_item ; \n \nif (! server || ! channel || ! modes ) \nreturn 0 ; \nirc_mode_channel_set ( struct t_irc_server * server , \n} \nelse if ( set_flag == '-') \n{ \n- irc_modelist_item_free ( ptr_modelist , \n- irc_modelist_item_search ( ptr_modelist , ptr_arg )); \n+ ptr_item = irc_modelist_item_search ( ptr_modelist , \n+ ptr_arg ); \n+ if ( ptr_item ) \n+ irc_modelist_item_free ( ptr_modelist , ptr_item ); \n} \n} \n}", "mmm src / core / wee - string . c \nppp src / core / wee - string . c \nstring_replace_regex ( const char * string , void * regex , const char * replace , \nint length , length_replace , start_offset , i , rc , end , last_match ; \nregmatch_t regex_match [ 100 ]; \n \n- if (! string ) \n+ if (! string || ! regex ) \nreturn NULL ; \n \nlength = strlen ( string ) + 1 ;", "mmm src / gui / curses / gui - curses - bar - window . c \nppp src / gui / curses / gui - curses - bar - window . c \ngui_bar_window_draw ( struct t_gui_bar_window * bar_window , \n \n/* move cursor if it was asked in an item content ( input_text does that \nto move cursor in user input text ) */ \n- if ( window && ( gui_current_window == window ) \n+ if ((! window || ( gui_current_window == window )) \n&& ( bar_window -> cursor_x >= 0 ) && ( bar_window -> cursor_y >= 0 )) \n{ \nmove ( bar_window -> cursor_y , bar_window -> cursor_x );", "mmm src / plugins / irc / irc - command . c \nppp src / plugins / irc / irc - command . c \nirc_command_server ( void * data , struct t_gui_buffer * buffer , int argc , \nif ( irc_current_server ) \n{ \nptr_server = irc_current_server -> next_server ; \n+ if (! ptr_server ) \n+ ptr_server = irc_servers ; \nwhile ( ptr_server != irc_current_server ) \n{ \nif ( ptr_server -> buffer )", "mmm src / plugins / irc / irc - server . c \nppp src / plugins / irc / irc - server . c \nirc_server_msgq_flush () \n/* new_msg = plugin_modifier_exec ( PLUGIN_MODIFIER_IRC_IN , \nirc_recv_msgq -> server -> name , \nptr_data );*/ \n+ new_msg = NULL ; \n+ \n/* no changes in new message */ \nif ( new_msg && ( strcmp ( ptr_data , new_msg ) == 0 )) \n{", "mmm src / plugins / trigger / trigger - callback . c \nppp src / plugins / trigger / trigger - callback . c \ntrigger_callback_replace_regex ( struct t_trigger * trigger , \n \nfor ( i = 0 ; i < trigger -> regex_count ; i ++) \n{ \n+ /* if regex is not set ( invalid ), skip it */ \n+ if (! trigger -> regex [ i ]. regex ) \n+ continue ; \n+ \nptr_key = ( trigger -> regex [ i ]. variable ) ? \ntrigger -> regex [ i ]. variable : \ntrigger_hook_regex_default_var [ weechat_config_integer ( trigger -> options [ TRIGGER_OPTION_HOOK ])];", "mmm src / plugins / scripts / lua / weechat - lua - api . c \nppp src / plugins / scripts / lua / weechat - lua - api . c \nweechat_lua_api_config_reload_cb ( void * data , \n{ \nlua_argv [ 0 ] = ( script_callback -> data ) ? script_callback -> data : empty_arg ; \nlua_argv [ 1 ] = script_ptr2str ( config_file ); \n- lua_argv [ 2 ] = NULL ; \n \nrc = ( int *) weechat_lua_exec ( script_callback -> script , \nWEECHAT_SCRIPT_EXEC_INT ,", "mmm src / gui / gui - buffer . c \nppp src / gui / gui - buffer . c \ngui_buffer_local_var_remove ( struct t_gui_buffer * buffer , \nbuffer -> local_variables = local_var -> next_var ; \nif ( buffer -> last_local_var == local_var ) \nbuffer -> last_local_var = local_var -> prev_var ; \n+ \n+ free ( local_var ); \n} \n \n/*", "mmm src / core / hook / wee - hook - line . c \nppp src / core / hook / wee - hook - line . c \nhook_line_free_data ( struct t_hook * hook ) \nif (! hook || ! hook -> hook_data ) \nreturn ; \n \n+ if ( HOOK_LINE ( hook , buffers )) \n+ { \n+ string_free_split ( HOOK_LINE ( hook , buffers )); \n+ HOOK_LINE ( hook , buffers ) = NULL ; \n+ } \nif ( HOOK_LINE ( hook , tags_array )) \n{ \nstring_free_split_tags ( HOOK_LINE ( hook , tags_array ));", "mmm src / gui / gui - buffer . c \nppp src / gui / gui - buffer . c \ngui_buffer_set_highlight_words_list ( struct t_gui_buffer * buffer , \n} \n \ngui_buffer_set_highlight_words ( buffer , words ); \n+ \n+ free ( words ); \n} \n \n/*", "mmm src / core / wee - command . c \nppp src / core / wee - command . c \nCOMMAND_CALLBACK ( cursor ) \ngui_cursor_move_xy ( x , y ); \n} \n} \n+ free ( str_x ); \n} \n} \nelse", "mmm src / plugins / relay / irc / relay - irc . c \nppp src / plugins / relay / irc / relay - irc . c \nrelay_irc_recv ( struct t_relay_client * client , const char * data ) \n/* server capabilities */ \nif ( irc_command && ( weechat_strcasecmp ( irc_command , \" cap \") == 0 )) \n{ \n- if (( irc_argc > 0 ) && irc_argv ) \n+ if ( irc_argc > 0 ) \n{ \nrelay_irc_recv_command_capab ( client , \nirc_argc , irc_argv , irc_argv_eol );", "mmm src / gui / curses / gui - curses - window . c \nppp src / gui / curses / gui - curses - window . c \ngui_window_set_custom_color_fg ( WINDOW * window , int fg ) \n{ \ncurrent_bg = window_current_style_bg ; \n \n+ gui_window_remove_color_style ( window , A_BOLD ); \n+ \nif (( fg > 0 ) && ( fg & GUI_COLOR_EXTENDED_FLAG )) \n{ \ngui_window_set_color ( window , \ngui_window_set_custom_color_fg ( WINDOW * window , int fg ) \n} \nelse if ( fg < GUI_CURSES_NUM_WEECHAT_COLORS ) \n{ \n- gui_window_remove_color_style ( window , A_BOLD ); \nattributes = gui_weechat_colors [ fg ]. attributes ; \ngui_window_set_color_style ( window , attributes ); \nfg = gui_weechat_colors [ fg ]. foreground ;", "mmm src / plugins / irc / irc - server . c \nppp src / plugins / irc / irc - server . c \nirc_server_msgq_flush () \nfree ( command ); \nif ( channel ) \nfree ( channel ); \n+ if ( arguments ) \n+ free ( arguments ); \nif ( msg_decoded ) \nfree ( msg_decoded ); \nif ( msg_decoded_without_color )", "mmm randpool . cpp \nppp randpool . cpp \nNAMESPACE_BEGIN ( CryptoPP ) \nRandomPool :: RandomPool () \n: m_pCipher ( new AES :: Encryption ), m_keySet ( false ) \n{ \n+ memset ( m_key , 0 , m_key . SizeInBytes ()); \n+ memset ( m_seed , 0 , m_seed . SizeInBytes ()); \n} \n \nvoid RandomPool :: IncorporateEntropy ( const byte * input , size_t length )", "mmm misc . h \nppp misc . h \ninline T1 RoundUpToMultipleOf ( const T1 & n , const T2 & m ) \n//! \\ details Internally the function calls C ++ 11 ' s < tt > alignof </ tt > if available . If not available , \n//! then the function uses compiler specific extensions such as < tt > __alignof </ tt > and \n//! < tt > _alignof_ </ tt >. If an extension is not available , then the function uses \n-//! < tt > __BIGGEST_ALIGNMENT__ </ tt >. < tt > sizeof ( T )</ tt > is used if the others are not available . \n+//! < tt > __BIGGEST_ALIGNMENT__ </ tt > if < tt > __BIGGEST_ALIGNMENT__ </ tt > is smaller than < tt > sizeof ( T )</ tt >. \n+//! < tt > sizeof ( T )</ tt > is used if all others are not available . \n//! In < em > all </ em > cases , if < tt > CRYPTOPP_ALLOW_UNALIGNED_DATA_ACCESS </ tt > is defined , then the \n//! function returns 1 . \ntemplate < class T > \ninline unsigned int GetAlignmentOf ( T * dummy = NULL ) // VC60 workaround \nreturn __alignof ( T ); \n# elif defined ( __GNUC__ ) \nreturn __alignof__ ( T ); \n-# elif __BIGGEST_ALIGNMENT__ \n- return __BIGGEST_ALIGNMENT__ ; \n# elif CRYPTOPP_BOOL_SLOW_WORD64 \nreturn UnsignedMin ( 4U , sizeof ( T )); \n# else \n+# if __BIGGEST_ALIGNMENT__ \n+ if ( __BIGGEST_ALIGNMENT__ < sizeof ( T )) \n+ return __BIGGEST_ALIGNMENT__ ; \n+ else \n+# endif \nreturn sizeof ( T ); \n# endif \n}", "mmm config . h \nppp config . h \ntypedef unsigned int word32 ; \n# if defined ( _MSC_VER ) || defined ( __BORLANDC__ ) \ntypedef unsigned __int64 word64 ; \n# define W64LIT ( x ) x ## ui64 \n-# elif ( _LP64 || __LP64__ ) && ! defined ( __SUNPRO_CC ) \n+# elif ( _LP64 || __LP64__ ) \ntypedef unsigned long word64 ; \n# define W64LIT ( x ) x ## UL \n# else", "mmm ppc - simd . cpp \nppp ppc - simd . cpp \n// is needed because additional CXXFLAGS are required to enable the \n// appropriate instructions sets in some build configurations . \n \n+// TODO : we still need to implement Power8 SHA . Once we have Power8 SHA , \n+// we should be able to use CRYPTOPP_POWER8_AES_AVAILABLE and \n+// CRYPTOPP_POWER8_SHA_AVAILABLE instead of the broader \n+// CRYPTOPP_POWER8_AVAILABLE . The change will need to be coordinated \n+// with the defines in config . h . \n+ \n+// TODO : Bob Wilkinson reported we are misdetecting CRYPTOPP_POWER8_AVAILABLE . \n+// The problem is , the updated compiler supports them but the down - level \n+// assembler and linker do not . We will probably need to fix that through \n+// the makefile , similar to the way x86 AES and SHA is handled . Another \n+// twist is , we don ' t have access to a test machine and it must be fixed \n+// for two compilers ( IBM XL C / C ++ and GCC ). Ugh ... \n+ \n# include \" pch . h \" \n# include \" config . h \" \n# include \" stdcpp . h \" \nbool CPU_ProbePower8 () \n{ \n# if defined ( CRYPTOPP_NO_CPU_FEATURE_PROBES ) \nreturn false ; \n-# elif ( CRYPTOPP_POWER7_AVAILABLE ) \n+# elif ( CRYPTOPP_POWER8_AVAILABLE ) \n# if defined ( CRYPTOPP_GNU_STYLE_INLINE_ASSEMBLY ) \n \n// longjmp and clobber warnings . Volatile is required .", "mmm ecp . cpp \nppp ecp . cpp \nECP :: ECP ( BufferedTransformation & bt ) \nGetField (). BERDecodeElement ( seq , m_b ); \n// skip optional seed \nif (! seq . EndReached ()) \n- BERDecodeOctetString ( seq , TheBitBucket ()); \n+ { \n+ SecByteBlock seed ; \n+ unsigned int unused ; \n+ BERDecodeBitString ( seq , seed , unused ); \n+ } \nseq . MessageEnd (); \n} \n", "mmm queue . cpp \nppp queue . cpp \npublic : \n \ninline size_t Put ( const byte * begin , size_t length ) \n{ \n+ if (! begin || ! length ) return length ; \nsize_t l = STDMIN ( length , MaxSize ()- m_tail ); \nif ( buf + m_tail != begin ) \nmemcpy ( buf + m_tail , begin , l ); \npublic : \n \ninline size_t Peek ( byte * target , size_t copyMax ) const \n{ \n+ if (! target || ! copyMax ) return 0 ; \nsize_t len = STDMIN ( copyMax , m_tail - m_head ); \nmemcpy ( target , buf + m_head , len ); \nreturn len ;", "mmm zrtp / ZrtpSdesStream . cpp \nppp zrtp / ZrtpSdesStream . cpp \nbool ZrtpSdesStream :: createSdesProfile ( char * cryptoString , size_t * maxLen ) { \n/* Get B64 code for master key and master salt */ \nb64Len = b64Encode ( keySalt , keyLenBytes + saltLenBytes , b64keySalt , sizeof ( b64keySalt )); \nb64keySalt [ b64Len ] = '\\ 0 '; \n- * maxLen = snprintf ( cryptoString , * maxLen , \"% d % s inline :% s \", tag , pSuite -> name , b64keySalt ); \n+ memset ( cryptoString , 0 , * maxLen ); \n+ * maxLen = snprintf ( cryptoString , * maxLen - 1 , \"% d % s inline :% s \", tag , pSuite -> name , b64keySalt ); \n \nmemset ( keySalt , 0 , sizeof ( keySalt )); \nreturn true ;", "mmm cryptcommon / ZrtpRandom . cpp \nppp cryptcommon / ZrtpRandom . cpp \nint ZrtpRandom :: getRandomData ( uint8_t * buffer , uint32_t length ) { \nuint8_t rdata [ AES_BLOCK_SIZE ]; \nuint32_t generated = length ; \n \n+ initialize (); \n+ \nlockRandom . Lock (); \n \n/* \nint ZrtpRandom :: getRandomData ( uint8_t * buffer , uint32_t length ) { \n \nint ZrtpRandom :: addEntropy ( const uint8_t * buffer , uint32_t length ) \n{ \n+ initialize (); \n+ \nif ( buffer && length ) { \nsha512_hash ( buffer , length , & mainCtx ); \n} \nvoid ZrtpRandom :: initialize () { \nreturn ; \n} \nsha512_begin (& mainCtx ); \n+ initialized = true ; \nlockRandom . Unlock (); \n} \n", "mmm src / game_config . cpp \nppp src / game_config . cpp \nnamespace game_config \nnamespace sounds { \nconst std :: string turn_bell = \" bell . wav \", \ntimer_bell = \" timer . wav \", \n- receive_message = \" chat - 3 . ogg \", \n+ receive_message = \" chat - 1 . ogg , chat - 2 . ogg , chat - 3 . ogg , chat - 4 . ogg \", \nreceive_message_highlight = \" chat - highlight . ogg \", \nreceive_message_friend = \" chat - 4 . ogg \", \nreceive_message_server = \" receive . wav \",", "mmm src / menu_events . cpp \nppp src / menu_events . cpp \nnamespace events { \n} \n} else if ( cmd == \" clear \") { \ngui_ -> clear_chat_messages (); \n- } else if ( cmd == \" sunset \") { \n+ } else if ( game_config :: debug && cmd == \" sunset \") { \nint delay = lexical_cast_default < int >( data ); \ngui_ -> sunset ( delay ); \n} else if ( cmd == \" w \") {", "mmm src / game_events . cpp \nppp src / game_events . cpp \nnamespace { \nstate_of_game -> get_variable ( var_name +\". recruit \") = side_data [\" recruit \"]; \nstate_of_game -> get_variable ( var_name +\". fog \") = side_data [\" fog \"]; \nstate_of_game -> get_variable ( var_name +\". shroud \") = side_data [\" shroud \"]; \n+ state_of_game -> get_variable ( var_name +\". hidden \") = side_data [\" hidden \"]; \n \nstate_of_game -> get_variable ( var_name +\". income \") = lexical_cast_default < std :: string >((* teams )[ team_index ]. income (),\"\"); \nstate_of_game -> get_variable ( var_name +\". village_gold \") = lexical_cast_default < std :: string >((* teams )[ team_index ]. village_gold (),\"\");", "mmm src / about . cpp \nppp src / about . cpp \nstd :: vector < std :: string > get_text () { \n\"- Michel Loos \", \n\"- Renato Cunha \", \n\"- S\u00e9rgio de Miranda Costa \", \n+ \"- Tiago Souza ( Salvador )\", \n \n\" _ \" N_ (\"+ Russian Translation \"), \n\"- Alexandr Menovchicov \",", "mmm src / whiteboard / manager . cpp \nppp src / whiteboard / manager . cpp \nvoid manager :: print_help_once () \n \nvoid manager :: set_active ( bool active ) \n{ \n- if ( is_observer ()) \n+ if ( wait_for_side_init_ \n+ || executing_actions_ \n+ || is_observer () \n+ || resources :: controller -> is_linger_mode ()) \n{ \nactive_ = false ; \n- LOG_WB << \" Whiteboard can ' t be activated by observers .\\ n \"; \n+ LOG_WB << \" Whiteboard can ' t be activated now .\\ n \"; \n} \nelse if ( active != active_ ) \n{ \nvoid manager :: set_invert_behavior ( bool invert ) \nbool block_whiteboard_activation = false ; \nif ( wait_for_side_init_ \n|| executing_actions_ \n- || is_observer ()) \n+ || is_observer () \n+ || resources :: controller -> is_linger_mode ()) \n{ \nblock_whiteboard_activation = true ; \n}", "mmm src / gui / auxiliary / event / dispatcher_private . hpp \nppp src / gui / auxiliary / event / dispatcher_private . hpp \nstruct find < false > \n// MSVC 2008 doesn ' t like operator () here so changed the name . \nreturn functor . template oper < item >( event ); \n} else { \n- typedef typename boost :: mpl :: next < itor >:: type itor ; \n- return find < boost :: is_same < itor , end >:: value > \n- :: execute (( itor *) 0 , ( end *) 0 , event , functor ); \n+ typedef typename boost :: mpl :: next < itor >:: type titor ; \n+ return find < boost :: is_same < titor , end >:: value > \n+ :: execute (( titor *) 0 , ( end *) 0 , event , functor ); \n} \n} \n};", "mmm src / campaign_server / campaign_server . cpp \nppp src / campaign_server / campaign_server . cpp \nnamespace { \nnet_manager_ ( min_thread , max_thread ), \nserver_manager_ ( load_config ()), \nhooks_ (), \n- input_ ( 0 ) \n+ input_ ( 0 ), \n+ compress_level_ ( 0 ) \n{ \nif ( cfg_ . child (\" campaigns \") == NULL ) { \ncfg_ . add_child (\" campaigns \");", "mmm src / server / room_manager . cpp \nppp src / server / room_manager . cpp \nvoid room_manager :: load_config ( const config & cfg ) \n{ \nfilename_ = cfg [\" room_save_file \"]; \ncompress_stored_rooms_ = utils :: string_bool ( cfg [\" compress_stored_rooms \"], true ); \n- new_room_policy_ = pp_from_string ( cfg [\" new_room_policy \"]); \n+ PRIVILEGE_POLICY pp = pp_from_string ( cfg [\" new_room_policy \"]); \n+ if ( pp != PP_COUNT ) new_room_policy_ = pp ; \n} \n \nconst std :: string & room_manager :: storage_filename () const", "mmm src / about . cpp \nppp src / about . cpp \nstd :: vector < std :: string > get_text () { \n \n\" _ \" N_ (\"+ Developers \"), \n\"- Alfredo Beaumont ( ziberpunk )\", \n+ \"- Bram Ridder ( Morloth )\", \n\"- Cedric Duval \", \n\"- Cyril Bouthors ( CyrilB )\", \n\"- Guillaume Melquiond ( silene )\", \nstd :: vector < std :: string > get_text () { \n\"- Justin Zaun ( jzaun )\", \n \n\" _ \" N_ (\"+ Multiplayer Maps \"), \n+ \"- Mike Quinones ( Doc Paterson )\", \n\"- Peter Groen ( pg )\", \n\"- Tom Chance ( telex4 )\", \n- \"- Mike Quinones ( Doc Paterson )\", \n \n\" _ \" N_ (\"+ Packagers \"), \n\"- Cyril Bouthors ( CyrilB )\",", "mmm src / units / map . hpp \nppp src / units / map . hpp \npublic : \nsize_t size () const { return lmap_ . size (); } \nsize_t num_iters () const ; \n \n+ bool empty () const { return lmap_ . empty (); } \n+ \nvoid clear ( bool force = false ); \n \n/**", "mmm src / hotkeys . cpp \nppp src / hotkeys . cpp \nvoid delete_all_wml_hotkeys () \n} \n} \n \n-// retunrs weather a hotkey was deleted . \n+// Returns whether a hotkey was deleted . \nbool remove_wml_hotkey ( const std :: string & id ) \n{ \nhotkey :: hotkey_command & command = get_hotkey_command ( id );", "mmm src / time_of_day . cpp \nppp src / time_of_day . cpp \ntime_of_day :: time_of_day ( const config & cfg ) \ntime_of_day :: time_of_day () \n: lawful_bonus ( 0 ) \n, bonus_modified ( 0 ) \n+, image () \n, name (\" NULL_TOD \") \n, id (\" nulltod \") \n+, image_mask () \n, red ( 0 ) \n, green ( 0 ) \n, blue ( 0 ) \n+, sounds () \n{ \n} \n", "mmm src / unit . cpp \nppp src / unit . cpp \nvoid unit :: write ( config & cfg ) const \nbreak ; \ncase unit_type :: LIMINAL : \ncfg [\" alignment \"] = \" liminal \"; \n+ break ; \ndefault : \ncfg [\" alignment \"] = \" neutral \"; \n}", "mmm src / campaign_server / campaign_server . cpp \nppp src / campaign_server / campaign_server . cpp \nvoid server :: handle_read_from_fifo ( const boost :: system :: error_code & error , std :: \n \nif ( ctl == \" shut_down \") { \nLOG_CS << \" Shut down requested by admin , shutting down ...\\ n \"; \n+ throw server_shutdown (\" Shut down via fifo command \"); \n} else if ( ctl == \" readonly \") { \nif ( ctl . args_count ()) { \ncfg_ [\" read_only \"] = read_only_ = utils :: string_bool ( ctl [ 1 ], true );", "mmm src / server / game . cpp \nppp src / server / game . cpp \nbool game :: describe_slots () { \nstd :: string descr = buf . str (); \n \nif ((* description_ )[\" slots \"] != descr ) { \n- description_ -> set_attr_dup (\" slots \", descr ); \n+ description_ -> set_attr_dup (\" slots \", descr . c_str ()); \nreturn true ; \n} else { \nreturn false ;", "mmm src / savegame . cpp \nppp src / savegame . cpp \nbool loadgame :: load_multiplayer_game () \nreturn false ; \n} \n \n+ if ( is_replay_save ( summary_ )) { \n+ gui2 :: show_transient_message ( video_ , _ (\" Load Game \"), _ (\" Replays are not supported in multiplayer mode .\")); \n+ return false ; \n+ } \n+ \nif ( gamestate_ . classification (). campaign_type != game_classification :: CAMPAIGN_TYPE :: MULTIPLAYER ) { \ngui2 :: show_transient_error_message ( video_ , _ (\" This is not a multiplayer save .\")); \nreturn false ;", "mmm src / map . cpp \nppp src / map . cpp \nbool gamemap :: is_village ( const gamemap :: location & loc ) const \n \nbool gamemap :: gives_healing ( const gamemap :: location & loc ) const \n{ \n- return is_village ( loc ); \n+ return on_board ( loc ) && gives_healing ( get_terrain ( loc )); \n} \n \nbool gamemap :: is_castle ( const gamemap :: location & loc ) const", "mmm src / about . cpp \nppp src / about . cpp \nvoid show_about ( display & disp ) \ntext . push_back (\"+ Developers \"); \ntext . push_back (\"- Alfredo Beaumont ( ziberpunk )\"); \ntext . push_back (\"- Cyril Bouthors ( CyrilB )\"); \n- text . push_back (\"- Guillaume Duwelz - Rebert \"); \ntext . push_back (\"- Isaac Clerencia \"); \ntext . push_back (\"- J . R . Blain ( Cowboy )\"); \ntext . push_back (\"- Justin Zaun ( jzaun )\");", "mmm src / serialization / binary_or_text . cpp \nppp src / serialization / binary_or_text . cpp \n \nbool detect_format_and_read ( config & cfg , std :: istream & in ) \n{ \n- try { \n+ unsigned char c = in . peek (); \n+ if ( c < 5 ) { \nread_compressed ( cfg , in ); \nreturn true ; \n- } catch ( config :: error &) { \n+ } else { \n+ read ( cfg , in ); \n+ return false ; \n} \n- \n- read ( cfg , in ); \n- return false ; \n} \n \nvoid write_possibly_compressed ( std :: string const & filename , config & cfg , bool compress )", "mmm src / map . cpp \nppp src / map . cpp \nbool gamemap :: location :: matches_range ( const std :: string & xloc , const std :: string \nstd :: vector < std :: string > xlocs = utils :: split ( xloc ); \nstd :: vector < std :: string > ylocs = utils :: split ( yloc ); \n \n- int size ; \n+ size_t size ; \nfor ( size = xlocs . size (); size < ylocs . size (); ++ size ) { \nxlocs . push_back (\"\"); \n} \nwhile ( size > ylocs . size ()) { \nylocs . push_back (\"\"); \n} \n- for ( int i = 0 ; i != size ; ++ i ) { \n+ for ( size_t i = 0 ; i != size ; ++ i ) { \nif ( matches_range ( xlocs [ i ], ylocs [ i ])) \nreturn true ; \n}", "mmm src / playcampaign . cpp \nppp src / playcampaign . cpp \nLEVEL_RESULT play_game ( display & disp , game_state & gamestate , const config & game_ \ngamestate . set_variables (* gamestate . snapshot . child (\" variables \")); \n} \n// Replace game label with that from snapshot \n- if (! state . snapshot [\" label \"]. empty ()){ \n- state . label = state . snapshot [\" label \"]; \n+ if (! gamestate . snapshot [\" label \"]. empty ()){ \n+ gamestate . label = gamestate . snapshot [\" label \"]; \n} \n// get the current gold values of players so they don ' t start with the amount \n// they had at the start of the scenario", "mmm src / variable_info . cpp \nppp src / variable_info . cpp \nnamespace \nchar * endptr ; \nint res = strtol ( index_str , & endptr , 10 ); \n \n- if (* endptr != ']' || res > int ( game_config :: max_loop )) \n+ if (* endptr != ']' || res > int ( game_config :: max_loop ) || endptr == index_str ) \n{ \nthrow invalid_variablename_exception (); \n}", "mmm src / editor / editor_controller . cpp \nppp src / editor / editor_controller . cpp \nbool editor_controller :: execute_command ( hotkey :: HOTKEY_COMMAND command , int inde \ngui_ -> init_flags (); \nreturn true ; \n \n+ // Transitions \n+ case HOTKEY_EDITOR_PARTIAL_UPDATE_TRANSITIONS : \n+ context_manager_ -> set_update_trasitions_mode ( 2 ); \n+ return true ; \ncase HOTKEY_EDITOR_AUTO_UPDATE_TRANSITIONS : \n+ context_manager_ -> set_update_trasitions_mode ( 1 ); \n+ return true ; \n+ case HOTKEY_EDITOR_NO_UPDATE_TRANSITIONS : \n+ context_manager_ -> set_update_trasitions_mode ( 0 ); \n+ return true ; \n+ case HOTKEY_EDITOR_TOGGLE_TRANSITIONS : \nif ( context_manager_ -> toggle_update_transitions ()) \nreturn true ; \n// else intentionally fall through \ncase HOTKEY_EDITOR_UPDATE_TRANSITIONS : \ncontext_manager_ -> refresh_all (); \nreturn true ; \n+ // Refresh \ncase HOTKEY_EDITOR_REFRESH : \ncontext_manager_ -> reload_map (); \nreturn true ;", "mmm src / playcampaign . cpp \nppp src / playcampaign . cpp \nLEVEL_RESULT play_game ( game_display & disp , saved_game & gamestate , \nif ( is_unit_test ) { \nreturn res ; \n} \n+ // in this case we might have skipped state . set_snapshot which means wew cannot do gamestate . convert_to_start_save (); \n+ if ( res == QUIT ) \n+ { \n+ return res ; \n+ } \n \n// Save - management options fire on game end . \n// This means : ( a ) we have a victory , or \nLEVEL_RESULT play_game ( game_display & disp , saved_game & gamestate , \n// On DEFEAT , QUIT , or OBSERVER_END , we ' re done now \n \n// If there is no next scenario we ' re done now . \n- if ( res == QUIT || ! end_level . proceed_to_next_level || gamestate . carryover_sides_start [\" next_scenario \"]. empty ()) \n+ if (! end_level . proceed_to_next_level || gamestate . carryover_sides_start [\" next_scenario \"]. empty ()) \n{ \nreturn res ; \n}", "mmm src / mp_options . cpp \nppp src / mp_options . cpp \nvoid manager :: init_info ( const config & cfg , const std :: string & key ) \nentry [\" id \"] = comp [\" id \"]; \nentry [\" name \"] = comp [\" name \"]; \n \n- if ( comp . has_child (\" options \") && ( comp [\" allow_new_game \"]. to_bool ( true )) { \n+ if ( comp . has_child (\" options \") && comp [\" allow_new_game \"]. to_bool ( true )) { \nconst config & options = comp . child (\" options \"); \n \nBOOST_FOREACH ( const config :: any_child & c ,", "mmm src / formula_string_utils . hpp \nppp src / formula_string_utils . hpp \nclass variable_set ; \n \nnamespace utils { \n \n+/** \n+ * Determines if a string might contain variables to interpolate . \n+ * This can allow one to skip future interpolations ( plural -- if there is only \n+ * one interpolation , the savings are not worth this check ). In this spirit , \n+ * precision is sacrificed in the name of efficiency ; the check is quick and \n+ * allows false positives , but there are no false negatives . ( A false negative \n+ * would lead to incorrect behavior , whereas a false positive leads to merely \n+ * inefficient behavior .) In practice , false positives should be uncommon enough \n+ * to not worry about . \n+ */ \n+ inline bool might_contain_variables ( const std :: string & str ) \n+{ return str . find ('$') != std :: string :: npos ; } \n+ \n/** \n* Function which will interpolate variables , starting with '$' in the string \n* ' str ' with the equivalent symbols in the given symbol table . If ' symbols '", "mmm src / game_events . cpp \nppp src / game_events . cpp \nWML_HANDLER_FUNCTION ( replace_schedule , /* event_info */, cfg ) \nERR_NG << \" attempted to to replace ToD schedule with empty schedule \\ n \"; \n} else { \nresources :: tod_manager -> replace_schedule ( cfg . get_parsed_config ()); \n+ resources :: screen -> new_turn (); \nLOG_NG << \" replaced ToD schedule \\ n \"; \n} \n}", "mmm src / actions / undo . cpp \nppp src / actions / undo . cpp \nvoid undo_list :: add_auto_shroud ( bool turned_on ) \n/// @ todo : Consecutive shroud actions can be collapsed into one . \n \n// Do not call add (), as this should not clear the redo stack . \n- undos_ . push_back ( new undo :: auto_shroud_action ( turned_on )); \n+ add ( new undo :: auto_shroud_action ( turned_on )); \n} \n \n/** \nvoid undo_list :: add_update_shroud () \n{ \n/// @ todo : Consecutive shroud actions can be collapsed into one . \n \n- // Do not call add (), as this should not clear the redo stack . \n- undos_ . push_back ( new undo :: update_shroud_action ()); \n+ add ( new undo :: update_shroud_action ()); \n} \n \n", "mmm src / tools / exploder_utils . cpp \nppp src / tools / exploder_utils . cpp \nvoid masked_overwrite_surface ( surface dest , surface src , surface mask , int x , in \nsmall_shift_before = 0 ; \n} \n \n- if ( x + src_width <= dest -> w ) { \n+ if ( x + src_width <= unsigned ( dest -> w )) { \nsmall_shift_after = 0 ; \n} else { \nsmall_shift_after = src_width - ( dest -> w - x ); \nvoid masked_overwrite_surface ( surface dest , surface src , surface mask , int x , in \ny = 0 ; \n} \n \n- if ( y + src_height > dest -> h ) { \n+ if ( y + src_height > unsigned ( dest -> h )) { \nsrc_height = dest -> h - y ; \n} \n", "mmm src / text . cpp \nppp src / text . cpp \nvoid ttext :: recalculate ( const bool force ) const \n<< \" result \" << rect_ \n<< \".\\ n \"; \n \n- if ( rect_ . width > maximum_width_ ) { \n+ if ( maximum_width_ != - 1 && rect_ . width > maximum_width_ ) { \nERR_GUI_L << \" ttext ::\" << __func__ \n<< \" text '\" << gui2 :: debug_truncate ( text_ ) \n<< \" ' width \" << rect_ . width", "mmm src / game_launcher . cpp \nppp src / game_launcher . cpp \ngame_launcher :: game_launcher ( const commandline_options & cmdline_opts , const char \nconst std :: string app_basename = filesystem :: base_name ( appname ); \njump_to_editor_ = app_basename . find (\" editor \") != std :: string :: npos ; \n \n+ if ( cmdline_opts_ . core_id ) { \n+ preferences :: set_core_id (* cmdline_opts_ . core_id ); \n+ } \nif ( cmdline_opts_ . campaign ) { \njump_to_campaign_ . jump_ = true ; \njump_to_campaign_ . campaign_id_ = * cmdline_opts_ . campaign ;", "mmm src / hotkey / command_executor . cpp \nppp src / hotkey / command_executor . cpp \nvoid execute_command ( display & disp , const hotkey_command & command , command_execu \n} \ncase LUA_CONSOLE : { \nif (! disp . in_game ()) { \n- WRN_G << \" caution : attempting to interface console with game lua kernel when we are not in game ...\\ n \"; \n+ // WRN_G << \" caution : attempting to interface console with game lua kernel when we are not in game ...\\ n \"; \n+ gui2 :: tlua_interpreter :: display ( disp . video (), gui2 :: tlua_interpreter :: APP ); \n+ } else { \n+ gui2 :: tlua_interpreter :: display ( disp . video (), gui2 :: tlua_interpreter :: GAME ); \n} \n- gui2 :: tlua_interpreter :: display ( disp . video (), gui2 :: tlua_interpreter :: GAME ); \nbreak ; \n} \ndefault :", "mmm src / multiplayer_ui . cpp \nppp src / multiplayer_ui . cpp \nstd :: string get_colour_string ( int id ) \n} \n} \n \n- chat :: chat () \n+ chat :: chat () : \n+ message_history_ (), \n+ last_update_ () \n{ \n} \n \nui :: ui ( game_display & disp , const std :: string & title , const config & cfg , chat & c , \nchat_textbox_ ( disp . video (), 100 , \"\", false ), \nusers_menu_ ( disp . video (), std :: vector < std :: string >(), false , - 1 , - 1 , NULL , & umenu_style ), \n \n+ user_list_ (), \nselected_game_ (\"\"), \n \nresult_ ( CONTINUE ),", "mmm src / mouse_events . cpp \nppp src / mouse_events . cpp \nbool mouse_handler :: left_click ( int x , int y , const bool browse ) \n \ngui (). unhighlight_reach (); \n \n+ // If the whiteboard is active , it intercepts any unit movement \nif ( resources :: whiteboard -> is_active ()) { \n// Unselect the current hex , and create planned move for whiteboard \nselected_hex_ = map_location (); \nbool mouse_handler :: left_click ( int x , int y , const bool browse ) \n{ \nresources :: whiteboard -> save_temp_move (); \n} \n- } else { \n+ // Otherwise proceed to normal unit movement , unless the selected unit already has actions \n+ // from the whiteboard . \n+ } else if (! resources :: whiteboard -> unit_has_actions (* u )) { \n// register the mouse - UI waypoints into the unit ' s waypoints \nu -> waypoints () = waypoints_ ; \n", "mmm doc / doxygen / doxygen . cpp \nppp doc / doxygen / doxygen . cpp \n@ li < a href =\" hierarchy . html \"> Classes </ a > \n@ li < a href =\" files . html \"> Source Files </ a > \n@ li < a href =\" todo . html \"> Todo </ a > \n+ @ li < a href =\" deprecated . html \"> Deprecated </ a > \n</ td > \n</ tr > \n</ table >", "mmm src / game . cpp \nppp src / game . cpp \nstatic int process_command_args ( int argc , char ** argv ) { \npython_ai :: invoke (\" documentation \"); \nreturn 0 ; \n} else if ( val == \"-- python - shell \") { \n- int ret = python_ai :: run_shell (); \n+ python_ai :: run_shell (); \nreturn 0 ; \n# endif \n} else if ( val == \"-- config - dir \") {", "mmm src / whiteboard / highlight_visitor . cpp \nppp src / whiteboard / highlight_visitor . cpp \naction_ptr highlight_visitor :: get_execute_target () \n} \naction_ptr highlight_visitor :: get_delete_target () \n{ \n- action_ptr action ; \n+ action_ptr action = action_ptr (); \nif ( owner_unit_ ) \n{ \n- action = * side_actions_ -> find_last_action_of (* owner_unit_ ); \n+ side_actions :: iterator it = side_actions_ -> find_last_action_of (* owner_unit_ ); \n+ if ( it != side_actions_ -> end ()) \n+ { \n+ action = * it ; \n+ } \n} \nreturn action ; \n}", "mmm src / unit . cpp \nppp src / unit . cpp \nvoid unit :: restart_animation ( const game_display & disp , int start_time ) { \n} \n \nvoid unit :: set_facing ( gamemap :: location :: DIRECTION dir ) { \n- wassert ( dir != gamemap :: location :: NDIRECTIONS ); \n- facing_ = dir ; \n+ if ( dir != gamemap :: location :: NDIRECTIONS ) { \n+ facing_ = dir ; \n+ } \n+ // else look at yourself ( not available so continue to face the same direction ) \n} \n \nvoid unit :: redraw_unit ( game_display & disp , const gamemap :: location & loc )", "mmm src / gui / widgets / window . hpp \nppp src / gui / widgets / window . hpp \npublic : \nstatic void set_sunset ( const unsigned interval ) \n{ sunset_ = interval ? interval : 5 ; } \n \n+ bool get_need_layout () const { return need_layout_ ; } \n+ \nprivate : \n \n/** Needed so we can change what ' s drawn on the screen . */", "mmm src / soundsource . cpp \nppp src / soundsource . cpp \nvoid positional_source :: write_config ( config & cfg ) const \ncfg [\" delay \"] = str_cast < unsigned int >( this -> min_delay_ ); \ncfg [\" chance \"] = str_cast < unsigned int >( this -> chance_ ); \ncfg [\" check_fogged \"] = this -> check_fogged_ ? \" yes \" : \" no \"; \n- cfg [\" check_shrouded \"] = this -> check_fogged_ ? \" yes \" : \" no \"; \n+ cfg [\" check_shrouded \"] = this -> check_shrouded_ ? \" yes \" : \" no \"; \n \ncfg [\" x \"] = cfg [\" y \"] = \"\"; \nbool first_loc = true ;", "mmm src / reports . cpp \nppp src / reports . cpp \nUnits cannot be killed by poison alone . The poison will not reduce it below 1 HP \n \nif ( flag_icon . empty ()) { \nflag_icon = game_config :: flag_icon_image ; \n- old_rgb = game_config :: flag_rgb ; \n- new_rgb = team :: get_side_colour_index ( playing_side ); \n- mods = \"~ RC (\" + old_rgb + \">\" + new_rgb + \")\"; \n} \n+ old_rgb = game_config :: flag_rgb ; \n+ new_rgb = team :: get_side_colour_index ( playing_side ); \n+ mods = \"~ RC (\" + old_rgb + \">\" + new_rgb + \")\"; \n \n// remove animation stuff we don ' t care about \n// const std :: vector < std :: string > items = utils :: split ( flag );", "mmm src / menu_events . cpp \nppp src / menu_events . cpp \nprivate : \nif ( network :: nconnections () == 0 ) { \nstd :: cerr << \" showing ai formula ...\\ n \"; \ntextbox_info_ . show ( gui :: TEXTBOX_AI , sgettext (\" prompt ^ Command :\"), \"\", false , * gui_ ); \n- } else { \n- add_chat_message ( time ( NULL ), _ (\" ai \"), 0 , \" Formula commandline not available in network games \"); \n} \n} \n", "mmm src / help . cpp \nppp src / help . cpp \npublic : \nstd :: string lang_unit = type -> type_name (); \nstd :: string ref_id ; \nif ( description_type (* type ) == FULL_DESCRIPTION ) { \n- ref_id = unit_prefix + type -> id (); \n+ const std :: string section_prefix = type -> variations (). empty () ? \"\" : \"..\"; \n+ ref_id = section_prefix + unit_prefix + type -> id (); \n} else { \nref_id = unknown_unit_topic ; \nlang_unit += \" (?)\";", "mmm src / saved_game . cpp \nppp src / saved_game . cpp \nvoid saved_game :: expand_random_scenario () \nLOG_NG << \" randomly generating scenario ...\\ n \"; \nconst cursor :: setter cursor_setter ( cursor :: WAIT ); \n \n- starting_pos_ = random_generate_scenario ( starting_pos_ [\" scenario_generation \"], \n+ config scenario_new = random_generate_scenario ( starting_pos_ [\" scenario_generation \"], \nstarting_pos_ . child (\" generator \")); \n+ // Preserve \" story \" form the scenario toplevel . \n+ BOOST_FOREACH ( config & story , starting_pos_ . child_range (\" story \")) \n+ { \n+ scenario_new . add_child (\" story \", story ); \n+ } \n+ starting_pos_ = scenario_new ; \n} \n// it looks like we support a map = where map = filename equals more or less map_data ={ filename } \nif ( starting_pos_ [\" map_data \"]. empty () && starting_pos_ [\" map \"] != \"\") {", "mmm src / display . cpp \nppp src / display . cpp \nvoid display :: clear_redraw_observers () \n \nvoid display :: draw ( bool update , bool force ) { \n// log_scope (\" display :: draw \"); \n- if ( screen_ . update_locked ()) { \n+ if ( screen_ . update_locked () || ( SDL_GetAppState () & SDL_APPACTIVE ) == 0 ) { \nreturn ; \n} \nbool changed = draw_init ();", "mmm src / multiplayer_connect . cpp \nppp src / multiplayer_connect . cpp \nconfig connect :: side :: get_config () const \n} \n{ \nres [\" id \"] = res [\" save_id \"]; \n- const config & ai_cfg = ai :: configuration :: get_ai_config_for ( ai_algorithm_ ); \n- res . add_child (\" ai \", ai_cfg ); \nutils :: string_map symbols ; \n- symbols [\" playername \"] = ai_cfg [\" description \"]; \n+ if ( allow_player_ ) { \n+ const config & ai_cfg = ai :: configuration :: get_ai_config_for ( ai_algorithm_ ); \n+ res . add_child (\" ai \", ai_cfg ); \n+ symbols [\" playername \"] = ai_cfg [\" description \"]; \n+ } else { // do not import default ai cfg here - all is set by scenario config \n+ symbols [\" playername \"] = _ (\" Computer Player \"); \n+ } \nsymbols [\" side \"] = res [\" side \"]. str (); \ndescription = vgettext (\"$ playername $ side \", symbols ); \n}", "mmm src / tools / schema / tag . cpp \nppp src / tools / schema / tag . cpp \nvoid class_tag :: add_tag ( const std :: string & path , const class_tag & tag , \nit -> second . add_keys ( tag . keys_ ); \nit -> second . add_links ( tag . links_ ); \n} \n+ links_ . erase ( tag . get_name ()); \nreturn ; \n} \nstd :: string :: size_type pos = path . find ('/'); \nvoid class_tag :: append_super ( const class_tag & tag , const std :: string & path ){ \nadd_keys ( tag . keys_ ); \nadd_links ( tag . links_ ); \nfor ( tag_map :: const_iterator i = tag . tags_ . begin (); i != tag . tags_ . end ();++ i ){ \n+ links_ . erase ( i -> first ); \nadd_link ( path + \"/\" + i -> first ); \n+ \n} \n} \n", "mmm src / multiplayer . cpp \nppp src / multiplayer . cpp \nvoid play_multiplayer ( display & disp , game_data & units_data , config cfg , \n} else if ( result < int ( choices . size ()/ 3 )* 2 ) { \ncontroller = \" ai \"; \nresult -= choices . size ()/ 3 ; \n+ sides [ res ]-> values [\" description \"] = \"\"; \n} else { \ncontroller = \" network \"; \nresult -= ( choices . size ()/ 3 )* 2 ;", "mmm src / cursor . cpp \nppp src / cursor . cpp \nvoid draw ( surface screen ) \nif ( use_colour_cursors () == false ) { \nreturn ; \n} \n- \n+ \n+ if ( current_cursor == NUM_CURSORS ) { \n+ return ; \n+ } \n+ \nif (! colour_ready ) { \n// display start to draw cursor \n// so it can now display colour cursor \nvoid draw ( surface screen ) \nset ( current_cursor ); \n} \n \n- if ( current_cursor == NUM_CURSORS ) { \n- return ; \n- } \n- \nif ( have_focus == false ) { \ncursor_buf = NULL ; \nreturn ;", "mmm src / loadscreen . cpp \nppp src / loadscreen . cpp \nloadscreen :: loadscreen ( CVideo & screen , const int & percent ): \nsetconfig_counter ( 0 ), \nparser_counter ( 0 ), \nscreen_ ( screen ), \n+ textarea_ (), \n+ logo_surface_ ( NULL ), \nlogo_drawn_ ( false ), \npby_offset_ ( 0 ), \nprcnt_ ( percent )", "mmm src / network_worker . cpp \nppp src / network_worker . cpp \nstatic int process_queue ( void * shard_num ) \n} else { \nstd :: string buffer ( buf . begin (), buf . end ()); \nstd :: istringstream stream ( buffer ); \n- // Binary wml starts with a char < 4 , the first char of a gzip header is 31 \n- // so test that here and use the proper reader . \ntry { \n- if ( stream . peek () == 31 ) { \n- read_gz ( received_data -> config_buf , stream ); \n- } else { \n- /// @ todo Possibly complain more loudly \n- ERR_NW << \" Receiving binary WML . Who is sending this ?\\ n \"; \n- } \n+ read_gz ( received_data -> config_buf , stream ); \n} catch ( config :: error & e ) \n{ \nreceived_data -> config_error = e . message ;", "mmm src / version . cpp \nppp src / version . cpp \nversion_info :: version_info ( unsigned int major , unsigned int minor , unsigned int \n} \n \nversion_info :: version_info ( const std :: string & str ) \n- : special_ (\"\"), special_separator_ ('\\ 0 '), sane_ ( true ) \n+ : nums_ () \n+ , special_ (\"\") \n+ , special_separator_ ('\\ 0 ') \n+ , sane_ ( true ) \n{ \nconst std :: vector < std :: string > string_parts = utils :: split ( str ,'.'); \n// first two components are required to be valid numbers , though", "mmm src / image_modifications . cpp \nppp src / image_modifications . cpp \nsurface rotate_modification :: operator ()( const surface & src ) const \ncase 180 : return rotate_180_surface ( src ); \ncase 270 : return rotate_90_surface ( src , false ); \ncase 360 : return src ; \n- default : return rotate_any_surface ( src , normalized , zoom_ , offset_ ); \n} \n \n- // Other values are not supported . Ignore them . \n- return src ; \n+ return rotate_any_surface ( src , normalized , zoom_ , offset_ ); \n} \n \nsurface gs_modification :: operator ()( const surface & src ) const \nREGISTER_MOD_PARSER ( ROTATE , args ) \nlexical_cast_default < int >( slice_params [ 1 ]), \nlexical_cast_default < int >( slice_params [ 2 ])); \nbreak ; \n- default : \n- return NULL ; \n- break ; \n} \nreturn NULL ; \n}", "mmm src / widgets / textbox . cpp \nppp src / widgets / textbox . cpp \nvoid textbox :: set_text ( std :: string text ) \n{ \ntext_ = string_to_wstring ( text ); \ncursor_ = text_ . size (); \n+ selstart_ = - 1 ; \n+ selend_ = - 1 ; \nset_dirty ( true ); \nupdate_text_cache ( true ); \n} \nvoid textbox :: clear () \ncursor_ = 0 ; \ncursor_pos_ = 0 ; \ntext_pos_ = 0 ; \n+ selstart_ = - 1 ; \n+ selend_ = - 1 ; \nset_dirty ( true ); \nupdate_text_cache ( true ); \n}", "mmm src / campaign_server / campaign_server . cpp \nppp src / campaign_server / campaign_server . cpp \nnamespace { \n \n// Copy over COPYING . txt \nstd :: string contents = read_file (\" COPYING . txt \"); \n- config & copying = dir . add_child (\" file \"); \n- copying [\" name \"] = \" COPYING . txt \"; \n- copying [\" contents \"] = contents ; \n- \nif ( contents . empty ()) { \nLOG_CS << \" Could not find COPYING . txt , path is \\\"\" \n<< game_config :: path << \"\\\"\\ n \"; \n+ return ; \n} \n+ config & copying = dir . add_child (\" file \"); \n+ copying [\" name \"] = \" COPYING . txt \"; \n+ copying [\" contents \"] = contents ; \n+ \n} \nvoid campaign_server :: convert_binary_to_gzip () \n{", "mmm src / actions . cpp \nppp src / actions . cpp \nbool can_recruit_on ( const gamemap & map , const map_location & leader , const map_lo \nif (! map . is_castle ( loc )) \nreturn false ; \n \n+ if (! map . is_keep ( leader )) \n+ return false ; \n+ \ncastle_cost_calculator calc ( map ); \n// The limit computed in the third argument is more than enough for \n// any convex castle on the map . Strictly speaking it could be", "mmm src / actions . cpp \nppp src / actions . cpp \nvoid calculate_healing ( display & disp , const gamemap & map , \n \nint pos_max = i -> second . max_hitpoints () - i -> second . hitpoints (); \nint neg_max = -( i -> second . hitpoints () - 1 ); \n+ if ( healing > 0 && pos_max <= 0 ) { \n+ // Do not try to \" heal \" if HP >= max HP \n+ continue ; \n+ } \nif ( healing > pos_max ) { \nhealing = pos_max ; \n} else if ( healing < neg_max ) {", "mmm src / game_events . cpp \nppp src / game_events . cpp \nbool event_handler :: handle_event_command ( const queued_event & event_info , \nconst int side = lexical_cast_default < int >( side_str . value (), - 1 ); \n \n// Select advancement if it is on the playing side and the player is a human \n- const bool sel = ( side == u . side () && (* teams )[ side - 1 ]. is_human ()); \n+ const bool sel = ( side == static_cast < int >( u . side ()) \n+ && (* teams )[ side - 1 ]. is_human ()); \n \n// The code in dialogs :: advance_unit tests whether the unit can advance \ndialogs :: advance_unit (* game_data_ptr , * game_map , * units , loc , * screen , ! sel , true );", "mmm src / terrain_filter . cpp \nppp src / terrain_filter . cpp \nnamespace { \nbool terrain_matches_filter ( const gamemap & map , const gamemap :: location & loc , const vconfig & cfg , \nconst gamestatus & game_status , const unit_map & units , const bool flat_tod , \nconst size_t max_loop ) \n-{ \n+{ \n+ if (! map . on_board ( loc )) return false ; \n+ \n// handle radius \nconst size_t radius = minimum < size_t >( max_loop , \nlexical_cast_default < size_t >( cfg [\" radius \"], 0 ));", "mmm src / image . cpp \nppp src / image . cpp \nstatic void precache_file_existence_internal ( const std :: string & dir , const std :: \nreturn ; \nprecached_dirs . insert ( checked_dir ); \n \n+ if (! filesystem :: is_directory ( checked_dir )) \n+ return ; \n+ \nstd :: vector < std :: string > files_found ; \nstd :: vector < std :: string > dirs_found ; \nfilesystem :: get_files_in_dir ( checked_dir , & files_found , & dirs_found ,", "mmm src / formula_ai . cpp \nppp src / formula_ai . cpp \npublic : \nclass fallback_function : public function_expression { \npublic : \nexplicit fallback_function ( const args_list & args ) \n- : function_expression (\" fallback \", args , 1 , 1 ) \n+ : function_expression (\" fallback \", args , 0 , 1 ) \n{} \nprivate : \nvariant execute ( const formula_callable & variables ) const { \n+ if ( args (). size () == 0 ) \n+ return variant ( new fallback_callable (\"\")); \nreturn variant ( new fallback_callable ( args ()[ 0 ]-> evaluate ( variables ). as_string ())); \n} \n};", "mmm src / playlevel . cpp \nppp src / playlevel . cpp \nredo_turn : \ninfo [\" type \"] = \" termination \"; \ninfo [\" condition \"] = \" game over \"; \nnetwork :: send_data ( cfg ); \n- } else \n+ } else { \ngui :: show_dialog ( gui , NULL , _ (\" Game Over \"), \n_ (\" The game is over .\"), gui :: OK_ONLY ); \n+ return QUIT ; \n+ } \n} \n \nif ( end_level . result == QUIT ) {", "mmm src / unit_display . cpp \nppp src / unit_display . cpp \nvoid unit_attack ( \nint damage_left = damage ; \nwhile ( damage_left > 0 && ! animator . would_end ()) { \nint step_left = ( animator . get_end_time () - animator . get_animation_time () )/ 50 ; \n- int removed_hp = damage_left / step_left ; \n+ int removed_hp = step_left ? damage_left / step_left : 1 ; \nif ( removed_hp < 1 ) removed_hp = 1 ; \nif ( step_left < 1 ) step_left = 1 ; \ndefender . take_hit ( removed_hp );", "mmm src / mouse_events . cpp \nppp src / mouse_events . cpp \npaths :: route mouse_handler :: get_route ( unit_map :: const_iterator un , map_location \n \nvoid mouse_handler :: mouse_press ( const SDL_MouseButtonEvent & event , const bool browse ) \n{ \n- if ( attackmove_ ) return ; \nmouse_handler_base :: mouse_press ( event , browse ); \n} \n \nbool mouse_handler :: left_click ( int x , int y , const bool browse ) \n \ngui (). unhighlight_reach (); \nmove_unit_along_current_route ( check_shroud ); \n- } else { \n+ } else if (! attackmove_ ) { \n+ // we block selection during attack + move ( because motion is blocked ) \n+ // FIXME : deal with selected event when commands_disabled \n// we select a ( maybe empty ) hex \nselect_hex ( hex , browse ); \n}", "mmm src / network_worker . cpp \nppp src / network_worker . cpp \nSOCKET_STATE receive_buf ( TCPsocket sock , std :: vector < char >& buf ) \n} \n} \n \n- const ssize_t res = SDLNet_TCP_Recv ( sock , beg , end - beg ); \n+ const int res = SDLNet_TCP_Recv ( sock , beg , end - beg ); \nif ( res <= 0 ) { \nif ( SDLNet_CheckSockets ( set , 15000 ) <= 0 ) { \nERR_NW << \" SDLNet_CheckSockets : \" << strerror ( errno ) << \"\\ n \";", "mmm src / actions / attack . cpp \nppp src / actions / attack . cpp \nint battle_context :: choose_attacker_weapon ( const unit & attacker , \nattacker_combatant_ = new combatant (* attacker_stats_ ); \ndefender_combatant_ = new combatant (* defender_stats_ , prev_def ); \nattacker_combatant_ -> fight (* defender_combatant_ ); \n+ } else { \n+ if ( attacker_stats_ -> disable ) { \n+ delete attacker_stats_ ; \n+ attacker_stats_ = nullptr ; \n+ continue ; \n+ } \n} \nif (! best_att_comb || better_combat (* attacker_combatant_ , * defender_combatant_ , \n* best_att_comb , * best_def_comb , harm_weight )) {", "mmm src / gui / widgets / scrollbar_container . cpp \nppp src / gui / widgets / scrollbar_container . cpp \nstatic void set_scrollbar_mode ( tgrid * scrollbar_grid , tscrollbar_ * scrollbar , \nreturn ; \n} \n \n- \nscrollbar -> set_item_count ( items ); \n+ scrollbar -> set_item_position ( 0 ); \nscrollbar -> set_visible_items ( visible_items ); \n \nif ( scrollbar_mode == tscrollbar_container :: auto_visible ) {", "mmm src / gui / widgets / widget . cpp \nppp src / gui / widgets / widget . cpp \nvoid widget :: set_visible ( const visibility visible ) \nvisible_ = visible ; \n \nif ( need_resize ) { \n- if ( new_widgets ) { \n+ if ( visible == visibility :: visible && new_widgets ) { \nevent :: message message ; \nfire ( event :: REQUEST_PLACEMENT , * this , message ); \n} else {", "mmm src / upload_log . cpp \nppp src / upload_log . cpp \nupload_log ::~ upload_log () \nif ( game_finished ( game_ )) \nconfig_ . add_child (\" game \", * game_ ); \n \n+ if ( game_ ) \n+ delete game_ ; \n+ \nif ( enabled_ && ! config_ . empty () && ! game_config :: debug ) { \nconfig_ [\" version \"] = VERSION ; \nconfig_ [\" format_version \"] = \" 1 \"; \nvoid upload_log :: start ( game_state & state , const team & team , \nif ( game_finished ( game_ )) \nconfig_ . add_child (\" game \", * game_ ); \n \n+ \n+ if ( game_ ) \n+ delete game_ ; \ngame_ = new config (); \n(* game_ )[\" time \"] = lexical_cast < std :: string >( SDL_GetTicks () / 1000 ); \n(* game_ )[\" campaign \"] = state . campaign_define ;", "mmm src / multiplayer_wait . cpp \nppp src / multiplayer_wait . cpp \nvoid wait :: start_game () \n \nLOG_NW << \" starting game \\ n \"; \nsound :: play_UI_sound ( game_config :: sounds :: mp_game_begins ); \n+ game_display :: get_singleton ()-> send_notification ( _ (\" Wesnoth \"), _ (\" Game has begun !\")); \n} \n \nvoid wait :: layout_children ( const SDL_Rect & rect )", "mmm src / team . cpp \nppp src / team . cpp \nvoid team :: team_info :: write ( config & cfg ) const \ncfg [\" hidden \"] = hidden ; \ncfg [\" suppress_end_turn_confirmation \"] = no_turn_confirmation ; \ncfg [\" scroll_to_leader \"] = scroll_to_leader ; \n- cfg [\" controller \"] = controller_string (); \n+ cfg [\" controller \"] = ( controller == IDLE ? \" human \" : controller_string ()); \n \nstd :: stringstream can_recruit_str ; \nfor ( std :: set < std :: string >:: const_iterator cr = can_recruit . begin (); cr != can_recruit . end (); ++ cr ) {", "mmm src / ai / default / ai . cpp \nppp src / ai / default / ai . cpp \nbool ai_default_recruitment_stage :: recruit_usage ( const std :: string & usage ) \n \nif ( imc != maximum_counts_ . end ()) { \nint count_active = 0 ; \n- for ( unit_map :: iterator u = get_info (). units . begin (); u != get_info (). units . end (); u ++) { \n+ for ( unit_map :: iterator u = get_info (). units . begin (); u != get_info (). units . end (); ++ u ) { \nif (( u -> second . side ()== get_side ()) && (! u -> second . incapacitated ()) && ( u -> second . type_id () == name )) { \n- count_active ++; \n+ ++ count_active ; \n} \n} \n", "mmm src / upload_log . cpp \nppp src / upload_log . cpp \nvoid upload_log :: start ( game_state & state , const team & team , \nif ( uploader_settings :: new_uploader ) { \n// replace newlines in map definition with semicolons so that braindead server - side wml parser doesn ' t get confused \nstd :: string encoded_map ( map_data ); \n- for ( int idx = 0 ; idx < encoded_map . length (); idx ++) { \n+ for ( size_t idx = 0 ; idx < encoded_map . length (); idx ++) { \nif ( encoded_map [ idx ] == '\\ n ') \nencoded_map [ idx ] = ';'; \n}", "mmm src / display . cpp \nppp src / display . cpp \n# include \" units / drawer . hpp \" \n# include \" whiteboard / manager . hpp \" \n# include \" show_dialog . hpp \" \n+# include \" gui / dialogs / loadscreen . hpp \" \n \n# include < SDL_image . h > \n \nvoid display :: handle_window_event ( const SDL_Event & event ) { \n} \n \nvoid display :: handle_event ( const SDL_Event & event ) { \n+ if ( gui2 :: tloadscreen :: displaying ()) { \n+ return ; \n+ } \nif ( event . type == DRAW_ALL_EVENT ) { \ndraw (); \n}", "mmm src / synced_commands . cpp \nppp src / synced_commands . cpp \nSYNCED_COMMAND_HANDLER_FUNCTION ( attack , child , /* use_undo */, show , error_handler \n} \n} \n \n- if ( size_t ( weapon_num ) >= u -> attacks (). size ()) { \n+ if ( static_cast < unsigned >( weapon_num ) >= u -> attacks (). size ()) { \nerror_handler (\" illegal weapon type in attack \\ n \", true ); \nreturn false ; \n}", "mmm src / widgets / scrollpane . cpp \nppp src / widgets / scrollpane . cpp \nvoid scrollpane :: draw () \n \nvoid scrollpane :: scroll ( unsigned int pos ) \n{ \n- if (( int ) pos == content_pos_ . y ) \n+ if ( static_cast < int >( pos ) == content_pos_ . y ) \nreturn ; \n \ncontent_pos_ . y = pos ;", "mmm src / about . cpp \nppp src / about . cpp \nstd :: vector < std :: string > get_text () { \n\" _ \" N_ (\"+ Catalan Translation \"), \n\"- Carles Company ( brrr )\", \n\"- Dan Ros\u00e0s Garcia ( focks )\", \n+ \"- Jonatan Alam\u00e0 ( tin )\", \n\"- Jord\u00e0 Polo ( ettin )\", \n\"- Mark Recasens \", \n\"- Pau Rul \u00b7 lan Ferragut \",", "mmm src / widgets / textbox . cpp \nppp src / widgets / textbox . cpp \nvoid textbox :: draw_cursor ( int pos ) const \n \nvoid textbox :: draw () const \n{ \n- if ( location (). h == 0 ) \n+ if ( location (). x == 0 ) \nreturn ; \n \nif ( buffer_ . get () != NULL ) { \nvoid textbox :: draw () const \n \nvoid textbox :: handle_event ( const SDL_Event & event ) \n{ \n+ if ( location (). x == 0 ) \n+ return ; \n+ \nint mousex , mousey ; \nSDL_GetMouseState (& mousex ,& mousey ); \n", "mmm src / extracts . cpp \nppp src / extracts . cpp \nvoid APar_Print_TrackDetails ( TrackInfo * track_info ) { \n} \n \nvoid APar_ExtractDetails ( FILE * isofile , uint8_t optional_output ) { \n- char uint32_buffer [ 5 ]; \n+ char uint32_buffer [ 8 ]; \nTrackage track = { 0 }; \n \nAtomicInfo * mvhdAtom = APar_FindAtom (\" moov . mvhd \", false , VERSIONED_ATOM , 0 );", "mmm wsutil / filesystem . c \nppp wsutil / filesystem . c \ncreate_persconffile_profile ( const char * profilename , char ** pf_dir_path_return ) \n* doing a \" stat ()\" on it . If it ' s a drive letter , \n* or if the \" stat ()\" succeeds , we assume it exists . \n*/ \n- pf_dir_path_copy = pf_dir_path ; \n+ pf_dir_path_copy = g_strdup ( pf_dir_path ); \npf_dir_parent_path = get_dirname ( pf_dir_path_copy ); \npf_dir_parent_path_len = strlen ( pf_dir_parent_path ); \nif ( pf_dir_parent_path_len > 0 \ncreate_persconffile_profile ( const char * profilename , char ** pf_dir_path_return ) \nsave_errno = errno ; \n* pf_dir_path_return = pf_dir_path ; \nerrno = save_errno ; \n+ g_free ( pf_dir_path_copy ); \nreturn - 1 ; \n} \n/* \ncreate_persconffile_profile ( const char * profilename , char ** pf_dir_path_return ) \nret = ws_mkdir ( pf_dir_parent_path , 0755 ); \nif ( ret == - 1 ) { \n* pf_dir_path_return = pf_dir_parent_path ; \n+ g_free ( pf_dir_path ); \nreturn - 1 ; \n} \n}", "mmm epan / dissectors / packet - ipsec . c \nppp epan / dissectors / packet - ipsec . c \ndissect_esp ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) \n/* Copy back the Authentication which was not encrypted */ \nif ( decrypted_len >= esp_auth_len ) \n{ \n- tvb_memcpy ( tvb , decrypted_data + decrypted_len - esp_auth_len , sizeof ( struct newesp )+ decrypted_len - esp_auth_len , esp_auth_len ); \n+ tvb_memcpy ( tvb , decrypted_data + decrypted_len - esp_auth_len , ( gint )( sizeof ( struct newesp )+ decrypted_len - esp_auth_len ), esp_auth_len ); \n} \n \n/* Decryption has finished */", "mmm packet - smb - browse . c \nppp packet - smb - browse . c \n* Routines for SMB Browser packet dissection \n* Copyright 1999 , Richard Sharpe < rsharpe @ ns . aus . com > \n* \n- * $ Id : packet - smb - browse . c , v 1 . 15 2001 / 08 / 01 03 : 47 : 00 guy Exp $ \n+ * $ Id : packet - smb - browse . c , v 1 . 16 2001 / 08 / 01 08 : 12 : 15 guy Exp $ \n* \n* Ethereal - Network traffic analyzer \n* By Gerald Combs < gerald @ ethereal . com > \ndissect_mailslot_browse ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * parent_tr \nproto_tree_add_item ( tree , hf_update_count , tvb , offset , 1 , TRUE ); \noffset += 1 ; \n \n- /* periodicity */ \n+ /* periodicity ( in milliseconds ) */ \nperiodicity = tvb_get_letohl ( tvb , offset ); \nproto_tree_add_uint_format ( tree , hf_periodicity , tvb , offset , 4 , \nperiodicity , \ndissect_mailslot_browse ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * parent_tr \n* \n* The document at \n* \n- * http :// www . samba . org / samba / ftp / specs / smbpub . txt \n+ * http :// www . samba . org / samba / ftp / specs / brow_rev . txt \n* \n* gives both formats of host announcement packets , saying that \n* \"[ The first ] format seems wrong \", that one being what appears to \ndissect_mailslot_lanman ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * parent_tr \nproto_tree_add_item ( tree , hf_os_minor , tvb , offset , 1 , TRUE ); \noffset += 1 ; \n \n- /* periodicity */ \n- periodicity = tvb_get_letohs ( tvb , offset ); \n+ /* periodicity ( in seconds ; convert to milliseconds ) */ \n+ periodicity = tvb_get_letohs ( tvb , offset )* 1000 ; \nproto_tree_add_uint_format ( tree , hf_periodicity , tvb , offset , 2 , \nperiodicity , \n\" Update Periodicity : % s \",", "mmm packet - esis . c \nppp packet - esis . c \n* Routines for ISO / OSI End System to Intermediate System \n* Routing Exchange Protocol ISO 9542 . \n* \n- * $ Id : packet - esis . c , v 1 . 27 2002 / 08 / 28 21 : 00 : 13 jmayer Exp $ \n+ * $ Id : packet - esis . c , v 1 . 28 2003 / 02 / 25 19 : 07 : 07 guy Exp $ \n* Ralf Schneider < Ralf . Schneider @ t - online . de > \n* \n* Ethereal - Network traffic analyzer \nproto_reg_handoff_esis ( void ) \ndissector_handle_t esis_handle ; \n \nesis_handle = create_dissector_handle ( dissect_esis , proto_esis ); \n+ register_dissector (\" esis \", dissect_esis , proto_esis ); \ndissector_add (\" osinl \", NLPID_ISO9542_ESIS , esis_handle ); \n}", "mmm wiretap / file_access . c \nppp wiretap / file_access . c \ncleanup_open_routines ( void ) \nguint i ; \nstruct open_info * i_open ; \n \n- for ( i = 0 , i_open = open_routines ; i < open_info_arr -> len ; i ++, i_open ++) { \n- if ( i_open -> extensions != NULL ) \n- g_strfreev ( i_open -> extensions_set ); \n- } \n+ if ( open_routines != NULL ) { \n+ for ( i = 0 , i_open = open_routines ; i < open_info_arr -> len ; i ++, i_open ++) { \n+ if ( i_open -> extensions != NULL ) \n+ g_strfreev ( i_open -> extensions_set ); \n+ } \n \n- g_array_free ( open_info_arr , TRUE ); \n+ g_array_free ( open_info_arr , TRUE ); \n+ } \n} \n \n/*", "mmm gtk / main . c \nppp gtk / main . c \nmain ( int argc , char * argv []) \n/* read in rc file from global and personal configuration paths . */ \nrc_file = get_datafile_path ( RC_FILE ); \ngtk_rc_parse ( rc_file ); \n+ g_free ( rc_file ); \nrc_file = get_persconffile_path ( RC_FILE , FALSE , FALSE ); \ngtk_rc_parse ( rc_file ); \n+ g_free ( rc_file ); \n \nfont_init (); \n \nmain ( int argc , char * argv []) \nu3_deregister_pid (); \n \nepan_cleanup (); \n- g_free ( rc_file ); \n \n# ifdef HAVE_AIRPDCAP \n/* Davide Schiera ( 2006 - 11 - 18 ): destroy AirPDcap context */", "mmm file . c \nppp file . c \n/* file . c \n* File I / O routines \n* \n- * $ Id : file . c , v 1 . 219 2000 / 09 / 11 22 : 43 : 02 sharpe Exp $ \n+ * $ Id : file . c , v 1 . 220 2000 / 09 / 12 03 : 27 : 00 guy Exp $ \n* \n* Ethereal - Network traffic analyzer \n* By Gerald Combs < gerald @ zing . org > \nrescan_packets ( capture_file * cf , const char * action , gboolean refilter , \n \nif ( redissect ) { \n/* Since all state for the frame was destroyed , mark the frame \n- * as not visited , and null out the pointer to the per - frame \n+ * as not visited , free the GSList referring to the state \n* data ( the per - frame data itself was freed by \n- * \" init_all_protocols ()\"). */ \n+ * \" init_all_protocols ()\"), and null out the GSlist pointer . */ \nfdata -> flags . visited = 0 ; \n- \n- /* If there is any per - frame data , delete that , as what it points to \n- * has gone as well . \n- */ \n- \nif ( fdata -> pfd ) { \ng_slist_free ( fdata -> pfd ); \n} \nrescan_packets ( capture_file * cf , const char * action , gboolean refilter , \nuntil it finishes . Should we just stick them with that ? */ \nfor (; fdata != NULL ; fdata = fdata -> next ) { \nfdata -> flags . visited = 0 ; \n+ if ( fdata -> pfd ) { \n+ g_slist_free ( fdata -> pfd ); \n+ } \nfdata -> pfd = NULL ; \n} \n}", "mmm ui / capture . c \nppp ui / capture . c \ncapture_start ( capture_options * capture_opts , capture_session * cap_session , void ( \nGString * source ; \n \ncap_session -> state = CAPTURE_PREPARING ; \n+ cap_session -> count = 0 ; \ng_log ( LOG_DOMAIN_CAPTURE , G_LOG_LEVEL_MESSAGE , \" Capture Start ...\"); \nsource = get_iface_list_string ( capture_opts , IFLIST_SHOW_FILTER ); \ncf_set_tempfile_source (( capture_file *) cap_session -> cf , source -> str );", "mmm epan / register . c \nppp epan / register . c \nregister_all_protocols ( register_cb cb , gpointer cb_data ) \n} \ng_thread_join ( rapw_thread ); \nif ( cb && ! called_back ) { \n- cb ( RA_REGISTER , \" Registration finished \", cb_data ); \n+ cb ( RA_REGISTER , \" finished \", cb_data ); \n} \n} \n \nregister_all_protocol_handoffs ( register_cb cb , gpointer cb_data ) \n} \ng_thread_join ( raphw_thread ); \nif ( cb && ! called_back ) { \n- cb ( RA_HANDOFF , \" Registration finished \", cb_data ); \n+ cb ( RA_HANDOFF , \" finished \", cb_data ); \n} \ng_async_queue_unref ( register_cb_done_q ); \n", "mmm epan / wslua / wslua_pinfo . c \nppp epan / wslua / wslua_pinfo . c \nWSLUA_METAMETHOD Columns__newindex ( lua_State * L ) { \n \nfor ( cn = colnames ; cn -> name ; cn ++) { \nif ( g_str_equal ( cn -> name , colname ) ) { \n- col_set_str ( cols -> cinfo , cn -> id , text ); \n+ col_add_str ( cols -> cinfo , cn -> id , text ); \nreturn 0 ; \n} \n}", "mmm asn1 / tcap / packet - tcap - template . c \nppp asn1 / tcap / packet - tcap - template . c \nproto_register_tcap ( void ) \n/* we will fake a ssn subfield which has the same value obtained from sccp */ \ntcap_itu_ssn_dissector_table = register_dissector_table (\" tcap . itu_ssn \", \" ITU TCAP SSN \", FT_UINT8 , BASE_DEC ); \ntcap_ansi_ssn_dissector_table = register_dissector_table (\" tcap . ansi_ssn \", \" ANSI TCAP SSN \", FT_UINT8 , BASE_DEC ); \n+ \n+ /* ' globally ' register dissector */ \n+ register_dissector (\" tcap \", dissect_tcap , proto_tcap ); \n+ \n} \n \n", "mmm epan / dissectors / packet - gprs - llc . c \nppp epan / dissectors / packet - gprs - llc . c \nproto_register_llcgprs ( void ) \nvoid \nproto_reg_handoff_llcgprs ( void ) \n{ \n- dissector_handle_t llcgprs_handle ; \n- \n- llcgprs_handle = create_dissector_handle ( dissect_llcgprs , \n- proto_llcgprs ); \n-/* dissector_add (\" PARENT_SUBFIELD \", ID_VALUE , llcgprs_handle ); \n-*/ \ndata_handle = find_dissector (\" data \"); \n}", "mmm epan / dissectors / packet - wsp . c \nppp epan / dissectors / packet - wsp . c \nadd_content_type ( proto_tree * tree , tvbuff_t * tvb , guint32 val_start , \nSo we have to disable that one and become \" slow \" by pretending that \nthe tree is \" visible \". \n*/ \n- PTREE_DATA ( tree )-> visible = 1 ; \n+ if ( tree ) \n+ PTREE_DATA ( tree )-> visible = 1 ; \n \n* textual_content = NULL ; \n* well_known_content = 0 ;", "mmm epan / dissectors / packet - gsm_a_bssmap . c \nppp epan / dissectors / packet - gsm_a_bssmap . c \nstatic const value_string bssap_speech_codec_values [] = { \nstatic guint8 \nbe_speech_codec_lst ( tvbuff_t * tvb , proto_tree * tree , guint32 offset , guint len _U_ , gchar * add_string _U_ , int string_len _U_ ) \n{ \n- guint32 curr_offset , consumed ; \n+ guint32 curr_offset , consumed = 0 ; \nguint8 codec ; \nguint8 number = 0 ; \nproto_item * item = NULL ;", "mmm epan / dissectors / packet - sbus . c \nppp epan / dissectors / packet - sbus . c \ndissect_sbus ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * data _U_ \n} \noffset += 2 ; /* now at the end of the telegram */ \n} \n- return tvb_length ( tvb ); \n+ return offset ; \n/* End of dissect_sbus */ \n} \n", "mmm capture . c \nppp capture . c \n/* capture . c \n* Routines for packet capture windows \n* \n- * $ Id : capture . c , v 1 . 102 2000 / 05 / 18 09 : 05 : 25 guy Exp $ \n+ * $ Id : capture . c , v 1 . 103 2000 / 05 / 19 19 : 53 : 48 gram Exp $ \n* \n* Ethereal - Network traffic analyzer \n* By Gerald Combs < gerald @ zing . org > \ndo_capture ( char * capfile_name ) \nerror = errno ; \nclose ( sync_pipe [ 1 ]); \nclose ( sync_pipe [ 0 ]); \n+ close ( cf . save_file_fd ); \nunlink ( cf . save_file ); \ng_free ( cf . save_file ); \ncf . save_file = NULL ; \ndo_capture ( char * capfile_name ) \nreturn ; \n} \n \n+ close ( cf . save_file_fd ); \n+ \n/* Parent process - read messages from the child process over the \nsync pipe . */ \nclose ( sync_pipe [ 1 ]); \ndo_capture ( char * capfile_name ) \n} else { \n/* Not sync mode . */ \ncapture_succeeded = capture (); \n+ close ( cf . save_file_fd ); \nif ( quit_after_cap ) { \n/* DON ' T unlink the save file . Presumably someone wants it . */ \ngtk_exit ( 0 );", "mmm epan / wslua / wslua_dumper . c \nppp epan / wslua / wslua_dumper . c \nWSLUA_METHOD Dumper_dump ( lua_State * L ) { \npkthdr . len = ba -> len ; \npkthdr . caplen = ba -> len ; \npkthdr . pkt_encap = DUMPER_ENCAP ( d ); \n- pkthdr . pseudo_header = * ph -> wph ; \n+ if ( ph -> wph ) { \n+ pkthdr . pseudo_header = * ph -> wph ; \n+ } \n \n/* TODO : Can we get access to pinfo -> pkt_comment here somehow ? We \n* should be copying it to pkthdr . opt_comment if we can . */", "mmm ui / gtk / stats_tree_stat . c \nppp ui / gtk / stats_tree_stat . c \nclear_node_pr ( stat_node * n ) \nclear_node_pr ( c ); \n} \n \n- if ( n -> pr -> iter ) { \n+ if ( n -> pr && n -> pr -> iter ) { \ngtk_tree_store_remove ( n -> st -> pr -> store , n -> pr -> iter ); \nn -> pr -> iter = NULL ; \n}", "mmm epan / dissectors / packet - mac - lte . c \nppp epan / dissectors / packet - mac - lte . c \nstatic void dissect_ulsch_or_dlsch ( tvbuff_t * tvb , packet_info * pinfo , proto_tree \ncase PADDING_LCID : \n/* No payload , unless its the last subheader , in which case \nit extends to the end of the PDU */ \n- if ( n == ( number_of_headers - 1 )) { \n+ if ( n == ( number_of_headers - 1 ) && ( tvb_length_remaining ( tvb , offset ) > 0 )) { \nproto_tree_add_item ( tree , hf_mac_lte_padding_data , \ntvb , offset , - 1 , FALSE ); \n}", "mmm epan / dissectors / packet - rtp . c \nppp epan / dissectors / packet - rtp . c \ndissect_rtp_hext_rfc5215_onebyte ( tvbuff_t * tvb , packet_info * pinfo , \nreturn ; \n \next_length = ( ext_hdr_hdr & 0x0F ) + 1 ; \n+ \n+ /* Exit on malformed extension headers */ \n+ if ( ext_offset + ext_length + 1 > tvb_captured_length ( tvb )) { \n+ return ; \n+ } \n+ \nif ( rtp_hext_tree ) { \nrtp_hext_rfc5285_tree = proto_tree_add_subtree ( rtp_hext_tree , tvb , ext_offset , ext_length + 1 , \nett_hdr_ext_rfc5285 , NULL , \" RFC 5285 Header Extension ( One - Byte Header )\");", "mmm epan / column - utils . c \nppp epan / column - utils . c \ncol_set_addr ( packet_info * pinfo , int col , address * addr , gboolean is_res , \ng_strlcpy ( pinfo -> cinfo -> col_expr . col_expr [ col ], \" ipv6 . src \", COL_MAX_LEN ); \nelse \ng_strlcpy ( pinfo -> cinfo -> col_expr . col_expr [ col ], \" ipv6 . dst \", COL_MAX_LEN ); \n+ memcpy (& ipv6_addr . bytes , addr -> data , sizeof ipv6_addr . bytes ); \ng_strlcpy ( pinfo -> cinfo -> col_expr . col_expr_val [ col ], ip6_to_str (& ipv6_addr ), COL_MAX_LEN ); \nbreak ; \n", "mmm epan / dissectors / packet - smb - mailslot . c \nppp epan / dissectors / packet - smb - mailslot . c \ndissect_mailslot_smb ( tvbuff_t * mshdr_tvb , tvbuff_t * setup_tvb , \n} \n \nsmb_info = pinfo -> private_data ; \n- if ( smb_info -> sip != NULL && smb_info -> sip -> extra_info_type == SMB_EI_TRI ) \n+ if ( smb_info != NULL && smb_info -> sip != NULL && smb_info -> sip -> extra_info_type == SMB_EI_TRI ) \ntri = smb_info -> sip -> extra_info ; \nelse \ntri = NULL ;", "mmm epan / dissectors / packet - mle . c \nppp epan / dissectors / packet - mle . c \ndissect_mle_decrypt ( tvbuff_t * tvb , \n \nDISSECTOR_ASSERT ( pinfo -> src . len == 16 ); \nDISSECTOR_ASSERT ( pinfo -> dst . len == 16 ); \n- memcpy ( d_a , ( guint8 *) pinfo -> src . data , pinfo -> src . len ); \n- memcpy ( d_a + 16 , ( guint8 *) pinfo -> dst . data , pinfo -> dst . len ); \n+ memcpy ( d_a , ( const guint8 *) pinfo -> src . data , pinfo -> src . len ); \n+ memcpy ( d_a + 16 , ( const guint8 *) pinfo -> dst . data , pinfo -> dst . len ); \n \ntvb_memcpy ( tvb , d_a + 32 , payload_info -> aux_offset , payload_info -> aux_length ); \nl_a = 32 + payload_info -> aux_length ;", "mmm dumpcap . c \nppp dumpcap . c \ncapture_loop_init_output ( capture_options * capture_opts , loop_data * ld , char * err \n- 1 , /* section_length */ \n& ld -> bytes_written , \n& err ); \n+ g_string_free ( cpu_info_str , TRUE ); \ng_free ( appname ); \n \nfor ( i = 0 ; successful && ( i < capture_opts -> ifaces -> len ); i ++) { \ndo_file_switch_or_stop ( capture_options * capture_opts , \n- 1 , /* section_length */ \n&( global_ld . bytes_written ), \n& global_ld . err ); \n+ g_string_free ( cpu_info_str , TRUE ); \ng_free ( appname ); \n \nfor ( i = 0 ; successful && ( i < capture_opts -> ifaces -> len ); i ++) {", "mmm epan / dissectors / packet - mpeg - descriptor . c \nppp epan / dissectors / packet - mpeg - descriptor . c \nproto_mpeg_descriptor_dissect_extension ( tvbuff_t * tvb , guint offset , guint8 len , \nproto_tree_add_text ( tree , tvb , offset , len - already_dissected , \" Private data \"); \nbreak ; \ndefault : \n- proto_tree_add_item ( tree , hf_mpeg_descr_extension_data , tvb , offset , len , ENC_NA ); \n+ already_dissected = offset - offset_start ; \n+ if ( already_dissected < len ) \n+ proto_tree_add_item ( tree , hf_mpeg_descr_extension_data , tvb , offset , len - already_dissected , ENC_NA ); \nbreak ; \n} \n", "mmm epan / dissectors / packet - e100 . c \nppp epan / dissectors / packet - e100 . c \nproto_reg_handoff_e100 ( void ) \n/* Check all UDP traffic , as the specific UDP port is configurable */ \nheur_dissector_add (\" udp \", dissect_e100 , \" E100 over UDP \", \" e100_udp \", proto_e100 , HEURISTIC_ENABLE ); \n/* e100 traffic encapsulates traffic from the ethernet frame on */ \n- eth_handle = find_dissector (\" eth \"); \n+ eth_handle = find_dissector (\" eth_withoutfcs \"); \n} \n \n/*", "mmm epan / dissectors / packet - dcerpc . c \nppp epan / dissectors / packet - dcerpc . c \ndissect_dcerpc_cn_bs_body ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) \n* it was just too short to tell and ask the TCP layer for more \n* data . */ \npinfo -> desegment_offset = offset ; \n- pinfo -> desegment_len = sizeof ( e_dce_cn_common_hdr_t ) - tvb_length_remaining ( tvb , offset ); \n+ pinfo -> desegment_len = ( guint32 )( sizeof ( e_dce_cn_common_hdr_t ) - tvb_length_remaining ( tvb , offset )); \n} else { \n/* Really not DCE - RPC */ \nbreak ;", "mmm gtk / packet_list_store . c \nppp gtk / packet_list_store . c \npacket_list_sortable_set_sort_column_id ( GtkTreeSortable * sortable , \npacket_list -> sort_order == order ) \nreturn ; \n \n+ if (! col_based_on_frame_data (& cfile . cinfo , sort_col_id )) { \n+ g_warning (\" Sorting on column % u not supported \", sort_col_id ); \n+ return ; \n+ } \n+ \npacket_list -> sort_id = sort_col_id ; \npacket_list -> sort_order = order ; \n", "mmm epan / dissectors / packet - ieee80211 . c \nppp epan / dissectors / packet - ieee80211 . c \nstatic void init_wepkeys ( void ) { \n \n# ifdef USE_ENV \nbuf = ep_alloc ( 128 ); \n- sprintf ( buf , 128 , \" ETHEREAL_WEPKEY % d \", i + 1 ); \n+ g_snprintf ( buf , 128 , \" ETHEREAL_WEPKEY % d \", i + 1 ); \ntmp = getenv ( buf ); \n# else \ntmp = wep_keystr [ i ];", "mmm ui / win32 / file_dlg_win32 . c \nppp ui / win32 / file_dlg_win32 . c \nbuild_file_save_type_list ( GArray * savable_file_types ) { \nft = g_array_index ( savable_file_types , int , i ); \nappend_file_type ( sa , ft ); \n} \n- g_array_free ( savable_file_types , TRUE ); \n} \n \n/* terminate the array */", "mmm epan / dissectors / packet - sigcomp . c \nppp epan / dissectors / packet - sigcomp . c \ndissect_sigcomp_tcp ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * _ \n \ncol_clear ( pinfo -> cinfo , COL_INFO ); \n \n- length = tvb_captured_length_remaining ( tvb , offset ); \n+ length = tvb_reported_length ( tvb ); \n \ntry_again : \n/* create display subtree for the protocol */", "mmm file . c \nppp file . c \ncf_print_packets ( capture_file * cf , print_args_t * print_args , \n} \n \n/* if num_visible_col is 0 , we are done */ \n- if ( num_visible_col == 0 ) \n+ if ( num_visible_col == 0 ) { \n+ g_free ( callback_args . header_line_buf ); \nreturn CF_PRINT_OK ; \n+ } \n \n/* Find the widths for each of the columns - maximum of the \nwidth of the title and the width of the data - and construct", "mmm capture_sync . c \nppp capture_sync . c \nsync_pipe_start ( capture_options * capture_opts ) { \nexecv ( argv [ 0 ], ( gpointer ) argv ); \ng_snprintf ( errmsg , sizeof errmsg , \" Couldn ' t run % s in child process : % s \", \nargv [ 0 ], strerror ( errno )); \n- sync_pipe_errmsg_to_parent ( errmsg , \"\"); \n+ sync_pipe_errmsg_to_parent ( 1 , errmsg , \"\"); \n \n/* Exit with \" _exit ()\", so that we don ' t close the connection \nto the X server ( and cause stuff buffered up by our parent but \nsync_interface_stats_open ( int * read_fd , int * fork_child , gchar ** msg ) { \n \n/* Close down the stats process */ \nint \n- sync_interface_stats_close ( int * read_fd , int * fork_child , gchar ** msg ) { \n+ sync_interface_stats_close ( int * read_fd , int * fork_child \n+# ifndef _WIN32 \n+ _U_ \n+# endif \n+, gchar ** msg ) { \n# ifdef _WIN32 \nreturn sync_pipe_close_command ( read_fd , fork_child , msg ); \n# else", "mmm epan / dissectors / packet - nsip . c \nppp epan / dissectors / packet - nsip . c \ndecode_pdu_sns_delete ( build_info_t * bi ) { \n{ NSIP_IE_IP4_ELEMENTS , NSIP_IE_PRESENCE_C , NSIP_IE_FORMAT_TLV , 0 , 0 }, \n{ NSIP_IE_IP6_ELEMENTS , NSIP_IE_PRESENCE_C , NSIP_IE_FORMAT_TLV , 0 , 0 }, \n}; \n- decode_iei_transaction_id ( ies , bi , bi -> offset ); \n- decode_pdu_general (& ies [ 1 ], 3 , bi ); \n+ decode_pdu_general ( ies , 1 , bi ); \n+ decode_iei_transaction_id (& ies [ 1 ], bi , bi -> offset ); \n+ decode_pdu_general (& ies [ 2 ], 3 , bi ); \n} \n \nstatic void", "mmm epan / dissectors / packet - cip . c \nppp epan / dissectors / packet - cip . c \nstatic int dissect_cip_attribute ( packet_info * pinfo , proto_tree * tree , proto_ite \n/* Convert to nstime epoch */ \ncomputed_time = CIP_TIMEBASE +( temp_data * 60 * 60 * 24 ); \ndate = gmtime (& computed_time ); \n- strftime ( date_str , 20 , \"% b % d , % Y \", date ); \n+ if ( date != NULL ) \n+ strftime ( date_str , 20 , \"% b % d , % Y \", date ); \n+ else \n+ g_strlcpy ( date_str , \" Not representable \", sizeof date_str ); \nproto_tree_add_uint_format_value ( tree , *( attr -> phf ), tvb , offset , 2 , temp_data , \"% s \", date_str ); \nconsumed = 2 ; \nbreak ;", "mmm epan / dissectors / packet - quic . c \nppp epan / dissectors / packet - quic . c \ndissect_quic_common ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , \n \n/* Diversification Nonce */ \nif ( puflags & PUFLAGS_DNONCE && quic_info -> version >= 33 ){ \n- proto_tree_add_item ( quic_tree , hf_quic_diversification_nonce , tvb , offset , 32 , ENC_NA ); \n- offset += 32 ; \n+ if ( pinfo -> srcport == 443 ){ /* Diversification nonce is only present from server to client */ \n+ proto_tree_add_item ( quic_tree , hf_quic_diversification_nonce , tvb , offset , 32 , ENC_NA ); \n+ offset += 32 ; \n+ } \n} \n \n- \n/* Packet Number */ \n \n/* Get len of packet number ( and packet number ), may be a more easy function to get the length ... */", "mmm epan / prefs . c \nppp epan / prefs . c \nset_pref ( gchar * pref_name , gchar * value , void * private_data _U_ , \nfind_index_from_string_array ( value , gui_layout_content_text , 0 ); \n} else if ( strcmp ( pref_name , PRS_CONSOLE_LOG_LEVEL ) == 0 ) { \nprefs . console_log_level = strtoul ( value , NULL , 10 ); \n- if ( prefs . console_log_level & G_LOG_LEVEL_INFO | G_LOG_LEVEL_DEBUG ) { \n+ if ( prefs . console_log_level & ( G_LOG_LEVEL_INFO | G_LOG_LEVEL_DEBUG )) { \n/* \n* GLib >= 2 . 32 drops INFO and DEBUG messages by default . Tell \n* it not to do that .", "mmm epan / dissectors / packet - usb . c \nppp epan / dissectors / packet - usb . c \ntry_dissect_next_protocol ( proto_tree * parent , tvbuff_t * next_tvb , gint offset , p \n \nif ( try_heuristics && dissector_try_heuristic ( heur_subdissector_list , next_tvb , pinfo , parent , usb_conv_info )) { \noffset += tvb_length ( next_tvb ); \n- } else if ( dissector_try_uint_new ( usb_dissector_table , usb_conv_info -> interfaceClass , next_tvb , pinfo , parent , TRUE , usb_conv_info )) { \n+ } else if ( usb_dissector_table && \n+ dissector_try_uint_new ( usb_dissector_table , usb_conv_info -> interfaceClass , next_tvb , pinfo , parent , TRUE , usb_conv_info )) { \noffset += tvb_length ( next_tvb ); \n} \n}", "mmm ui / gtk / profile_dlg . c \nppp ui / gtk / profile_dlg . c \nfill_list ( GtkWidget * main_w ) \n* and use it later without any crashes . This may not be a \n* valid assumption . \n*/ \n+ g_free ( l_select ); \nl_select = ( GtkTreeIter *) g_memdup (& iter , sizeof ( iter )); \n} \nfl_entry = g_list_next ( fl_entry );", "mmm plugins / mgcp / packet - mgcp . c \nppp plugins / mgcp / packet - mgcp . c \n* PKT - SP - EC - MGCP - I09 - 040113 , January 13 , 2004 , Cable Television \n* Laboratories , Inc ., http :// www . PacketCable . com / \n* \n- * $ Id : packet - mgcp . c , v 1 . 46 2004 / 05 / 30 17 : 58 : 35 etxrab Exp $ \n+ * $ Id : packet - mgcp . c , v 1 . 47 2004 / 05 / 31 19 : 31 : 14 etxrab Exp $ \n* \n* Copyright ( c ) 2000 by Ed Warnicke < hagbard @ physics . rutgers . edu > \n* Copyright ( c ) 2004 by Thomas Anders < thomas . anders [ AT ] blue - cable . de > \ndissect_mgcp_connectionparams ( proto_tree * parent_tree , tvbuff_t * tvb , gint offse \n} \noffset += tokenlen + 1 ; /* 1 extra for the delimiter */ \n} \n+ g_strfreev ( typval ); \n+ g_strfreev ( tokens ); \n+ \n} \n \n/*", "mmm epan / dissectors / packet - corosync - totemnet . c \nppp epan / dissectors / packet - corosync - totemnet . c \ndissect_corosynec_totemnet ( tvbuff_t * tvb , \nreturn call_dissector ( corosync_totemsrp_handle , tvb , pinfo , parent_tree ); \n} \n \n+ static void \n+ corosync_totemnet_shutdown ( void ) \n+{ \n+ g_strfreev ( corosync_totemnet_private_keys_list ); \n+} \n \nvoid \nproto_register_corosync_totemnet ( void ) \nproto_register_corosync_totemnet ( void ) \nprefs_register_string_preference ( corosync_totemnet_module , \" private_keys \", \" Private keys \", \n\" Semicolon - separated list of keys for decryption ( e . g . key1 ; key2 ;...\" , \n( const gchar **)& corosync_totemnet_private_keys ); \n+ \n+ register_shutdown_routine ( corosync_totemnet_shutdown ); \n} \n \nvoid", "mmm packet - dcerpc - mapi . c \nppp packet - dcerpc - mapi . c \n* Routines for MS Exchange MAPI \n* Copyright 2002 , Ronnie Sahlberg \n* \n- * $ Id : packet - dcerpc - mapi . c , v 1 . 5 2002 / 05 / 25 09 : 19 : 45 sahlberg Exp $ \n+ * $ Id : packet - dcerpc - mapi . c , v 1 . 6 2002 / 05 / 25 10 : 25 : 27 guy Exp $ \n* \n* Ethereal - Network traffic analyzer \n* By Gerald Combs < gerald @ ethereal . com > \nmapi_decrypt_pdu ( tvbuff_t * tvb , int offset , \nproto_tree_add_item ( tr , hf_mapi_decrypted_data , mmd -> tvb , 2 , pdu_len , FALSE ); \n \nproto_tree_add_item ( tr , hf_mapi_pdu_trailer , mmd -> tvb , pdu_len , 4 , FALSE ); \n- if ( len >( pdu_len + 4 )){ \n+ if ( len >(( guint32 ) pdu_len + 4 )){ \nproto_tree_add_item ( tr , hf_mapi_pdu_extra_trailer , mmd -> tvb , pdu_len + 4 , len -( pdu_len + 4 ), FALSE ); \n} \n", "mmm epan / dissectors / packet - sua . c \nppp epan / dissectors / packet - sua . c \nproto_register_sua ( void ) \n\" This may affect TCAP ' s ability to recognize which messages belong to which TCAP session .\", & set_addresses ); \n \nheur_subdissector_list = register_heur_dissector_list (\" sua \"); \n- sua_parameter_table = register_dissector_table (\" sua . prop . tags \", \" SUA Proprietary Tags \", FT_UINT16 , BASE_DEC , DISSECTOR_TABLE_NOT_ALLOW_DUPLICATE ); \n+ sua_parameter_table = register_dissector_table (\" sua . prop . tags \", \" SUA Proprietary Tags \", FT_UINT16 , BASE_DEC , DISSECTOR_TABLE_ALLOW_DUPLICATE ); \nsua_tap = register_tap (\" sua \"); \n \nassocs = wmem_tree_new_autoreset ( wmem_epan_scope (), wmem_file_scope ());", "mmm wiretap / netmon . c \nppp wiretap / netmon . c \nnetmon_process_record ( wtap * wth , FILE_T fh , struct wtap_pkthdr * phdr , \nswitch ( network ) \n{ \ncase 0xE080 : // \" WiFi Message \" \n+ pkt_encap = WTAP_ENCAP_IEEE_802_11 ; \n+ break ; \ncase 0xE081 : // \" Ndis Etw WiFi Channel Message \" \ncase 0xE082 : // \" Fiddler Netmon Message \" \ncase 0xE089 : // \" Pef Ndis Msg \";", "mmm epan / dissectors / packet - ssl - utils . c \nppp epan / dissectors / packet - ssl - utils . c \nssl_find_private_key ( SslDecryptSession * ssl_session , GHashTable * key_hash , GTree \nssl_debug_printf (\" ssl_find_private_key server % s :% u \\ n \", \nep_address_to_str (& dummy . addr ), dummy . port ); \n \n+ if ( g_hash_table_size ( key_hash ) == 0 ) { \n+ ssl_debug_printf (\" ssl_find_private_key : no keys found \\ n \"); \n+ return ; \n+ } else { \n+ ssl_debug_printf (\" ssl_find_private_key : testing % i keys \\ n \", \n+ g_hash_table_size ( key_hash )); \n+ } \n+ \n/* try to retrieve private key for this service . Do it now ' cause pinfo \n* is not always available \n* Note that with HAVE_LIBGNUTLS undefined private_key is allways 0", "mmm epan / wslua / wslua_internals . c \nppp epan / wslua / wslua_internals . c \nWSLUA_API void wslua_setfuncs ( lua_State * L , const luaL_Reg * l , int nup ) { \n} \n \n/* identical to lua_getfield but without triggering metamethods */ \n- WSLUA_API void lua_rawgetfield ( lua_State * L , int index , const char * k ) { \n+ WSLUA_API void lua_rawgetfield ( lua_State * L , int idx , const char * k ) { \nlua_pushstring ( L , k ); \n- lua_rawget ( L , index ); \n+ lua_rawget ( L , idx ); \n} \n \n/* identical to lua_setfield but without triggering metamethods */ \n- WSLUA_API void lua_rawsetfield ( lua_State * L , int index , const char * k ) { \n+ WSLUA_API void lua_rawsetfield ( lua_State * L , int idx , const char * k ) { \nlua_pushstring ( L , k ); \nlua_insert ( L , - 2 ); \n- lua_rawset ( L , index ); \n+ lua_rawset ( L , idx ); \n} \n \nWSLUA_API void wslua_print_stack ( char * s , lua_State * L ) {", "mmm epan / dissectors / packet - gtp . c \nppp epan / dissectors / packet - gtp . c \n* Copyright 2011 , Grzegorz Szczytowski < grzegorz . szczytowski @ gmail . com > \n* \n* Updates and corrections : \n- * Copyright 2011 - 2012 , Anders Broman < anders . broman @ ericsson . com > \n+ * Copyright 2011 - 2013 , Anders Broman < anders . broman @ ericsson . com > \n* \n* PDCP PDU number extension header support added by Martin Isaksson < martin . isaksson @ ericsson . com > \n* \ndecode_gtp_priv_ext ( tvbuff_t * tvb , int offset , packet_info * pinfo _U_ , proto_t \noffset = offset + 2 ; \n \nif ( length > 2 ) { \n- next_tvb = tvb_new_subset_remaining ( tvb , offset ); \n+ next_tvb = tvb_new_subset ( tvb , offset , length - 2 , length - 2 ); \nif (! dissector_try_uint ( gtp_priv_ext_dissector_table , ext_id , next_tvb , pinfo , ext_tree_priv_ext )){ \nproto_tree_add_item ( ext_tree_priv_ext , hf_gtp_ext_val , tvb , offset , length - 2 , ENC_NA ); \n}", "mmm epan / dissectors / packet - xot . c \nppp epan / dissectors / packet - xot . c \nproto_register_xot ( void ) \nproto_xot = proto_register_protocol (\" X . 25 over TCP \", \" XOT \", \" xot \"); \nproto_register_field_array ( proto_xot , hf , array_length ( hf )); \nproto_register_subtree_array ( ett , array_length ( ett )); \n+ register_dissector (\" xot \", dissect_xot , proto_xot ); \n \nxot_module = prefs_register_protocol ( proto_xot , NULL ); \nprefs_register_bool_preference ( xot_module , \" desegment \",", "mmm epan / dissectors / packet - ssl - utils . c \nppp epan / dissectors / packet - ssl - utils . c \nssl_association_remove ( GTree * associations , SslAssociation * assoc ) \nif ( assoc -> handle ) \ndissector_delete (( assoc -> tcp )?\" tcp . port \":\" udp . port \", assoc -> ssl_port , assoc -> handle ); \n \n+ g_free ( assoc -> info ); \n+ \ng_tree_remove ( associations , assoc ); \ng_free ( assoc ); \n}", "mmm wiretap / netscreen . c \nppp wiretap / netscreen . c \nparse_netscreen_packet ( FILE_T fh , struct wtap_pkthdr * phdr , Buffer * buf , \n \nphdr -> rec_type = REC_TYPE_PACKET ; \nphdr -> presence_flags = WTAP_HAS_TS | WTAP_HAS_CAP_LEN ; \n+ /* Suppress compiler warnings */ \n+ memset ( cap_int , 0 , sizeof ( cap_int )); \n+ memset ( cap_dst , 0 , sizeof ( cap_dst )); \n \nif ( sscanf ( line , \"% 9d .% 9d : % 15 [ a - z0 - 9 /:.-](% 1 [ io ]) len =% 9d :% 12s ->% 12s /\", \n& sec , & dsec , cap_int , direction , & pkt_len , cap_src , cap_dst ) < 5 ) {", "mmm epan / tvbuff . c \nppp epan / tvbuff . c \n* the data of a backing tvbuff , or can be a composite of \n* other tvbuffs . \n* \n- * $ Id : tvbuff . c , v 1 . 63 2004 / 05 / 06 17 : 40 : 52 obiot Exp $ \n+ * $ Id : tvbuff . c , v 1 . 64 2004 / 05 / 07 18 : 15 : 24 obiot Exp $ \n* \n* Copyright ( c ) 2000 by Gilbert Ramirez < gram @ alumni . rice . edu > \n* \ntvb_uncompress ( tvbuff_t * tvb , int offset , int comprlen ) \nif ( uncompr != NULL ) { \nuncompr_tvb = tvb_new_real_data (( guint8 *) uncompr , bytes_out , \nbytes_out ); \n+ tvb_set_free_cb ( uncompr_tvb , g_free ); \n} \ng_free ( compr ); \nreturn uncompr_tvb ;", "mmm epan / dissectors / packet - etsi_card_app_toolkit . c \nppp epan / dissectors / packet - etsi_card_app_toolkit . c \ndissect_cat ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) \nbreak ; \ncase 0x05 : /* alpha identifier */ \nbreak ; \n+ case 0x06 : /* address */ \n+ de_cld_party_bcd_num ( tvb , elem_tree , pinfo , pos , len , NULL , 0 ); \n+ break ; \ncase 0x0b : /* sms tpdu */ \nnew_tvb = tvb_new_subset ( tvb , pos , len , len ); \nif ( new_tvb ) {", "mmm epan / wslua / wslua_util . c \nppp epan / wslua / wslua_util . c \nWSLUA_METAMETHOD Dir__call ( lua_State * L ) { \nconst gchar * filename ; \nconst char * ext ; \n \n- if (! dir ) \n+ if (! dir ) { \nluaL_argerror ( L , 1 ,\" must be a Dir \"); \n+ return 0 ; \n+ } \n \nif (! dir -> dir ) { \nreturn 0 ;", "mmm epan / dissectors / packet - websocket . c \nppp epan / dissectors / packet - websocket . c \ndissect_websocket_frame ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , voi \nif ( http_conv ) { \nwebsocket_conv -> subprotocol = http_conv -> websocket_protocol ; \nwebsocket_conv -> server_port = http_conv -> server_port ; \n- websocket_parse_extensions ( websocket_conv , http_conv -> websocket_extensions ); \n+ if ( http_conv -> websocket_extensions ) { \n+ websocket_parse_extensions ( websocket_conv , http_conv -> websocket_extensions ); \n+ } \n} \n \nconversation_add_proto_data ( conv , proto_websocket , websocket_conv );", "mmm epan / dissectors / packet - ieee80211 - radiotap - iter . c \nppp epan / dissectors / packet - ieee80211 - radiotap - iter . c \nint ieee80211_radiotap_iterator_init ( \n \n/* find payload start allowing for extended bitmap ( s ) */ \nif ( iterator -> _bitmap_shifter & ( 1 << IEEE80211_RADIOTAP_EXT )) { \n+ if (! ITERATOR_VALID ( iterator , sizeof ( guint32 ))) \n+ return - EINVAL ; \nwhile ( get_unaligned_le32 ( iterator -> _arg ) & \n( 1 << IEEE80211_RADIOTAP_EXT )) { \niterator -> _arg += sizeof ( guint32 );", "mmm epan / dissectors / packet - mim . c \nppp epan / dissectors / packet - mim . c \nproto_reg_handoff_fabricpath ( void ) \n/* \ndissector_handle_t fp_handle ; \nfp_handle = new_create_dissector_handle ( dissect_fp , proto_fp ); \n- dissector_add (\" ethertype \", ETHERTYPE_DCE , fp_handle ); \n+ dissector_add_uint (\" ethertype \", ETHERTYPE_DCE , fp_handle ); \n*/ \nstatic gboolean prefs_initialized = FALSE ; \n", "mmm ui / gtk / simple_dialog . c \nppp ui / gtk / simple_dialog . c \ndo_simple_message_box ( ESD_TYPE_E type , gboolean * notagain , \nif ( notagain != NULL ) { \ncheckbox = gtk_check_button_new_with_label (\" Don ' t show this message again .\"); \ngtk_container_set_border_width ( GTK_CONTAINER ( checkbox ), 12 ); \n- gtk_box_pack_start ( GTK_BOX ( gtk_message_dialog_get_message_area ( GTK_MESSAGE_DIALOG ( msg_dialog ))), checkbox , \n- TRUE , TRUE , 0 ); \n+ gtk_box_pack_start ( GTK_BOX ( gtk_dialog_get_content_area ( GTK_DIALOG ( msg_dialog ))), \n+ checkbox , TRUE , TRUE , 0 ); \ngtk_widget_show ( checkbox ); \n} \n", "mmm ui / gtk / capture_dlg . c \nppp ui / gtk / capture_dlg . c \ncapture_all_filter_check_syntax_cb ( GtkWidget * w _U_ , gpointer user_data _U_ ) \n} \n# ifdef HAVE_EXTCAP \n/* Can ' t verify extcap capture filters */ \n- if ( device . if_info . extcap != NULL ) \n+ if ( device . if_info . extcap != NULL && strlen ( device . if_info . extcap ) > 0 ) \ncontinue ; \n# endif \nfilter_text = gtk_combo_box_text_get_active_text ( GTK_COMBO_BOX_TEXT ( filter_cm ));", "mmm epan / dissectors / packet - snmp . c \nppp epan / dissectors / packet - snmp . c \nextern int dissect_snmp_VarBind ( gboolean implicit_tag _U_ , \n \nadd_oid_debug_subtree ( oid_info , pt_name ); \n \n- if ( subids && oid_matched + oid_left ) { \n+ if (! subids ) { \n+ proto_item * pi = proto_tree_add_text ( pt_name , tvb , 0 , 0 , \" invalid oid : % s \", oid_bytes ); \n+ pt = proto_item_add_subtree ( pi , ett_decoding_error ); \n+ expert_add_info_format ( actx -> pinfo , pi , PI_MALFORMED , PI_WARN , \" invalid oid : % s \", oid_bytes ); \n+ return dissect_unknown_ber ( actx -> pinfo , tvb , name_offset , pt ); \n+ } \n+ \n+ if ( oid_matched + oid_left ) { \noid_string = oid_subid2string ( subids , oid_matched + oid_left ); \n} \n", "mmm ui / qt / packet_list . cpp \nppp ui / qt / packet_list . cpp \nvoid PacketList :: columnsChanged () \nsetColumnVisibility (); \ncreate_far_overlay_ = true ; \npacket_list_model_ -> resetColumns (); \n+ applyRecentColumnWidths (); \ncolumns_changed_ = false ; \n} \n \nvoid PacketList :: setCaptureFile ( capture_file * cf ) \ncap_file_ = cf ; \nif ( cap_file_ && columns_changed_ ) { \ncolumnsChanged (); \n- applyRecentColumnWidths (); \n} \npacket_list_model_ -> setCaptureFile ( cf ); \ncreate_near_overlay_ = true ;", "mmm gtk / gui_utils . c \nppp gtk / gui_utils . c \nstr_ptr_data_func ( GtkTreeViewColumn * column _U_ , \nGtkTreeModel * model , \nGtkTreeIter * iter , \ngpointer user_data ) \n- { \n+ { \nconst gchar * str = NULL ; \n \n/* The col to get data from is in userdata */ \nstr_ptr_sort_func ( GtkTreeModel * model , \ngtk_tree_model_get ( model , a , data_column , & str_a , - 1 ); \ngtk_tree_model_get ( model , b , data_column , & str_b , - 1 ); \n \n- if ( str_a == NULL || str_b == NULL ){ \n- if ( str_a == NULL && str_b == NULL ) \n- return 0 ; \n+ if ( str_a == str_b ) { \n+ /* it ' s worth testing because a lot of row point to \n+ the same data */ \n+ return 0 ; \n+ } \n+ else if ( str_a == NULL || str_b == NULL ) { \nret = ( str_a == NULL ) ? - 1 : 1 ; \n- } else { \n+ } \n+ else { \nret = g_ascii_strcasecmp ( str_a , str_b ); \n} \nreturn ret ;", "mmm epan / dissectors / packet - usb . c \nppp epan / dissectors / packet - usb . c \ndissect_usb_common ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * parent , \nguint8 header_info ) \n{ \ngint offset = 0 ; \n- gint new_offset ; \nint endpoint ; \ngint type_2 = 0 ; \nguint8 urb_type ; \ndissect_usb_common ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * parent , \ndefault : \n/* Try to find a non - standard specific dissector */ \nif ( tvb_reported_length_remaining ( tvb , offset ) != 0 ) { \n- next_tvb = tvb_new_subset_remaining ( tvb , offset ); \n- new_offset = try_dissect_next_protocol ( tree , parent , next_tvb , offset , pinfo , usb_conv_info , type_2 , urb_type , NULL , NULL ); \n- if ( new_offset > offset ) \n- offset = new_offset ; \n+ gint new_offset ; \n+ next_tvb = tvb_new_subset_remaining ( tvb , offset ); \n+ new_offset = try_dissect_next_protocol ( tree , parent , next_tvb , offset , pinfo , usb_conv_info , type_2 , urb_type , NULL , NULL ); \n+ if ( new_offset > offset ) \n+ offset = new_offset ; \n} \n \nif ( tvb_reported_length_remaining ( tvb , offset ) != 0 ) {", "mmm proto . c \nppp proto . c \n/* proto . c \n* Routines for protocol tree \n* \n- * $ Id : proto . c , v 1 . 59 2000 / 04 / 04 06 : 17 : 29 guy Exp $ \n+ * $ Id : proto . c , v 1 . 60 2000 / 04 / 04 17 : 07 : 07 gram Exp $ \n* \n* Ethereal - Network traffic analyzer \n* By Gerald Combs < gerald @ zing . org > \nproto_tree_add_bytes_format ( proto_tree * tree , int hfindex , gint start , gint leng \nstatic void \nproto_tree_set_bytes ( field_info * fi , const guint8 * start_ptr , gint length ) \n{ \n- \n+ g_assert ( start_ptr != NULL ); \n+ g_assert ( length > 0 ); \n/* This g_malloc ' ed memory is freed in \nproto_tree_free_node () */ \nfi -> value . bytes = g_malloc ( length ); \nproto_tree_add_field_info ( int hfindex , gint start , gint length , int visible ) \n \nfi = g_mem_chunk_alloc ( gmc_field_info ); \n \n+ g_assert ( hfindex >= 0 && hfindex < gpa_hfinfo -> len ); \nfi -> hfinfo = proto_registrar_get_nth ( hfindex ); \ng_assert ( fi -> hfinfo != NULL ); \nfi -> start = start ;", "mmm epan / dissectors / packet - telnet . c \nppp epan / dissectors / packet - telnet . c \nunescape_and_tvbuffify_telnet_option ( packet_info * pinfo , tvbuff_t * tvb , int offs \nreturn NULL ; \n \nspos = tvb_get_ptr ( tvb , offset , len ); \n- /* XXX we never g_free () this one . This is done automagically \n- when the parent tvb is destroyed ? \n- */ \nbuf = g_malloc ( len ); \ndpos = buf ; \nskip = 0 ; \nunescape_and_tvbuffify_telnet_option ( packet_info * pinfo , tvbuff_t * tvb , int offs \nl --; \n} \nkrb5_tvb = tvb_new_real_data ( buf , len - skip , len - skip ); \n+ tvb_set_free_cb ( krb5_tvb , g_free ); \ntvb_set_child_real_data_tvbuff ( tvb , krb5_tvb ); \nadd_new_data_source ( pinfo , krb5_tvb , \" Unpacked Telnet Uption \"); \n", "mmm epan / dissectors / packet - umts_fp . c \nppp epan / dissectors / packet - umts_fp . c \ncheck_payload_crc_for_heur ( tvbuff_t * tvb , guint16 header_length ) \nstatic guint32 \ngenerate_ue_id_for_heur ( packet_info * pinfo ) \n{ \n- if ( pinfo -> ptype != PT_UDP && pinfo -> src . type == AT_IPv4 && pinfo -> dst . type == AT_IPv4 ) { \n+ if ( pinfo -> ptype == PT_UDP && pinfo -> src . type == AT_IPv4 && pinfo -> dst . type == AT_IPv4 ) { \n/* This logic assumes FP is delivered over IP / UDP */ \n/* Will return the same ID even if the address and ports are reversed */ \n", "mmm epan / dissectors / packet - ssl - utils . c \nppp epan / dissectors / packet - ssl - utils . c \nstatic const char * ciphers []={ \n\" RC2 \", \n\" IDEA \", \n\" AES \", \n- \" AES256 \" \n+ \" AES256 \", \n+ \"* UNKNOWN *\" \n}; \n \n/* look in openssl / ssl / ssl_lib . c for a complete list of available cipersuite */ \nssl_create_decoder ( SslDecoder * dec , SslCipherSuite * cipher_suite , \n} \nif ( ciph == 0 ) { \nssl_debug_printf (\" ssl_create_decoder can ' t find cipher % s \\ n \", \n- ciphers [ cipher_suite -> enc - 0x30 ]); \n+ ciphers [( cipher_suite -> enc - 0x30 ) > 7 ? 7 : ( cipher_suite -> enc - 0x30 )]); \nreturn - 1 ; \n} \n", "mmm epan / dissectors / packet - ntlmssp . c \nppp epan / dissectors / packet - ntlmssp . c \ndissect_ntlmssp_payload ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , voi \n/* Encrypted body */ \nproto_tree_add_item ( ntlmssp_tree , hf_ntlmssp_verf_body , \ntvb , offset , ntlm_signature_size + ntlm_seq_size , ENC_NA ); \n+ memset ( key , 0 , sizeof ( key )); \ntvb_memcpy ( tvb , key , offset , ntlm_signature_size + ntlm_seq_size ); \n/* Try to decrypt */ \ndecrypt_data_payload ( tvb , offset +( ntlm_signature_size + ntlm_seq_size ), encrypted_block_length -( ntlm_signature_size + ntlm_seq_size ), pinfo , ntlmssp_tree , key );", "mmm packet - icmpv6 . c \nppp packet - icmpv6 . c \n/* packet - icmpv6 . c \n* Routines for ICMPv6 packet disassembly \n* \n- * $ Id : packet - icmpv6 . c , v 1 . 57 2002 / 01 / 09 19 : 13 : 03 guy Exp $ \n+ * $ Id : packet - icmpv6 . c , v 1 . 58 2002 / 01 / 10 09 : 49 : 35 guy Exp $ \n* \n* Ethereal - Network traffic analyzer \n* By Gerald Combs < gerald @ ethereal . com > \nagain : \nND_OPT_MAP_FLAG_P , 8 , \" P \", \" No P \")); \nproto_tree_add_text ( icmp6opt_tree , tvb , \noffset + offsetof ( struct nd_opt_map_info , nd_opt_map_lifetime ), \n- 4 , \" Lifetime : % d \", pntohl (& map -> nd_opt_map_lifetime )); \n+ 4 , \" Lifetime : % u \", pntohl (& map -> nd_opt_map_lifetime )); \n \nproto_tree_add_text ( icmp6opt_tree , tvb , \noffset + offsetof ( struct nd_opt_map_info , nd_opt_map_address ), 16 ,", "mmm gtk / main . c \nppp gtk / main . c \nmain_filter_packets ( capture_file * cf , const gchar * dftext , gboolean force ) \nchar * s ; \ncf_status_t cf_status ; \n \n+ /* we ' ll crash later on if dftext is NULL */ \n+ g_assert ( dftext != NULL ); \n+ \ns = g_strdup ( dftext ); \n \n/* GtkCombos don ' t let us get at their list contents easily , so we maintain", "mmm text2pcap . c \nppp text2pcap . c \nparse_options ( int argc , char * argv []) \n{\" version \", no_argument , NULL , ' v '}, \n{ 0 , 0 , 0 , 0 } \n}; \n+ struct tm * now_tm ; \n \n# ifdef _WIN32 \narg_list_utf_16to8 ( argc , argv ); \nparse_options ( int argc , char * argv []) \n} \n \nts_sec = time ( 0 ); /* initialize to current time */ \n- /* We trust the OS to return a time after the Epoch . */ \n- timecode_default = * localtime (& ts_sec ); \n+ now_tm = localtime (& ts_sec ); \n+ if ( now_tm == NULL ) { \n+ /* \n+ * This shouldn ' t happen - on UN * X , this should Just Work , and \n+ * on Windows , it won ' t work if ts_sec is before the Epoch , \n+ * but it ' s long after 1970 , so .... \n+ */ \n+ fprintf ( stderr , \" localtime ( right now ) failed \\ n \"); \n+ return EXIT_FAILURE ; \n+ } \n+ timecode_default = * now_tm ; \ntimecode_default . tm_isdst = - 1 ; /* Unknown for now , depends on time given to the strptime () function */ \n \n/* Display summary of our state */", "mmm packet - dcerpc . c \nppp packet - dcerpc . c \n* Copyright 2001 , Todd Sabin < tas @ webspan . net > \n* Copyright 2003 , Tim Potter < tpot @ samba . org > \n* \n- * $ Id : packet - dcerpc . c , v 1 . 151 2003 / 11 / 06 07 : 44 : 13 sahlberg Exp $ \n+ * $ Id : packet - dcerpc . c , v 1 . 152 2003 / 11 / 06 09 : 13 : 26 guy Exp $ \n* \n* Ethereal - Network traffic analyzer \n* By Gerald Combs < gerald @ ethereal . com > \ndcerpc_try_handoff ( packet_info * pinfo , proto_tree * tree , \npinfo -> current_proto = saved_proto ; \npinfo -> private_data = saved_private_data ; \n} else { \n- /* No subdissector - show it as * decrypted * stub data . */ \n+ /* No subdissector - show it as stub data . */ \nif ( decrypted_tvb ){ \nshow_stub_data ( decrypted_tvb , 0 , tree , auth_info , FALSE ); \n} else { \ndissect_dcerpc_cn_stub ( tvbuff_t * tvb , int offset , packet_info * pinfo , \nthus we must reassemble it . \n*/ \n \n+ /* Do we have any non - encrypted data to reassemble ? */ \n+ if ( decrypted_tvb == NULL ) { \n+ /* No . We can ' t even try to reassemble . */ \n+ goto end_cn_stub ; \n+ } \n+ \n/* if this is the first fragment we need to start reassembly \n*/ \nif ( hdr -> flags & PFC_FIRST_FRAG ){", "mmm epan / dissectors / packet - ber . c \nppp epan / dissectors / packet - ber . c \nreassemble_octet_string ( asn1_ctx_t * actx , proto_tree * tree , gint hf_id , tvbuff_t \n \n/* so we need to consume octet strings for the given length */ \n \n- /* not sure we need this */ \n- actx -> pinfo -> fragmented = TRUE ; \n- \nif ( out_tvb ) \n* out_tvb = NULL ; \n \n+ if ( con_len == 0 ) /* Zero encodings ( 8 . 7 . 3 ) */ \n+ return offset ; \n+ \n+ /* not sure we need this */ \n+ actx -> pinfo -> fragmented = TRUE ; \n+ \nwhile (! fd_head ) { \n \noffset = dissect_ber_octet_string ( FALSE , actx , NULL , tvb , offset , hf_id , & next_tvb );", "mmm epan / dissectors / packet - rtps . c \nppp epan / dissectors / packet - rtps . c \nstatic void dissect_HEARTBEAT_VIRTUAL ( tvbuff_t * tvb , packet_info * pinfo _U_ , gin \nif (!( flags & FLAG_VIRTUAL_HEARTBEAT_N )) { \nproto_tree_add_item ( sil_tree_writer , hf_rtps_virtual_heartbeat_num_virtual_guids , tvb , \noffset , 4 , little_endian ? ENC_LITTLE_ENDIAN : ENC_BIG_ENDIAN ); \n+ num_virtual_guids = NEXT_guint32 ( tvb , offset , little_endian ); \noffset += 4 ; \n} else { \nnum_virtual_guids = 0 ;", "mmm wiretap / pppdump . c \nppp wiretap / pppdump . c \n/* pppdump . c \n* \n- * $ Id : pppdump . c , v 1 . 5 2000 / 11 / 19 03 : 47 : 36 guy Exp $ \n+ * $ Id : pppdump . c , v 1 . 6 2000 / 11 / 19 20 : 56 : 17 gerald Exp $ \n* \n* Copyright ( c ) 2000 by Gilbert Ramirez < gram @ xiexie . org > \n* \nprocess_data ( pppdump_t * state , FILE_T fh , pkt_t * pkt , int n , guint8 * pd , int * er \nreturn 0 ; \n} \n \n+ if ( num_written > sizeof ( pd )) { \n+ * err = WTAP_ERR_UNC_OVERFLOW ; \n+ return - 1 ; \n+ } \n+ \nmemcpy ( pd , pkt -> buf , num_written ); \n \nnum_bytes --;", "mmm wiretap / erf . c \nppp wiretap / erf . c \nstatic void erf_write_wtap_option_to_capture_tag ( wtap_block_t block _U_ , \nbreak ; \ndefault : \nerf_meta_tag_free ( tag_ptr ); \n- return ; \n+ tag_ptr = NULL ; \n+ break ; \n} \n \n- g_ptr_array_add ( section_ptr -> tags , tag_ptr ); \n+ if ( tag_ptr ) \n+ g_ptr_array_add ( section_ptr -> tags , tag_ptr ); \n} \n \nstatic void erf_write_wtap_option_to_host_tag ( wtap_block_t block _U_ , \nstatic void erf_write_wtap_option_to_host_tag ( wtap_block_t block _U_ , \nbreak ; \ndefault : \nerf_meta_tag_free ( tag_ptr ); \n- return ; \n+ tag_ptr = NULL ; \n+ break ; \n} \n \n- g_ptr_array_add ( section_ptr -> tags , tag_ptr ); \n+ if ( tag_ptr ) \n+ g_ptr_array_add ( section_ptr -> tags , tag_ptr ); \n} \n \nstatic void erf_write_wtap_option_to_interface_tag ( wtap_block_t block _U_ ,", "mmm epan / dissectors / packet - tcp . c \nppp epan / dissectors / packet - tcp . c \ndissect_tcpopt_mptcp ( const ip_tcp_opt * optp _U_ , tvbuff_t * tvb , \nguint8 indx ; \nguint8 flags ; \nguint8 ipver ; \n+ int start_offset = offset ; \n \nmptcp_tree = proto_tree_add_subtree ( opt_tree , tvb , offset , optlen , ett_tcp_option_mptcp , & ti , \" Multipath TCP \"); \n \ndissect_tcpopt_mptcp ( const ip_tcp_opt * optp _U_ , tvbuff_t * tvb , \n2 , ENC_BIG_ENDIAN ); \noffset += 2 ; \n \n- proto_tree_add_item ( mptcp_tree , \n- hf_tcp_option_mptcp_checksum , tvb , offset , \n- 2 , ENC_BIG_ENDIAN ); \n+ if (( int ) optlen >= offset - start_offset + 4 ) \n+ { \n+ proto_tree_add_item ( mptcp_tree , \n+ hf_tcp_option_mptcp_checksum , tvb , offset , \n+ 2 , ENC_BIG_ENDIAN ); \n+ } \n} \nbreak ; \n", "mmm ui / cli / tap - rtp . c \nppp ui / cli / tap - rtp . c \nrtp_streams_stat_draw ( void * arg _U_ ) \n \nlist = g_list_next ( list ); \n \n- g_free ( payload_type ); \nwmem_free ( NULL , src_addr ); \nwmem_free ( NULL , dst_addr ); \nwmem_free ( NULL , payload_type );", "mmm randpkt . c \nppp randpkt . c \nmain ( int argc , char ** argv ) \npkthdr . ts . tv_sec = i ; /* just for variety */ \n \nfor ( j = example -> sample_length ; j < len_random ; j ++) { \n- buffer [ j ] = ( rand () % 0x100 ); \n+ /* Add format strings here and there */ \n+ if (( int ) ( 100 . 0 * rand ()/( RAND_MAX + 1 . 0 )) < 3 && j < ( len_random - 3 )) { \n+ memcpy (& buffer [ j ], \"% s \", 3 ); \n+ j += 2 ; \n+ } else { \n+ buffer [ j ] = ( rand () % 0x100 ); \n+ } \n} \n \nwtap_dump ( dump , & pkthdr , & ps_header , & buffer [ 0 ], & err );", "mmm gtk / capture_file_dlg . c \nppp gtk / capture_file_dlg . c \ncolor_global_cb ( GtkWidget * widget _U_ , gpointer data ) \n \ngtk_file_chooser_select_filename ( GTK_FILE_CHOOSER ( fs_widget ), path ); \n \n- g_free (( gchar *) path ); \n+ g_free ( path ); \n} \n \n/* Import color filters */", "mmm epan / dissectors / packet - sdp . c \nppp epan / dissectors / packet - sdp . c \nstatic void dissect_sdp_media_attribute ( tvbuff_t * tvb , packet_info * pinfo , proto \nif ( port_offset != - 1 ) { \n/* Port ends with '/' */ \nport_end_offset = tvb_find_guint8 ( tvb , port_offset , - 1 , '/'); \n- \n+ if ( port_end_offset == - 1 ) { \n+ /* No \"/\" look for the \";\" */ \n+ port_end_offset = tvb_find_guint8 ( tvb , port_offset , - 1 , ';');; \n+ } \n/* Attempt to convert address */ \nif ( inet_pton ( AF_INET , \n( char *) tvb_get_ephemeral_string ( tvb , address_offset , port_offset - address_offset ),", "mmm ui / qt / packet_list . cpp \nppp ui / qt / packet_list . cpp \nPacketList :: PacketList ( QWidget * parent ) : \ndecode_as_ ( NULL ), \nctx_column_ (- 1 ), \ncapture_in_progress_ ( false ), \n- tail_timer_id_ ( 0 ) \n+ tail_timer_id_ ( 0 ), \n+ rows_inserted_ ( false ) \n{ \nQMenu * submenu , * subsubmenu ; \nQAction * action ;", "mmm epan / dissectors / packet - pdcp - lte . c \nppp epan / dissectors / packet - pdcp - lte . c \nUAT_CSTRING_CB_DEF ( uat_ue_keys_records , rrcIntegrityKeyString , uat_ue_keys_reco \n \nstatic gboolean global_pdcp_decipher_signalling = FALSE ; \nstatic gboolean global_pdcp_decipher_userplane = FALSE ; \n- static gboolean global_pdcp_check_integrity = FALSE ; \n# endif \n+ static gboolean global_pdcp_check_integrity = FALSE ; \n \nstatic const value_string direction_vals [] = \n{", "mmm epan / dissectors / packet - isup_thin . c \nppp epan / dissectors / packet - isup_thin . c \n# include < epan / packet . h > \n# include \" prefs . h \" \n \n- static int ISUP_thinTCPPort = 0 ; \n+ static guint ISUP_thinTCPPort = 0 ; \n \n/* Initialize the protocol and registered fields */ \nstatic int proto_isup_thin = - 1 ; \ndissect_isup_thin ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) \nvoid \nproto_reg_handoff_isup_thin ( void ) \n{ \n- static int Initialized = FALSE ; \n+ static gboolean Initialized = FALSE ; \nstatic dissector_handle_t isup_thin_handle ; \n- static int saved_tcp_port ; \n+ static guint saved_tcp_port ; \n \nif (! Initialized ) { \nisup_thin_handle = find_dissector (\" isup_thin \");", "mmm ui / qt / overlay_scroll_bar . cpp \nppp ui / qt / overlay_scroll_bar . cpp \nvoid OverlayScrollBar :: paintEvent ( QPaintEvent * event ) \npm_painter . setPen ( border_color ); \npm_painter . drawLine ( near_dest . topLeft (), near_dest . bottomLeft ()); \npm_painter . drawLine ( near_dest . topRight (), near_dest . bottomRight ()); \n+ pm_painter . drawLine ( near_dest . bottomLeft (), near_dest . bottomRight ()); \npm_painter . restore (); \n \n// Draw the map .", "mmm epan / dissectors / packet - zbee - nwk . c \nppp epan / dissectors / packet - zbee - nwk . c \ndissect_zbee_nwk_heur ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void \nieee802154_packet * packet = ( ieee802154_packet *) data ; \n \n/* All ZigBee frames must always have a 16 - bit source address . */ \n- if ( packet -> src_addr_mode != IEEE802154_FCF_ADDR_SHORT ) { \n+ if ( ( packet == NULL ) || \n+ ( packet -> src_addr_mode != IEEE802154_FCF_ADDR_SHORT ) ) { \nreturn FALSE ; \n} \n/* ZigBee MAC frames must always contain a 16 - bit destination address . */", "mmm gtk / main . c \nppp gtk / main . c \n/* main . c \n* \n- * $ Id : main . c , v 1 . 386 2004 / 02 / 01 20 : 28 : 11 ulfl Exp $ \n+ * $ Id : main . c , v 1 . 387 2004 / 02 / 01 22 : 43 : 34 guy Exp $ \n* \n* Ethereal - Network traffic analyzer \n* By Gerald Combs < gerald @ ethereal . com > \nmain_window_delete_event_cb ( GtkWidget * widget _U_ , GdkEvent * event _U_ , gpointer \n} \n \nstatic void \n- main_load_window_geometry ( GtkWidget * widget ) \n+ main_load_window_geometry ( GtkWidget * widget \n+# if GTK_MAJOR_VERSION < 2 \n+ _U_ \n+# endif \n+) \n{ \n/* as we now have the geometry from the recent file , set it */ \nif ( prefs . gui_geometry_save_position ) {", "mmm epan / dissectors / packet - mq - pcf . c \nppp epan / dissectors / packet - mq - pcf . c \nstatic void dissect_mqpcf ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , m \n \nstatic gboolean dissect_mqpcf_heur ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * data ) \n{ \n- if ( tvb_length ( tvb ) >= 36 ) \n+ if ( data && tvb_length ( tvb ) >= 36 ) \n{ \nmq_parm_t * p_mq_parm = ( mq_parm_t *) data ; \nif ( strncmp (( const char *) p_mq_parm -> mq_format , MQ_MQFMT_ADMIN , 8 ) == 0", "mmm file . c \nppp file . c \n/* file . c \n* File I / O routines \n* \n- * $ Id : file . c , v 1 . 59 1999 / 08 / 10 04 : 13 : 36 guy Exp $ \n+ * $ Id : file . c , v 1 . 60 1999 / 08 / 10 06 : 54 : 12 guy Exp $ \n* \n* Ethereal - Network traffic analyzer \n* By Gerald Combs < gerald @ zing . org > \nwtap_dispatch_cb ( u_char * user , const struct wtap_pkthdr * phdr , int offset , \n/* Allocate the next list entry , and add it to the list . */ \nfdata = ( frame_data *) g_malloc ( sizeof ( frame_data )); \n \n+ fdata -> next = NULL ; \nfdata -> pkt_len = phdr -> len ; \nfdata -> cap_len = phdr -> caplen ; \nfdata -> file_off = offset ;", "mmm epan / dissectors / packet - rtacser . c \nppp epan / dissectors / packet - rtacser . c \ndissect_rtacser_data ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) \n \np_add_proto_data ( pinfo -> pool , pinfo , proto_rtacser , 0 , GUINT_TO_POINTER ( global_rtacser_payload_proto )); \n \n- if ( tvb_reported_length_remaining ( tvb , RTACSER_HEADER_LEN ) > 0 ) { \n+ if ( tvb_reported_length_remaining ( tvb , offset ) > 0 ) { \npayload_tvb = tvb_new_subset_remaining ( tvb , RTACSER_HEADER_LEN ); \nif (! dissector_try_uint ( subdissector_table , global_rtacser_payload_proto , payload_tvb , pinfo , tree )){ \ncall_dissector ( data_handle , payload_tvb , pinfo , tree );", "mmm epan / dissectors / packet - iax2 . c \nppp epan / dissectors / packet - iax2 . c \nstatic guint iax_circuit_lookup ( const address * address , \nnew_key -> addr . type = address -> type ; \nnew_key -> addr . len = MIN ( address -> len , MAX_ADDRESS ); \nnew_key -> addr . data = new_key -> address_data ; \n- memmove ( new_key -> address_data , address -> data , new_key -> addr . len ); \n+ memcpy ( new_key -> address_data , address -> data , new_key -> addr . len ); \nnew_key -> ptype = ptype ; \nnew_key -> port = port ; \nnew_key -> callno = callno ;", "mmm epan / decode_as . c \nppp epan / decode_as . c \nsave_decode_as_entries ( gchar ** err ) \n \ndissector_all_tables_foreach_changed ( decode_as_write_entry , da_file ); \nfclose ( da_file ); \n+ g_free ( daf_path ); \nreturn 0 ; \n} \n", "mmm epan / wslua / wslua_byte_array . c \nppp epan / wslua / wslua_byte_array . c \nWSLUA_CONSTRUCTOR ByteArray_tvb ( lua_State * L ) { \ndata = ( guint8 *) g_memdup ( ba -> data , ba -> len ); \n \ntvb = ( Tvb ) g_malloc ( sizeof ( struct _wslua_tvb )); \n- tvb -> ws_tvb = tvb_new_real_data ( data , ba -> len , ba -> len ); \n+ tvb -> ws_tvb = tvb_new_child_real_data ( lua_tvb , data , ba -> len , ba -> len ); \ntvb -> expired = FALSE ; \n- tvb -> need_free = TRUE ; \n+ tvb -> need_free = FALSE ; \ntvb_set_free_cb ( tvb -> ws_tvb , g_free ); \n \nadd_new_data_source ( lua_pinfo , tvb -> ws_tvb , name );", "mmm gtk / gui_utils . c \nppp gtk / gui_utils . c \nwindow_new_with_geom ( GtkWindowType type , const gchar * title , const gchar * geom_n \n} \n \n \n-/* Create a new window for a splash screen ; it ' s a main window , with no title , \n+/* Create a new window for a splash screen ; it ' s a main window , without decoration , \npositioned in the center of the screen . */ \nGtkWidget * \nsplash_window_new ( void ) \n{ \nGtkWidget * win ; \n \n- win = gtk_window_new ( GTK_WINDOW_TOPLEVEL ); \n+ win = window_new ( GTK_WINDOW_TOPLEVEL , \" Wireshark \"); \ngtk_window_set_decorated ( GTK_WINDOW ( win ), FALSE ); \n \n/* set the initial position ( must be done , before show is called !) */", "mmm wiretap / snoop . c \nppp wiretap / snoop . c \n/* snoop . c \n* \n- * $ Id : snoop . c , v 1 . 65 2003 / 11 / 11 20 : 49 : 46 guy Exp $ \n+ * $ Id : snoop . c , v 1 . 66 2003 / 12 / 19 22 : 23 : 05 guy Exp $ \n* \n* Wiretap Library \n* Copyright ( c ) 1998 by Gilbert Ramirez < gram @ alumni . rice . edu > \nstatic gboolean snoop_read ( wtap * wth , int * err , long * data_offset ) \n* err = WTAP_ERR_BAD_RECORD ; \nreturn FALSE ; \n} \n+ if ( packet_size > rec_size ) { \n+ /* \n+ * Probably a corrupt capture file . \n+ */ \n+ g_message (\" snoop : File has % u - byte packet , bigger than record size % u \", \n+ packet_size , rec_size ); \n+ * err = WTAP_ERR_BAD_RECORD ; \n+ return FALSE ; \n+ } \n \n* data_offset = wth -> data_offset ; \n", "mmm epan / prefs . c \nppp epan / prefs . c \nprefs_register_protocol_subtree ( const char * subtree , int id , void (* apply_cb )( vo \n \n} \n \n- /* g_free ( csubtree ); */ \n+ g_free ( csubtree ); \n \n} \n", "mmm epan / dissectors / packet - rtp . h \nppp epan / dissectors / packet - rtp . h \nstruct _rtp_conversation_info \n{ \ngchar method [ MAX_RTP_SETUP_METHOD_SIZE + 1 ]; \nguint32 frame_number ; \n- guint32 rtp_event_pt ; /* this is payload type for dynamic RTP events ( RFC2833 ) */ \n+ GHashTable * rtp_dyn_payload ; /* a hash table with the dynamic RTP payload */ \n}; \n \n/* Add an RTP conversation with the given details */ \nvoid rtp_add_address ( packet_info * pinfo , \nint other_port , \ngchar * setup_method , \nguint32 setup_frame_number , \n- int rtp_event_pt ); \n+ GHashTable * rtp_dyn_payload ); \n+ \n+/* Free and destroy the dyn_payload hash table */ \n+ void rtp_free_hash_dyn_payload ( GHashTable * rtp_dyn_payload ); \n+", "mmm gtk / gui_utils . c \nppp gtk / gui_utils . c \nGtkWidget * xpm_to_widget_from_parent ( GtkWidget * parent , const char ** xpm ) { \n} \n \n \n-/* convert an xpm to a GtkWidget , using the top_level window settings */ \n-/* ( be sure that the top_level window is already being displayed ) */ \n+/* convert an xpm to a GtkWidget */ \nGtkWidget * xpm_to_widget ( const char ** xpm ) { \n- return xpm_to_widget_from_parent ( top_level , xpm ); \n+ GdkPixbuf * pixbuf ; \n+ \n+ pixbuf = gdk_pixbuf_new_from_xpm_data ( xpm ); \n+ return gtk_image_new_from_pixbuf ( pixbuf ); \n} \n \n/* Convert an pixbuf data to a GtkWidget */", "mmm epan / emem . c \nppp epan / emem . c \nemem_alloc ( size_t size , emem_header_t * mem , gboolean use_chunks , guint8 * canary ) \n/* There ' s no padding / alignment involved ( from our point of view ) when \n* we fetch the memory directly from the system pool , so WYSIWYG */ \nnpc -> free_offset = npc -> free_offset_init = 0 ; \n- npc -> amount_free = npc -> amount_free_init = size ; \n+ npc -> amount_free = npc -> amount_free_init = ( unsigned int ) size ; \n} \n \nreturn buf ;", "mmm gtk / packet_win . c \nppp gtk / packet_win . c \nfinfo_integer_changed ( GtkSpinButton * spinbutton , gpointer user_data ) \n \nelse if ( finfo_type == FT_UINT8 || finfo_type == FT_UINT16 || finfo_type == FT_UINT24 || finfo_type == FT_UINT32 || finfo_type == FT_UINT64 ) \nu_val = ( guint64 ) val ; \n+ else { \n+ g_assert_not_reached (); \n+ return ; \n+ } \n \nif ( FI_GET_FLAG ( finfo , FI_LITTLE_ENDIAN )) { \nwhile ( finfo_length ) {", "mmm epan / dissectors / packet - dcerpc - netlogon . c \nppp epan / dissectors / packet - dcerpc - netlogon . c \nstatic const true_false_string get_dcname_request_flags_force_rediscovery = { \n\" You may return cached data \" \n}; \nstatic const true_false_string get_dcname_request_flags_directory_service_required = { \n- \" DIRECRTORY SERVICE is REQUIRED on the server \", \n+ \" DIRECTORY SERVICE is REQUIRED on the server \", \n\" We do NOT require directory service servers \" \n}; \nstatic const true_false_string get_dcname_request_flags_directory_service_preferred = { \nstatic const true_false_string get_dcname_request_flags_timeserv_required = { \n\" timeserv service is NOT required \" \n}; \nstatic const true_false_string get_dcname_request_flags_writable_required = { \n- \" the requrned dc MUST be WRITEABLE \", \n+ \" the returned dc MUST be WRITEABLE \", \n\" a read - only dc may be returned \" \n}; \nstatic const true_false_string get_dcname_request_flags_good_timeserv_preferred = {", "mmm text2pcap . c \nppp text2pcap . c \nwrite_current_packet ( void ) \n( guint32 ) ts_sec , ts_usec , \nlength , length , \n0 , \n- 6 , \n+ 1000000 , \npacket_buf , 0 , \n& bytes_written , & err ); \n} else { \nwrite_file_header ( void ) \n102400 , \n& bytes_written , \n0 , \n- 6 , \n+ 0 , \n& err ); \n} \n} else {", "mmm packet - ip . c \nppp packet - ip . c \n/* packet - ip . c \n* Routines for IP and miscellaneous IP protocol packet disassembly \n* \n- * $ Id : packet - ip . c , v 1 . 66 1999 / 12 / 09 21 : 58 : 04 guy Exp $ \n+ * $ Id : packet - ip . c , v 1 . 67 1999 / 12 / 13 05 : 09 : 05 gram Exp $ \n* \n* Ethereal - Network traffic analyzer \n* By Gerald Combs < gerald @ zing . org > \ndissect_ip_tcp_options ( const u_char * opd , int offset , guint length , \noption length . */ \nproto_tree_add_text ( opt_tree , offset , 2 , \n\"% s ( with too - short option length = % u byte % s )\", name , \n- plurality ( len , \"\", \" s \")); \n+ len , plurality ( len , \"\", \" s \")); \nreturn ; \n} else if ( len - 2 > length ) { \n/* Bogus - option goes past the end of the header . */", "mmm epan / dissectors / packet - erf . c \nppp epan / dissectors / packet - erf . c \ndissect_erf ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , void * data _U_ ) \natm_info . vpi = (( atm_hdr & 0x0ff00000 ) >> 20 ); \natm_info . vci = (( atm_hdr & 0x000ffff0 ) >> 4 ); \natm_info . channel = ( flags & 0x03 ); \n+ atm_info . aal2_cid = aal2_cid ; \natm_info . type = TRAF_UNKNOWN ; \natm_info . subtype = TRAF_ST_UNKNOWN ; \n", "mmm epan / dissectors / packet - pppoe . c \nppp epan / dissectors / packet - pppoe . c \nvoid proto_register_pppoed ( void ) \n} \n}, \n{ & hf_pppoed_tag_host_uniq , \n- { \" Host - Uniq \", \" pppoed . tags . host_uniq \", FT_STRING , BASE_NONE , \n+ { \" Host - Uniq \", \" pppoed . tags . host_uniq \", FT_BYTES , BASE_NONE , \nNULL , 0x0 , \"\", HFILL \n} \n}, \n{ & hf_pppoed_tag_ac_cookie , \n- { \" AC - Cookie \", \" pppoed . tags . ac_cookie \", FT_BYTES , BASE_HEX , \n+ { \" AC - Cookie \", \" pppoed . tags . ac_cookie \", FT_BYTES , BASE_NONE , \nNULL , 0x0 , \"\", HFILL \n} \n}, \nvoid proto_register_pppoed ( void ) \n} \n}, \n{ & hf_pppoed_tag_relay_session_id , \n- { \" Relay - Session - Id \", \" pppoed . tags . relay_session_id \", FT_BYTES , BASE_HEX , \n+ { \" Relay - Session - Id \", \" pppoed . tags . relay_session_id \", FT_BYTES , BASE_NONE , \nNULL , 0x0 , \"\", HFILL \n} \n},", "mmm wsutil / strtoi . c \nppp wsutil / strtoi . c \ngboolean ws_strtou64 ( const gchar * str , guint64 * cint ) \ngchar * endptr ; \nguint64 val ; \n \n+ if ( str [ 0 ] == '-' || str [ 0 ] == '+') { \n+ /* \n+ * Unsigned numbers don ' t have a sign . \n+ */ \n+ errno = EINVAL ; \n+ return FALSE ; \n+ } \nerrno = 0 ; \nval = g_ascii_strtoull ( str , & endptr , 10 ); \nif (( val == 0 && endptr == str ) || (* endptr != 0 )) {", "mmm dumpcap . c \nppp dumpcap . c \ncapture_loop_dispatch ( capture_options * capture_opts _U_ , loop_data * ld , \ninpkts = pcap_dispatch ( ld -> pcap_h , 1 , capture_loop_packet_cb , \n( u_char *) ld ); \nif ( inpkts < 0 ) { \n- ld -> pcap_err = TRUE ; \n+ if ( inpkts == - 1 ) { \n+ /* Error , rather than pcap_breakloop (). */ \n+ ld -> pcap_err = TRUE ; \n+ } \nld -> go = FALSE ; /* error or pcap_breakloop () - stop capturing */ \n} \n} else {", "mmm epan / dissectors / packet - infiniband . c \nppp epan / dissectors / packet - infiniband . c \ncreate_conv_and_add_proto_data ( packet_info * pinfo , guint64 service_id , \nconversation_add_proto_data ( conv , proto_infiniband , proto_data ); \n \n/* next , register the conversation using the LIDs */ \n- set_address ( addr , AT_IB , sizeof ( guint16 ), & lid ); \n+ set_address ( addr , AT_IB , sizeof ( guint16 ), wmem_memdup ( pinfo -> pool , & lid , sizeof lid )); \nconv = conversation_new ( pinfo -> num , addr , addr , \nPT_IBQP , port , port , options ); \nconversation_add_proto_data ( conv , proto_infiniband , proto_data );", "mmm gtk / main . c \nppp gtk / main . c \nmain_widgets_show_or_hide ( void ) \n} else { \ngtk_widget_hide ( welcome_pane ); \n} \n+ \n+ /* workaround for bug in GtkCList to ensure packet list scrollbar is updated */ \n+ packet_list_freeze (); \n+ packet_list_thaw (); \n} \n \n", "mmm epan / dissectors / packet - gsm_a . c \nppp epan / dissectors / packet - gsm_a . c \nbe_cell_id_aux ( tvbuff_t * tvb , proto_tree * tree , guint32 offset , guint len , gchar \n \ncase 0x01 : \ncase 0x05 : \n- case 0x0a : /* For intersystem handover from GSM to UMTS or cdma2000 : */ \n+ case 0x0a : /* For intersystem handover from GSM to UMTS or cdma2000 : */ \n \n/* LAC */ \n \nbe_cell_id_aux ( tvbuff_t * tvb , proto_tree * tree , guint32 offset , guint len , gchar \nif ( add_string ) \ng_snprintf ( add_string , string_len , \" - LAC ( 0x % 04x )\", value ); \n \n- case 0x09 : /* For intersystem handover from GSM to UMTS or cdma2000 : */ \n+ /* FALLTHRU */ \n+ \n+ case 0x09 : /* For intersystem handover from GSM to UMTS or cdma2000 : */ \n \nif (( disc == 0x08 ) ||( disc == 0x09 ) || ( disc == 0x0a )){ \n/* RNC - ID */", "mmm pcapio . c \nppp pcapio . c \npcapng_write_enhanced_packet_block ( FILE * pfile , \nsizeof ( guint32 )); \n} \n/* If we have options add size of end - of - options */ \n- /* If we have options add size of end - of - options */ \nif ( options_length != 0 ) { \noptions_length += ( guint32 ) sizeof ( struct option ); \n} \npcapng_write_enhanced_packet_block ( FILE * pfile , \noption . value_length = 0 ; \nif (! write_to_file ( pfile , ( const guint8 *)& option , sizeof ( struct option ), bytes_written , err )) \nreturn FALSE ; \n- } \n+ } \n+ if ( options_length != 0 ) { \n+ /* write end of options */ \n+ option . type = OPT_ENDOFOPT ; \n+ option . value_length = 0 ; \n+ if (! write_to_file ( pfile , ( const guint8 *)& option , sizeof ( struct option ), bytes_written , err )) \n+ return FALSE ; \n+ } \n \nreturn write_to_file ( pfile , ( const guint8 *)& block_total_length , sizeof ( guint32 ), bytes_written , err ); \n}", "mmm epan / epan . c \nppp epan / epan . c \nepan_init ( void (* register_all_protocols_func )( register_cb cb , gpointer client_da \nregister_cb cb , \ngpointer client_data ) \n{ \n- gboolean status = TRUE ; \n+ volatile gboolean status = TRUE ; \n \n/* initialize memory allocation subsystem */ \nwmem_init ();", "mmm epan / dissectors / packet - spnego . c \nppp epan / dissectors / packet - spnego . c \ndissect_spnego_supportedMech ( tvbuff_t * tvb , int offset , packet_info * pinfo _U_ , \nproto_tree_add_text ( tree , tvb , offset , nbytes , \" supportedMech : % s \", \noid_string ); \n \n- g_free ( oid_string ); \n- \noffset += nbytes ; \n \n/* Should check for an unrecognized OID ... */", "mmm plugins / megaco / packet - megaco . c \nppp plugins / megaco / packet - megaco . c \n* Routines for megaco packet disassembly \n* RFC 3015 \n* \n-* $ Id : packet - megaco . c , v 1 . 15 2004 / 04 / 21 19 : 58 : 14 etxrab Exp $ \n+* $ Id : packet - megaco . c , v 1 . 16 2004 / 04 / 23 03 : 20 : 58 guy Exp $ \n* \n* Christian Falckenberg , 2002 / 10 / 17 \n* Copyright ( c ) 2002 by Christian Falckenberg \ndissect_megaco_text ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) \nif ( tree ) \nlen = tvb_len - tvb_previous_offset ; \nproto_tree_add_text ( megaco_tree , tvb , tvb_previous_offset , - 1 , \n- \"% s \", tvb_format_text ( tvb , tvb_previous_offset , len ), tvb_len , \n- tvb_previous_offset ); \n+ \"% s \", tvb_format_text ( tvb , tvb_previous_offset , len )); \nif ( global_megaco_raw_text ){ \ntvb_raw_text_add ( tvb , megaco_tree ); \n}", "mmm wiretap / libpcap . c \nppp wiretap / libpcap . c \n/* libpcap . c \n* \n- * $ Id : libpcap . c , v 1 . 16 1999 / 08 / 28 01 : 19 : 44 guy Exp $ \n+ * $ Id : libpcap . c , v 1 . 17 1999 / 08 / 31 22 : 36 : 20 guy Exp $ \n* \n* Wiretap Library \n* Copyright ( c ) 1998 by Gilbert Ramirez < gram @ verdict . uthscsa . edu > \n((( x )& 0x00FF )<< 8 )) \n \n/* On some systems , the FDDI MAC addresses are bit - swapped . */ \n-# if ! defined ( ultrix ) && ! defined ( __alpha ) && ! defined ( __bsdi ) \n+# if ! defined ( ultrix ) && ! defined ( __alpha ) && ! defined ( __bsdi__ ) \n# define BIT_SWAPPED_MAC_ADDRS \n# endif \n", "mmm epan / dissectors / packet - vmlab . c \nppp epan / dissectors / packet - vmlab . c \ndissect_vmlab ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) \nguint8 attributes ; \nguint8 portgroup ; \n \n- guint16 encap_proto ; \n+ volatile guint16 encap_proto ; \n \ncol_set_str ( pinfo -> cinfo , COL_PROTOCOL , \" VMLAB \"); \ncol_clear ( pinfo -> cinfo , COL_INFO );", "mmm epan / dissectors / packet - isakmp . c \nppp epan / dissectors / packet - isakmp . c \nstatic struct strfunc { \n{\" Delete \", dissect_delete }, \n{\" Vendor ID \", dissect_vid }, \n{\" Attrib \", dissect_config }, \n- {\" NAT - Discovery \", dissect_nat_discovery }, /* draft - ietf - ipsec - nat - t - ike */ \n+ {\" NAT - Discovery \", dissect_nat_discovery }, /* draft - ietf - ipsec - nat - t - ike - 04 */ \n{\" NAT - Original Address \", dissect_nat_original_address } /* draft - ietf - ipsec - nat - t - ike */ \n}; \n \npayloadtype2str ( guint8 type ) { \nif ( type < 128 ) \nreturn \" RESERVED \"; \nif ( type == 130 ) \n- return \" NAT - D ( draft - ietf - ipsec - nat - t - ike - 01 to 04 )\"; \n+ return \" NAT - D ( draft - ietf - ipsec - nat - t - ike - 01 to 03 )\"; \nif ( type == 131 ) \nreturn \" NAT - OA ( draft - ietf - ipsec - nat - t - ike - 01 to 04 )\"; \nreturn \" Private USE \";", "mmm packet - smb . c \nppp packet - smb . c \n* Copyright 1999 , Richard Sharpe < rsharpe @ ns . aus . com > \n* 2001 Rewrite by Ronnie Sahlberg and Guy Harris \n* \n- * $ Id : packet - smb . c , v 1 . 327 2003 / 04 / 14 17 : 38 : 49 guy Exp $ \n+ * $ Id : packet - smb . c , v 1 . 328 2003 / 04 / 17 00 : 13 : 26 guy Exp $ \n* \n* Ethereal - Network traffic analyzer \n* By Gerald Combs < gerald @ ethereal . com > \nproto_reg_handoff_smb ( void ) \nntlmssp_handle = find_dissector (\" ntlmssp \"); \n \nheur_dissector_add (\" netbios \", dissect_smb_heur , proto_smb ); \n+ heur_dissector_add (\" cotp \", dissect_smb_heur , proto_smb ); \nsmb_handle = create_dissector_handle ( dissect_smb , proto_smb ); \ndissector_add (\" ipx . socket \", IPX_SOCKET_NWLINK_SMB_SERVER , smb_handle ); \ndissector_add (\" ipx . socket \", IPX_SOCKET_NWLINK_SMB_REDIR , smb_handle );", "mmm epan / dissectors / packet - nfs . c \nppp epan / dissectors / packet - nfs . c \ndissect_nfs_argop4 ( tvbuff_t * tvb , int offset , packet_info * pinfo , \n} \n} \n \n+ for ( ops_counter = 0 ; ops_counter < ops ; ops_counter ++) \n+ { \n+ g_string_free ( op_summary [ ops_counter ]. optext , TRUE ); \n+ } \n+ \n+ g_free ( op_summary ); \n \nreturn offset ; \n} \ndissect_nfs_resop4 ( tvbuff_t * tvb , int offset , packet_info * pinfo , \n} \n} \n \n+ for ( ops_counter = 0 ; ops_counter < ops ; ops_counter ++) \n+ { \n+ g_string_free ( op_summary [ ops_counter ]. optext , TRUE ); \n+ } \n+ \n+ g_free ( op_summary ); \n \nreturn offset ; \n}", "mmm gtk / gtkvumeter . c \nppp gtk / gtkvumeter . c \nstatic void gtk_vumeter_size_calculate ( GtkWidget * widget , GtkRequisition * requi \nPangoLayout * layout = gtk_widget_create_pango_layout ( widget , item -> label ); \npango_layout_get_pixel_size ( layout , & layout_width , & layout_height ); \n/* XXX - memleak */ \n+ } else { \n+ layout_width = 0 ; \n+ layout_height = 0 ; \n} \n \nif ( vumeter -> vertical == TRUE ) {", "mmm ui / qt / io_graph_dialog . cpp \nppp ui / qt / io_graph_dialog . cpp \nstatic uat_field_t io_graph_fields [] = { \nUAT_END_FIELDS \n}; \n \n- static void * io_graph_copy_cb ( void * dst_ptr , const void * src_ptr , size_t len _U_ ) { \n+ static void * io_graph_copy_cb ( void * dst_ptr , const void * src_ptr , size_t len ) { \n+ Q_UNUSED ( len ); \nio_graph_settings_t * dst = ( io_graph_settings_t *) dst_ptr ; \nconst io_graph_settings_t * src = ( const io_graph_settings_t *) src_ptr ; \n", "mmm tshark . c \nppp tshark . c \nprint_usage ( gboolean print_ver ) \n \n/* fprintf ( output , \"\\ n \");*/ \nfprintf ( output , \" Output :\\ n \"); \n- fprintf ( output , \" - w < outfile |-> set the output filename ( or '-' for stdout )\\ n \"); \n+ fprintf ( output , \" - w < outfile |-> write packets to a pcap - format file named \\\" outfile \\\"\\ n \"); \n+ fprintf ( output , \" ( or to the standard output for \\\"-\\\")\\ n \"); \nfprintf ( output , \" - C < config profile > start with specified configuration profile \\ n \"); \nfprintf ( output , \" - F < output file type > set the output file type , default is libpcap \\ n \"); \nfprintf ( output , \" an empty \\\"- F \\\" option will list the file types \\ n \");", "mmm epan / dissectors / packet - prp . c \nppp epan / dissectors / packet - prp . c \ndissect_prp_redundancy_control_trailer ( tvbuff_t * tvb , packet_info * pinfo _U_ , pr \nif ( length < 14 ) \nreturn 0 ; \n \n+ /* \n+ * This is horribly broken . It assumes the frame is an Ethernet \n+ * frame , with a type field at an offset of 12 bytes from the header . \n+ * That is not guaranteed to be true . \n+ */ \n+ if (! tvb_bytes_exist ( tvb , 12 , 2 )) \n+ return 0 ; \nif ( ETHERTYPE_VLAN == tvb_get_ntohs ( tvb , 12 )) /* tagged frame */ \n{ \noffset = 18 ; \ndissect_prp_redundancy_control_trailer ( tvbuff_t * tvb , packet_info * pinfo _U_ , pr \nif (! tree ) \nreturn tvb_captured_length ( tvb ); \n \n+ /* \n+ * Is there enough data in the packet to every try to search for a \n+ * trailer ? \n+ */ \n+ if (! tvb_bytes_exist ( tvb , ( length - 4 )+ 2 , 2 )) \n+ return 0 ; /* no */ \n+ \n/* search for PRP - 0 trailer */ \n/* If the frame is > 64 bytes , the PRP - 0 trailer is always at the end . */ \n/* If the frame is <= 64 bytes , the PRP - 0 trailer may be anywhere ( before the padding ) */", "mmm epan / filesystem . c \nppp epan / filesystem . c \nfile_open_error_message ( int err , gboolean for_writing ) \nbreak ; \n# endif \n \n+ case EINVAL : \n+ errmsg = \" The file \\\"% s \\\" could not be created because an invalid filename was specified .\"; \n+ break ; \n+ \ndefault : \ng_snprintf ( errmsg_errno , sizeof ( errmsg_errno ), \n\" The file \\\"%% s \\\" could not be % s : % s .\",", "mmm epan / crypt / airpdcap . c \nppp epan / crypt / airpdcap . c \nAirPDcapGetStaAddress ( \nswitch ( AIRPDCAP_DS_BITS ( frame -> fc [ 1 ])) { /* Bit 1 = FromDS , bit 0 = ToDS */ \ncase 0 : \ncase 1 : \n- case 3 : \nreturn frame -> addr2 ; \ncase 2 : \nreturn frame -> addr1 ; \n+ case 3 : \n+ if ( memcmp ( frame -> addr1 , frame -> addr2 , AIRPDCAP_MAC_LEN ) < 0 ) \n+ return frame -> addr1 ; \n+ else \n+ return frame -> addr2 ; \n+ \ndefault : \nreturn NULL ; \n} \nAirPDcapGetBssidAddress ( \ncase 0 : \nreturn frame -> addr3 ; \ncase 1 : \n- case 3 : \nreturn frame -> addr1 ; \ncase 2 : \nreturn frame -> addr2 ; \n+ case 3 : \n+ if ( memcmp ( frame -> addr1 , frame -> addr2 , AIRPDCAP_MAC_LEN ) > 0 ) \n+ return frame -> addr1 ; \n+ else \n+ return frame -> addr2 ; \n+ \ndefault : \nreturn NULL ; \n}", "mmm ui / gtk / rlc_lte_graph . c \nppp ui / gtk / rlc_lte_graph . c \n# define MOUSE_BUTTON_MIDDLE 2 \n# define MOUSE_BUTTON_RIGHT 3 \n \n-# define MAX_PIXELS_PER_SN 90 \n+# define MAX_PIXELS_PER_SN 90 \n+# define MAX_PIXELS_PER_SECOND 50000 \n \nextern int proto_rlc_lte ; \n \nstatic void do_zoom_common ( struct graph * g , GdkEventButton * event , \n} \n} else { \n/* Zoom in */ \n- if ( lock_horizontal ) { \n+ if (( lock_horizontal ) || ( g -> geom . width >= ( g -> bounds . width * MAX_PIXELS_PER_SECOND ))) { \nfactor . x = 1 . 0 ; \n} \nelse { \nstatic void do_zoom_common ( struct graph * g , GdkEventButton * event , \n} \n \n/* Don ' t zoom in too far vertically */ \n- if (( g -> geom . height >= ( g -> bounds . height * MAX_PIXELS_PER_SN )) || lock_vertical ) { \n+ if ( lock_vertical || ( g -> geom . height >= ( g -> bounds . height * MAX_PIXELS_PER_SN ))) { \nfactor . y = 1 . 0 ; \n} \nelse {", "mmm epan / dissectors / packet - rohc . c \nppp epan / dissectors / packet - rohc . c \nstart_over : \n} \ncol_prepend_fstr ( pinfo -> cinfo , COL_PROTOCOL , \" ROHC <\"); \ncol_append_str ( pinfo -> cinfo , COL_PROTOCOL , \">\"); \n+ pinfo -> private_data = save_private_data ; \n+ return ; \n} \nelse if ((( oct & 0x80 )== 0x00 ) && ( rohc_cid_context -> profile == ROHC_PROFILE_RTP )) { \n/* 5 . 7 . 1 . Packet type 0 : UO - 0 , R - 0 , R - 0 - CRC */ \nstart_over : \n} \n \npayload_tvb = tvb_new_subset_remaining ( tvb , offset ); \n- call_dissector_only ( data_handle , payload_tvb , pinfo , rohc_tree , NULL ); \n+ call_dissector_only ( data_handle , payload_tvb , pinfo , tree , NULL ); \n \npinfo -> private_data = save_private_data ; \n}", "mmm epan / proto . c \nppp epan / proto . c \nproto_item_set_len ( proto_item * pi , const gint length ) \nDISSECTOR_ASSERT ( length >= 0 ); \nfi -> length = length ; \n \n- if ( fi -> value . ftype -> ftype == FT_BYTES ) \n+ /* \n+ * You cannot just make the \" len \" field of a GByteArray \n+ * larger , if there ' s no data to back that length ; \n+ * you can only make it smaller . \n+ */ \n+ if ( fi -> value . ftype -> ftype == FT_BYTES && length <= fi -> length ) \nfi -> value . value . bytes -> len = length ; \n} \n", "mmm ui / qt / multicast_statistics_dialog . cpp \nppp ui / qt / multicast_statistics_dialog . cpp \nvoid MulticastStatisticsDialog :: updateMulticastParameters () \n \nparam = buffer_alarm_threshold_le_ -> text (). toInt (& ok ); \nif ( ok && param > 0 ) { \n- mcast_stream_trigger = param ; \n+ mcast_stream_bufferalarm = param ; \n} \n \nparam = stream_empty_speed_le_ -> text (). toInt (& ok );", "mmm epan / dissectors / packet - pdcp - lte . c \nppp epan / dissectors / packet - pdcp - lte . c \nstatic gint pdcp_channel_equal ( gconstpointer v , gconstpointer v2 ) \nstatic guint pdcp_channel_hash_func ( gconstpointer v ) \n{ \n/* Just use pointer , as the fields are all in this value */ \n- return ( guint ) v ; \n+ return GPOINTER_TO_UINT ( v ); \n} \n \n", "mmm gtk / main . c \nppp gtk / main . c \ncreate_main_window ( gint pl_size , gint tv_size , gint bv_size , e_prefs * prefs ) \nchannel_list = g_list_append ( channel_list , ieee80211_mhz_to_str ( airpcap_if_active -> pSupportedChannels [ i ]. Frequency )); \n} \ngtk_combo_set_popdown_strings ( GTK_COMBO ( channel_cm ), channel_list ); \n+ g_list_free ( channel_list ); \n} \n \ngtk_tooltips_set_tip ( airpcap_tooltips , GTK_WIDGET ( GTK_COMBO ( channel_cm )-> entry ), \ncreate_main_window ( gint pl_size , gint tv_size , gint bv_size , e_prefs * prefs ) \nlinktype_list = g_list_append ( linktype_list , AIRPCAP_VALIDATION_TYPE_NAME_CORRUPT ); \n \ngtk_combo_set_popdown_strings ( GTK_COMBO ( wrong_crc_cm ), linktype_list ) ; \n+ g_list_free ( linktype_list ); \ngtk_tooltips_set_tip ( airpcap_tooltips , GTK_WIDGET ( GTK_COMBO ( wrong_crc_cm )-> entry ), \n\" Select the 802 . 11 FCS filter that the wireless adapter will apply .\", \nNULL );", "mmm epan / dissectors / packet - sdp . c \nppp epan / dissectors / packet - sdp . c \ndissect_sdp_media ( tvbuff_t * tvb , proto_item * ti , \nproto_tree_add_string ( sdp_media_tree , hf_media_format , tvb , offset , \ntokenlen , val_to_str ( atol ( media_format ), rtp_payload_type_vals , \"% u \")); \ntransport_info -> media_pt [ transport_info -> media_pt_count ] = atol ( media_format ); \n- if ( transport_info -> media_pt_count < SDP_MAX_RTP_PAYLOAD_TYPES ) \n+ if ( transport_info -> media_pt_count < SDP_MAX_RTP_PAYLOAD_TYPES - 1 ) \ntransport_info -> media_pt_count ++; \ng_free ( media_format ); \n} else {", "mmm epan / dissectors / packet - tipc . c \nppp epan / dissectors / packet - tipc . c \nvoid proto_register_tipc ( void ); \n \nstatic int proto_tipc = - 1 ; \n \n-/* dissector handles */ \n- static dissector_handle_t ip_handle ; \n- \nstatic int hf_tipc_msg_fragments = - 1 ; \nstatic int hf_tipc_msg_fragment = - 1 ; \nstatic int hf_tipc_msg_fragment_overlap = - 1 ; \nproto_reg_handoff_tipc ( void ) \ndissector_handle_t tipc_tcp_handle ; \n \ntipc_tcp_handle = create_dissector_handle ( dissect_tipc_tcp , proto_tipc ); \n- ip_handle = find_dissector (\" ip \"); \n \ndissector_add_uint (\" ethertype \", ETHERTYPE_TIPC , tipc_handle ); \ndissector_add_for_decode_as_with_preference (\" tcp . port \", tipc_tcp_handle );", "mmm packet - dcerpc - spoolss . c \nppp packet - dcerpc - spoolss . c \n* Routines for SMB \\ PIPE \\ spoolss packet disassembly \n* Copyright 2001 , Tim Potter < tpot @ samba . org > \n* \n- * $ Id : packet - dcerpc - spoolss . c , v 1 . 5 2002 / 03 / 19 22 : 09 : 23 guy Exp $ \n+ * $ Id : packet - dcerpc - spoolss . c , v 1 . 6 2002 / 03 / 20 09 : 09 : 07 guy Exp $ \n* \n* Ethereal - Network traffic analyzer \n* By Gerald Combs < gerald @ ethereal . com > \nstatic int prs_uint16uni ( tvbuff_t * tvb , int offset , packet_info * pinfo , \n \n/* Get remaining data in buffer as a string */ \n \n- remaining = tvb_length_remaining ( tvb , offset ); \n+ remaining = tvb_length_remaining ( tvb , offset )/ 2 ; \ntext = fake_unicode ( tvb , offset , remaining ); \nlen = strlen ( text ); \n", "mmm epan / dissectors / packet - rtps . c \nppp epan / dissectors / packet - rtps . c \nstatic const struct Flag_definition DATA_FRAG_FLAGS [] = { \n{ ' Q ', \" Inline QoS \" }, /* Bit 1 */ \n{ ' E ', \" Endianness bit \" } /* Bit 0 */ \n}; \n+# if 0 \n/* Vendor specific : RTI */ \nstatic const struct Flag_definition NACK_FLAGS [] = { \n{ RESERVEDFLAG_CHAR , RESERVEDFLAG_STRING }, /* Bit 7 */ \nstatic const struct Flag_definition NACK_FLAGS [] = { \n{ ' F ', \" Final flag \" }, /* Bit 1 */ \n{ ' E ', \" Endianness bit \" } /* Bit 0 */ \n}; \n+# endif \n \n \n/***************************************************************************/ \nstatic void dissect_DATA_FRAG ( tvbuff_t * tvb , packet_info * pinfo , gint offset , gu \nproto_item * octet_item ; \nguint32 wid ; \ngboolean from_builtin_writer ; \n- rtps_util_decode_flags ( tree , tvb , offset + 1 , flags , NOKEY_DATA_FRAG_FLAGS ); \n+ rtps_util_decode_flags ( tree , tvb , offset + 1 , flags , DATA_FRAG_FLAGS ); \n \noctet_item = proto_tree_add_item ( tree , hf_rtps_sm_octets_to_next_header , tvb , \noffset + 2 , 2 , little_endian ? ENC_LITTLE_ENDIAN : ENC_BIG_ENDIAN );", "mmm plugins / profinet / packet - dcom - cba . c \nppp plugins / profinet / packet - dcom - cba . c \ndissect_ICBAPhysicalDevice_get_LogicalDevice_rqst ( tvbuff_t * tvb , int offset , \n \noffset = dissect_dcom_dcerpc_pointer ( tvb , offset , pinfo , tree , di , drep , \n& u32Pointer ); \n+ \n+ szStr [ 0 ] ='\\ 0 '; \n+ \nif ( u32Pointer ) { \noffset = dissect_dcom_BSTR ( tvb , offset , pinfo , tree , di , drep , \nhf_cba_name , szStr , u32MaxStr );", "mmm epan / dissectors / packet - dcerpc - spoolss . c \nppp epan / dissectors / packet - dcerpc - spoolss . c \ndissect_spoolss_uint16uni ( tvbuff_t * tvb , int offset , packet_info * pinfo _U_ , \n \n/* Get remaining data in buffer as a string */ \n \n- remaining = tvb_captured_length_remaining ( tvb , offset ); \n+ remaining = tvb_reported_length_remaining ( tvb , offset ); \nif ( remaining <= 0 ) { \nif ( data ) \n* data = g_strdup (\"\"); \ndissect_spoolss_keybuffer ( tvbuff_t * tvb , int offset , packet_info * pinfo , \nend_offset = tvb_reported_length_remaining ( tvb , offset ) + 1 ; \n} \n \n- while ( offset < end_offset ) \n+ while ( offset > 0 && offset < end_offset ) { \noffset = dissect_spoolss_uint16uni ( \ntvb , offset , pinfo , tree , drep , NULL , hf_keybuffer ); \n+ } \n \nreturn offset ; \n}", "mmm epan / crypt / airpdcap . c \nppp epan / crypt / airpdcap . c \nAirPDcapDecryptWPABroadcastKey ( const EAPOL_RSN_KEY * pEAPKey , guint8 * decryption_ \n} \n} \n \n- if ( key_bytes_len < GROUP_KEY_MIN_LEN || key_bytes_len > eapol_len - sizeof ( EAPOL_RSN_KEY )) { \n+ if (( key_bytes_len < GROUP_KEY_MIN_LEN ) || \n+ ( eapol_len < sizeof ( EAPOL_RSN_KEY )) || \n+ ( key_bytes_len > eapol_len - sizeof ( EAPOL_RSN_KEY ))) { \nreturn AIRPDCAP_RET_NO_VALID_HANDSHAKE ; \n} \n", "mmm epan / tvbuff . c \nppp epan / tvbuff . c \ntvb_get_letohguid ( tvbuff_t * tvb , const gint offset , e_guid_t * guid ) \nguid -> data1 = pletohl ( ptr + 0 ); \nguid -> data2 = pletohs ( ptr + 4 ); \nguid -> data3 = pletohs ( ptr + 6 ); \n- memcpy ( guid -> data4 , offset + 8 , sizeof guid -> data4 ); \n+ memcpy ( guid -> data4 , ptr + 8 , sizeof guid -> data4 ); \n} \n \n/*", "mmm epan / dissectors / packet - tds . c \nppp epan / dissectors / packet - tds . c \ndissect_tds_resp ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree ) \n \nlength_remaining = tvb_ensure_length_remaining ( tvb , pos ); \n \n+ if (( int ) token_sz < 0 ) { \n+ proto_tree_add_text ( tree , tvb , pos , 0 , \" Bogus token size : % u \", \n+ token_sz ); \n+ break ; \n+ } \n+ if (( int ) token_len_field_size < 0 ) { \n+ proto_tree_add_text ( tree , tvb , pos , 0 , \" Bogus token length field size : % u \", \n+ token_len_field_size ); \n+ break ; \n+ } \ntoken_item = proto_tree_add_text ( tree , tvb , pos , token_sz , \n\" Token 0x % 02x % s \", token , \nval_to_str ( token , token_names , \" Unknown Token Type \"));", "mmm extcap . c \nppp extcap . c \nextcap_register_preferences_callback ( gpointer key , gpointer value _U_ , gpointer \n \nvoid extcap_register_preferences ( void ) \n{ \n+ if ( prefs . capture_no_extcap ) \n+ return ; \n+ \nmodule_t * dev_module = prefs_find_module (\" extcap \"); \n \nif (! dev_module ) \nextcap_load_interface_list ( void ) \ngchar * argv ; \ngchar * error ; \n \n+ if ( prefs . capture_no_extcap ) \n+ return ; \n+ \nif ( _toolbars ) \n{ \n// Remove existing interface toolbars here instead of in extcap_clear_interfaces ()", "mmm follow . c \nppp follow . c \n/* follow . c \n* \n- * $ Id : follow . c , v 1 . 3 1998 / 10 / 10 03 : 32 : 09 gerald Exp $ \n+ * $ Id : follow . c , v 1 . 4 1998 / 10 / 28 01 : 29 : 16 guy Exp $ \n* \n* Copyright 1998 Mike Hall < mlh @ io . com > \n* \nreassemble_tcp ( u_long sequence , u_long length , const char * data , int synflag , u \ntmp_frag -> data = ( u_char *) malloc ( length ); \ntmp_frag -> seq = sequence ; \ntmp_frag -> len = length ; \n- bcopy ( data , tmp_frag -> data , length ); \n+ memcpy ( tmp_frag -> data , data , length ); \nif ( frags [ src_index ] ) { \ntmp_frag -> next = frags [ src_index ]; \n} else {", "mmm packet - isis - clv . c \nppp packet - isis - clv . c \n/* packet - isis - clv . c \n* Common CLV decode routines . \n* \n- * $ Id : packet - isis - clv . c , v 1 . 6 2000 / 06 / 19 08 : 33 : 47 guy Exp $ \n+ * $ Id : packet - isis - clv . c , v 1 . 7 2000 / 08 / 10 14 : 21 : 09 deniel Exp $ \n* Stuart Stanley < stuarts @ mxmail . net > \n* \n* Ethereal - Network traffic analyzer \nisis_dissect_clvs ( const isis_clv_handle_t * opts , int len , int id_length , \nlength = pd [ offset ++]; \nadj = ( sizeof ( code ) + sizeof ( length ) + length ); \nlen -= adj ; \n- if ( len < 0 ) { \n+ if ( len < 0 || ! BYTES_ARE_IN_FRAME ( offset , length ) ) { \nisis_dissect_unknown ( offset , adj , tree , fd , \n\" Short CLV header (% d vs % d )\", \nadj , len + adj );", "mmm epan / dissectors / packet - epon . c \nppp epan / dissectors / packet - epon . c \ndissect_epon ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , \nguint dpoe_sec_byte ; \ngboolean dpoe_encrypted = FALSE ; \n \n- /* Start_of_Packet delimiter (/ S /) can either happen in byte 1 or byte 2 , \n- * making the captured preamble either 7 or 6 bytes in length . If the \n+ /* Start_of_Packet delimiter (/ S /) can happen in byte 1 , 2 or 3 , \n+ * making the captured preamble 8 , 7 or 6 bytes in length . If the \n* preamble starts with 0x55 , then / S / happened in byte 1 , making the \n* captured preamble 7 bytes in length . \n*/ \n- if ( tvb_get_ntoh24 ( tvb , 0 ) == 0x55D555 ) { \n+ if ( tvb_get_ntohl ( tvb , 0 ) == 0x5555D555 ) { \n+ offset += 2 ; \n+ } else if ( tvb_get_ntoh24 ( tvb , 0 ) == 0x55D555 ) { \noffset += 1 ; \n} else if ( tvb_get_ntohs ( tvb , 0 ) == 0xD555 ) { \noffset += 0 ;", "mmm epan / dissectors / packet - btobex . c \nppp epan / dissectors / packet - btobex . c \ndissect_headers ( proto_tree * tree , tvbuff_t * tvb , int offset , packet_info * pinfo , \nproto_item_append_text ( hdr_tree , \" (\\\"% s \\\")\", str ); \n \ncol_append_fstr ( pinfo -> cinfo , COL_INFO , \" \\\"% s \\\"\", str ); \n+ offset += item_length - 3 ; \n} \nelse { \ncol_append_str ( pinfo -> cinfo , COL_INFO , \" \\\"\\\"\"); \n} \n- \n- offset += item_length - 3 ; \n} \nbreak ; \ncase 0x40 : /* byte sequence */ \ndissect_headers ( proto_tree * tree , tvbuff_t * tvb , int offset , packet_info * pinfo , \ncol_append_fstr ( pinfo -> cinfo , COL_INFO , \" \\\"% s \\\"\", tvb_get_ephemeral_string ( tvb , offset , item_length - 3 )); \n} \n \n- offset += item_length - 3 ; \n+ if ( item_length >= 3 ) /* prevent infinite loops */ \n+ offset += item_length - 3 ; \nbreak ; \ncase 0x80 : /* 1 byte */ \nproto_item_append_text ( hdr_tree , \" (% i )\", tvb_get_ntohl ( tvb , offset ));", "mmm gtk / uat_gui . c \nppp gtk / uat_gui . c \nstatic gboolean uat_cancel_dlg_cb ( GtkWidget * win _U_ , gpointer user_data ) { \nif ( dd -> is_new ) g_free ( dd -> rec ); \ng_ptr_array_free ( dd -> entries , TRUE ); \nwindow_destroy ( GTK_WIDGET ( dd -> win )); \n- g_free ( dd ); \n \nwhile ( dd -> tobe_freed -> len ) g_free ( g_ptr_array_remove_index_fast ( dd -> tobe_freed , dd -> tobe_freed -> len - 1 ) ); \n \n+ g_free ( dd ); \n+ \nreturn TRUE ; \n} \n", "mmm epan / dissectors / packet - bthci_evt . c \nppp epan / dissectors / packet - bthci_evt . c \ndissect_bthci_evt_inq_result_with_rssi ( tvbuff_t * tvb , int offset , packet_info * p \nstatic int \ndissect_bthci_evt_eir_ad_data ( tvbuff_t * tvb , int offset , packet_info * pinfo _U_ , proto_tree * tree , guint8 size ) \n{ \n- guint16 i ; \n- guint8 j , length , type ; \n+ guint16 i , j ; \n+ guint8 length , type ; \nproto_item * ti_eir = NULL ; \nproto_item * ti_eir_subtree = NULL ; \n", "mmm epan / tvbuff . c \nppp epan / tvbuff . c \ntvb_uncompress ( tvbuff_t * tvb , int offset , int comprlen ) \ninflateReset ( strm ); \nnext = c ; \nstrm -> next_in = next ; \n+ if ( c - compr > comprlen ) { \n+ g_free ( strm ); \n+ g_free ( compr ); \n+ g_free ( strmbuf ); \n+ return NULL ; \n+ } \ncomprlen -= ( c - compr ); \n \nerr = inflateInit2 ( strm , wbits );", "mmm capture_loop . c \nppp capture_loop . c \ncapture_loop_packet_cb ( guchar * user , const struct pcap_pkthdr * phdr , \nint err ; \n \n/* if the user told us to stop after x packets , do we have enough ? */ \n- if (( ld -> packets_max > 0 ) && (++ ld -> counts . total >= ld -> packets_max )) \n+ ld -> counts . total ++; \n+ if (( ld -> packets_max > 0 ) && ( ld -> counts . total >= ld -> packets_max )) \n{ \nld -> go = FALSE ; \n}", "mmm epan / dissectors / packet - geneve . c \nppp epan / dissectors / packet - geneve . c \n/* packet - geneve . c \n* Routines for Geneve - Generic Network Virtualization Encapsulation \n- * http :// tools . ietf . org / html / draft - gross - geneve - 00 \n+ * http :// tools . ietf . org / html / draft - ietf - nvo3 - geneve \n* \n* Copyright ( c ) 2014 VMware , Inc . All Rights Reserved . \n* Author : Jesse Gross < jesse @ nicira . com > \n \nstatic const range_string class_id_names [] = { \n{ 0 , 0xFF , \" Standard \" }, \n- { 0xFFFF , 0xFFFF , \" Experimental \" }, \n+ { 0x0100 , 0x0100 , \" Linux \" }, \n+ { 0x0101 , 0x0101 , \" Open vSwitch \" }, \n+ { 0x0102 , 0x0102 , \" Open Virtual Networking ( OVN )\" }, \n+ { 0x0103 , 0x0103 , \" In - band Network Telemetry ( INT )\" }, \n+ { 0x0104 , 0x0104 , \" VMware \" }, \n+ { 0xFFF0 , 0xFFFF , \" Experimental \" }, \n{ 0 , 0 , NULL } \n}; \n", "mmm wiretap / pppdump . c \nppp wiretap / pppdump . c \n/* pppdump . c \n* \n- * $ Id : pppdump . c , v 1 . 11 2001 / 12 / 13 05 : 49 : 12 gram Exp $ \n+ * $ Id : pppdump . c , v 1 . 12 2001 / 12 / 13 05 : 50 : 51 gram Exp $ \n* \n* Copyright ( c ) 2000 by Gilbert Ramirez < gram @ alumni . rice . edu > \n* \npppdump_close ( wtap * wth ) \n} \n \nif ( state -> pids ) { /* should always be TRUE */ \n- int i ; \n+ unsigned int i ; \nfor ( i = 0 ; i < g_ptr_array_len ( state -> pids ); i ++) { \ng_free ( g_ptr_array_index ( state -> pids , i )); \n}", "mmm epan / frame_data . c \nppp epan / frame_data . c \nvoid \nframe_data_reset ( frame_data * fdata ) \n{ \nfdata -> flags . visited = 0 ; \n+ fdata -> subnum = 0 ; \n \nif ( fdata -> pfd ) { \ng_slist_free ( fdata -> pfd );", "mmm wiretap / pcapng . c \nppp wiretap / pcapng . c \npcapng_read_section_header_block ( FILE_T fh , pcapng_block_header_t * bh , \nbytes_read = pcapng_read_option ( fh , pn , & oh , option_content , opt_cont_buf_len , to_read , err , err_info , \" section_header \"); \nif ( bytes_read <= 0 ) { \npcapng_debug (\" pcapng_read_section_header_block : failed to read option \"); \n+ g_free ( option_content ); \nreturn PCAPNG_BLOCK_ERROR ; \n} \nto_read -= bytes_read ;", "mmm wiretap / peektagged . c \nppp wiretap / peektagged . c \npeektagged_read_packet ( wtap * wth , FILE_T fh , struct wtap_pkthdr * phdr , \n \ncase TAG_PEEKTAGGED_CENTER_FREQUENCY : \n/* XXX - also seen in an EtherPeek capture ; value unknown */ \n+ ieee_802_11 . presence_flags |= PHDR_802_11_HAS_FREQUENCY ; \n+ ieee_802_11 . frequency = pletoh32 (& tag_value [ 2 ]); \nbreak ; \n \ncase TAG_PEEKTAGGED_UNKNOWN_0x000E :", "mmm epan / dissectors / packet - rtcp . c \nppp epan / dissectors / packet - rtcp . c \nstatic void calculate_roundtrip_delay ( tvbuff_t * tvb , packet_info * pinfo , \np_add_proto_data ( pinfo -> fd , proto_rtcp , p_packet_data ); \n} \n \n+ /* Don ' t allow match seemingly calculated from same frame ! */ \n+ if ( pinfo -> fd -> num == p_conv_data -> last_received_frame_number ) \n+ { \n+ return ; \n+ } \n+ \n/* Any previous report must match the lsr given here */ \nif ( p_conv_data -> last_received_ts == lsr ) \n{ \nstatic void calculate_roundtrip_delay ( tvbuff_t * tvb , packet_info * pinfo , \ngint nseconds_between_packets = \npinfo -> fd -> abs_ts . nsecs - p_conv_data -> last_received_timestamp . nsecs ; \n \n- \n- gint total_gap = (( seconds_between_packets * 1000 ) + \n- nseconds_between_packets ) / 1000000 ; \n+ gint total_gap = ( seconds_between_packets * 1000 ) + \n+ ( nseconds_between_packets / 1000000 ); \ngint delay = total_gap - ( int )((( double ) dlsr /( double ) 65536 ) * 1000 . 0 ); \n \n/* No useful calculation can be done if dlsr not set ... */", "mmm capture_opts . h \nppp capture_opts . h \ntypedef struct capture_options_tag { \n \n/* GUI related */ \ngboolean real_time_mode ; /**< Update list of packets in real time */ \n- gboolean show_info ; /**< show the info dialog . GTK + only . */ \n+ gboolean show_info ; /**< show the info dialog . */ \ngboolean restart ; /**< restart after closing is done */ \ngchar * orig_save_file ; /**< the original capture file name ( saved for a restart ) */ \n", "mmm epan / dissectors / packet - hip . c \nppp epan / dissectors / packet - hip . c \ndissect_hip_tlv ( tvbuff_t * tvb , packet_info * pinfo , int offset , proto_item * ti , i \nnewoffset += ( 1 + tvb_get_guint8 ( tvb , newoffset + 2 )); \ntlv_len -= ( 1 + tvb_get_guint8 ( tvb , newoffset + 2 )); \n} \n- if ( ti_loc ) { \n+ if ( locator_type <= 2 ) { \nti_loc = proto_item_add_subtree ( ti_loc , ett_hip_locator_data ); \n/* Traffic type */ \nproto_tree_add_item ( ti_loc , hf_hip_tlv_locator_traffic_type , tvb ,", "mmm packet - icq . c \nppp packet - icq . c \n/* packet - icq . c \n* Routines for ICQ packet disassembly \n* \n- * $ Id : packet - icq . c , v 1 . 22 2000 / 11 / 19 08 : 53 : 58 guy Exp $ \n+ * $ Id : packet - icq . c , v 1 . 23 2000 / 11 / 19 19 : 23 : 54 gerald Exp $ \n* \n* Ethereal - Network traffic analyzer \n* By Johan Feyaerts \ndissect_icqv5Client ( const u_char * pd , \nguint16 seqnum1 = 0 , seqnum2 = 0 ; \nguint32 uin = - 1 , sessionid = - 1 ; \nguint32 key = - 1 ; \n- guint16 pktsize = - 1 ; /* The size of the ICQ content */ \n- u_char decr_pd [ 1600 ]; /* Decrypted content , size should be dynamic */ \n+ guint16 pktsize = - 1 ; /* The size of the ICQ content */ \n+ static u_char * decr_pd = NULL ; /* Decrypted content */ \n \npktsize = END_OF_FRAME ; \n+ \n+ if ( decr_pd == NULL ) \n+ decr_pd = ( u_char *) g_malloc ( sizeof ( u_char ) * 128 ); \n+ \n+ while ( sizeof ( decr_pd ) < pktsize + 3 ) \n+ decr_pd = ( u_char *) g_realloc ( decr_pd , sizeof ( decr_pd ) * 2 ); \n+ \n/* First copy the memory , we don ' t want to overwrite the old content */ \nmemcpy ( decr_pd , & pd [ offset ], pktsize ); \nif ( pktsize > 0x14 ) {", "mmm epan / dissectors / packet - radius . c \nppp epan / dissectors / packet - radius . c \nstatic void dissect_attribute_value_pairs ( proto_tree * tree , packet_info * pinfo , \nlast_eap = TRUE ; \n} \n \n- if ( last_eap ) { \n+ if ( last_eap && eap_buffer ) { \ngboolean save_writable ; \n \nproto_item_append_text ( avp_item ,", "mmm gtk / main . c \nppp gtk / main . c \nmain_cf_cb_file_closing ( capture_file * cf ) \nwill there ever be more than one on the stack ? */ \nstatusbar_pop_file_msg (); \n \n- /* go back to \" No packets \" */ \n- packets_bar_update (); \n- \n/* Restore the standard title bar message . */ \nset_main_window_name (\" The Ethereal Network Analyzer \"); \n \nmain_cf_cb_file_closed ( capture_file * cf _U_ ) \nsplash_destroy ( close_dlg ); \nclose_dlg = NULL ; \n} \n+ \n+ /* go back to \" No packets \" */ \n+ packets_bar_update (); \n} \n \nstatic void", "mmm epan / dissectors / packet - zbee - zcl - general . c \nppp epan / dissectors / packet - zbee - zcl - general . c \ndissect_zcl_pwr_prof_enphsschednotif ( tvbuff_t * tvb , proto_tree * tree , guint * off \n* offset += 1 ; \n \n/* Scheduled Energy Phases decoding */ \n- for ( i = 0 ; i < num_of_sched_phases ; i ++) { \n+ for ( i = 0 ; ( i < num_of_sched_phases && i < ZBEE_ZCL_PWR_PROF_NUM_EN_PHS_ETT ); i ++) { \n/* Create subtree */ \nsub_tree = proto_tree_add_subtree_format ( tree , tvb , * offset , 1 , \nett_zbee_zcl_pwr_prof_enphases [ i ], NULL , \" Energy Phase #% u \", i ); \ndissect_zcl_pwr_prof_pwrprofnotif ( tvbuff_t * tvb , proto_tree * tree , guint * offset \n* offset += 1 ; \n \n/* Energy Phases decoding */ \n- for ( i = 0 ; i < num_of_transferred_phases ; i ++) { \n+ for ( i = 0 ; ( i < num_of_transferred_phases && i < ZBEE_ZCL_PWR_PROF_NUM_EN_PHS_ETT ); i ++) { \n/* Create subtree */ \nsub_tree = proto_tree_add_subtree_format ( tree , tvb , * offset , 1 , \nett_zbee_zcl_pwr_prof_enphases [ i ], NULL , \" Energy Phase #% u \", i );", "mmm epan / wmem / wmem_allocator_block . c \nppp epan / wmem / wmem_allocator_block . c \nwmem_block_split_used_chunk ( wmem_block_allocator_t * allocator , \nextra -> prev = ( guint32 ) ( aligned_size + sizeof ( wmem_block_chunk_t )); \nextra -> used = FALSE ; \n \n+ /* merge it to its right if possible ( it can ' t be merged left , obviously ) */ \n+ wmem_block_merge_free ( allocator , extra ); \n+ \n/* add it to the free list */ \nwmem_block_add_to_free_list ( allocator , extra ); \n}", "mmm epan / tvbuff . c \nppp epan / tvbuff . c \ntvb_skip_wsp ( tvbuff_t * tvb , const gint offset , const gint maxlength ) \n} \n \ngint \n- tvb_skip_wsp_return ( tvbuff_t * tvb , const gint offset ) { \n+ tvb_skip_wsp_return ( tvbuff_t * tvb , const gint offset ) \n+{ \ngint counter = offset ; \nguint8 tempchar ; \n \n- for ( counter = offset ; counter > 0 && \n+ DISSECTOR_ASSERT ( tvb && tvb -> initialized ); \n+ \n+ for ( counter = offset ; counter > 0 && \n(( tempchar = tvb_get_guint8 ( tvb , counter )) == ' ' || \ntempchar == '\\ t ' || tempchar == '\\ n ' || tempchar == '\\ r '); counter --); \ncounter ++; \n+ \nreturn ( counter ); \n} \n", "mmm gtk / display_opts . c \nppp gtk / display_opts . c \n/* display_opts . c \n* Routines for packet display windows \n* \n- * $ Id : display_opts . c , v 1 . 3 2000 / 05 / 08 01 : 11 : 46 guy Exp $ \n+ * $ Id : display_opts . c , v 1 . 4 2000 / 05 / 08 01 : 23 : 16 guy Exp $ \n* \n* Ethereal - Network traffic analyzer \n* By Gerald Combs < gerald @ zing . org > \n# include \" packet . h \" \n# include \" file . h \" \n# include \" display_opts . h \" \n+# include \" dlg_utils . h \" \n \nextern capture_file cf ; \nextern GtkWidget * packet_list ; \ndisplay_opt_cb ( GtkWidget * w , gpointer d ) { \ngtk_box_pack_start ( GTK_BOX ( bbox ), cancel_bt , TRUE , TRUE , 0 ); \ngtk_widget_show ( cancel_bt ); \n \n+ /* Catch the \" key_press_event \" signal in the window , so that we can catch \n+ the ESC key being pressed and act as if the \" Cancel \" button had \n+ been selected . */ \n+ dlg_set_cancel ( display_opt_w , cancel_bt ); \n+ \ndisplay_opt_window_active = TRUE ; \ngtk_widget_show ( display_opt_w ); \n}", "mmm gtk / gtkclist . c \nppp gtk / gtkclist . c \n* Copyright ( C ) 1995 - 1997 Peter Mattis , Spencer Kimball , Josh MacDonald , \n* Copyright ( C ) 1997 - 1998 Jay Painter < jpaint @ serv . net >< jpaint @ gimp . org > \n* \n- * $ Id : gtkclist . c , v 1 . 13 2002 / 09 / 09 20 : 32 : 30 jmayer Exp $ \n+ * $ Id : gtkclist . c , v 1 . 14 2003 / 06 / 28 21 : 46 : 08 sahlberg Exp $ \n* \n* This library is free software ; you can redistribute it and / or \n* modify it under the terms of the GNU Library General Public \n* GTK + at ftp :// ftp . gtk . org / pub / gtk /. \n*/ \n \n+/* TODO : \n+ * get rid of autoresize of the columns completely and just use some \n+ * sane default widths instead \n+ */ \n+ \n# include \" config . h \" \n# include < stdlib . h > \n# include < string . h > \nLIST_WIDTH ( GtkCList * clist ) \n} G_STMT_END \n \n \n+/* maximum size in pxels that columns will be autosized to */ \n+# define MAX_COLUMN_AUTOSIZE_WIDTH 600 \n+ \n/* Signals */ \nenum { \nSELECT_ROW , \ngtk_clist_set_column_auto_resize ( GtkCList * clist , \n{ \ngint width ; \n \n- width = gtk_clist_optimal_column_width ( clist , column ); \n+ /* cap the auto - rezised width to something reasonable */ \n+ width = MIN ( gtk_clist_optimal_column_width ( clist , column ), MAX_COLUMN_AUTOSIZE_WIDTH ); \ngtk_clist_set_column_width ( clist , column , width ); \n} \n}", "mmm epan / dissectors / packet - q931 . c \nppp epan / dissectors / packet - q931 . c \ndissect_q931_pdu ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , \noffset += call_ref_len ; \n} \nmessage_type = tvb_get_guint8 ( tvb , offset ); \n- if ( have_valid_q931_pi ) { \n+ if ( have_valid_q931_pi && q931_pi ) { \nq931_pi -> message_type = message_type ; \n} \ncol_add_str ( pinfo -> cinfo , COL_INFO , get_message_name ( prot_discr , message_type ));", "mmm epan / oids . c \nppp epan / oids . c \nstatic oid_info_t * add_oid ( const char * name , oid_kind_t kind , const oid_value_ty \nif (! g_str_equal ( n -> name , name )) { \nD ( 2 ,(\" Renaming Oid from : % s -> % s , this means the same oid is registered more than once \", n -> name , name )); \n} \n- /* XXX - Don ' t free n -> name here . It may be part of an hf_register_info \n- * struct that has been appended to the hfa GArray . */ \n+ /* There used to be a comment here that claimed we couldn ' t free \n+ * n -> name since it may be part of an hf_register_info struct \n+ * that has been appended to the hfa GArray . I think that comment \n+ * was wrong , because we only ever create oid_info_t ' s in this \n+ * function , and we are always careful here to g_strdup the name . \n+ * All that to justify freeing n -> name in the next line , since \n+ * doing so fixes some memory leaks . */ \n+ g_free ( n -> name ); \n} \n \nn -> name = g_strdup ( name );", "mmm plugins / gryphon / packet - gryphon . c \nppp plugins / gryphon / packet - gryphon . c \ndissect_gryphon_message ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * tree , \n/* \n* Indicate what kind of message this is . \n*/ \n- col_set_str ( pinfo -> cinfo , COL_INFO , val_to_str ( frmtyp , frame_type , \"- Invalid -\")); \n+ col_set_str ( pinfo -> cinfo , COL_INFO , val_to_str_const ( frmtyp , frame_type , \"- Invalid -\")); \n} \n \nif ( tree == NULL )", "mmm epan / dissectors / packet - mqtt . c \nppp epan / dissectors / packet - mqtt . c \nstatic void * mqtt_message_decode_copy_cb ( void * dest , const void * orig , size_t le \nconst mqtt_message_decode_t * o = ( const mqtt_message_decode_t *) orig ; \nmqtt_message_decode_t * d = ( mqtt_message_decode_t *) dest ; \n \n+ d -> match_criteria = o -> match_criteria ; \nd -> topic_pattern = g_strdup ( o -> topic_pattern ); \nd -> payload_proto_name = g_strdup ( o -> payload_proto_name ); \n", "mmm epan / dissectors / packet - sflow . c \nppp epan / dissectors / packet - sflow . c \nstatic const value_string sflow_245_ipv4_precedence_types [] = { \n{ SFLOW_245_IPV4_PRECEDENCE_CRITIC_ECP , \" CRITIC / ECP \"}, \n{ SFLOW_245_IPV4_PRECEDENCE_INTERNETWORK_CONTROL , \" Internetwork Control \"}, \n{ SFLOW_245_IPV4_PRECEDENCE_NETWORK_CONTROL , \" Network Control \"}, \n+ { 0 , NULL } \n}; \n \n/* sFlow v5 flow record formats */ \ndissect_sflow_5_extended_mpls_lvp_fec ( tvbuff_t * tvb , proto_tree * tree , gint offs \nguint32 length ; \n \nlength = tvb_get_ntohl ( tvb , offset ); \n- proto_tree_add_text ( tree , tvb , offset , 4 , \" MPLS FEC Address Pre\ufb01x Length : % u bytes \", length ); \n+ proto_tree_add_text ( tree , tvb , offset , 4 , \" MPLS FEC Address Prefix Length : % u bytes \", length ); \noffset += 4 ; \nreturn offset ; \n}", "mmm epan / dissectors / packet - xml . c \nppp epan / dissectors / packet - xml . c \nnext_attribute : \ng_ptr_array_free ( new -> element_names , TRUE ); \n \ng_hash_table_insert ( root_element -> elements , new -> name , new ); \n- \n- g_free ( curr_name ); \n} \n} \n", "mmm ui / qt / wireless_frame . cpp \nppp ui / qt / wireless_frame . cpp \nWirelessFrame :: WirelessFrame ( QWidget * parent ) : \n \nWirelessFrame ::~ WirelessFrame () \n{ \n+ ws80211_free_interfaces ( interfaces_ ); \ndelete ui ; \n} \n", "mmm epan / oids . c \nppp epan / oids . c \nguint oid_string2subid ( wmem_allocator_t * scope , const char * str , guint32 ** subid \nsubid += * r - ' 0 '; \n \nif ( subids >= subids_overflow || subid > 0xffffffff ) { \n+ wmem_free ( scope , * subids_p ); \n* subids_p = NULL ; \nreturn 0 ; \n}", "mmm epan / dissectors / packet - radius . c \nppp epan / dissectors / packet - radius . c \ndissect_attribute_value_pairs ( proto_tree * tree , packet_info * pinfo , tvbuff_t * tv \n \navp_vsa_len -= avp_vsa_header_len ; \n \n+ memset (& vendor_type , 0 , sizeof ( vendor_type )); \nif ( avp_is_extended ) { \nvendor_type . u8_code [ 0 ] = avp_type . u8_code [ 0 ]; \nvendor_type . u8_code [ 1 ] = avp_vsa_type ;", "mmm epan / dissectors / packet - sip . c \nppp epan / dissectors / packet - sip . c \ndissect_sip_common ( tvbuff_t * tvb , int offset , packet_info * pinfo , proto_tree * tr \n} \n} \n \n- if ( sub_value_offset == linelen ) \n+ if ( sub_value_offset == value_len ) \n{ \n/* Didn ' t find method name */ \nTHROW ( ReportedBoundsError ); \ndissect_sip_common ( tvbuff_t * tvb , int offset , packet_info * pinfo , proto_tree * tr \n} \n \n/* Extract method name from value */ \n- strlen_to_copy = ( int ) linelen - sub_value_offset ; \n+ strlen_to_copy = ( int ) value_len - sub_value_offset ; \nif ( strlen_to_copy > MAX_CSEQ_METHOD_SIZE ) { \n/* Note the error in the protocol tree */ \nif ( hdr_tree ) {", "mmm ui / win32 / console_win32 . c \nppp ui / win32 / console_win32 . c \n/* console_win32 . c \n* Console support for MSWindows \n* \n- * $ Id : console_win32 . c 45689 2012 - 10 - 21 15 : 04 : 50Z alagoutte $ \n+ * $ Id $ \n* \n* Wireshark - Network traffic analyzer \n* By Gerald Combs < gerald @ wireshark . org > \n* \n*/ \n \n+# ifdef _WIN32 \n+ \n# include < string . h > \n# include < stdio . h > \n# include < stdlib . h > \n# include \" console_win32 . h \" \n# include \"../../ console_io . h \" \n \n-# ifdef _WIN32 /* Needed for console I / O */ \n# if _MSC_VER < 1500 \n/* AttachConsole () needs this # define ! */ \n# define _WIN32_WINNT 0x0501 \n# include < conio . h > \n# include < windows . h > \n# include < tchar . h > \n-# endif \n \n-# ifdef _WIN32 \nstatic gboolean has_console ; /* TRUE if app has console */ \nstatic gboolean console_wait ; /* \" Press any key ...\" */ \nstatic gboolean stdin_capture = FALSE ; /* Don ' t grab stdin & stdout if TRUE */ \n-# endif \n \n-# ifdef _WIN32 \n/* The code to create and desstroy console windows should not be necessary , \nat least as I read the GLib source code , as it looks as if GLib is , on \nWin32 , * supposed * to create a console window into which to display its \nset_console_wait ( gboolean set_console_wait ) \n{ \nconsole_wait = set_console_wait ; \n} \n+ \ngboolean \nget_console_wait ( void ) \n{ \nget_stdin_capture ( void ) \n{ \nreturn stdin_capture ; \n} \n+ \n# endif /* _WIN32 */ \n \n/*", "mmm epan / dissectors / packet - smb . c \nppp epan / dissectors / packet - smb . c \ndissect_smb_command ( tvbuff_t * tvb , packet_info * pinfo , int offset , proto_tree * s \nsmb_dissector [ cmd ]. request : smb_dissector [ cmd ]. response ; \n \noffset = (* dissector )( tvb , pinfo , cmd_tree , offset , smb_tree ); \n+ \n+ if (! tvb_offset_exists ( tvb , offset - 1 )) { \n+ THROW ( ReportedBoundsError ); \n+ } \nproto_item_set_end ( cmd_item , tvb , offset ); \n} \nreturn offset ;", "mmm epan / dissectors / packet - ieee80211 . c \nppp epan / dissectors / packet - ieee80211 . c \ndissect_extended_capabilities_ie ( packet_info * pinfo , proto_tree * tree , \nexpert_add_info_format ( pinfo , ti_len , PI_MALFORMED , PI_ERROR , \" Tag length % u too short , must be greater than 0 \", tag_len ); \nreturn offset ; \n} \n- proto_item_append_text ( ti , \" (% d octets )\", tag_len ); \n+ proto_item_append_text ( ti , \" (% u octet % s )\", tag_len , plurality ( tag_len , \"\", \" s \")); \n \n/* Extended Capability octet 1 */ \nti_ex_cap = proto_tree_add_item ( tree , hf_ieee80211_tag_extended_capabilities , tvb , offset , 1 , ENC_NA ); \nadd_tagged_field ( packet_info * pinfo , proto_tree * tree , tvbuff_t * tvb , int offset \n\" (% s ) code not implemented , Contact \" \n\" Wireshark developers if you want this supported \", val_to_str_ext ( tag_no , \n& tag_num_vals_ext , \"(% d )\")); \n- proto_item_append_text ( ti , \": Tag % u Len % u \", tag_no , tag_len ); \n+ proto_item_append_text ( ti , \": Undecoded \"); \nbreak ; \n} \nif ( offset < tag_end ) {", "mmm epan / wslua / wslua_field . c \nppp epan / wslua / wslua_field . c \nstatic int FieldInfo_get_range ( lua_State * L ) { \nr -> tvb = ep_new ( struct _wslua_tvb ); \n \nr -> tvb -> ws_tvb = fi -> ds_tvb ; \n+ r -> tvb -> expired = FALSE ; \n+ r -> tvb -> need_free = FALSE ; \nr -> offset = fi -> start ; \nr -> len = fi -> length ; \n", "mmm epan / dissectors / packet - umts_mac . c \nppp epan / dissectors / packet - umts_mac . c \nstatic void dissect_mac_fdd_dch ( tvbuff_t * tvb , packet_info * pinfo , proto_tree * t \n \nmacinf = p_get_proto_data ( pinfo -> fd , proto_umts_mac ); \nfpinf = p_get_proto_data ( pinfo -> fd , proto_fp ); \n- pos = fpinf -> cur_tb ; \nif (! macinf || ! fpinf ) { \nproto_tree_add_text ( dch_tree , tvb , 0 , - 1 , \n\" Cannot dissect MAC frame because per - frame info is missing \"); \nreturn ; \n} \n+ pos = fpinf -> cur_tb ; \nif ( macinf -> ctmux [ pos ]) { \nproto_tree_add_bits_item ( dch_tree , hf_mac_ct , tvb , 0 , 4 , FALSE ); \nbitoffs = 4 ;", "mmm ctaocrypt / src / aes . c \nppp ctaocrypt / src / aes . c \nvoid AesCtrEncrypt ( Aes * aes , byte * out , const byte * in , word32 sz ) \nword32 blocks = sz / AES_BLOCK_SIZE ; \n \nwhile ( blocks --) { \n- AesEncrypt ( aes , aes -> reg , out ); \n+ AesEncrypt ( aes , ( byte *) aes -> reg , out ); \nIncrementAesCounter (( byte *) aes -> reg ); \nxorbuf ( out , in , AES_BLOCK_SIZE ); \n", "mmm src / tls . c \nppp src / tls . c \nstatic int TLSX_KeyShare_Parse ( WOLFSSL * ssl , byte * input , word16 length , \nif ( TLSX_KeyShare_Find ( ssl , group )) \nreturn BAD_KEY_SHARE_DATA ; \n \n+ /* Clear out unusable key shares . */ \n+ ret = TLSX_KeyShare_Empty ( ssl ); \n+ if ( ret != 0 ) \n+ return ret ; \n+ \n/* Try to use the server ' s group . */ \nret = TLSX_KeyShare_Use ( ssl , group , 0 , NULL , NULL ); \n}", "mmm wolfcrypt / src / logging . c \nppp wolfcrypt / src / logging . c \nint wc_AddErrorNode ( int error , int line , char * buf , char * file ) \nif ( wc_errors != NULL ) { \n/* check for unexpected case before over writing wc_errors */ \nWOLFSSL_MSG (\" ERROR in adding new node to logging queue !!\\ n \"); \n+ /* In the event both wc_last_node and wc_errors are NULL , err \n+ * goes unassigned to external wc_errors , wc_last_node . Free \n+ * err in this instance since wc_ClearErrorNodes will not \n+ */ \n+ XFREE ( err , wc_error_heap , DYNAMIC_TYPE_LOG ); \n} \nelse { \nwc_errors = err ;", "mmm src / ssl . c \nppp src / ssl . c \nvoid wolfSSL_X509_STORE_CTX_set_time ( WOLFSSL_X509_STORE_CTX * ctx , \n{ \n( void ) flags ; \n \n+ if ( ctx == NULL ) \n+ return ; \n+ \nctx -> param -> check_time = t ; \nctx -> param -> flags |= WOLFSSL_USE_CHECK_TIME ; \n}", "mmm src / internal . c \nppp src / internal . c \nint DoSessionTicket ( WOLFSSL * ssl , \n# ifdef WOLFSSL_DTLS \nHmac cookieHmac ; \nbyte peerCookie [ MAX_COOKIE_LEN ]; \n- byte peerCookieSz ; \n+ byte peerCookieSz = 0 ; \nbyte cookieType ; \nbyte cookieSz ; \n# endif /* WOLFSSL_DTLS */", "mmm src / internal . c \nppp src / internal . c \nstatic int BuildMessage ( CYASSL * ssl , byte * output , int outSz , \nivSz = blockSz ; \nsz += ivSz ; \n \n+ if ( ivSz > ( word32 ) sizeof ( iv )) \n+ return BUFFER_E ; \n+ \nret = RNG_GenerateBlock ( ssl -> rng , iv , ivSz ); \nif ( ret != 0 ) \nreturn ret ;", "mmm src / ssl . c \nppp src / ssl . c \nint AddCA ( WOLFSSL_CERT_MANAGER * cm , DerBuffer ** pDer , int type , int verify ) \nret = MEMORY_ERROR ; \nelse { \nsigner -> keyOID = cert -> keyOID ; \n- signer -> publicKey = cert -> publicKey ; \n- signer -> pubKeySize = cert -> pubKeySize ; \n- signer -> nameLen = cert -> subjectCNLen ; \n- signer -> name = cert -> subjectCN ; \n+ if ( cert -> pubKeyStored ) { \n+ signer -> publicKey = cert -> publicKey ; \n+ signer -> pubKeySize = cert -> pubKeySize ; \n+ } \n+ if ( cert -> subjectCNStored ) { \n+ signer -> nameLen = cert -> subjectCNLen ; \n+ signer -> name = cert -> subjectCN ; \n+ } \nsigner -> pathLength = cert -> pathLength ; \nsigner -> pathLengthSet = cert -> pathLengthSet ; \n# ifndef IGNORE_NAME_CONSTRAINTS", "mmm src / internal . c \nppp src / internal . c \nint SendCertificateRequest ( WOLFSSL * ssl ) \n/* write to output */ \noutput [ i ++] = ( byte ) typeTotal ; /* # of types */ \n# ifdef HAVE_ECC \n- if ( ssl -> options . cipherSuite0 == ECC_BYTE && \n+ if (( ssl -> options . cipherSuite0 == ECC_BYTE || \n+ ssl -> options . cipherSuite0 == CHACHA_BYTE ) && \nssl -> specs . sig_algo == ecc_dsa_sa_algo ) { \noutput [ i ++] = ecdsa_sign ; \n} else", "mmm wolfcrypt / src / integer . c \nppp wolfcrypt / src / integer . c \nint mp_init ( mp_int * a ) \n{ \nint i ; \n \n+ /* Safeguard against passing in a null pointer */ \n+ if ( a == NULL ) \n+ return MP_VAL ; \n+ \n/* allocate memory required and clear it */ \na -> dp = OPT_CAST ( mp_digit ) XMALLOC ( sizeof ( mp_digit ) * MP_PREC , 0 , \nDYNAMIC_TYPE_BIGINT ); \nmp_copy ( mp_int * a , mp_int * b ) \n{ \nint res , n ; \n \n+ /* Safeguard against passing in a null pointer */ \n+ if ( a == NULL || b == NULL ) \n+ return MP_VAL ; \n+ \n/* if dst == src do nothing */ \nif ( a == b ) { \nreturn MP_OKAY ;", "mmm cyassl / ctaocrypt / settings . h \nppp cyassl / ctaocrypt / settings . h \n# include \" mutex . h \" \n# endif \n \n- # define XMALLOC ( s , h , type ) ( void *) _mem_alloc_system (( s )) \n- # define XFREE ( p , h , type ) _mem_free ( p ) \n+ # define XMALLOC ( s , h , t ) ( void *) _mem_alloc_system (( s )) \n+ # define XFREE ( p , h , t ) { void * xp = ( p ); if (( xp )) _mem_free (( xp ));} \n/* Note : MQX has no realloc , using fastmath above */ \n# endif \n", "mmm src / internal . c \nppp src / internal . c \nint SetCipherList ( WOLFSSL_CTX * ctx , Suites * suites , const char * list ) \n} \n# endif /* WOLFSSL_DTLS */ \n \n+ if ( idx + 1 >= WOLFSSL_MAX_SUITE_SZ ) { \n+ WOLFSSL_MSG (\" WOLFSSL_MAX_SUITE_SZ set too low \"); \n+ return 0 ; /* suites buffer not large enough , error out */ \n+ } \n+ \nsuites -> suites [ idx ++] = ( XSTRSTR ( name , \" TLS13 \")) ? TLS13_BYTE \n: ( XSTRSTR ( name , \" CHACHA \")) ? CHACHA_BYTE \n: ( XSTRSTR ( name , \" QSH \")) ? QSH_BYTE", "mmm src / ssl . c \nppp src / ssl . c \nlong wolfSSL_set_options ( WOLFSSL * ssl , long op ) \nlong wolfSSL_get_options ( const WOLFSSL * ssl ) \n{ \nWOLFSSL_ENTER (\" wolfSSL_get_options \"); \n- if ( ssl == NULL ) return WOLFSSL_FAILURE ; \n+ if ( ssl == NULL ) \n+ return WOLFSSL_FAILURE ; \nreturn ssl -> options . mask ; \n} \n \nlong wolfSSL_clear_options ( WOLFSSL * ssl , long opt ) \n{ \nWOLFSSL_ENTER (\" SSL_clear_options \"); \n+ if ( ssl == NULL ) \n+ return WOLFSSL_FAILURE ; \nssl -> options . mask &= ~ opt ; \nreturn ssl -> options . mask ; \n}", "mmm src / tls . c \nppp src / tls . c \nstatic int TLSX_SNI_Parse ( WOLFSSL * ssl , byte * input , word16 length , \nreturn BUFFER_ERROR ; \n \nfor ( size = 0 ; offset < length ; offset += size ) { \n- SNI * sni ; \n+ SNI * sni = NULL ; \nbyte type = input [ offset ++]; \n \nif ( offset + OPAQUE16_LEN > length )", "mmm src / internal . c \nppp src / internal . c \nstatic int DoCertificate ( CYASSL * ssl , byte * input , word32 * inOutIdx , \nret = KEYUSE_ENCIPHER_E ; \n} \nif (( ssl -> specs . sig_algo == rsa_sa_algo || \n- ssl -> specs . sig_algo == ecc_dsa_sa_algo ) && \n+ ( ssl -> specs . sig_algo == ecc_dsa_sa_algo && \n+ ! ssl -> specs . static_ecdh )) && \n( dCert . extKeyUsage & KEYUSE_DIGITAL_SIG ) == 0 ) { \nCYASSL_MSG (\" KeyUse Digital Sig not set \"); \nret = KEYUSE_SIGNATURE_E ;", "mmm src / internal . c \nppp src / internal . c \nstatic int DoHandShakeMsgType ( CYASSL * ssl , byte * input , word32 * inOutIdx , \nreturn OUT_OF_ORDER_E ; \n} \n \n+ if ( ssl -> options . side == CLIENT_END && ssl -> options . dtls == 0 && \n+ ssl -> options . serverState == NULL_STATE && type != server_hello ) { \n+ CYASSL_MSG (\" First server message not server hello \"); \n+ return OUT_OF_ORDER_E ; \n+ } \n+ \n+ if ( ssl -> options . side == SERVER_END && \n+ ssl -> options . clientState == NULL_STATE && type != client_hello ) { \n+ CYASSL_MSG (\" First client message not client hello \"); \n+ return OUT_OF_ORDER_E ; \n+ } \n+ \n+ \nswitch ( type ) { \n \ncase hello_request :", "mmm src / internal . c \nppp src / internal . c \nint DoSessionTicket ( WOLFSSL * ssl , const byte * input , word32 * inOutIdx , \n{ \nint i ; \n \n- if ( suites == NULL ) { \n- WOLFSSL_MSG (\" Suites pointer error \"); \n+ if ( suites == NULL || suites -> suiteSz == 0 ) { \n+ WOLFSSL_MSG (\" Suites pointer error or suiteSz 0 \"); \nreturn SUITES_ERROR ; \n} \n \n- for ( i = 0 ; i < suites -> suiteSz ; i += 2 ) { \n+ for ( i = 0 ; i < suites -> suiteSz - 1 ; i += SUITE_LEN ) { \nif ( suites -> suites [ i ] == first && \nsuites -> suites [ i + 1 ] == second ) \nreturn i ;", "mmm wolfcrypt / benchmark / benchmark . c \nppp wolfcrypt / benchmark / benchmark . c \nvoid bench_chacha ( void ) \nvoid bench_chacha20_poly1305_aead ( void ) \n{ \ndouble start ; \n- int ret , i , count ; \n+ int ret = 0 , i , count ; \n \nbyte authTag [ CHACHA20_POLY1305_AEAD_AUTHTAG_SIZE ]; \nXMEMSET ( authTag , 0 , sizeof ( authTag ));", "mmm src / internal . c \nppp src / internal . c \nint SetCipherList ( Suites * s , const char * list ) \nbyte b ; \nbyte compression ; \nProtocolVersion pv ; \n- word16 extSz ; \nword32 i = * inOutIdx ; \nword32 begin = i ; \n", "mmm ctaocrypt / src / asn . c \nppp ctaocrypt / src / asn . c \nstatic int SetMyVersion ( word32 version , byte * output , int header ) \n} \n \n \n+/* convert der buffer to pem into output , can ' t do inplace , der and output \n+ need to be different */ \nint DerToPem ( const byte * der , word32 derSz , byte * output , word32 outSz , \nint type ) \n{ \nint DerToPem ( const byte * der , word32 derSz , byte * output , word32 outSz , \nint err ; \nint outLen ; /* return length or error */ \n \n+ if ( der == output ) /* no in place conversion */ \n+ return BAD_FUNC_ARG ; \n+ \nif ( type == CERT_TYPE ) { \nXSTRNCPY ( header , \"----- BEGIN CERTIFICATE -----\\ n \", sizeof ( header )); \nXSTRNCPY ( footer , \"----- END CERTIFICATE -----\\ n \", sizeof ( footer ));", "mmm src / ssl . c \nppp src / ssl . c \nint wolfSSL_BN_hex2bn ( WOLFSSL_BIGNUM ** bn , const char * str ) \n# else \nbyte decoded [ 1024 ]; \n# endif \n+ int weOwn = 0 ; \n \nWOLFSSL_MSG (\" wolfSSL_BN_hex2bn \"); \n \nint wolfSSL_BN_hex2bn ( WOLFSSL_BIGNUM ** bn , const char * str ) \nelse if ( bn == NULL ) \nret = decSz ; \nelse { \n- if (* bn == NULL ) \n+ if (* bn == NULL ) { \n* bn = wolfSSL_BN_new (); \n+ if (* bn != NULL ) { \n+ weOwn = 1 ; \n+ } \n+ } \n \nif (* bn == NULL ) \nWOLFSSL_MSG (\" BN new failed \"); \nelse if ( wolfSSL_BN_bin2bn ( decoded , decSz , * bn ) == NULL ) { \nWOLFSSL_MSG (\" Bad bin2bn error \"); \n- wolfSSL_BN_free (* bn ); /* Free new BN */ \n+ if ( weOwn == 1 ) { \n+ wolfSSL_BN_free (* bn ); /* Free new BN */ \n+ } \n} \nelse \nret = WOLFSSL_SUCCESS ;", "mmm xbmc / cores / paplayer / VideoPlayerCodec . cpp \nppp xbmc / cores / paplayer / VideoPlayerCodec . cpp \nbool VideoPlayerCodec :: Init ( const CFileItem & file , unsigned int filecache ) \n// we have to decode initial data in order to get channels / samplerate \n// for sanity - we read no more than 10 packets \nint nErrors = 0 ; \n- for ( int nPacket = 0 ; nPacket < 10 && ( m_channels == 0 || m_format . m_sampleRate == 0 ); nPacket ++) \n+ for ( int nPacket = 0 ; \n+ nPacket < 10 && ( m_channels == 0 || m_format . m_sampleRate == 0 || m_format . m_frameSize == 0 ); \n+ nPacket ++) \n{ \nuint8_t dummy [ 256 ]; \nsize_t nSize = 256 ; \nbool VideoPlayerCodec :: Init ( const CFileItem & file , unsigned int filecache ) \nif ( NeedConvert ( m_srcFormat . m_dataFormat )) \n{ \nm_needConvert = true ; \n+ // if we don ' t know the framesize yet , we will fail when converting \n+ if ( m_srcFormat . m_frameSize == 0 ) \n+ return false ; \n+ \nm_pResampler = ActiveAE :: CAEResampleFactory :: Create (); \n \nSampleConfig dstConfig , srcConfig ;", "mmm thunar / thunar - transfer - job . c \nppp thunar / thunar - transfer - job . c \nthunar_transfer_job_copy_node ( ThunarTransferJob * job , \n} \n \n/* update progress information */ \n- exo_job_info_message ( EXO_JOB ( job ), g_file_info_get_display_name ( info )); \n+ exo_job_info_message ( EXO_JOB ( job ), \"% s \", g_file_info_get_display_name ( info )); \n \nretry_copy : \n/* copy the item specified by this node ( not recursively ) */", "mmm src / opusfile . c \nppp src / opusfile . c \nstatic int op_get_data ( OggOpusFile * _of , int _nbytes ){ \nint nbytes ; \nOP_ASSERT ( _nbytes > 0 ); \nbuffer =( unsigned char *) ogg_sync_buffer (& _of -> oy , _nbytes ); \n+ if ( OP_UNLIKELY ( buffer == NULL )) return OP_EFAULT ; \nnbytes =( int )(* _of -> callbacks . read )( _of -> stream , buffer , _nbytes ); \nOP_ASSERT ( nbytes <= _nbytes ); \nif ( OP_LIKELY ( nbytes > 0 )) ogg_sync_wrote (& _of -> oy , nbytes ); \nstatic int op_open1 ( OggOpusFile * _of , \nif ( _initial_bytes > 0 ){ \nchar * buffer ; \nbuffer = ogg_sync_buffer (& _of -> oy ,( long ) _initial_bytes ); \n+ if ( OP_UNLIKELY ( buffer == NULL )) return OP_EFAULT ; \nmemcpy ( buffer , _initial_data , _initial_bytes * sizeof (* buffer )); \nogg_sync_wrote (& _of -> oy ,( long ) _initial_bytes ); \n}", "mmm src / xkbcomp / expr . c \nppp src / xkbcomp / expr . c \nExprResolveBoolean ( struct xkb_context * ctx , const ExprDef * expr , \n \ncase EXPR_INVERT : \ncase EXPR_NOT : \n- ok = ExprResolveBoolean ( ctx , expr , set_rtrn ); \n+ ok = ExprResolveBoolean ( ctx , expr -> unary . child , set_rtrn ); \nif ( ok ) \n* set_rtrn = !* set_rtrn ; \nreturn ok ;", "mmm src / xkbcomp / expr . c \nppp src / xkbcomp / expr . c \nExprResolveLhs ( struct xkb_context * ctx , const ExprDef * expr , \n* elem_rtrn = NULL ; \n* field_rtrn = xkb_atom_text ( ctx , expr -> ident . ident ); \n* index_rtrn = NULL ; \n- return true ; \n+ return (* field_rtrn != NULL ); \ncase EXPR_FIELD_REF : \n* elem_rtrn = xkb_atom_text ( ctx , expr -> field_ref . element ); \n* field_rtrn = xkb_atom_text ( ctx , expr -> field_ref . field );", "mmm src / xkbcomp / expr . c \nppp src / xkbcomp / expr . c \nLookupModMask ( struct xkb_context * ctx , const void * priv , xkb_atom_t field , \nreturn false ; \n \nstr = xkb_atom_text ( ctx , field ); \n+ if (! str ) \n+ return false ; \n \nif ( istreq ( str , \" all \")) { \n* val_rtrn = MOD_REAL_MASK_ALL ;", "mmm src / utils . c \nppp src / utils . c \nbool \nmap_file ( FILE * file , char ** string_out , size_t * size_out ) \n{ \nstruct stat stat_buf ; \n- const int fd = fileno ( file ); \n+ int fd ; \nchar * string ; \n \n/* Make sure to keep the errno on failure ! */ \n+ fd = fileno ( file ); \n+ if ( fd < 0 ) \n+ return false ; \n \nif ( fstat ( fd , & stat_buf ) != 0 ) \nreturn false ;", "mmm src / compose / parser . c \nppp src / compose / parser . c \nskip_more_whitespace_and_comments : \n \n/* LHS Keysym . */ \nif ( chr ( s , '<')) { \n- while ( peek ( s ) != '>' && ! eol ( s )) \n+ while ( peek ( s ) != '>' && ! eol ( s ) && ! eof ( s )) \nbuf_append ( s , next ( s )); \nif (! chr ( s , '>')) { \nscanner_err ( s , \" unterminated keysym literal \");", "mmm src / xkbcomp / compat . c \nppp src / xkbcomp / compat . c \nResolveStateAndPredicate ( ExprDef * expr , enum xkb_match_operation * pred_rtrn , \n* pred_rtrn = MATCH_EXACTLY ; \nif ( expr -> expr . op == EXPR_ACTION_DECL ) { \nconst char * pred_txt = xkb_atom_text ( info -> ctx , expr -> action . name ); \n- if (! LookupString ( symInterpretMatchMaskNames , pred_txt , pred_rtrn )) { \n+ if (! LookupString ( symInterpretMatchMaskNames , pred_txt , pred_rtrn ) || \n+ ! expr -> action . args ) { \nlog_err ( info -> ctx , \n\" Illegal modifier predicate \\\"% s \\\"; Ignored \\ n \", pred_txt ); \nreturn false ;", "mmm src / xkbcomp / keycodes . c \nppp src / xkbcomp / keycodes . c \nCopyKeyAliasesToKeymap ( struct xkb_keymap * keymap , KeyNamesInfo * info ) \nkey_aliases = calloc ( num_key_aliases , sizeof (* key_aliases )); \nif (! key_aliases ) \nreturn false ; \n- } \n \n- i = 0 ; \n- darray_foreach ( alias , info -> aliases ) { \n- if ( alias -> real != XKB_ATOM_NONE ) { \n- key_aliases [ i ]. alias = alias -> alias ; \n- key_aliases [ i ]. real = alias -> real ; \n- i ++; \n+ i = 0 ; \n+ darray_foreach ( alias , info -> aliases ) { \n+ if ( alias -> real != XKB_ATOM_NONE ) { \n+ key_aliases [ i ]. alias = alias -> alias ; \n+ key_aliases [ i ]. real = alias -> real ; \n+ i ++; \n+ } \n} \n} \n", "mmm src / xkbcomp / expr . c \nppp src / xkbcomp / expr . c \nExprResolveLhs ( struct xkb_context * ctx , const ExprDef * expr , \n* elem_rtrn = xkb_atom_text ( ctx , expr -> field_ref . element ); \n* field_rtrn = xkb_atom_text ( ctx , expr -> field_ref . field ); \n* index_rtrn = NULL ; \n- return true ; \n+ return (* elem_rtrn != NULL && * field_rtrn != NULL ); \ncase EXPR_ARRAY_REF : \n* elem_rtrn = xkb_atom_text ( ctx , expr -> array_ref . element ); \n* field_rtrn = xkb_atom_text ( ctx , expr -> array_ref . field ); \n* index_rtrn = expr -> array_ref . entry ; \n+ if ( expr -> array_ref . element != XKB_ATOM_NONE && * elem_rtrn == NULL ) \n+ return false ; \n+ if (* field_rtrn == NULL ) \n+ return false ; \nreturn true ; \ndefault : \nbreak ;", "mmm src / xkbcomp / ast - build . c \nppp src / xkbcomp / ast - build . c \nExprAppendMultiKeysymList ( ExprDef * expr , ExprDef * append ) \ndarray_append ( expr -> keysym_list . symsNumEntries , numEntries ); \ndarray_concat ( expr -> keysym_list . syms , append -> keysym_list . syms ); \n \n- FreeStmt (( ParseCommon *) & append ); \n+ FreeStmt (( ParseCommon *) append ); \n \nreturn expr ; \n}", "mmm src / XrdCl / XrdClPlugInManager . cc \nppp src / XrdCl / XrdClPlugInManager . cc \nnamespace XrdCl \n \nXrdSysPwd pwdHandler ; \npasswd * pwd = pwdHandler . Get ( getuid () ); \n+ if ( ! pwd ) return ; \nstd :: string userPlugIns = pwd -> pw_dir ; \nuserPlugIns += \"/. xrootd / client . plugins . d \"; \nProcessConfigDir ( userPlugIns );", "mmm src / XrdOdc / XrdOdcFinder . cc \nppp src / XrdOdc / XrdOdcFinder . cc \nint XrdOdcFinderRMT :: Locate ( XrdOucErrInfo & Resp , const char * path , int flags , \n{ xmsg [ 1 ]. iov_base = ( char *)\" select \" ; xmsg [ 1 ]. iov_len = 7 ;} \nxmsg [ 2 ]. iov_base = ( char *) ptype ; xmsg [ 2 ]. iov_len = 2 ; \nif ( Avoid ) \n- { xmsg [ 3 ]. iov_base = ( char *)\" -\"; xmsg [ 3 ]. iov_len = 2 ; \n+ { xmsg [ 3 ]. iov_base = ( char *)\"-\"; xmsg [ 3 ]. iov_len = 1 ; \nxmsg [ 4 ]. iov_base = Avoid ; xmsg [ 4 ]. iov_len = strlen ( Avoid ); \nxmsg [ 5 ]. iov_base = ( char *)\" \"; xmsg [ 5 ]. iov_len = 1 ; \nioveol = 6 ;", "mmm src / XrdCl / XrdClXRootDMsgHandler . cc \nppp src / XrdCl / XrdClXRootDMsgHandler . cc \nnamespace XrdCl \nXRDCL_SMART_PTR_T < Message > msgPtr ( pResponse ); \npResponse = 0 ; \n \n- if ( rsp -> hdr . dlen < 4 ) \n+ if ( rsp -> hdr . dlen <= 4 ) \n{ \nlog -> Error ( XRootDMsg , \"[% s ] Got invalid redirect response .\", \npUrl . GetHostId (). c_str () );", "mmm src / XrdClient / XrdClientUrlSet . cc \nppp src / XrdClient / XrdClientUrlSet . cc \nvoid XrdClientUrlSet :: ConvertDNSAlias ( UrlArray & urls , XrdClientString proto , \n// Notify \nInfo ( XrdClientDebug :: kHIDEBUG , \" ConvertDNSAlias \", \n\" found host \" << newurl -> Host << \" with addr \" << newurl -> HostAddr ); \n+ \n+ // Get a copy , if we need to store another \n+ if ( i < ( naddr - 1 )) \n+ newurl = new XrdClientUrlInfo (* newurl ); \n+ \n} \n}", "mmm src / XrdSut / XrdSutAux . cc \nppp src / XrdSut / XrdSutAux . cc \nint XrdSutGetPass ( const char * prompt , XrdOucString & passwd ) \n \nchar * pw = getpass ( prompt ); \nif ( pw ) { \n- if ( pw [ strlen ( pw )- 1 ] == '\\ n ') \n- pw [ strlen ( pw ) - 1 ] = 0 ; // get rid of \\ n \n+ // Get rid of special chars , if any \n+ int k = 0 , i = 0 , len = strlen ( pw ); \n+ for (; i < len ; i ++) \n+ if ( pw [ i ] > 0x20 ) pw [ k ++] = pw [ i ]; \n+ pw [ k ] = 0 ; \npasswd = pw ; \n- XrdSutMemSet (( volatile void *) pw , 0 , strlen ( pw )); \n+ XrdSutMemSet (( volatile void *) pw , 0 , len ); \n} else { \nDEBUG (\" error from getpass \"); \nreturn - 1 ;", "mmm src / XrdApps / XrdCpConfig . cc \nppp src / XrdApps / XrdCpConfig . cc \ndo { while ( optind < Argc && Legacy ( optind )) {} \nswitch ( opC ) \n{ case OpCksum : defCks ( optarg ); \nbreak ; \n+ case OpCoerce : OpSpec |= DoCoerce ; \n+ break ; \ncase OpDebug : OpSpec |= DoDebug ; \nif (! a2i ( optarg , & Dlvl , 0 , 3 )) Usage ( 22 ); \nbreak ;", "mmm src / XrdOuc / XrdOuca2x . cc \nppp src / XrdOuc / XrdOuca2x . cc \nint XrdOuca2x :: a2sz ( XrdSysError & Eroute , const char * emsg , const char * item , \nelse if (* fP == ' t ' || * fP == ' T ') qmult = 1024LL * 1024LL * 1024LL * 1024LL ; \nelse { qmult = 1 ; fP ++;} \nerrno = 0 ; \n- * val = strtoll ( item , & eP , 10 ) * qmult ; \n+ double dval = strtod ( item , & eP ) * qmult ; \nif ( errno || eP != fP ) \n{ Eroute . Emsg (\" a2x \", emsg , item , \" is not a number \"); \nreturn - 1 ; \n} \n+ * val = ( long long ) dval ; \nif (* val < minv ) \nreturn Emsg ( Eroute , emsg , item , \" may not be less than % lld \", minv ); \nif ( maxv >= 0 && * val > maxv )", "mmm src / XrdSsi / XrdSsiUtils . cc \nppp src / XrdSsi / XrdSsiUtils . cc \nvoid DoIt () { myMutex . Lock (); \nvirtual void Finished ( XrdSsiRequest & rqstR , \nconst XrdSsiRespInfo & rInfo , \nbool cancel = false ) \n- { myMutex . Lock (); \n+ { UnBindRequest (); \n+ myMutex . Lock (); \nif (! isActive ) delete this ; \nelse { isActive = false ; \nmyMutex . UnLock ();", "mmm src / configure . cpp \nppp src / configure . cpp \nbool Handler :: xsecretkey ( XrdOucStream & config_obj , XrdSysError * log , std :: string \nreturn false ; \n} \n \n- FILE * fp = fopen ( val , \" r +\"); \n+ FILE * fp = fopen ( val , \" rb \"); \n \nif ( fp == NULL ) { \nlog -> Emsg (\" Config \", \" Cannot open shared secret key file '\", val , \"'\");", "mmm XrdClFileStateHandler . cc \nppp XrdClFileStateHandler . cc \nnamespace XrdCl \npFileUrl ( 0 ), \npDataServer ( 0 ), \npLoadBalancer ( 0 ), \n+ pStateRedirect ( 0 ), \npFileHandle ( 0 ), \npOpenMode ( 0 ), \npOpenFlags ( 0 ),", "mmm src / XrdClient / XrdClientConn . cc \nppp src / XrdClient / XrdClientConn . cc \nXReqErrorType XrdClientConn :: GoBackToRedirector () { \n// redirections . Used typically for stat and similar functions \nDisconnect ( false ); \nif ( fGlobalRedirCnt ) fGlobalRedirCnt --; \n- return GoToAnotherServer (* fLBSUrl ); \n+ return ( fLBSUrl ? GoToAnotherServer (* fLBSUrl ) : kOK ); \n} \n \n// _____________________________________________________________________________", "mmm src / XrdOlb / XrdOlbConfig . cc \nppp src / XrdOlb / XrdOlbConfig . cc \nint XrdOlbConfig :: Configure2 () \n// \nSay . Say ( 0 , myInstance , \" phase 2 initialization started .\"); \n \n+// Readjust the thread parameters as we know how many we will actually need \n+// \n+ Sched -> setParms ( 16 , 256 , 8 , 0 ); \n+ \n// Determine who we are . If we are a manager or supervisor start the file \n// location cache scrubber . \n//", "mmm src / XrdFileCache / XrdFileCacheFactory . cc \nppp src / XrdFileCache / XrdFileCacheFactory . cc \nbool Factory :: ConfigParameters ( std :: string part , XrdOucStream & config ) \n} \nelse if ( part == \" prefetch \" ) \n{ \n- printf (\" prefetch enabled !!!!\\ n \"); \n- m_configuration . m_prefetch = true ; \n- config . GetWord (); \n+ int p = :: atoi ( config . GetWord ()); \n+ if ( p != 0 ) { \n+ printf (\" prefetch enabled !!!!\\ n \"); \n+ m_configuration . m_prefetch = true ; \n+ } \n+ else { \n+ m_configuration . m_prefetch = false ; \n+ } \n} \nelse if ( part == \" nram \" ) \n{", "mmm src / XrdCl / XrdClCopyProcess . cc \nppp src / XrdCl / XrdClCopyProcess . cc \nnamespace XrdCl \n \nprops . Get ( \" source \", tmp ); \nURL source = tmp ; \n+ if ( ! source . IsValid () ) \n+ return XRootDStatus ( stError , errInvalidArgs , 0 , \" invalid source \" ); \n+ \nprops . Get ( \" target \", tmp ); \nURL target = tmp ; \n+ if ( ! target . IsValid () ) \n+ return XRootDStatus ( stError , errInvalidArgs , 0 , \" invalid target \" ); \n \nbool tpc = false ; \nbool tpcFallBack = false ;", "mmm src / XrdNet / XrdNet . cc \nppp src / XrdNet / XrdNet . cc \nint XrdNet :: do_Accept_UDP ( XrdNetPeer & myPeer , int opts ) \n \n// Read the message and get the host address \n// \n- do { dlen = recvfrom ( iofd , ( Sokdata_t ) bp -> data , BuffSize , 0 , & addr ,& addrlen ); \n+ do { dlen = recvfrom ( iofd ,( Sokdata_t ) bp -> data , BuffSize - 1 , 0 ,& addr ,& addrlen ); \n} while ( dlen < 0 && errno == EINTR ); \n \nif ( dlen < 0 ) \n{ eDest -> Emsg (\" Receive \", errno , \" perform UDP recvfrom ()\"); \nBuffQ -> Recycle ( bp ); \nreturn 0 ; \n- } \n+ } else bp -> data [ dlen ] = '\\ 0 '; \n \n// Authorize this connection . We don ' t accept messages that set the \n// loopback address since this can be trivially spoofed in UDP packets .", "mmm src / XrdClient / Xrdcp . cc \nppp src / XrdClient / Xrdcp . cc \nint doCp_xrd2xrd ( XrdClient ** xrddest , const char * src , const char * dst ) { \ncout << endl ; \n} \n \n- if (( unsigned ) cpnfo . len != bytesread ) retvalue = 13 ; \n+ if ( cpnfo . len != bytesread ) retvalue = 13 ; \n \n# ifdef HAVE_XRDCRYPTO \nif ( md5 ) MD_5 -> Final (); \nint doCp_xrd2loc ( const char * src , const char * dst ) { \ncout << endl ; \n} \n \n- if (( unsigned ) cpnfo . len != bytesread ) retvalue = 13 ; \n+ if ( cpnfo . len != bytesread ) retvalue = 13 ; \n \n# ifdef HAVE_XRDCRYPTO \nif ( md5 ) MD_5 -> Final ();", "mmm src / XrdXrootd / XrdXrootdMonitor . cc \nppp src / XrdXrootd / XrdXrootdMonitor . cc \nXrdXrootdMonitor ::~ XrdXrootdMonitor () \n \nvoid XrdXrootdMonitor :: appID ( char * id ) \n{ \n+ static const int apInfoSize = sizeof ( XrdXrootdMonTrace )- 4 ; \n \n// Application ID ' s are only meaningful for io event recording \n// \nvoid XrdXrootdMonitor :: appID ( char * id ) \nif ( lastWindow != currWindow ) Mark (); \nelse if ( nextEnt == lastEnt ) Flush (); \nmonBuff -> info [ nextEnt ]. arg0 . id [ 0 ] = XROOTD_MON_APPID ; \n- strncpy (( char *)& monBuff -> info [ nextEnt ]. arg0 . id [ 4 ], id , \n- sizeof ( XrdXrootdMonTrace )- 4 ); \n+ strncpy (( char *)(&( monBuff -> info [ nextEnt ])+ 4 ), id , apInfoSize ); \n} \n \n/******************************************************************************/", "mmm src / XrdHttp / XrdHttpReq . cc \nppp src / XrdHttp / XrdHttpReq . cc \nint XrdHttpReq :: PostProcessHTTPReq ( bool final_ ) { \n \n} else \nfor ( int i = 0 ; i < iovN ; i ++) { \n- prot -> SendData (( char *) iovP [ i ]. iov_base , iovP [ i ]. iov_len ); \n+ if ( prot -> SendData (( char *) iovP [ i ]. iov_base , iovP [ i ]. iov_len )) return 1 ; \nwrittenbytes += iovP [ i ]. iov_len ; \n} \n", "mmm src / XrdClient / XrdCommandLine . cc \nppp src / XrdClient / XrdCommandLine . cc \nint main ( int argc , char ** argv ) { \n \nif (! path . length ()) { \ncout << \" The current path is empty .\" << endl ; \n- retval = 1 ; \n+ path = '/'; \n} \n \n// Now try to issue the request", "mmm src / XrdNet / XrdNet . cc \nppp src / XrdNet / XrdNet . cc \nint XrdNet :: do_Accept_TCP ( XrdNetAddr & hAddr , int opts ) \n \n// Initialize the address of the new connection \n// \n- hAddr . Set (& IP . Addr , newfd ); \n+ const char * eMsg = hAddr . Set (& IP . Addr , newfd ); \n+ if ( eMsg ) \n+ { char buff [ 256 ]; \n+ snprintf ( buff , sizeof ( buff ), \"% d ;\", newfd ); \n+ eDest -> Emsg (\" Accept \", \" Failed to identify FD \", buff , eMsg ); \n+ close ( newfd ); \n+ return 0 ; \n+ } \n \n// Remove TCP_NODELAY option for unix domain sockets to avoid error message \n//", "mmm src / XrdFileCache / XrdFileCachePrefetch . cc \nppp src / XrdFileCache / XrdFileCachePrefetch . cc \nssize_t Prefetch :: ReadInBlocks ( char * buff , off_t off , size_t size ) \n \nint Prefetch :: ReadV ( const XrdOucIOVec * readV , int n ) \n{ \n+ { \n+ XrdSysCondVarHelper monitor ( m_stateCond ); \n+ \n+ // AMT check if this can be done once during initalization \n+ if ( m_failed ) return m_input . ReadV ( readV , n ); \n+ \n+ if ( ! m_started ) \n+ { \n+ m_stateCond . Wait (); \n+ if ( m_failed ) return 0 ; \n+ } \n+ } \n+ \n// check if read sizes are big enough to cache \n \nXrdCl :: XRootDStatus Status ;", "mmm src / XrdClient / XrdClientAdmin_c . cc \nppp src / XrdClient / XrdClientAdmin_c . cc \nextern \" C \" { \nchar tok1 [ 256 ], tok2 [ 256 ]; \nlong v ; \n \n- if ( sscanf ((* env )[ it ]. c_str (), \"% 256s % d \", tok1 , & v ) == 2 ) { \n+ if ( sscanf ((* env )[ it ]. c_str (), \"% 256s % ld \", tok1 , & v ) == 2 ) { \n// It ' s an integer value \nEnvPutInt ( tok1 , v ); \n// cout << \" Env : \" << tok1 << \" Val =\" << EnvGetLong ( tok1 ) << endl ;", "mmm src / XrdNet / XrdNetConnect . cc \nppp src / XrdNet / XrdNetConnect . cc \nint XrdNetConnect :: Connect ( int fd , \nnew_flags = old_flags | O_NDELAY | O_NONBLOCK ; \nfcntl ( fd , F_SETFL , new_flags ); \nif (! connect ( fd , name , namelen )) myRC = 0 ; \n- else if ( EINPROGRESS != errno ) myRC = errno ; \n+ else if ( EINPROGRESS != net_errno ) myRC = net_errno ; \nelse { struct pollfd polltab = { fd , POLLOUT | POLLWRNORM , 0 }; \ndo { myRC = poll (& polltab , 1 , tsec * 1000 );} \nwhile ( myRC < 0 && errno == EINTR );", "mmm src / XrdCeph / XrdCephPosix . cc \nppp src / XrdCeph / XrdCephPosix . cc \nint ceph_posix_open ( XrdOucEnv * env , const char * pathname , int flags , mode_t mode \n// in case of O_TRUNC , we should truncate the file \nif ( flags & O_TRUNC ) { \nint rc = ceph_posix_internal_truncate ( fr , 0 ); \n- if ( rc < 0 ) return rc ; \n+ // fail only if file exists and cannot be truncated \n+ if ( rc < 0 && rc != - ENOENT ) return rc ; \n} \nreturn g_nextCephFd - 1 ; \n}", "mmm src / XrdOfs / XrdOfsConfig . cc \nppp src / XrdOfs / XrdOfsConfig . cc \nint XrdOfs :: xred ( XrdOucStream & Config , XrdOucError & Eroute ) \nif (! ropt ) ropt = XrdOfsREDIRRMT ; \nelse if ( val ) val = Config . GetWord (); \n \n- if ( val && ! strcmp (\" if \", val )) \n- if (( rc = XrdOucUtils :: doIf (& Eroute , Config , \" redirect directive \", \n+ if ( val ) \n+ { if ( strcmp (\" if \", val )) \n+ { Config . RetToken (); \n+ Eroute . Emsg (\" Config \", \" Warning ! Implied ' if ' on redirect is now deprecated .\"); \n+ } \n+ if (( rc = XrdOucUtils :: doIf (& Eroute , Config , \" redirect directive \", \ngetenv (\" XRDHOST \"), getenv (\" XRDNAME \"))) <= 0 ) \n- return ( rc < 0 ); \n- \n+ return ( rc < 0 ); \n+ } \nOptions |= ropt ; \nreturn 0 ; \n}", "mmm src / XrdXrootd / XrdXrootdResponse . cc \nppp src / XrdXrootd / XrdXrootdResponse . cc \nint XrdXrootdResponse :: Send ( XResponseType rcode , int info , const char * data ) \nkXR_int32 xbuf = static_cast < kXR_int32 >( htonl ( info )); \nint dlen ; \n \n- TRACES ( RSP , \" sending \" << dlen <<\" data bytes ; status =\" << rcode ); \n- \nRespIO [ 1 ]. iov_base = ( caddr_t )(& xbuf ); \nRespIO [ 1 ]. iov_len = sizeof ( xbuf ); \nRespIO [ 2 ]. iov_base = ( caddr_t ) data ; \nRespIO [ 2 ]. iov_len = dlen = strlen ( data ); \n \n+ TRACES ( RSP ,\" sending \" <<( sizeof ( xbuf )+ dlen ) <<\" data bytes ; status =\" << rcode ); \n+ \nif ( Bridge ) \n{ if ( Bridge -> Send ( rcode , & RespIO [ 1 ], 1 , dlen ) >= 0 ) return 0 ; \nreturn Link -> setEtext (\" send failure \");", "mmm src / XrdOuc / XrdOucPup . cc \nppp src / XrdOuc / XrdOucPup . cc \nint XrdOucPup :: Pack ( struct iovec * iovP , struct iovec * iovE , XrdOucPupArgs * pup , \nbreak ; \n \ncase PT_int : \n- n32 = htons (* Base . B32 ); \n+ n32 = htonl (* Base . B32 ); \n* wP = PT_int ; memcpy ( wP + 1 , & n32 , sizeof ( n32 )); \nvP -> iov_base = wP ; vP -> iov_len = Sz32 ; vP ++; \nwP += Sz32 ; TotLen += Sz32 ; dlen = sizeof ( n32 ); \nbreak ; \n \ncase PT_longlong : \n- n64 = htons (* Base . B64 ); \n+ h2nll (* Base . B64 , n64 ); \n* wP = PT_longlong ; memcpy ( wP + 1 , & n64 , sizeof ( n64 )); \nvP -> iov_base = wP ; vP -> iov_len = Sz64 ; vP ++; \nwP += Sz64 ; TotLen += Sz64 ; dlen = sizeof ( n64 );", "mmm viostor / virtio_stor_hw_helper . c \nppp viostor / virtio_stor_hw_helper . c \nRhelShutDown ( \n \nvirtio_device_reset (& adaptExt -> vdev ); \nvirtio_delete_queues (& adaptExt -> vdev ); \n+ virtio_device_shutdown (& adaptExt -> vdev ); \nadaptExt -> vq = NULL ; \n} \n", "mmm lib / ytnef . c \nppp lib / ytnef . c \nBYTE * DecompressRTF ( variableLength * p , int * size ) { \nALLOCCHECK_CHAR ( dst ); \nmemcpy ( dst , comp_Prebuf . data , comp_Prebuf . size ); \nout = comp_Prebuf . size ; \n- while ( out < ( comp_Prebuf . size + uncompressedSize )) { \n+ while (( out < ( comp_Prebuf . size + uncompressedSize )) && ( in < p -> size )) { \n// each flag byte flags 8 literals / references , 1 per bit \nflags = ( flagCount ++ % 8 == 0 ) ? src [ in ++] : flags >> 1 ; \nif (( flags & 1 ) == 1 ) { // each flag bit is 1 for reference , 0 for literal", "mmm ytnef / src / ytnef / vcal . c \nppp ytnef / src / ytnef / vcal . c \nvoid SaveVCalendar ( TNEFStruct TNEF , int isMtgReq ) { \nif ( isMtgReq ) { \nCreateUniqueFilename ( ifilename , MAX_FILENAME_SIZE , \" MtgReq \", \" ics \", filepath ); \n} else { \n- CreateUniqueFilename ( ifilename , MAX_FILENAME_SIZE , \" calendar \", \" vcf \", filepath ); \n+ CreateUniqueFilename ( ifilename , MAX_FILENAME_SIZE , \" calendar \", \" ics \", filepath ); \n} \n \nprintf (\"% s \\ n \", ifilename );", "mmm lib / ytnef . c \nppp lib / ytnef . c \nvoid MAPIPrint ( MAPIProps * p ) { \nprintf (\"] (% llu )\\ n \", ddword_tmp ); \nbreak ; \ncase PT_LONG : \n- printf (\" Value : % li \\ n \", *(( long *) mapidata -> data )); \n+ printf (\" Value : % i \\ n \", *(( int *) mapidata -> data )); \nbreak ; \ncase PT_I2 : \nprintf (\" Value : % hi \\ n \", *(( short int *) mapidata -> data ));", "mmm probe . c \nppp probe . c \nvoid hexdump ( msg_info msg_info , const char * mem , unsigned int len ) \n} \nstr [ c ++] = '\\ n '; \nstr [ c ++] = 0 ; \n- print_message ( msg_info , str ); \n+ print_message ( msg_info , \"% s \", str ); \nc = 0 ; \n} \n}", "mmm util . c \nppp util . c \ncheck_user_token ( const char * authfile , \n{ \nif ( verbose ) \nD ( debug_file , \" Match user / token as % s /% s \", username , otp_id ); \n+ \n+ fclose ( opwfile ); \nreturn AUTH_FOUND ; \n} \n}", "mmm src / libcoreint / opcodes - ecma - relational . c \nppp src / libcoreint / opcodes - ecma - relational . c \nopfunc_in ( opcode_t opdata __unused , /**< operation data */ \nconst idx_t left_var_idx = opdata . data . in . var_left ; \nconst idx_t right_var_idx = opdata . data . in . var_right ; \n \n+ int_data -> pos ++; \n+ \necma_completion_value_t ret_value ; \n \nECMA_TRY_CATCH ( left_value , get_variable_value ( int_data , left_var_idx , false ), ret_value );", "mmm src / mod_auth_openidc . c \nppp src / mod_auth_openidc . c \nstatic int oidc_request_post_preserved_restore ( request_rec * r , \n\" input . type = \\\" hidden \\\";\\ n \" \n\" document . forms [ 0 ]. appendChild ( input );\\ n \" \n\" }\\ n \" \n- \" document . forms [ 0 ]. action = '% s ';\\ n \" \n+ \" document . forms [ 0 ]. action = \\\"% s \\\";\\ n \" \n\" document . forms [ 0 ]. submit ();\\ n \" \n\" }\\ n \" \n\" </ script >\\ n \", method , original_url );", "mmm lib / Components / ExtensionClass / src / ExtensionClass . c \nppp lib / Components / ExtensionClass / src / ExtensionClass . c \nstatic char ExtensionClass_module_documentation [] = \n\" - They provide access to unbound methods ,\\ n \" \n\" - They can be called to create instances .\\ n \" \n\"\\ n \" \n-\"$ Id : ExtensionClass . c , v 1 . 56 2002 / 06 / 18 23 : 19 : 02 jeremy Exp $\\ n \" \n+\"$ Id : ExtensionClass . c , v 1 . 57 2002 / 08 / 22 16 : 55 : 53 shane Exp $\\ n \" \n; \n \n# include < stdio . h > \nPMethod_repr ( PMethod * self ) \nchar * func_name , buf [ 8192 ]; \nint n ; \n \n- func_name = PyString_AS_STRING ((( PyFunctionObject *) self -> meth )-> func_name ); \n+ if ( PyFunction_Check ( self -> meth )) { \n+ func_name = PyString_AS_STRING ( \n+ (( PyFunctionObject *) self -> meth )-> func_name ); \n+ } \n+ else { \n+ /* self -> meth is some other kind of object */ \n+ func_name = \"(?)\"; \n+ } \n+ \nif ( self -> self ) { \nPyObject * repr = PyObject_Repr ( self -> self ); \nif (! repr )"]